{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154ea003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Set\n",
    "from transformers import GPT2TokenizerFast\n",
    "import argparse, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from transformers import GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30f3061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use load_env to trace the path of .env:\n",
    "load_dotenv('/home/alabarga/BSC/code/askmybook/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8895a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff2a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "\n",
    "MODEL_NAME = \"curie\"\n",
    "\n",
    "DOC_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-doc-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a29161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c4c1787a244b0b895d901935fa4df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1732170799b2413398c3eaa3273f4b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c06ffb1bdaa401d9225d48b59c6f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c226313ce9f047208c7e92efbbb36752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8f1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def extract_pages(\n",
    "    page_text: str,\n",
    "    index: int,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extract the text from the page\n",
    "    \"\"\"\n",
    "    if len(page_text) == 0:\n",
    "        return []\n",
    "\n",
    "    content = \" \".join(page_text.split())\n",
    "    print(\"page text: \" + content)\n",
    "    outputs = [(\"Page \" + str(index), content, count_tokens(content)+4)]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aba2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, DOC_EMBEDDINGS_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a6bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/alabarga/BSC/code/askmybook/books/TheBookOfOhdsi.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcf3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a7925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edaedeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/464 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "  1%|█▍                                                                                                                                         | 5/464 [00:00<00:11, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: The Book of OHDSI ObservationalHealthDataSciencesandInformatics 2020­11­25\n",
      "page text: ii\n",
      "page text: Contents Preface ix GoalsofthisBook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix StructureoftheBook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix Contributors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x SoftwareVersions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x License. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi HowtheBookIsDeveloped . . . . . . . . . . . . . . . . . . . . . . . . . . xi I The OHDSI Community 1 1 The OHDSI Community 3 1.1 TheJourneyfromDatatoEvidence . . . . . . . . . . . . . . . . . . . 3 1.2 ObservationalMedicalOutcomesPartnership . . . . . . . . . . . . . . 5 1.3 OHDSIasanOpen­ScienceCollaborative . . . . . . . . . . . . . . . . 6 1.4 OHDSI’sProgress . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.5 CollaboratinginOHDSI . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2 Where to Begin 11 2.1 JointheJourney . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.2 WhereYouFitIn . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3 Open Science 21 3.1 OpenScience . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.2 Open­ScienceinAction: theStudy­a­Thon . . . . . . . . . . . . . . . 23 3.3 OpenStandards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.4 OpenSource . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.5 OpenData . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.6 OpenDiscourse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.7 OHDSIandtheFAIRGuidingPrinciples . . . . . . . . . . . . . . . . 25 iii\n",
      "page text: iv Contents II Uniform Data Representation 29 4 The Common Data Model 31 4.1 DesignPrinciples . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.2 DataModelConventions . . . . . . . . . . . . . . . . . . . . . . . . 34 4.3 CDMStandardizedTables . . . . . . . . . . . . . . . . . . . . . . . . 39 4.4 AdditionalInformation . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 5 Standardized Vocabularies 55 5.1 WhyVocabularies,andWhyStandardizing . . . . . . . . . . . . . . . 55 5.2 Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 5.3 Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5.4 Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5.5 InternalReferenceTables . . . . . . . . . . . . . . . . . . . . . . . . 70 5.6 SpecialSituations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 5.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 5.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 6 Extract Transform Load 75 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 6.2 Step1: DesigntheETL . . . . . . . . . . . . . . . . . . . . . . . . . 75 6.3 Step2: CreatetheCodeMappings . . . . . . . . . . . . . . . . . . . . 84 6.4 Step3: ImplementtheETL . . . . . . . . . . . . . . . . . . . . . . . 92 6.5 Step4: QualityControl . . . . . . . . . . . . . . . . . . . . . . . . . 93 6.6 ETLConventionsandTHEMIS . . . . . . . . . . . . . . . . . . . . . 94 6.7 CDMandETLMaintenance . . . . . . . . . . . . . . . . . . . . . . . 95 6.8 FinalThoughtsonETL . . . . . . . . . . . . . . . . . . . . . . . . . 96 6.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 6.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 III Data Analytics 99 7 Data Analytics Use Cases 101 7.1 Characterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 7.2 Population­LevelEstimation . . . . . . . . . . . . . . . . . . . . . . . 102 7.3 Patient­LevelPrediction . . . . . . . . . . . . . . . . . . . . . . . . . 103 7.4 ExampleUseCasesinHypertension . . . . . . . . . . . . . . . . . . . 104 7.5 LimitationsofObservationalResearch . . . . . . . . . . . . . . . . . 105 7.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 7.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 8 OHDSI Analytics Tools 107\n",
      "page text: Contents v 8.1 AnalysisImplementation . . . . . . . . . . . . . . . . . . . . . . . . 107 8.2 AnalysisStrategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 8.3 ATLAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 8.4 MethodsLibrary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 8.5 DeploymentStrategies . . . . . . . . . . . . . . . . . . . . . . . . . . 118 8.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 9 SQL and R 121 9.1 SqlRender . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 9.2 DatabaseConnector . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 9.3 QueryingtheCDM . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 9.4 UsingtheVocabularyWhenQuerying . . . . . . . . . . . . . . . . . . 136 9.5 QueryLibrary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 9.6 DesigningaSimpleStudy . . . . . . . . . . . . . . . . . . . . . . . . 138 9.7 ImplementingtheStudyUsingSQLandR . . . . . . . . . . . . . . . 139 9.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 9.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 10 Defining Cohorts 147 10.1 WhatIsaCohort? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 10.2 Rule­BasedCohortDefinitions . . . . . . . . . . . . . . . . . . . . . 149 10.3 ConceptSets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 10.4 ProbabilisticCohortDefinitions . . . . . . . . . . . . . . . . . . . . . 152 10.5 CohortDefinitionValidity . . . . . . . . . . . . . . . . . . . . . . . . 152 10.6 DefiningaCohortforHypertension . . . . . . . . . . . . . . . . . . . 153 10.7 ImplementingaCohortUsingATLAS . . . . . . . . . . . . . . . . . . 154 10.8 ImplementingtheCohortUsingSQL . . . . . . . . . . . . . . . . . . 164 10.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171 10.10Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172 11 Characterization 173 11.1 DatabaseLevelCharacterization . . . . . . . . . . . . . . . . . . . . . 174 11.2 CohortCharacterization . . . . . . . . . . . . . . . . . . . . . . . . . 174 11.3 TreatmentPathways . . . . . . . . . . . . . . . . . . . . . . . . . . . 174 11.4 Incidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175 11.5 CharacterizingHypertensivePersons . . . . . . . . . . . . . . . . . . 176 11.6 DatabaseCharacterizationinATLAS . . . . . . . . . . . . . . . . . . 177 11.7 CohortCharacterizationinATLAS . . . . . . . . . . . . . . . . . . . 180 11.8 CohortCharacterizationinR . . . . . . . . . . . . . . . . . . . . . . 187 11.9 CohortPathwaysinATLAS . . . . . . . . . . . . . . . . . . . . . . . 190 11.10IncidenceAnalysisinATLAS . . . . . . . . . . . . . . . . . . . . . . 194 11.11Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 11.12Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 12 Population­Level Estimation 201\n",
      "page text: vi Contents 12.1 TheCohortMethodDesign . . . . . . . . . . . . . . . . . . . . . . . 202 12.2 TheSelf­ControlledCohortDesign . . . . . . . . . . . . . . . . . . . 206 12.3 TheCase­ControlDesign . . . . . . . . . . . . . . . . . . . . . . . . 206 12.4 TheCase­CrossoverDesign . . . . . . . . . . . . . . . . . . . . . . . 207 12.5 TheSelf­ControlledCaseSeriesDesign . . . . . . . . . . . . . . . . . 208 12.6 DesigningaHypertensionStudy . . . . . . . . . . . . . . . . . . . . . 209 12.7 ImplementingtheStudyUsingATLAS . . . . . . . . . . . . . . . . . 211 12.8 ImplementingtheStudyUsingR . . . . . . . . . . . . . . . . . . . . 224 12.9 StudyOutputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232 12.10Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 12.11Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 13 Patient­Level Prediction 239 13.1 ThePredictionProblem . . . . . . . . . . . . . . . . . . . . . . . . . 240 13.2 DataExtraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 13.3 FittingtheModel . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243 13.4 EvaluatingPredictionModels . . . . . . . . . . . . . . . . . . . . . . 248 13.5 DesigningaPatient­LevelPredictionStudy . . . . . . . . . . . . . . . 252 13.6 ImplementingtheStudyinATLAS . . . . . . . . . . . . . . . . . . . 255 13.7 ImplementingtheStudyinR . . . . . . . . . . . . . . . . . . . . . . 266 13.8 ResultsDissemination . . . . . . . . . . . . . . . . . . . . . . . . . . 272 13.9 AdditionalPatient­LevelPredictionFeatures . . . . . . . . . . . . . . 280 13.10Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282 13.11Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282 IV Evidence Quality 285 14 Evidence Quality 287 14.1 AttributesofReliableEvidence . . . . . . . . . . . . . . . . . . . . . 287 14.2 UnderstandingEvidenceQuality . . . . . . . . . . . . . . . . . . . . . 289 14.3 CommunicatingEvidenceQuality . . . . . . . . . . . . . . . . . . . . 290 14.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290 15 Data Quality 291 15.1 SourcesofDataQualityProblems . . . . . . . . . . . . . . . . . . . . 292 15.2 DataQualityinGeneral . . . . . . . . . . . . . . . . . . . . . . . . . 292 15.3 Study­SpecificChecks . . . . . . . . . . . . . . . . . . . . . . . . . . 297 15.4 ACHILLESinPractice . . . . . . . . . . . . . . . . . . . . . . . . . 299 15.5 DataQualityDashboardinPractice . . . . . . . . . . . . . . . . . . . 301 15.6 Study­SpecificChecksinPractice . . . . . . . . . . . . . . . . . . . . 302 15.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305 15.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305 16 Clinical Validity 307\n",
      "page text: Contents vii 16.1 CharacteristicsofHealthCareDatabases . . . . . . . . . . . . . . . . 307 16.2 CohortValidation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308 16.3 SourceRecordVerification . . . . . . . . . . . . . . . . . . . . . . . 311 16.4 PheValuator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314 16.5 GeneralizabilityoftheEvidence . . . . . . . . . . . . . . . . . . . . . 324 16.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325 17 Software Validity 327 17.1 StudyCodeValidity . . . . . . . . . . . . . . . . . . . . . . . . . . . 327 17.2 MethodsLibrarySoftwareDevelopmentProcess . . . . . . . . . . . . 329 17.3 MethodsLibraryTesting . . . . . . . . . . . . . . . . . . . . . . . . . 332 17.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333 18 Method Validity 335 18.1 Design­SpecificDiagnostics . . . . . . . . . . . . . . . . . . . . . . . 335 18.2 DiagnosticsforAllEstimation . . . . . . . . . . . . . . . . . . . . . . 336 18.3 MethodValidationinPractice . . . . . . . . . . . . . . . . . . . . . . 343 18.4 OHDSIMethodsBenchmark . . . . . . . . . . . . . . . . . . . . . . 351 18.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352 V OHDSI Studies 355 19 Study steps 357 19.1 GeneralBestPracticeGuidelines . . . . . . . . . . . . . . . . . . . . 358 19.2 StudyStepsinDetail . . . . . . . . . . . . . . . . . . . . . . . . . . . 361 19.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367 20 OHDSI Network Research 369 20.1 OHDSIasaResearchNetwork . . . . . . . . . . . . . . . . . . . . . 369 20.2 OHDSINetworkStudies . . . . . . . . . . . . . . . . . . . . . . . . . 370 20.3 RunninganOHDSINetworkStudy . . . . . . . . . . . . . . . . . . . 374 20.4 ForwardLooking: UsingNetworkStudyAutomation . . . . . . . . . . 377 20.5 BestPracticeforOHDSINetworkStudies . . . . . . . . . . . . . . . . 378 20.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380 Appendix 380 A Glossary 381 B Cohort definitions 385 B.1 ACEInhibitors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385 B.2 NewUsersofACEInhibitorsMonotherapy . . . . . . . . . . . . . . . 386 B.3 AcuteMyocardialInfarction(AMI) . . . . . . . . . . . . . . . . . . . 389 B.4 Angioedema . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390 B.5 NewUsersofThiazide­LikeDiureticsMonotherapy . . . . . . . . . . 391\n",
      "page text: viii Contents B.6 PatientsInitiatingFirst­LineTherapyforHypertension . . . . . . . . . 394 B.7 Patients Initiating First­Line Therapy for Hypertension With >3 Yr Follow­Up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397 B.8 ACEInhibitorUse . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397 B.9 AngiotensinReceptorBlocker(ARB)Use . . . . . . . . . . . . . . . . 398 B.10 ThiazideOrThiazide­LikeDiureticUse . . . . . . . . . . . . . . . . . 399 B.11 DihydropyridineCalciumChannelBlocker(dCCB)Use . . . . . . . . 399 B.12 Non­DihydropyridineCalciumChannelBlocker(ndCCB)Use . . . . . 399 B.13 Beta­BlockerUse . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400 B.14 Diuretic­LoopUse . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400 B.15 Diuretic­PotassiumSparingUse . . . . . . . . . . . . . . . . . . . . . 401 B.16 Alpha­1BlockerUse . . . . . . . . . . . . . . . . . . . . . . . . . . . 401 C Negative controls 403 C.1 ACEiandTHZ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403 D Protocol template 407 E Suggested Answers 409 E.1 TheCommonDataModel . . . . . . . . . . . . . . . . . . . . . . . . 409 E.2 StandardizedVocabularies . . . . . . . . . . . . . . . . . . . . . . . . 413 E.3 ExtractTransformLoad . . . . . . . . . . . . . . . . . . . . . . . . . 413 E.4 DataAnalyticsUseCases . . . . . . . . . . . . . . . . . . . . . . . . 414 E.5 SQLandR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415 E.6 DefiningCohorts . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417 E.7 Characterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421 E.8 Population­LevelEstimation . . . . . . . . . . . . . . . . . . . . . . . 429 E.9 Patient­LevelPrediction . . . . . . . . . . . . . . . . . . . . . . . . . 434 E.10 DataQuality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436 Bibliography 439 Index 449\n",
      "page text: Preface This is a book about the Observational Health Data Sciences and Informatics (OHDSI) collaborative. The OHDSI community wrote the book to serve as a central knowledge repositoryforallthingsOHDSI.TheBookisalivingdocument,community­maintained through open­source development tools, and evolves continuously. The online version, availableforfreeat http://book.ohdsi.org ,alwaysrepresentsthelatestversion. Aphysical copyofthebookisavailablefrom Amazonatcostprice. Goals of this Book This book aims to be a central knowledge repository for OHDSI, and it focuses on de­ scribingtheOHDSIcommunity,OHDSIdatastandards,andOHDSItools. Itisintended for both OHDSI newcomers and veterans alike, and aims to be practical, providing the necessarytheoryandsubsequentinstructionsonhowtodothings. Afterreadingthisbook you will understand what OHDSI is, and how you can join the journey. You will learn whatthecommondatamodelandstandardvocabulariesare,andhowtheycanbeusedto standardizeanobservationalhealthcaredatabase. Youwilllearnthethreemainusecases forthesedata: characterization,population­levelestimation,andpatient­levelprediction. YouwillreadaboutOHDSI’sopen­sourcetoolsthatsupportallthreeactivitiesandhowto usethosetools. Chaptersondataquality,clinicalvalidity,softwarevalidity,andmethod validity will explain how to establish the quality of the generated evidence. Lastly, you will learn how to use the OHDSI tools to execute these studies in a distributed research network. Structure of the Book Thisbookisorganizedinfivemajorsections: I)TheOHDSICommunity II)Uniformdatarepresentation III)DataAnalytics IV)EvidenceQuality V)OHDSIStudies ix\n",
      "page text: x Contents Eachsectionhasmultiplechapters,and,asappropriate,eachchapterfollowsthesequence: Introduction,Theory,Practice,Summary,andExercises. Contributors Eachchapterlistsoneormorechapterleads. Thesearethepeoplewholeadthewriting ofthechapter. However,therearemanyothersthathavecontributedtothebook,whom wewouldliketoacknowledgehere: HamedAbedtash MustafaAscha MarkBeno ClairBlacketer DavidBlatt BrianChristian GinoCloft FrankDeFalco SaraDempster JonDuke SergioEslava ClarkEvans ThomasFalconer GeorgeHripcsak VojtechHuser MarkKhayter GregKlebanov KristinKostka BobLanese WandaLattimore ChunLi DavidMadigan SindhooshaMalay HarryMenegay AkihikoNishimura EllenPalmer NiravPatil JosePosada NicolePratt DaniPrieto­Alhambra ChristianReich JennaReps PeterRijnbeek PatrickRyan CraigSachson IzzySaridakis PaolaSaroufim MartijnSchuemie SarahSeager AnthonySena SunahSong MattSpotnitz MarcSuchard JoelSwerdel DevinTian DonTorok KeesvanBochove MuiVanZandt EricaVoss KristinWaite MikeWarfe JamieWeaver JamesWiggins AndrewWilliams SengChanYou Software Versions Alargepartofthisbookisabouttheopen­sourcesoftwareofOHDSI,andthissoftware will evolve over time. Although the developers do their best to offer a consistent and stableexperiencetotheusers,itisinevitablethatovertimeimprovementstothesoftware will render some of the instructions in this book outdated. The community will update theonlineversionofthebooktoreflectthosechanges,andneweditionsofthehardcopy willbereleasedovertime. Forreference, thesearetheversionnumbersofthesoftware usedinthisversionofthebook: •ACHILLES:version1.6.6 •ATLAS:version2.7.3 •EUNOMIA:version1.0.0 •MethodsLibrarypackages: seeTable 1\n",
      "page text: Contents xi Table1:VersionsofpackagesintheMethodsLibraryusedinthisbook. Package Version CaseControl 1.6.0 CaseCrossover 1.1.0 CohortMethod 3.1.0 Cyclops 2.0.2 DatabaseConnector 2.4.1 EmpiricalCalibration 2.0.0 EvidenceSynthesis 0.0.4 FeatureExtraction 2.2.4 MethodEvaluation 1.1.0 ParallelLogger 1.1.0 PatientLevelPrediction 3.0.6 SelfControlledCaseSeries 1.4.0 SelfControlledCohort 1.5.0 SqlRender 1.6.2 License Thisbookislicensedunderthe CreativeCommonsZerov1.0Universallicense . How the Book Is Developed The book is written in RMarkdown using the bookdown package. The online ver­ sion is automatically rebuilt from the source repository at https://github.com/OHDSI/ TheBookOfOhdsi through the continuous integration system “travis”. At regular intervalsasnapshotistakenofthestateofthebookandmarkedasan“edition.” These editionswillbeavailableasphysicalcopiesfromAmazon.\n",
      "page text: xii Contents\n",
      "page text: Part I The OHDSI Community 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████                                                                                                                                  | 27/464 [00:00<00:04, 87.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: Chapter 1 The OHDSI Community Chapter leads: Patrick Ryan & George Hripcsak Coming together is a beginning; staying together is progress; working to­ getherissuccess. Henry Ford 1.1 The Journey from Data to Evidence Everywhereinhealthcare,allacrosstheworld,withinacademicmedicalcentersandpri­ vatepractices,regulatoryagenciesandmedicalproductmanufacturers,insurancecompa­ nies and policy centers, and at the heart of every patient­provider interaction, there is a common challenge: how do we apply what we’ve learned from the past to make better decisionsforthefuture? Formorethanadecade,manyhavearguedforthevisionofa learning healthcare sys­ tem, “designed to generate and apply the best evidence for the collaborative healthcare choices of each patient and provider; to drive the process of discovery as a natural out­ growthofpatientcare;andtoensureinnovation,quality,safety,andvalueinhealthcare”. (Olsenetal. ,2007)Achiefcomponentofthisambitionrestsontheexcitingprospectthat patient­level data captured during the routine course of clinical care could be analyzed toproduce real­world evidence , whichinturncouldbedisseminatedacrossthehealth­ caresystemtoinformclinicalpractice. In2007,theInstituteofMedicineRoundtableon Evidence­BasedMedicineissuedareportwhichestablishedagoalthat“Bytheyear2020, 90percentofclinicaldecisionswillbesupportedbyaccurate,timely,andup­to­dateclin­ icalinformation,andwillreflectthebestavailableevidence.” ( Olsenetal. ,2007)While tremendous progress has been made on many different fronts, we still fall well short of theselaudableaspirations. Why? Inpart,becausethejourneyfrompatient­leveldatatoreliableevidenceisanardu­ ous one. There is no single defined path from data to evidence, and no single map that canhelptonavigatealongtheway. Infact,thereisnosinglenotionof“data,”noristhere asingularnotionof“evidence.” 3\n",
      "page text: 4 Chapter 1. The OHDSI Community Figure1.1: Thejourneyfromdatatoevidence Therearedifferenttypesofobservationaldatabaseswhichcapturedisparatepatient­level data in source systems. These databases are as diverse as the healthcare system itself, reflectingdifferentpopulations,caresettings,anddatacaptureprocesses. Therearealso different types of evidence that could be useful to inform decision­making, which can beclassifiedbytheanalyticusecasesofclinicalcharacterization,population­leveleffect estimation, and patient­level prediction. Independent from the origin (source data) and desireddestination(evidence),thechallengeisfurthercomplicatedbythebreadthofclin­ ical,scientific,andtechnicalcompetenciesthatarerequiredtoundertakethejourney. It requiresathoroughunderstandingofhealthinformatics,includingitsfullprovenanceof thesourcedatafromthepoint­of­careinteractionbetweenapatientandproviderthrough theadministrativeandclinicalsystemsandintofinalrepository,withanappreciationof the biases that can arise as part of the health policies and behavioral incentives associ­ ated with the data capture and curation processes. It requires mastery of epidemiologic principles and statistical methods to translate a clinical question into an observational studydesignproperlysuitedtoproducearelevantanswer. Itrequiresthetechnicalability to implement and execute computationally­efficient data science algorithms to datasets containingmillionsofpatientswithbillionsofclinicalobservationsoveryearsoflongi­ tudinalfollow­up. Itrequirestheclinicalknowledgetosynthesizewhathasbeenlearned acrossanobservationaldatanetworkwithevidencefromotherinformationsources,and todeterminehowthisnewknowledgeshouldimpacthealthpolicyandclinicalpractice. Accordingly,itisquiterarethatanyoneindividualwouldpossesstherequisiteskillsand resourcestosuccessfullytrekfromdatatoevidencealone. Instead,thejourneyoftenre­\n",
      "page text: 1.2. Observational Medical Outcomes Partnership 5 quirescollaborationacrossmultipleindividualsandorganizationstoensurethatthebest availabledataareanalyzedusingthemostappropriatemethodstoproducetheevidence thatallstakeholderscantrustanduseintheirdecision­makingprocesses. 1.2 Observational Medical Outcomes Partnership AnotableexampleofcollaborationinobservationalresearchwastheObservationalMed­ icalOutcomesPartnership(OMOP).OMOPwasapublic­privatepartnership,chairedby theUSFoodandDrugAdministration,administeredbytheFoundationfortheNational InstitutesofHealth,andfundedbyaconsortiumofpharmaceuticalcompaniesthatcollab­ oratedwithacademicresearchersandhealthdatapartnerstoestablisharesearchprogram that sought to advance the science of active medical product safety surveillance using observationalhealthcaredata. ( Stangetal. ,2010)OMOPestablishedamulti­stakeholder governancestructureanddesignedaseriesofmethodologicalexperimentstoempirically test the performance of alternative epidemiologic designs and statistical methods when applied to an array of administrative claims and electronic health records databases for the task of identifying true drug safety associations and discriminating them from false positivefindings. Recognizing the technical challenges of conducting research across disparate observa­ tionaldatabasesinbothacentralizedenvironmentandadistributedresearchnetwork,the teamdesignedtheOMOPCommonDataModel(CDM)asamechanismto standardize thestructure,contentandsemanticsofobservationaldataandtomakeitpossibletowrite statistical analysis code once that could be re­used at every data site. ( Overhage et al. , 2012)TheOMOPexperimentsdemonstrateditwasfeasibletoestablishacommondata model and standardized vocabularies that could accommodate different data types from differentcaresettingsandrepresentedbydifferentsourcevocabulariesinamannerthat couldfacilitatecross­institutionalcollaborationandcomputationally­efficientanalytics. From its inception, OMOP adopted an open­science approach, placing all of its work products,includingstudydesigns,datastandards,analysiscode,andempiricalresults,in thepublicdomaintopromotetransparency,buildconfidenceintheresearchthatOMOP was conducting, but also to provide a community resource that could be repurposed to advanceothers’researchobjectives. WhileOMOP’soriginalfocuswasdrugsafety,the OMOPCDMcontinuallyevolvedtosupportanexpandedsetofanalyticalusecases,in­ cludingcomparativeeffectivenessofmedicalinterventionsandhealthsystempolicies. And while OMOP was successful in completing its large­scale empirical experiments, (Ryan et al. ,2012,2013b) developing methodological innovations, ( Schuemie et al. , 2014) and generating useful knowledge that has informed the appropriate use of observational data for safety decision­making, ( Madigan et al. ,2013b,a) the legacy of OMOP may be more remembered for its early adoption of open­science principles and itsstimulusthatmotivatedtheformationoftheOHDSIcommunity. WhentheOMOPprojecthadcompleted,havingfulfilleditsmandatetoperformmethod­ ologicalresearchtoinformtheFDA’sactivesurveillanceactivities,theteamrecognized\n",
      "page text: 6 Chapter 1. The OHDSI Community the end of the OMOP journey needed to become the start of a new journey together. In spiteofOMOP’smethodologicalresearchprovidingtangibleinsightsintoscientificbest practicesthatcoulddemonstrablyimprovethequalityofevidencegeneratedfromobser­ vationaldata,adoptionofthosebestpracticeswasslow. Severalbarrierswereidentified, including: 1) fundamental concerns about observational data quality that were felt to behigher priority to address before analytics innovations; 2)insufficientconceptual un­ derstandingofthemethodologicalproblemsandsolutions; 3)inabilitytoindependently implementsolutionswithintheirlocalenvironment;4)uncertaintyoverwhethertheseap­ proacheswereapplicabletotheirclinicalproblemsofinterest. Theonecommonthread toeverybarrierwasthesensethatonepersonalonedidn’thaveeverythingtheyneeded to enact change by themselves, but with some collaborative support all issues could be overcome. Butseveralareasofcollaborationwereneeded: •Collaborationonestablishingopen­communitydatastandards,standardizedvocab­ ulariesandETL(Extract­Transform­Load)conventionsthatwouldincreaseconfi­ denceintheunderlyingdataqualityandpromoteconsistencyinstructure,content, andsemanticstoenablestandardizedanalytics. •Collaborationonmethodologicalresearchbeyonddrugsafetytoestablishbestprac­ ticesmorebroadlyforclinicalcharacterization,population­leveleffectestimation, andpatient­levelprediction. Collaborationonopen­sourceanalyticsdevelopment, tocodifythescientificbestpracticesproventhroughmethodologicalresearchand make accessible as publicly available tools that can be easily adopted by the re­ searchcommunity. •Collaboration on clinical applications that address important health questions of shared interest across the community by collectively navigating the journey from datatoevidence. Fromthisinsight,OHDSIwasborn. 1.3 OHDSI as an Open-Science Collaborative ObservationalHealthDataSciencesandInformatics(OHDSI,pronounced“Odyssey”)is anopen­sciencecommunitythataimstoimprovehealthbyempoweringthecommunityto collaborativelygeneratetheevidencethatpromotesbetterhealthdecisionsandbettercare. (Hripcsak et al. ,2015) OHDSI conducts methodological research to establish scientific bestpracticesfortheappropriateuseofobservationalhealthdata,developsopen­source analytics software that codify these practices into consistent, transparent, reproducible solutions,andappliesthesetoolsandpracticestoclinicalquestionstogenerateevidence thatcanguidehealthcarepolicyandpatientcare. 1.3.1 Our Mission Toimprovehealthbyempoweringacommunitytocollaborativelygenerate theevidencethatpromotesbetterhealthdecisionsandbettercare.\n",
      "page text: 1.4. OHDSI’ s Progress 7 1.3.2 Our Vision A world in which observational research produces a comprehensive under­ standingofhealthanddisease. 1.3.3 Our Objectives •Innovation : Observationalresearchisafieldwhichwillbenefitgreatlyfromdis­ ruptivethinking. Weactivelyseekandencouragefreshmethodologicalapproaches inourwork. •Reproducibility : Accurate, reproducible, and well­calibrated evidence is neces­ saryforhealthimprovement. •Community : EveryoneiswelcometoactivelyparticipateinOHDSI,whetheryou areapatient,ahealthprofessional,aresearcher,orsomeonewhosimplybelieves inourcause. •Collaboration : Weworkcollectivelytoprioritizeandaddressthereal­worldneeds ofourcommunity’sparticipants. •Openness: We strive to make all our community’s proceeds open and publicly accessible,includingthemethods,toolsandtheevidencethatwegenerate. •Beneficence : Weseektoprotecttherightsofindividualsandorganizationswithin ourcommunityatalltimes. 1.4 OHDSI’s Progress OHDSI has grown since its inception in 2014 to include over 2,500 collaborators on its online forums from different stakeholders, including academia, medical product in­ dustry,regulators,government,payers,technologyproviders,healthsystems,clinicians, patients, and representing different disciplines, including computer science, epidemiol­ ogy, statistics, biomedical informatics, health policy, and clinical sciences. A listing of self­identified OHDSI collaborators is available on the OHDSI website.1The OHDSI collaborator map (Figure 1.2) highlights the breadth and diversity of the international community. As of August, 2019, OHDSI has also established a data network of over 100 different healthcare databases from over 20 countries, collectively capturing over one billion pa­ tientrecordsbyapplyingadistributednetworkapproachusinganopen­communitydata standard it maintains, the OMOP CDM. A distributed network means that patient­level dataarenotrequiredtobesharedbetweenindividualsororganizations. Instead,research questionsareaskedbyindividualswithinthecommunityintheformofastudyprotocol and accompanied by analysis code that generates evidence as a set of aggregated sum­ mary statistics, and only these summary statistics are shared amongst the partners who 1https://www.ohdsi.org/who­we­are/collaborators/\n",
      "page text: 8 Chapter 1. The OHDSI Community Figure1.2: MapofOHDSIcollaboratorsasofAugust,2019 opt to collaborate in the study. With the OHDSI distributed network, each data partner retainsfullautonomyovertheuseoftheirpatient­leveldata,andcontinuestoobservethe datagovernancepolicieswithintheirrespectiveinstitutions. The OHDSI developer community has created a robust library of open­source analytics toolsatoptheOMOPCDMtosupport3usecases: 1)clinicalcharacterizationfordisease natural history, treatment utilization, and quality improvement; 2) population­level ef­ fectestimationtoapplycausalinferencemethodsformedicalproductsafetysurveillance and comparative effectiveness; and 3) patient­level prediction to apply machine learn­ ingalgorithmsforprecisionmedicineanddiseaseinterception. OHDSIdevelopershave alsodevelopedapplicationstosupportadoptionoftheOMOPCDM,dataqualityassess­ ment,andfacilitationofOHDSInetworkstudies. Thesetoolsincludeback­endstatistical packagesbuiltinRandPython,andfront­endwebapplicationsdevelopedinHTMLand Javascript. AllOHDSItoolsareopensourceandpubliclyavailableviaGithub.2 OHDSI’sopensciencecommunityapproach,coupledwithitsopen­sourcetools,hasen­ abled tremendous advances in observational research. One of the first OHDSI network analyses examined treatment pathways across three chronic diseases: diabetes, depres­ sion, and hypertension. Published in the Proceedings of the National Academy of Sci­ ence, it was one of the largest observational studies ever conducted, with results from 11 data sources covering more than 250 million patients and revealed tremendous geo­ graphic differences and patient heterogeneity in treatment choices that had never been previously observable. ( Hripcsak et al. ,2016) OHDSI has developed new statistical methods for confounding adjustment ( Tian et al.,2018) and evaluating the validity of 2https://github.com/OHDSI\n",
      "page text: 1.5. Collaborating in OHDSI 9 observational evidence for causal inference, ( Schuemie et al. ,2018a) and it has applied theseapproachesinmultiplecontexts,fromanindividualsafetysurveillancequestionin epilepsy(Dukeetal. ,2017)tocomparativeeffectivenessofsecond­linediabetesmedica­ tions (Vashisht et al. ,2018) to a large­scale population­level effect estimation study for comparativesafetyofdepressiontreatments. ( Schuemieetal. ,2018b)TheOHDSIcom­ munityhasalsoestablishedaframeworkforhowtoresponsiblyapplymachinelearning algorithms to observational healthcare data, ( Reps et al. ,2018) which has been applied acrossvarioustherapeuticareas. ( Johnstonetal. ,2019;Cepedaetal. ,2018;Repsetal. , 2019) 1.5 Collaborating in OHDSI SinceOHDSIisacommunityaimedtoempowercollaborationtogenerateevidence,what doesitmeantobeanOHDSIcollaborator? IfyouaresomeonewhobelievesinOHDSI’s missionandisinterestedinmakingacontributionanywherealongthejourneyfromdata to evidence, then OHDSI can be the community for you. Collaborators can be individ­ uals who have access to patient­level data who are interested in seeing that data put to usetogenerateevidence. Collaboratorscanbemethodologistsinterestedinestablishing scientificbestpracticesandevaluatingalternativeapproaches. Collaboratorscanbesoft­ ware developers who are interested in applying their programming skills to create tools thatcanbeusedbytherestofthecommunity. Collaboratorscanbeclinicalresearchers who have important public health questions and are seeking to provide the evidence to thosequestionstothebroaderhealthcarecommunitythroughpublicationandotherforms of dissemination. Collaborators can be individuals or organizations who believe in this commoncauseforpublichealthandwishtoprovideresourcestoensurethatthecommu­ nity can sustain itself and continue its mission, including hosting community activities andtrainingsessionsaroundtheworld. Nomatteryourdisciplinarybackgroundorstake­ holder affiliation, OHDSI seeks to be a place where individuals can work together to­ wardsacommonpurpose,eachmakingtheirindividualcontributionswhichcollectively canadvancehealthcare. Ifyouareinterestedinjoiningthejourney,checkoutChapter 2 (“WhereToBegin”)forhowtogetstarted. 1.6 Summary –OHDSI’s mission is to improve health by empowering a community to col­ laboratively generate the evidence that promotes better health decisions and bettercare. –Ourvisionisaworldinwhichobservationalresearchproducesacomprehen­ siveunderstandingofhealthanddisease,whichwillbeachievedthroughour objectives of innovation, reproducibility, community, collaboration, open­ ness,andbeneficence.\n",
      "page text: 10 Chapter 1. The OHDSI Community –OHDSI collaborators are focused on open­community data standards, methodological research, open­source analytics development, and clinical applicationstoimprovethejourneyfromdatatoevidence.\n",
      "page text: Chapter 2 Where to Begin Chapter leads: Hamed Abedtash & Kristin Kostka “Ajourneyofathousandmilesbeginswithasinglestep.” ­LaoTzu The OHDSI community represents a mosaic of stakeholders across academia, industry andgovernment­entities. Ourworkbenefitsarangeofindividualsandorganizations,in­ cludingpatients,providers,andresearchers,aswellashealthcaresystems,industry,and government agencies. This benefit is achieved by improving both the quality of health­ caredataanalyticsaswellastheusefulnessofhealthcaredatatothesestakeholders. We believeobservationalresearchisafieldwhichbenefitsgreatlyfromdisruptivethinking. Weactivelyseekandencouragefreshmethodologicalapproachesinourwork. 2.1 Join the Journey EveryoneiswelcometoactivelyparticipateinOHDSI,whetheryouareapatient,ahealth professional, aresearcher, orsomeonewhosimplybelievesinourcause. OHDSImain­ tains an inclusive membership model. To become an OHDSI collaborator requires no membershipfee. Collaborationisassimpleasraisingahandtobeincludedintheyearly OHDSImembershipcount. Involvementisentirelyat­will. Acollaboratorcanhaveany level of contribution within the community, ranging from someone who attends weekly community calls to leading network studies or OHDSI working groups. Collaborators donothavetobedataholderstobeconsideredactivemembersofthecommunity. The OHDSI community aims to serve data holders, researchers, health care providers and patients&consumersalike. Arecordofcollaboratorprofilesaremaintainedandperiod­ ically updated on the OHDSI website. Membership is fostered via OHDSI community calls,workgroupsandregionalchapters. 11\n",
      "page text: 12 Chapter 2. Where to Begin Figure2.1: Jointhejourney­HowtobecomeanOHDSIcollaborator.\n",
      "page text: 2.1. Join the Journey 13 2.1.1 OHDSI Forums TheOHDSIForums1isanonlinediscussionsitewhereOHDSICommunityCollaborators can hold conversations in the form of posted messages. The forums consist of a tree­ like directory structure. The top end is “Categories”. The forums can be divided into categories for the relevant discussions. Under the categories are sub­forums and these sub­forums can further have more sub­forums. The topics (commonly called threads) comeunderthelowestlevelofsub­forumsandthesearetheplacesunderwhichforums memberscanstarttheirdiscussionsorposts. IntheOHDSIforums,youcanfindcategoriesofcontentincluding: •General:for general discussion about the OHDSI community and how to get in­ volved •Implementers: fordiscussionabouthowtoimplementtheCommonDataModel andOHDSIanalyticsframeworkinyourlocalenvironment •Developers: fordiscussionaroundopen­sourceddevelopmentofOHDSIapplica­ tionsandothertoolsthatleveragetheOMOPCDM •Researchers: fordiscussionaroundCDM­basedresearch,includingevidencegen­ eration,collaborativeresearch,statisticalmethodsandothertopicsofinteresttothe OHDSIResearchNetwork •CDM Builders: fordiscussionofongoingCDMdevelopment,includingrequire­ ments,vocabulary,andtechnicalaspects •Vocabulary Users: fordiscussionaroundvocabularycontent •Regional Chapters (e.g. Korea, China, Europe): forregionaldiscussionsintheir nativelanguagesrelatedtolocalOMOPimplementationsandOHDSIcommunity activities Tobeginpostingyourowntopics,youwillneedtosignupforanaccount. Onceyouhave aforumsaccount,youareencouragedtointroduceyourselfontheGeneralTopicunderthe threadcalled“WelcometoOHDSI!­Pleaseintroduceyourself”. Youareinvitedtoreply and1)Introduceyourselfandtellusabitaboutwhatyoudoand2)Letusknowhowyou’d liketohelpoutinthecommunity(ex. softwaredevelopment,runstudies,writeresearch papers, etc). Now you are on your OHDSI Journey! From here, you are encouraged to joininthediscussion. TheOHDSICommunityencouragesusingtheForumsasyourway toaskquestions,discussnewideasandcollaborate. Youcanselecttopicsto“watch.” Whatthismeansiswheneveranewpostisadded inatopicyou’rewatching,youwillreceiveanemailandbeabletoreplytothepost directlythroughyouremail. Watchthegeneralthreadtorecievedetailsaboutup­ comingmeetingagendas,collaborationopportunitiesandhavetheweeklyOHDSI digestdelivereddirectlytoyourinbox! 1https://forums.ohdsi.org\n",
      "page text: 14 Chapter 2. Where to Begin 2.1.2 OHDSI Events OHDSIregularlyholdsin­personeventstoprovideopportunitiesforcollaboratorstolearn fromeachotherandconnecttofosterfuturecollaborations. Theseeventsarecommuni­ catedontheOHDSIwebsite,andarefreeforanyoneinterestedinattending. OHDSI Symposia are scientific conferences, held annually in US, Europe, and Asia, where collaborators can present their latest research through plenary talks, poster pre­ sentations, and software demonstrations. OHDSI Symposia provide a great venue for networking and to learn about the most recent progress across the community. OHDSI SymposiaaregenerallyaccompaniedbyOHDSItutorials, taughtbyfellowOHDSIcol­ laboratorsasthecoursefaculty,whichprovidecommunitynewcomerstheopportunityfor hands­onengagementontopicsarounddatastandardsandanalysisbestpractices. These tutorialsaregenerallyvideo­recordedandmadeavailableontheOHDSIwebsiteafterthe eventsforthosewhocan’tmakeitinperson. OHDSICollaboratorface­to­faceeventsaresmallerforawhicharetypicallycenteredon a problem of shared interest to focus on during the time together. Past events have in­ cludedaphenotypehack­a­thon,anddataqualityhack­a­thon,andopen­sourcesoftware documentation­a­thon. OHDSIhashostedmultipleStudy­a­thonevents,wherethegoal of the multi­day session is to collaborate as a team on a particular research question by designing and implementing an appropriate observational analysis, executing the study across the OHDSI network, and synthesizing the evidence for public dissemination. In alloftheseevents,thereisashareddesiretosolveacommonproblembutalsoashared interestinprovidingawelcomingenvironmentthatencourageslearningandcontinuous improvementontheprocessofcollaborativeproblem­solving. LearnmoreaboutthepoweroftheOHDSICommunity. Explorepastsymposiums,face­ to­facemeetingsandwatchOHDSItutorialsbyvisitingthe OHDSIPastEventssection ontheOHDSIwebsite. PastEventsisupdatedregularlytoarchivecommunityevents. 2.1.3 OHDSI Community Calls OHDSICommunityCallsareaweeklyopportunitytospotlightongoingactivitywithin the OHDSI community. Held every Tuesday from 12­1pm ET, these teleconferences are a time for the OHDSI community to come together to share recent developments andrecognizetheaccomplishmentsofindividualcollaborators,workinggroupsandthe communityasawhole. Eachweek’smeetingisrecorded,andpresentationsarearchived intheOHDSIwebsiteresources. AllOHDSICollaboratorsarewelcometoparticipateinthisweeklyteleconferenceanden­ couragedtoproposetopicsforcommunitydiscussion. OHDSICommunityCallscanbea forumtoshareresearchfindings,presentandseekfeedbackforactiveworks­in­progress, demonstrateopen­sourcesoftwaretoolsunderdevelopment,debatecommunitybestprac­ tices for data modeling and analytics, and brainstorm future collaborative opportunities forgrants/publications/conferenceworkshops. IfyouareaCollaboratorwithatopicfor anupcomingOHDSICollaboratormeeting,youareinvitedtopostyourthoughtsonthe\n",
      "page text: 2.1. Join the Journey 15 OHDSIForums. AsanewcomertotheOHDSIcommunity,itisencouragedtoaddthiscallseriestoyour calendar to get acquainted with what is happening across the OHDSI network. If you wouldliketojoinanOHDSIcall,pleaseconsultthe OHDSIwiki . Communitycalltopics varyfromweek­to­week. YoucanalsoconsulttheOHDSIWeeklyDigestontheOHDSI forum for more information on weekly presentation topics. Newcomers are invited to introduce themselves on their first call and tell the community about themselves, their backgroundandwhatbroughtthemtoOHDSI. 2.1.4 OHDSI Workgroups OHDSI has a variety of ongoing projects lead by workgroup teams. Each workgroup hasitsownleadershipteamwhichdeterminetheproject’sobjectives,goalsandartifacts to be contributed to the community. Workgroup participation is open to all who have aninterestincontributingtotheprojectobjectivesandgoals. Workgroupsmaybelong­ standing,strategicobjectivesorshort­termprojectstoaccomplishaspecificneedinthe community. Workgroupmeetingcadenceisdeterminedbytheprojectleadershipandwill varyfrom groupto group. Alist ofthe activeworkgroups ismaintained onthe OHDSI Wiki. Table2.1providesaquickreferencetoactiveOHDSIworkgroups. Youareencouraged tojoinacallandlearnmore. Table2.1: NotableOHDSIWorkgroups Workgroup Name Objective TargetAudience Atlas& WebAPIAtlasandWebAPIarepartoftheOHDSI open­sourcesoftwarearchitecturethataimto providestandardizedanalyticcapabilities builtonthefoundationoftheOMOP CommonDataModel.Java&JavaScript softwaredevelopers aimingtoimproveand contributetothe open­source Atlas/WebAPIplatform CDM& VocabularyTocontinuetodeveloptheOMOPCommon DataModelforthepurposeofsystematic, standardizedandlarge­scaleanalytics appliedtoclinicalpatientdata. Toimprove thequalityoftheStandardizedVocabularies byincreasingtheircoverageofinternational codingsystemsandclinicalaspectsof patientcareinordertosupportthe standardizedanalyticsdevelopedbyother workinggroups.Anywhohasan interestinimproving theOMOPCommon DataModeland Standardized Vocabulariestomeet allneedsandusecases\n",
      "page text: 16 Chapter 2. Where to Begin Workgroup Name Objective TargetAudience Genomics ExpandtheOMOPCDMtoincorporate genomicdatafrompatients. Thegroupwill defineaCDM­compatibleschemathatcan storeinformationforgeneticvariantsfrom varioussequencingprocess.Opentoall Population­ Level EstimationDevelopscientificmethodsforobservational researchleadingtopopulationlevel estimatesofeffectsthatareaccurate, reliable,andreproducible,andfacilitatethe useofthesemethodsbythecommunity.Opentoall Natural Language ProcessingTopromotetheuseoftextualinformation fromElectronicHealthRecords(EHRs)for observationalstudiesundertheOHDSI umbrella. Tofacilitatethisobjective,the groupwilldevelopmethodsandsoftware thatcanbeimplementedtoutilizeclinical textforstudiesbytheOHDSIcommunity.Opentoall Patient­ Level Predictionestablishastandardizedprocessfor developingaccurateandwell­calibrated patient­centeredpredictivemodelsthatcan beutilizedformultipleoutcomesofinterest andcanbeappliedtoobservational healthcaredatafromanypatient subpopulationofinterestOpentoall Gold Standard Phenotype LibraryToenablemembersoftheOHDSI communitytofind,evaluate,andutilize community­validatedcohortdefinitionsfor researchandotheractivitiesOpentoallwithan interestincurationand validationof phenotypes FHIR WorkgroupToestablishtheroadmapfortheOHDSI FHIRintegrationandtomake recommendationstothebroadercommunity forleveragingtheFHIRimplementationand datainEHRcommunityforthe OHDSI­basedobservationstudiesandfor disseminatingtheOHDSIdataandresearch resultsthroughtheFHIR­basedtoolsand APIs.Opentoallwithan interestin interoperability GIS ExpandtheOMOPCDMandleverage OHDSItoolssothatpatients’environmental exposurehistoriescanberelatedtotheir clinicalphenotypesOpentoallwithan interestin health­related geographicattributes\n",
      "page text: 2.1. Join the Journey 17 Workgroup Name Objective TargetAudience Clinical TrialsUnderstandclinicaltrialusecaseswherethe OHDSIplatform&ecosystemcanaidtrials inanyaspect,andassistindrivingupdatesin OHDSItoolstosupport.Opentoallwithan interestinclinicaltrials THEMIS TheobjectiveofTHEMISistodevelop standardconventions,aboveandbeyondthe OMOPCDMconventions,toensureETL protocolsdesignedateachOMOPsiteareof highestquality,reproducibleandefficient. Metadata & AnnotationsOurgoalistodefineastandardprocessfor storinghuman­andmachine­authored metadataandannotationsintheCommon DataModeltoensureresearcherscan consumeandcreateusefuldataartifacts aboutobservationaldatasets.Opentoall Patient Generated Health Data (PGHD)ThegoalofthisWGwouldbedeveloping ETLconventions,integrationprocesswith clinicaldata,andanalyticprocessforPGHD, whichisgeneratedthroughSmart Phone/App/Wearabledevices.Opentoall Womenof OHDSIToprovideaforumforwomenwithinthe OHDSIcommunitytocometogetherand discusschallengestheyfaceaswomen workinginscience,technology,engineering andmathematics(STEM).Weaimto facilitatediscusseswherewomencanshare theirperspectives,raiseconcerns,propose ideasonhowtheOHDSIcommunitycan supportwomeninSTEM,andultimately inspirewomentobecomeleaderswithinthe communityandtheirrespectivefields.Opentoallwho identifywiththis mission Steering CommitteeToupholdOHDSI’smissionvisionand valuesbyensuringallOHDSIactivitiesand eventsarealignedwiththeneedsofour growingcommunity. Inaddition,thegroup servesasanadvisorygroupfortheOHDSI coordinatingcenterbasedatColumbiaby providingguidanceforOHDSI’sfuture direction.Leaderswithinthe community\n",
      "page text: 18 Chapter 2. Where to Begin 2.1.5 OHDSI Regional Chapters AnOHDSIregionalchapterrepresentsagroupofOHDSIcollaboratorslocatedinageo­ graphicareawhowishtoholdlocalnetworkingeventsandmeetingstoaddressproblems specifictotheirgeographiclocation. Today,OHDSIregionalchaptersincludeOHDSIin Europe2,OHDSIinSouthKorea3andOHDSIinChina.4Ifyouwouldliketoset­upan OHDSIregionalchapterinyourregion,youmaydosobyfollowingtheOHDSIregional chapterprocessoutlinedonthe OHDSIwebsite . 2.1.6 OHDSI Research Network ManyOHDSIcollaboratorsareinterestedinconvertingtheirdataintotheOMOPCom­ monDataModel. TheOHDSIresearchnetworkrepresentsadiverse,globalcommunity ofobservationaldatabasesthathaveundergoneExtract­Transform­Load(ETL)processes to become OMOP compliant. If your journey in the OHDSI community includes trans­ formingdata,therearenumerouscommunityresourcesavailabletoaidyouinyourjour­ ney including tutorials on the OMOP CDM and Vocabularies, freely available tools to assist with conversion, and workgroups targeting specific domains or types of data con­ versions. TheOHDSIcollaboratorsareencouragedtoutilizetheOHDSIforumtodiscuss andtroubleshootchallengesthatariseduringCDMconversions. 2.2 Where Y ou Fit In Bynow,youmaybewondering: where do I fit into the OHDSI Community? I am a clinical researcher looking to start a study. If you are a clinical researcher interestinginusingtheOHDSIResearchNetworktoansweraspecificquestion–maybe even publish a paper – you’re in the right place. You can start by posting your idea to theOHDSI Researchers Topic on the OHDSI Forum. This will help you connect with researchersofsimilarinterest. OHDSIlovestopublishandhasmanyresourcesavailable toexpediteturningyourresearchquestionintoananalysisandapaper. Youcanfindmore informationinChapters 11,12,and13. I want to read and consume the information the OHDSI community produces. Whetheryou’reapatient,apracticingclinicianorsubjectmatterexpertiseinhealthcare, OHDSI wants to provide you with high quality evidence to help you better understand healthoutcomes. Maybeit’sbeenawhilesinceyouhavewrittencode. Maybeyounever program. Youhaveaplaceinthiscommunity. Wecallyouan evidence consumer –you aretheindividualswhoareturningOHDSIresearchintoaction. Youaresiftingthrough toknowwhatevidenceOHDSIhasgeneratedandisgenerating,possiblyalsowantingto suggestquestionsrelevantforyou. Wewelcomeyoutojointhediscussion. Startasking questions on the OHDSI Forum . Attend Community Calls and hear about the latest research. AttendtheOHDSISymposiumsandFace­to­FaceMeetingstoengagedirectly 2https://www.ohdsi­europe.org/ 3https://forums.ohdsi.org/c/For­collaborators­wishing­to­communicate­in­Korean 4https://ohdsichina.org/\n",
      "page text: 2.2. Where You Fit In 19 with the community. Your questions are an important part of the OHDSI community. Speakupandhelpuslearnmoreaboutwhatevidenceyouaresearchingfor! I work in a healthcare leadership role. I may be a data owner and/or represent one. I am evaluating the utility of the OMOP CDM and OHDSI analytical tools for my organization. Asanadministrator/leaderofanorganization,youmayhaveheardabout OHDSI and are curious to know the OMOP CDM could work for your use cases. You may start by looking through OHDSI Past Events materials to see the body of research. YoumayjoinaCommunityCallandsimplylistenin. YoumayalsofindthatChapter 7 (DataAnalyticsUseCases)helpsyouunderstandthekindofresearchtheOMOPCDM andOHDSIanalyticstoolscanenable. TheOHDSICommunityishereforyouinyour journey. Don’t be afraid to speak up and ask for examples if you have specific areas you’reinterestedin. Morethan200organizationsaroundtheworldarecollaboratingin OHDSI,there’splentyofsuccessstoriestohelpshowcasethevalueofthiscommunity. I am a database administrator looking to ETL/convert my institution’s data to the OMOP CDM. Choosingto“OMOP”yourdataisanovelandworthwhileundertaking. If you’rejuststartingoutonyourETLprocess,consultthe OHDSICommunityETLTuto­ rialSlides orsign­upforthenextofferingatanupcomingOHDSISymposium. Consider dialing into the THEMIS workgroup calls and engaging the OHDSI Forum with your questions. Youwillfindawealthofknowledgeinthecommunitywhoareinterestedin helpingyoursuccessfulimplementationoftheOMOPCDM.Don’tbeshy! I am a biostatistician and/or methods developer interested in contributing to the OHDSI tool stack. You’re savvy in R. You know how to commit to Git. Most of all, you’reeagertobringyourexpertisetotheOHDSIMethodsLibraryandfurtherdevelop thesemethodologies. You’llwanttostartbyjoiningeitherthePopulation­LevelEstima­ tion or Patient Level Prediction workgroup calls to hear more about current community priorities. Asyou’reusingtheOHDSItools,youcanalsofileIssuesundertherespective GitHubrepo(e.g.ifitisaSQLRenderpackageproblem,youwouldfileundertheGitHub RepoforOHDSI/SqlRender). Wewelcomeyourcontributions! I am a software developer interested in building a tool that complements the OHDSI tool stack. Welcometothecommunity! AspartoftheOHDSImission,ourtoolsareopen sourceandgovernedunderApachelicenses. Youarewelcometodevelopsolutionsthat complement the OHDSI tool stack. Feel free to join a workgroup and pitch your ideas. PleasebemindfulthatOHDSIisheavilyinvestedinopen­scienceandopencollaboration. Proprietaryalgorithmsandsoftwaresolutionsarewelcomebutarenotthemainfocusof oursoftwaredevelopmentefforts. I am a consultant looking to advise the OHDSI Community. Welcometothecommu­ nity! Yourexpertiseisvaluableandappreciated. Youarewelcometopromoteyourser­ vicesontheOHDSIForum,asappropriate. You’reinvitedtojoinusatOHDSITutorials andconsidergiving backbycontributing yourexpertisein theSymposiumproceedings andOHDSIface­to­facemeetingsthroughouttheyear. I am a student looking to learn more about OHDSI. You’reintherightplace! Consider\n",
      "page text: 20 Chapter 2. Where to Begin joining an OHDSI Community Call and introducing yourself. You are encouraged to delve into the OHDSI tutorials, attend OHDSI Symposiums and face­to­face meetings tolearnmoreaboutthe methodsandtoolsthe OHDSIcommunityoffers. Ifyouhave a specificresearchinterest, letusknowbypostingintheResearchertopicontheOHDSI Forum. Many organizations offer OHDSI sponsored research opportunities (e.g. post­ Doc, research fellowships). The OHDSI Forum will give you the latest information on theseopportunitiesandmore. 2.3 Summary –GettingstartedintheOHDSICommunityisaseasyassayinghello! Poston theOHDSI Forum andjoinaCommunityCall. –PostyourresearchorETLquestionstotheOHDSIForum.\n",
      "page text: Chapter 3 Open Science Chapter lead: Kees van Bochove FromtheinceptionoftheOHDSIcommunity,thegoalwastoestablishaninternational collaborativebybuildingonopen­sciencevalues,suchastheuseofopen­sourcesoftware, public availability of all conference proceedings and materials, and transparent, open­ access publication of generated medical evidence. But what exactly is open­science? AndhowcouldOHDSIbuildanopen­scienceoropen­datastrategyaroundmedicaldata, which is very privacy­sensitive and typically not open for good reasons? Why is it so importanttohavereproducibilityofanalysis,andhowdoestheOHDSIcommunityaim toachievethis? Thesearesomeofthequestionsthatwetouchoninthischapter. 3.1 Open Science Theterm‘openscience’hasbeenusedsincethenineties,butitreallygainedtractioninthe 2010s,duringthesameperiodOHDSIwasborn. Wikipedia( Wikipedia,2019a)definesit as“themovementtomakescientificresearch(includingpublications,data,physicalsam­ ples, and software) and its dissemination accessible to all levels of an inquiring society, amateur or professional,” and goes on to state that it is typically developed through col­ laborativenetworks. AlthoughtheOHDSIcommunityneverpositioneditselfexplicitly asan‘open­science’collectiveornetwork,thetermisfrequentlyusedtoexplainthedriv­ ing concepts and principles behind OHDSI. For example, in 2015, Jon Duke presented OHDSIas“AnOpenScienceApproachtoMedicalEvidenceGeneration,”1andin2019, the EHDEN consortium’s introductory webinar hailed the OHDSI network approach as “21stCenturyRealWorldOpenScience.”2Indeed,asweshallseeinthischapter,many ofthepracticesofopen­sciencecanbefoundintoday’sOHDSIcommunity. Onecouldar­ guethattheOHDSIcommunityisagrassrootsopen­sciencecollectivedrivenbyashared desireforimprovingthetransparencyandreliabilityofmedicalevidencegeneration. 1https://www.ohdsi.org/wp­content/uploads/2014/07/ARM­OHDSI_Duke.pdf 2https://www.ehden.eu/webinars/ 21\n",
      "page text: 22 Chapter 3. Open Science Open­science or “Science 2.0” ( Wikipedia,2019b) approaches mean to address a num­ berofperceivedproblemswithinthecurrentscientificpractice. Informationtechnology has led to an explosion of data generation and analysis methods, and for individual re­ searchers,itisveryhardtokeepupwithallliteraturepublishedintheirareaofexpertise. This holds even more true for medical doctors who have a practice to run as their day job, but still need to keep abreast of the latest medical evidence. In addition, there is growing concern that many experiments may suffer from poor statistical designs, publi­ cation bias, p­hacking and similar statistical problems, and are hard to reproduce. The traditionalmethodofcorrectingtheseconcerns, peerreviewofpublishedarticles, often fails to identify and tackle these problems. The special 2018 Nature edition on “Chal­ lengesinirreproducibleresearch”3includesseveralexamplesofthis. Agroupofauthors attemptingtoapplysystematicpeerreviewonthearticlesintheirfieldfoundthat,forvar­ iousreasons,itwasveryhardtogettheerrorstheyidentifiedrectified. Experimentsthat haveaflaweddesigntobeginwithareespeciallyhardtocorrect. InthewordsofRonald Fisher: “Toconsultthestatisticianafteranexperimentisfinishedisoftenmerelytoask him to conduct a post mortem examination. He can perhaps say what the experiment diedof.” (Wikiquote,2019)Theauthorsencounteredcommonstatisticalproblemssuch aspoorrandomizationdesignsleadingtofalseconclusionsaboutstatisticalsignificance, miscalculationsinmeta­analyses,andinappropriatebaselinecomparisons. ( Allisonetal. , 2016)Anotherpaperfromthesamecollection,takingexperiencesfromphysicsasanex­ ample,arguesthatitiscriticaltonotonlyprovideaccesstotheunderlyingdata,butalso topublishandproperlydocumentthedataprocessingandanalysisscriptstoachievefull reproducibility. ( Chenetal. ,2018) The OHDSI community addresses these challenges in its own way, and it puts signifi­ cant emphasis on the importance of generating medical evidence at scale. As stated in Schuemieetal. (2018b),whilethecurrentparadigm“centersongeneratingoneestimate atatimeusingauniquestudydesignwithunknownreliabilityandpublishing(ornot)one estimateatatime,”theOHDSIcommunity“advocatesforhigh­throughputobservational studies using consistent and standardized methods, allowing evaluation, calibration and unbiased dissemination to generate a more reliable and complete evidence base.” This is achieved by a combination of a network of medical data sources that map their data totheOMOPcommondatamodel,opensourceanalyticscodethatcanbeusedandver­ ifiedbyall,andlarge­scalebaselinedatasuchastheconditionoccurrencespublishedat howoften.org. Inthefollowingparagraphs,concreteexamplesareprovidedandtheopen­ scienceapproachofOHDSIisdetailedfurtherusingthefourprinciplesofOpenStandards, OpenSource,OpenDataandOpenDiscourseasaguide. Thechapterisconcludedwith a brief reference to the FAIR principles and outlook for OHDSI from an open­science perspective. 3https://www.nature.com/collections/prbfkwmwvz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████████▊                                                                                                                           | 50/464 [00:00<00:04, 98.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 3.2. Open­Science in Action: the Study­a­Thon 23 3.2 Open-Science in Action: the Study-a-Thon Arecentdevelopmentinthecommunityistheemergenceof‘study­a­thons’: short,con­ centrated face­to­face gatherings of a multidisciplinary group of scientists aimed at an­ sweringanimportant,clinicallyrelevantresearchquestionusingtheOMOPdatamodel andtheOHDSItools. Aniceexampleisthe2018Oxfordstudy­a­thon,whichisexplained inanEHDENwebinar4thatprovidesawalkthroughoftheprocessandalsohighlightsthe openlyavailableresults. Intheperiodleadinguptothestudy­a­thon,theparticipantspro­ posemedicallyrelevantresearchquestionstostudy,andoneormoreresearchquestions areselectedtostudyduringthestudy­a­thonitself. Dataisprovidedthroughparticipants that have access to patient­level data in OMOP format and are able to run queries on these data sources. Much of the actual study­a­thon time is devoted to discussing the statistical approach (see also chapter 2), the suitability of the data sources, the results which are interactively produced and the follow­up questions that are inevitably raised by these results. In the case of the Oxford study­a­thon, the questions centered around studyingadversepost­surgicaleffectsofdifferentkneereplacementmethods,andthere­ sultswerepublishedinteractivelyduringthestudy­a­thonusingtheOHDSIforumsand tools(seechapter 8). TheOHDSItoolssuchasATLASfacilitaterapidcreation,exchange, discussion and tests of cohort definitions, which greatly speeds up the initial process of achievingconsensusonproblemdefinitionandchoiceofmethods. Thankstotheusage oftheOMOPCommonDataModelbytheinvolveddatasourcesandtheavailabilityof theOHDSIopensourcepatientlevelpredictionpackages 13,itwaspossibletocreatea predictionmodelfor90­daypost­operativemortalityinoneday,andvalidatethemodel externallyinseverallargedatasourcesthedayafter. Thestudy­a­thonalsoresultedina traditionalscholarlypaper(Developmentandvalidationofpatient­levelpredictionmod­ elsforadverseoutcomesfollowingtotalkneearthroplasty,RossWilliams,DanielPrieto­ Alhambraetal.,manuscriptinpreparation),whichtookmonthstoprocessthroughpeer review. Butthefactthattheanalysisscriptsandresultsforseveralhealthcaredatabases coveringhundredsofmillionsofpatientrecordswereconceived,producedandpublished fromscratchwithinaweekillustratesthefundamentalimprovementsOHDSIcanbring tomedicalscience,reducingtheturnaroundtimeforevidencetobecomeavailablefrom monthstodays. 3.3 Open Standards AverysignificantcommunityresourcethatismaintainedintheOHDSIcommunityisthe OMOP Common Data Model (see chapter 4) and associated Standardized Vocabularies (seechapter 5). Themodelitselfisscopedtocaptureobservationalhealthcaredata,and itwasoriginallymeanttoanalyzeassociationsbetweenexposuressuchasdrugs, proce­ dures,devices,etc.,andoutcomessuchasconditionsandmeasurements. Ithasbeenex­ tendedforvariousanalysisusecases(seealso 7). However,harmonizinghealthcaredata worldwidefromawidevarietyofcodingsystems,healthcareparadigmanddifferenttypes ofhealthcaresourcesrequiresamassiveamountof‘mappings’betweensourcecodesand 4https://youtu.be/X5yuoJoL6xs\n",
      "page text: 24 Chapter 3. Open Science their closest standardized counterparts. The OMOP Standardized Vocabulary is further describedinchapter 7andincludesmappingsfromhundredsofmedicalcodingsystems that are used worldwide, and is browsable through the OHDSI Athena tool. By provid­ ing these vocabularies and mappings as a freely available community resource, OMOP and the OHDSI community make a significant contribution to healthcare data analytics andis,byseveralaccounts,themostcomprehensivemodelforthispurpose,representing approximately1.2billionhealthcarerecordsworldwide.5(Garzaetal. ,2016) 3.4 Open Source AnotherkeyresourcetheOHDSIcommunityprovidesareopensourceprograms. These canbedividedinseveralcategories,suchasthehelpertoolstomapdatatoOMOP(see chapter6),theOHDSIMethodsLibrarywhichcontainapowerfulsuiteofcommonlyused statistical methods, open source code for published observational studies, and ATLAS, Athenaandotherinfrastructure­relatedsoftwarewhichunderpinstheOHDSIecosystem (seechapter 8). Fromanopen­scienceperspective, oneofthemostimportantresources isthecodefortheactualexecutionofstudies,suchasstudiesfromtheOHDSIResearch Network(seechapter 20). Inturn,theseprogramsleveragethefullyopensourceOHDSI stack, which can be inspected, reviewed and contributed to via GitHub. For example, network studies often build on the Methods Library, which ensures a consistent re­use of statistical methods across analytical use cases. See chapter 17for a more detailed overview of how the use of and collaboration on open source software in OHDSI ulti­ matelyunderpinsthequalityandreliabilityofthegeneratedevidence. 3.5 Open Data Because of the privacy­sensitive nature of healthcare data, fully open, comprehensive patient­level datasets are typically not available. However, it is possible to leverage OMOP mapped datasets to publish important aggregated data and results sets, such as the earlier mentioned http://howoften.org and other public result sets that are published tohttp://data.ohdsi.org . Also, the OHDSI community provides simulated datasets such as SynPUF for testing and development purposes, and the OHDSI Research Network (see20) can be leveraged to run studies in a network of available datasources that have mappedtheirdatatoOMOP.Inordertomakethemappingbetweenthesourcedataand theOMOPCDMtransparent,itisencouragedfordatasourcestore­usetheOHDSIETL or‘mapping’toolsandpublishtheirmappingcodeasopensourceaswell. 3.6 Open Discourse Openstandards,opensourceandopendataaregreatassets,butleftbythemselves,they willnotimpactmedicalpractice. Keytotheopen­sciencepracticeandimpactofOHDSI is the implementation of medical evidence generation and the translation of the science 5https://www.ema.europa.eu/en/events/common­data­model­europe­why­which­how\n",
      "page text: 3.7. OHDSI and the F AIR Guiding Principles 25 tomedicalpractice. TheOHDSIcommunityhasseveralannualOHDSISymposia,held in the United States, Europe, and Asia as well as dedicated communities of practice in, amongstothers,ChinaandKorea. Thesesymposiadiscusstheadvancementsinstatistical methods,dataandsoftwaretooling,thestandardizedvocabularies,andallotheraspectsof theOHDSIopensourcecommunity. TheOHDSIforums6andwiki7facilitatethousands ofresearchersworldwideinpracticingobservationalresearch. Thecommunitycalls8and the code, issues and pull requests in Github9constantly evolve the open­community as­ setssuchascodeandtheCDM,andintheOHDSINetworkStudies,globalobservational researchispracticedinanopenandtransparentwayusinghundredsofmillionsofpatient recordsworldwide. Opennessandopendiscourseisencouragedthroughoutthecommu­ nity, and this very book is written via an open process facilitated by the OHDSI wiki, community calls and a GitHub repository.10It needs to be stressed however that with­ outalltheOHDSIcollaborators,theprocessesandtoolswouldbeemptyshells. Indeed, one could argue that the true value of the OHDSI community is with its members, who shareavisionofimprovinghealththroughcollaborativeandopen­science,asdiscussed inChapter 1. 3.7 OHDSI and the F AIR Guiding Principles 3.7.1 Introduction ThislastparagraphofthechaptertakesalookatthecurrentstateoftheOHDSIcommu­ nity and tooling, using the FAIR Data Guiding Principles published in Wilkinson et al. (2016). 3.7.2 Findability Any healthcare database that is mapped to OMOP and used for analytics should, from a scientific perspective, persist for future reference and reproducibility. The use of persistent identifiers for OMOP databases is not yet widespread, partly because these databasesareoftencontainedbehindfirewallsandoninternalnetworksandnotnecessar­ ilyconnectedtotheinternet. However,itisentirelypossibletopublishsummariesofthe databases as a descriptor record that can be referenced for e.g. citation purposes. This methodisfollowedinforexampletheEMIFcatalog11,whichprovidesacomprehensive record of the database in terms of data­gathering purpose, sources, vocabularies and terms, access control mechanisms, license, consents, etc. ( Oliveira et al. ,2019) This approachisfurtherdevelopedintheIMIEHDENproject. 6https://forums.ohdsi.org 7https://www.ohdsi.org/web/wiki 8https://www.ohdsi.org/web/wiki/doku.php?id=projects:overview 9https://github.com/ohdsi 10https://github.com/OHDSI/TheBookOfOhdsi 11https://emif­catalogue.eu\n",
      "page text: 26 Chapter 3. Open Science 3.7.3 Accessibility Accessibility of OMOP mapped data through an open protocol is typically achieved throughtheSQLinterface, whichcombinedwiththeOMOPCDMprovidesastandard­ ized and well­documented method for accessing OMOP data. However, as discussed above, OMOP sources are often not directly available over the internet for security reasons. Creating a secure worldwide healthcare data network that is accessible for researchersisanactiveresearchtopicandoperationalgoalofprojectslikeIMIEHDEN. However, results of analyses in multiple OMOP databases, as shown through OHDSI initiativessuchasLEGENDand http://howoften.org ,canbeopenlypublished. 3.7.4 Interoperability InteroperabilityisarguablythestrongsuitoftheOMOPdatamodelandOHDSItooling. Inordertobuildastrongnetworkofmedicaldatasourcesworldwidewhichcanbelever­ agedforevidencegeneration,achievinginteroperabilitybetweenhealthcaredatasources is key, and this is achieved through the OMOP model and Standardized Vocabularies. However, by sharing cohort definitions and statistical approaches, the OHDSI commu­ nity goes beyond code mapping and also provides a platform to build an interoperable understandingoftheanalysismethodsforhealthcaredata. Sincehealthcaresystemssuch as hospitals are often the source of record for OMOP data, the interoperability of the OHDSI approach could be further enhanced by alignment with operational healthcare interoperability standards such as HL7 FHIR, HL7 CIMI and openEHR. The same is true for alignment with clinical interoperability standards such as CDISC and biomedi­ cal ontologies. Especially in areas such as oncology, this is an important topic, and the OncologyWorkingGroupandClinicalTrialsWorkingGroupintheOHDSIcommunity providegoodexamplesofforumswheretheseissuesareactivelydiscussed. Intermsof referencestootherdataandspecificallyontologyterms,ATLASandOHDSIAthenaare importanttools,astheyallowtheexplorationoftheOMOPStandardizedVocabulariesin thecontextofotheravailablemedicalcodingsystems. 3.7.5 Reusability TheFAIRprinciplesaroundreusabilityfocusonimportantissuessuchasthedatalicense, provenance(clarifyinghowthedatacameinexistence)andthelinktorelevantcommu­ nitystandards. Datalicensingisacomplicatedtopic,especiallyacrossjurisdictions,and itwouldfalloutsideofthescopeofthisbooktocoveritextensively. However,itisim­ portant to state that if you intend for your data (e.g. analysis results) to be freely used by others, it is good practice to explicitly provide these permissions via a data license. Thisisnotyetacommonpracticeformostdatathatcanbefoundontheinternet,andthe OHDSI community is unfortunately not an exception here. Concerning the data prove­ nanceofOMOPdatabases,potentialimprovementsexistformakingmeta­dataavailable in an automated way, including, for example, CDM version, Standardized Vocabularies release, custom code lists, etc. The OHDSI ETL tools do not currently produce this in­ formation automatically, but working groups such as the Data Quality Working Group\n",
      "page text: 3.7. OHDSI and the F AIR Guiding Principles 27 and Metadata Working Group actively work on these. Another important aspect is the provenanceoftheunderlyingdatabasesitself;itisimportanttoknowifahospitalorGP information system was replaced or changed, and when known data omissions or other data issues occurred historically. Exploring ways to attach this metadata systematically intheOMOPCDMisthedomainoftheMetadataWorkingGroup. –The OHDSI community can be seen as an open­science community that is activelypursuingtheinteroperabilityandreproducibilityofmedicalevidence generation. –Italsoadvocatesaparadigmshiftfromsinglestudyandsingleestimatemed­ icalresearchtolarge­scalesystematicevidencegeneration,wherefactssuch asbaselineoccurrenceareknownandtheevidencefocusesonstatisticallyes­ timatingtheeffectsofinterventionsandtreatmentsfromrealworldhealthcare sources.\n",
      "page text: 28 Chapter 3. Open Science\n",
      "page text: Part II Uniform Data Representation 29\n",
      "page text: Chapter 4 The Common Data Model Chapter lead: Clair Blacketer Observationaldataprovidesaview ofwhathappenstoa patientwhilereceivinghealth­ care. Dataarecollectedandstoredforincreasinglylargenumbersofpatientsalloverthe world creating what is often called Big Health Data. The purpose of these collections are threefold: (i) directly to facilitate research (often in the form of survey or registry data),or(ii)tosupporttheconductofhealthcare(usuallycalledEHR­ElectronicHealth Records)or(iii)tomanagethepaymentforhealthcare(usuallycalledclaimsdata). All threeareroutinelyusedforclinicalresearch,thelattertwoassecondaryusedata,andall threetypicallyhavetheiruniqueformattingandencodingofthecontent. WhydoweneedaCommonDataModelforobservationalhealthcaredata? Dependingontheirprimaryneedsnoneoftheobservationaldatabasescaptureallclinical eventsequallywell. Therefore,researchresultsmustbedrawnfrommanydisparatedata sources and compared and contrasted to understand the effect of potential capture bias. In addition, in order to draw conclusions with statistical power we need large numbers of observed patients. That explains the need for assessing and analyzing multiple data sources concurrently. In order to do that, data need to be harmonized into a common datastandard. Inaddition,patientdatarequireahighlevelofprotection. Toextractdata for analysis purposes as it is done traditionally requires strict data use agreements and complex access control. A common data standard can alleviate this need by omitting theextractionstepandallowingastandardizedanalytictobeexecutedonthedatainit’s nativeenvironment­theanalyticcomestothedatainsteadofthedatatotheanalytic. This standard is provided by the Common Data Model (CDM). The CDM, combined with its standardized content (see Chapter 5), will ensure that research methods can be systematicallyappliedtoproducemeaningfullycomparableandreproducibleresults. In this chapter we provide an overview of the data model itself, design, conventions, and discussionofselecttables. AnoverviewofallthetablesintheCDMisprovidedinFigure 4.1. 31\n",
      "page text: 32 Chapter 4. The Common Data Model Figure4.1: OverviewofalltablesintheCDMversion6.0. Notethatnotallrelationships betweentablesareshown.\n",
      "page text: 4.1. Design Principles 33 4.1 Design Principles TheCDMisoptimizedfortypicalobservationalresearchpurposesof •Identifying patient populations with certain healthcare interventions (drug expo­ sure,procedures,healthcarepolicychangesetc.) andoutcomes(conditions,proce­ dures,otherdrugexposuresetc.), •Characterization of these patient populations for various parameters like demo­ graphic information, disease natural history, healthcare delivery, utilization and cost,morbidities,treatmentsandsequenceoftreatmentetc., •Predictingtheoccurrenceoftheseoutcomesinindividualpatients­seeChapter 13, •Estimatingtheeffecttheseinterventionshaveapopulation­seeChapter 12, Toachievethisgoal,thedevelopmentoftheCDMfollowsthefollowingdesignelements: •Suitability for purpose : TheCDMaimstoprovidedataorganizedinawayopti­ malforanalysis,ratherthanforthepurposeofaddressingtheoperationalneedsof healthcareprovidersorpayers. •Data protection : Alldatathatmightjeopardizetheidentityandprotectionofpa­ tients, such as names, precise birthdays etc. are limited. Exceptions are possible when the research expressly requires more detailed information, such as precise birthdatesforthestudyofinfants. •Design of domains : Thedomains aremodeledina person­centricrelationaldata model,whereforeachrecordtheidentityofthepersonandadateiscapturedasa minimum. Here, a relational datamodel is one where thedata is represented as a collectionoftableslinkedbyprimaryandforeignkeys. •Rationale for domains : Domainsareidentifiedandseparatelydefinedinanentity­ relationshipmodeliftheyhaveananalysisusecase(conditions,forexample)and thedomainhasspecificattributesthatarenototherwiseapplicable. Allotherdata can be preserved as an observation in the observation table in an entity­attribute­ valuestructure. •Standardized Vocabularies : Tostandardizethecontentofthoserecords,theCDM relies on the Standardized Vocabularies containing all necessary and appropriate correspondingstandardhealthcareconcepts. •Reuse of existing vocabularies : If possible, these concepts are leveraged from national or industry standardization or vocabulary definition organizations or ini­ tiatives, such as the National Library of Medicine, the Department of Veterans’ Affairs,theCenterofDiseaseControlandPrevention,etc. •Maintaining source codes : EventhoughallcodesaremappedtotheStandardized Vocabularies,themodelalsostorestheoriginalsourcecodetoensurenoinforma­ tionislost. •Technology neutrality : The CDM does not require a specific technology. It can berealizedinanyrelationaldatabase,suchasOracle,SQLServeretc.,orasSAS analyticaldatasets. •Scalability : TheCDMis optimizedfordata processingandcomputational analy­ sis to accommodate data sources that vary in size, including databases with up to\n",
      "page text: 34 Chapter 4. The Common Data Model hundredsofmillionsofpersonsandbillionsofclinicalobservations. •Backwards compatibility : All changes from previous CDMs are clearly delin­ eated in the github repository (https://github.com/OHDSI/CommonDataModel) . OlderversionsoftheCDMcanbeeasilycreatedfromthecurrentversion,andno informationislostthatwaspresentpreviously. 4.2 Data Model Conventions There are a number of implicit and explicit conventions that have been adopted in the CDM. Developers of methods that run against the CDM need to understand these con­ ventions. 4.2.1 General Conventions of the Model TheCDMisconsidereda“person­centric”model,meaningthatallclinicalEventtables are linked to the PERSON table. Together with the date or start date this allows for a longitudinalviewonallhealthcare­relevantEventsbyperson. Theexceptionsfromthis rulearethestandardizedhealthsystemdatatables,whicharelinkeddirectlytoEventsof thevariousdomains. 4.2.2 General Conventions of Schemas Schemas,ordatabaseusersinsomesystems,allowforseparationbetweenread­onlyand read­write tables. The clinical Event and vocabulary tables are in the “CDM” schema and are considered read­only to the end user or analytic tool. Tables that need to be manipulatedbyweb­basedtoolsorendusersarestoredinthe“Results”schema. Thetwo tablesinthe“Results”schemaareCOHORTandCOHORT_DEFINITION.Thesetables aremeanttodescribegroupsofinterestthattheusermightdefine,asdetailedinChapter 10. Thesetablescanbewrittento,meaningthatacohortcanbestoredintheCOHORT table at run time. Since there is only one read­write schema for all users it is up to the implementationoftheCDMhowmultipleuseraccessisorganizedandcontrolled. 4.2.3 General Conventions of Data T ables TheCDMisplatform­independent. DatatypesaredefinedgenericallyusingANSISQL data types (VARCHAR, INTEGER, FLOAT, DATE, DATETIME, CLOB). Precision is provided only for VARCHAR. It reflects the minimal required string length, but can be expanded within a concrete CDM instantiation. The CDM does not prescribe the date and datetime format. Standard queries against CDM may vary for local instances and date/datetimeconfigurations. Note: While the data model itself is platform­independent, many of the tools that have been built to work with it require certain specifications. For more about this please see Chapter8.\n",
      "page text: 4.2. Data Model Conventions 35 4.2.4 General Conventions of Domains Events of different nature are organized into Domains. These Events are stored in ta­ bles and fields which are Domain­specific, and represented by Standard Concepts that arealsoDomain­specificasdefinedintheStandardizedVocabularies(seesection 5.2.3). EachStandardConcepthasauniqueDomainassignment,whichdefineswhichtablethey are recorded in. Even though the correct Domain assignment is subject for debate in the community, this strict Domain­table­field correspondence rule assures that there is alwaysanunambiguouslocationforanycodeorconcept. Forexample,signs,symptoms and diagnosis Concepts are of the Condition Domain, and are recorded in the CONDI­ TION_CONCEPT_IDoftheCONDITION_OCCURRENCEtable. So­calledProcedure Drugsaretypicallyrecordedasprocedurecodesinaproceduretableinthesourcedata. In anCDM,theserecordsarefoundintheDRUG_EXPOSUREtablebecausethemapped StandardConceptshavetheDomainassignmentDrug. Thereisatotalof30Domains,as shownintable 4.1. Table4.1: Numberofstandardconceptsbelongingtoeachdomain. ConceptCount DomainID ConceptCount DomainID 1731378 Drug 183 Route 477597 Device 180 Currency 257000 Procedure 158 Payer 163807 Condition 123 Visit 145898 Observation 51 Cost 89645 Measurement 50 Race 33759 SpecAnatomicSite 13 PlanStopReason 17302 MeasValue 11 Plan 1799 Specimen 6 Episode 1215 ProviderSpecialty 6 Sponsor 1046 Unit 5 MeasValueOperator 944 Metadata 3 SpecDiseaseStatus 538 RevenueCode 2 Gender 336 TypeConcept 2 Ethnicity 194 Relationship 1 ObservationType 4.2.5 Representation of Content Through Concepts InCDMdatatablesthecontentofeachrecordisfullynormalizedandrepresentedthrough Concepts. Concepts are stored in Event tables with their CONCEPT_ID values, which areforeignkeystotheCONCEPTtable,whichservesasthegeneralreferencetable. All CDM instances use the same CONCEPT table as a reference of the Concepts, which together with the Common Data Model is a key mechanism of interoperability and the foundation of the OHDSI research network. If a Standard Concept does not exist or cannotbeidentified,thevalueoftheCONCEPT_IDissetto0,representinganon­existing concept,anunknownorun­mappablevalue.\n",
      "page text: 36 Chapter 4. The Common Data Model RecordsintheCONCEPTtablecontaindetailedinformationabouteachconcept(name, domain, class etc.). Concepts, Concept Relationships, Concept Ancestors and other in­ formationrelatingtoConceptsiscontainedinthetablesoftheStandardizedVocabularies (seeChapter 5). 4.2.6 General Naming Conventions of Fields Variablenamesacrossalltablesfollowoneconvention: Table4.2: Fieldnameconventions. Notation Description [Event]_ID Uniqueidentifierforeachrecord,whichservesasa foreignkeysestablishingrelationshipsacrossEvent tables. Forexample,PERSON_IDuniquelyidentifies eachindividual. VISIT_OCCURRENCE_ID uniquelyidentifiesaVisit. [Event]_CONCEPT_ID ForeignkeytoaStandardConceptrecordinthe CONCEPTreferencetable. Thisisthemain representationoftheEvent,servingastheprimary basisforallstandardizedanalytics. Forexample, CONDITION_CONCEPT_ID= 31967containsthe referencevaluefortheSNOMEDconceptof “Nausea”. [Event]_SOURCE _CONCEPT_IDForeignkeytoarecordintheCONCEPTreference table. ThisConceptistheequivalentoftheSource Value(below),anditmayhappentobeaStandard Concept,atwhichpointitwouldbeidenticaltothe [Event]_CONCEPT_ID,oranothernon­standard concept. Forexample, CONDITION_SOURCE_CONCEPT_ID= 45431665 denotestheconceptof“Nausea”inthe Readterminology,andtheanalogous CONDITION_CONCEPT_IDistheStandard SNOMED­CTConcept 31967. TheuseofSource Conceptsforstandardanalyticsapplicationsis discouragedsinceonlyStandardConceptsrepresent thesemanticcontentofanEventinaunambiguous wayandthereforeSourceConceptsarenot interoperable.\n",
      "page text: 4.2. Data Model Conventions 37 Notation Description [Event]_TYPE_CONCEPT_ID ForeignkeytoarecordintheCONCEPTreference table,representingtheoriginofthesource information,standardizedwithintheStandardized Vocabularies. Notethatdespitethefieldnamethisis notatypeofanEvent,ortypeofaConcept,but declaresthecapturemechanismthatcreatedthis record. Forexample,DRUG_TYPE_CONCEPT_ID discriminatesifaDrugrecordwasderivedfroma dispensingEventinthepharmacy(“Pharmacy dispensing”)orfromane­prescribingapplication (“Prescriptionwritten”) [Event]_SOURCE_VALUE Verbatimcodeorfreetextstringreflectinghowthis Eventwasrepresentedinthesourcedata. Itsuseis discouragedforstandardanalyticsapplications,as theseSourceValuesarenotharmonizedacrossdata sources. Forexample, CONDITION_SOURCE_VALUEmightcontaina recordof“78702”,correspondingtoICD­9code 787.02writteninanotationomittingthedot. 4.2.7 Difference Between Concepts and Source Values Many tables contain equivalent information in multiple places: as a Source Value, a SourceConceptandasaStandardConcept. •Source Values aretheoriginalrepresentationofanEventrecordinthesourcedata. Theycanbecodesfromwidelyusedcodingsystems,whichareoftenpublicdomain, such as ICD9CM, NDC or Read, proprietary coding systems like CPT4, GPI or MedDRA,orcontrolledvocabulariesusedonlyinthesourcedata,suchasFforfe­ maleandMformale. Theycanalsobeshortfreetextphrasesthatarenotstandard­ ized and controlled. Source Values are stored in the [Event]_SOURCE_VALUE fieldsinthedatatables. •ConceptsareCDM­specificentitiesthatnormalizethemeaningofaclinicalfact. MostConceptsarebasedonexistingpublicorproprietarycodingsystemsinhealth­ care,whileotherswerecreatedde­novo(CONCEPT_CODEstartswith“OMOP”). ConceptshaveuniqueIDsacrossalldomains. •Source Concepts are the Concepts that represent the code used in the source. Source Concepts are only used for existing public or proprietary coding sys­ tems, not for OMOP­generated Concepts. Source Concepts are stored in the [Event]_SOURCE_CONCEPT_IDfieldinthedatatables. •Standard Concepts are those Concepts that are used to define the meaning of a clinical entity uniquely across all databases and independent from the coding system used in the sources. Standard Concepts are typically drawn from existing\n",
      "page text: 38 Chapter 4. The Common Data Model public or proprietary vocabulary sources. Non­standard Concepts that have the equivalent meaning to a Standard Concept have a mapping to the Standard Con­ cept in the Standardized Vocabularies. Standard Concepts are referred to in the [Event]_CONCEPT_IDfieldofthedatatables. Source Values are only provided for convenience and quality assurance (QA) purposes. They may contain information that is only meaningful in the context of a specific data source. TheuseofSourceValuesandSourceConceptsisoptional,eventhough strongly recommended if the source data make use of coding systems. Standard Concepts are mandatory however. ThismandatoryuseofStandardConceptsiswhatallowsallCDM instancestospeakthesamelanguage. Forexample,thecondition“PulmonaryTubercu­ losis”(TB,Figure 4.2)showsthattheICD9CMcodeforTBis011. Figure4.2: ICD9CMcodeforPulmonaryTuberculosis Withoutcontext,thecode011couldbeinterpretedas“HospitalInpatient(IncludingMedi­ care Part A)” from the UB04 vocabulary, or as “Nervous System Neoplasms without Complications, Comorbidities” from the DRG vocabulary. This is where Concept IDs, bothSourceandStandard,arevaluable. TheCONCEPT_IDvaluethatrepresentsthe011 ICD9CMcodeis 44828631. ThisdifferentiatestheICD9CMfromtheUBO4andDRG. TheICD9CMTBSourceConceptmapstoStandardConcept 253954fromtheSNOMED\n",
      "page text: 4.3. CDM Standardized Tables 39 vocabularythroughtherelationship“Non­standardtoStandardmap(OMOP)”asshown infigure4.3. ThissamemappingrelationshipsexistsforRead,ICD10,CIEL,andMeSH codes,amongothers,sothatanyresearchthatreferencesthestandardSNOMEDconcept issuretoincludeallsupportedsourcecodes. Figure4.3: SNOMEDcodeforPulmonaryTuberculosis An example of how the Standard Concept to Source Concept relationship is depicted is showninTable 4.7. 4.3 CDM Standardized T ables The CDM contains 16 Clinical Event tables, 10 Vocabulary tables, 2 metadata tables, 4 healthsystemdatatables,2healtheconomicsdatatables,3standardizedderivedelements, and2Resultsschematables. ThesetablesarefullyspecifiedintheCDMWiki.1 Toillustratehowthesetablesareusedinpractice,thedataofonepersonwillbeusedas acommonthreadthroughouttherestofthechapter. 4.3.1 Running Example: Endometriosis Endometriosis is a painful condition whereby cells normally found in the lining of a woman’suterusoccurelsewhereinthebody. Severecasescanleadtoinfertility,bowel, and bladder problems. The following sections will detail one patient’s experience with thisdiseaseandhowitmightberepresentedintheCommonDataModel. 1https://github.com/OHDSI/CommonDataModel/wiki\n",
      "page text: 40 Chapter 4. The Common Data Model EverystepofthispainfuljourneyIhadtoconvinceeveryonehowmuchpain Iwasin. Laurenhadbeenexperiencingendometriosissymptomsformanyyears;however,ittook arupturedcystinherovarybeforeshewasdiagnosed. YoucanreadmoreaboutLauren athttps://endometriosis­uk.org/laurens­story . 4.3.2 PERSON T able What Do We Know About Lauren? •Sheisa36­year­oldwoman •Herbirthdayis12­March­1982 •Sheiswhite •SheisEnglish Withthatinmind,herPERSONtablemightlooksomethinglikethis: Table4.3: ThePERSONtable. Columnname Value Explanation PERSON_ID 1 ThePERSON_IDshouldbeaninteger, eitherdirectlyfromthesourceorgenerated aspartofthebuildprocess. GENDER_CONCEPT_ID 8532 TheconceptIDreferringtofemalegender is8532. YEAR_OF_BIRTH 1982 MONTH_OF_BIRTH 3 DAY_OF_BIRTH 12 BIRTH_DATETIME 1982­03­12 00:00:00Whenthetimeisnotknownmidnightis used. DEATH_DATETIME\n",
      "page text: 4.3. CDM Standardized Tables 41 Columnname Value Explanation RACE_CONCEPT_ID 8527 TheconceptIDreferringtowhiteraceis 8527. Englishethnicityis 4093769. Either oneiscorrect,thelatterwillrolluptothe former. Noticethatethnicitiesarestored hereaspartofRaces,notinthe ETHNICITY_CONCEPT_ID ETHNICITY_CONCEPT_ ID38003564 ThisisaUS­typicalnotationtodistinguish Hispanicsfromtherest. Ethnicities,inthis caseEnglish,isstoredinthe RACE_CONCEPT_ID.OutsidetheUS thisisnotused. 38003564 refersto“Not hispanic”. LOCATION_ID Heraddressisnotknown. PROVIDER_ID HerprimarycareProviderisnotknown. CARE_SITE HerprimaryCareSiteisnotknown. PERSON_SOURCE_ VALUE1 Typicallythiswouldbeheridentifierinthe sourcedata,thoughoftenitisthesameas thePERSON_ID. GENDER_SOURCE_ VALUEF Thegendervalueasitappearsinthe sourceisstoredhere. GENDER_SOURCE_ CONCEPT_ID0 Ifthegendervalueinthesourcewascoded usingacodingschemesupportedby OHDSIthatConceptwouldgohere. For example,ifhergenderwas“sex­F”inthe sourceanditwasstatedtobeinthe PCORNetvocabularyconcept 44814665 wouldgointhisfield. RACE_SOURCE_ VALUEwhite Theracevalueasitappearsinthesourceis storedhere. RACE_SOURCE_ CONCEPT_ID0 Sameprincipleas GENDER_SOURCE_CONCEPT_ID. ETHNICITY_SOURCE_ VALUEenglish Theethnicityvalueasitappearsinthe sourceisstoredhere. ETHNICITY_SOURCE_ CONCEPT_ID0 Sameprincipleas GENDER_SOURCE_CONCEPT_ID. 4.3.3 OBSERV A TION_PERIOD T able TheOBSERVATION_PERIODtableisdesignedtodefinetheamountoftimeforwhich at least a patient’s demographics, conditions, procedures and drugs are recorded in the sourcesystemwiththeexpectationofareasonablesensitivityandspecificity. Forinsur­ ance data this is typically the enrollment period of the patient. It’s trickier in electronic healthrecords(EHR),asmosthealthcaresystemsdonotdeterminewhichhealthcarein­\n",
      "page text: 42 Chapter 4. The Common Data Model stitutionorproviderisvisited. Asanextbestsolution,oftenthefirstrecordinthesystem isconsideredtheStartDateoftheObservationPeriodandthelatestrecordisconsidered theEndDate. How Is Lauren’s Observation Period Defined? Let’ssayLauren’sinformationasshowninTable 4.4isrecordedlikeinanEHRsystem. HerencountersfromwhichtheObservationPeriodwasderivedare: Table4.4: Lauren’shealthcareencounters. EncounterID Startdate Stopdate Type 70 2010­01­06 2010­01­06 outpatient 80 2011­01­06 2011­01­06 outpatient 90 2012­01­06 2012­01­06 outpatient 100 2013­01­07 2013­01­07 outpatient 101 2013­01­14 2013­01­14 ambulatory 102 2013­01­17 2013­01­24 inpatient Based on the encounter records her OBSERVATION_PERIOD table might look some­ thinglikethis: Table4.5: TheOBSERVATION_PERIODtable. Columnname Value Explanation OBSERVATION_ PERIOD_ID1 Thisistypicallyanautogeneratedvalue creatingauniqueidentifierforeachrecord inthetable. PERSON_ID 1 ThisisaforeignkeytoLaura’srecordin thePERSONtableandlinksPERSONto OBSERVATION_PERIODtable. OBSERVATION_PERIOD_ START_DATE2010­01­06 Thisisthestartdateofherearliest encounteronrecord. OBSERVATION_PERIOD_ END_DATE2013­01­24 Thisistheenddateofherlatestencounter onrecord. PERIOD_TYPE_ CONCEPT_ID44814725 ThebestoptionintheVocabularywiththe conceptclass“ObsPeriodType”is 44814724,whichstandsfor“Period coveringhealthcareencounters”. 4.3.4 VISIT_OCCURRENCE the VISIT_OCCURRENCE table houses information about a patient’s encounters with thehealthcaresystem. WithintheOHDSIvernacularthesearereferredtoasVisitsandare\n",
      "page text: 4.3. CDM Standardized Tables 43 consideredtobediscreteevents. Thereare12topcategoriesofVisitswithanextensive hierarchy,depictingthemanydifferentcircumstanceshealthcaremightbedelivered. The most common Visits recorded are inpatient, outpatient, emergency department and non­ medicalinstitutionVisits. How Are Lauren’s Encounters Represented As Visits? Asanexamplelet’srepresenttheinpatientencounterinTable 4.4intheVISIT_OCCURRENCE table. Table4.6: theVISIT_OCCURRENCEtable. Columnname Value Explanation VISIT_OCCURRENCE_ ID514 Thisistypicallyanautogeneratedvalue creatingauniqueidentifierforeachrecord. PERSON_ID 1 ThisisaforeignkeytoLaura’srecordin thePERSONtableandlinksPERSONto VISIT_OCCURRENCE. VISIT_CONCEPT_ID 9201 AforeignkeyreferringtoanInpatient Visitis9201. VISIT_START_DATE 2013­01­17 ThestartdateoftheVisit. VISIT_START_ DATETIME2013­01­17 00:00:00ThedateandtimeoftheVisit. Thetimeis unknown,somidnightisused. VISIT_END_DATE 2013­01­24 TheenddateoftheVisit. Ifthisisa one­dayVisittheenddateshouldmatch thestartdate. VISIT_END_DATETIME 2013­01­24 00:00:00ThedateandtimeoftheVisitend. The timeisunknown,somidnightisused. VISIT_TYPE_ CONCEPT_ID32034 Thisprovidesinformationaboutthe provenanceoftheVisitrecord,i.e.doesit comefromaninsuranceclaim,hospital billing,EHRrecord,etc. Forthisexample theconceptID 32035(“Visitderivedfrom EHRencounterrecord”)isusedasthe encountersaresimilartoElectronicHealth Records PROVIDER_ID* NULL Iftheencounterrecordhasaprovider associatedtheIDforthatprovidergoes intothisfield. Thisshouldbethecontent ofthePROVIDER_IDfieldfromthe PROVIDERtable.\n",
      "page text: 44 Chapter 4. The Common Data Model Columnname Value Explanation CARE_SITE_ID NULL IftheencounterrecordhasaCareSite associated,theIDforthatCareSitegoes intothisfield. Thisshouldbethe CARE_SITE_IDfromtheCARE_SITE table. VISIT_SOURCE_ VALUEinpatient TheVisitvalueasitappearsinthesource goeshere. Lauren’sdatadonothavethat. VISIT_SOURCE_ CONCEPT_ID0 IftheVisitvaluefromthesourceiscoded usingavocabularythatisrecognizedby OHDSItheCONCEPT_IDvalue representingthesourcecodewouldbe foundhere. Lauren’sdatadonothavethat. ADMITTED_FROM_ CONCEPT_ID0 Ifknown,thisiscontainsaConcept representingwherethepatientwas admittedfrom. Thisconceptshouldhave thedomain“Visit”. Forexample,ifthe patientwereadmittedtothehospitalfrom homeitwouldcontain 8536(“Home”). ADMITTED_FROM_ SOURCE_CONCEPT_IDNULL Thisisthevaluefromthesourcethat representswherethepatientwasadmitted from. Usingtheaboveexample,thiswould be“home”. DISCHARGE_TO_ CONCEPT_ID0 Ifknown,thisreferstoaConcept representingwherethepatientwas dischargedto. Thisconceptshouldhave domain“Visit”. Forexample,ifapatient wasreleasedtoanassistedlivingfacility, theconceptIDwouldbe 8615(“Assisted LivingFacility”). DISCHARGE_TO_ SOURCE_VALUE0 Thisisthevaluefromthesourcethat representswherethepatientwas dischargedto. Usingtheaboveexample, thiswouldbe“Assistedlivingfacility”. PRECEDING_VISIT_ OCCURRENCE_IDNULL ThisdenotestheVisitimmediately precedingthecurrentone. Incontrastto ADMITTED_FROM_CONCEPT_IDthis linkstotheactualVisitOccurrencerecord ratherthanaVisitConcept. Also,note thereisnorecordforthefollowingVisit Occurrence,VisitOccurrencesareonly linkedthroughthisfield. •A patient may interact with multiple health care Providers during one visit, as\n",
      "page text: 4.3. CDM Standardized Tables 45 is often the case with inpatient stays. These interactions can be recorded in the VISIT_DETAIL table. While not covered in depth in this chapter, you can read moreabouttheVISIT_DETAILtableinthe CDMwiki . 4.3.5 CONDITION_OCCURRENCE Records in the CONDITION_OCCURRENCE table are diagnoses, signs, or symptoms ofaconditioneitherobservedbyaProviderorreportedbythepatient. What Are Lauren’s Conditions? Revisitingheraccountshesays: About3yearsagoInoticedmyperiods, whichhadalsobeenpainful, were getting increasingly more painful. I started becoming aware of a sharp jab­ bing pain right by my colon and feeling tender and bloated around my tail­ bone and lower pelvis area. My periods had become so painful that I was missing 1­2 days of work a month. Painkillers sometimes dulled the pain, butusuallytheydidn’tdomuch. The SNOMED code for painful menstruation cramps, otherwise known as dysmenor­ rhea, is 266599000. Table 4.7shows how that would be represented in the CONDI­ TION_OCCURRENCEtable: Table4.7: TheCONDITION_OCCURRENCEtable. Columnname Value Explanation CONDITION_ OCCURRENCE_ID964 Thisistypicallyanautogeneratedvalue creatingauniqueidentifierforeachrecord. PERSON_ID 1 ThisisaforeignkeytoLaura’srecordin thePERSONtableandlinksPERSONto CONDITION_OCCURRENCE. CONDITION_ CONCEPT_ID194696 AforeignkeyreferringtotheSNOMED code266599000: 194696. CONDITION_START_ DATE2010­01­06 Thedatewhentheinstanceofthe Conditionisrecorded. CONDITION_START_ DATETIME2010­01­06 00:00:00Thedateandtimewhentheinstanceofthe Conditionisrecorded. Midnightisused sincethetimeisunknown. CONDITION_END_ DATENULL Thisisthedatewhentheinstanceofthe Conditionisconsideredtohaveended,but thisisrarelyrecorded. CONDITION_END_ DATETIMENULL Ifknown,thisisthedateandtimewhen theinstanceoftheConditionisconsidered tohaveended.\n",
      "page text: 46 Chapter 4. The Common Data Model Columnname Value Explanation CONDITION_TYPE_ CONCEPT_ID32020 Thiscolumnisintendedtoprovide informationabouttheprovenanceofthe record,i.e.thatitcomesfromaninsurance claim,hospitalbillingrecord,EHRrecord, etc. Forthisexampletheconcept 32020 (“EHRencounterdiagnosis”)isusedasthe encountersaresimilartoelectronichealth records. Conceptsinthisfieldshouldbein the“ConditionType”vocabulary. CONDITION_STATUS_ CONCEPT_ID0 Ifknown,thethistellsthecircumstance and. Forexample,aconditioncouldbean admittingdiagnosis,inwhichcasethe conceptID 4203942wasused. STOP_REASON NULL Ifknown,thereasonthattheCondition wasnolongerpresent,asindicatedinthe sourcedata. PROVIDER_ID NULL Iftheconditionrecordhasadiagnosing providerlisted,theIDforthatprovider goesinthisfield. Thisshouldbethe provider_idfromthePROVIDERtable thatrepresentstheprovideronthe encounter. VISIT_OCCURRENCE_ ID509 TheVisit(foreignkeytothe VISIT_OCCURRENCE_IDinthe VISIT_OCCURRENCEtable)during whichtheConditionwasdiagnosed. CONDITION_SOURCE_ VALUE266599000 Thisistheoriginalsourcevalue representingtheCondition. InLauren’s caseofdysmenorrheatheSNOMEDcode forthatConditionisstoredhere,whilethe Conceptrepresentingthecodewenttothe CONDITION_SOURCE_CONCEPT_ID andtheStandardConceptmappedfrom thatisstoredinthe CONDITION_CONCEPT_IDfield.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████▊                                                                                                                   | 74/464 [00:00<00:03, 106.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 4.3. CDM Standardized Tables 47 Columnname Value Explanation CONDITION_SOURCE_ CONCEPT_ID194696 Iftheconditionvaluefromthesourceis codedusingavocabularythatis recognizedbyOHDSI,theconceptIDthat representsthatvaluewouldgohere. Inthe exampleofdysmennorheathesourcevalue isaSNOMEDcodesotheConcept representingthatcodeis194696. Inthis caseithasthesamevalueasthe CONDITION_CONCEPT_IDfield. CONDITION_STATUS_ SOURCE_VALUE0 IftheConditionStatusvaluefromthe sourceiscodedusingacodingscheme supportedbyOHDSIthatconceptwould gohere. 4.3.6 DRUG_EXPOSURE The DRUG_EXPOSURE table captures records about the intent or actual introduction of a drug into the body of the patient. Drugs include prescription and over­the­counter medicines,vaccines,andlarge­moleculebiologictherapies. Drugexposuresareinferred fromclinicaleventsassociatedwithorders,prescriptionswritten,pharmacydispensings, proceduraladministrations,andotherpatient­reportedinformation. How Are Lauren’s Drug Exposures Represented? To help with her dysmenorrhea pain, Lauren was given 60 oral tablets with 375 mg Acetaminophen (aka Paracetamol, e.g. sold in the US under NDC code 69842087651) each for 30 days at her Visit on 2010­01­06. Here’s how that might look in the DRUG_EXPOSUREtable: Table4.8: TheDRUG_EXPOSUREtable. Columnname Value Explanation DRUG_EXPOSURE_ID 1001 Thisistypicallyanautogeneratedvalue creatingauniqueidentifierforeachrecord. PERSON_ID 1 ThisisaforeignkeytoLaura’srecordin thePERSONtableandlinksPERSONto DRUG_EXPOSURE. DRUG_CONCEPT_ID 1127433 TheConceptfortheDrugproduct. The NDCcodeforacetaminophenmapstothe RxNormcode313782whichisrepresented bytheConcept 1127433. DRUG_EXPOSURE_ START_DATE2010­01­06 ThestartdateoftheexposuretotheDrug.\n",
      "page text: 48 Chapter 4. The Common Data Model Columnname Value Explanation DRUG_EXPOSURE_ START_DATETIME2010­01­06 00:00:00Thestartdateandtimeofthedrug exposure. Midnightisusedasthetimeis notknown. DRUG_EXPOSURE_ END_DATE2010­02­05 TheenddateoftheDrugExposure. Dependingondifferentsources,itcouldbe aknownoraninferreddateanddenotes thelastdayatwhichthepatientwasstill exposedtothedrug. Inthiscasethisdate isinferredsinceweknowLaurenhada30 dayssupply. DRUG_EXPOSURE_ END_DATETIME2010­02­05 00:00:00Theenddateandtimeofthedrug exposure. Similarrulesapplyasto DRUG_EXPOSURE_END_DATE. Midnightisusedastimeisunknown. VERBATIM_END_DATE NULL Ifthesourcerecordedanexplicitactual enddate. Theinferredenddatebankson theassumptionthatthefullrangeofdays supplywasutilizedbythepatient. DRUG_TYPE_ CONCEPT_ID38000177 Thiscolumnisintendedtoprovide informationabouttheprovenanceofthe record,i.e.doesitcomefromaninsurance claim,prescriptionrecord,etc. Forthis exampletheconcept 38000177 (“Prescriptionwritten”)isused. STOP_REASON NULL ThereasontheadministrationoftheDrug wasstopped. Reasonsincluderegimen completed,changed,removed,etc. This informationisveryrarelycaptured. REFILLS NULL Thenumberofautomaticrefillsafterthe initialprescriptionthatarepartofthe prescriptionsysteminmanycountries. The initialprescriptionisnotcounted,values startwithNULL.InthecaseofLauren’s acetaminophenshedidnothaveanyrefills sothevalueisNULL. QUANTITY 60 Thequantityofdrugasrecordedinthe originalprescriptionordispensingrecord. DAYS_SUPPLY 30 Thenumberofdaysofsupplyofthe medicationasprescribed.\n",
      "page text: 4.3. CDM Standardized Tables 49 Columnname Value Explanation SIG NULL Thedirections(“signetur”)ontheDrug prescriptionasrecordedintheoriginal prescriptionordispensingrecord(and printedonthecontainerintheUSdrug prescriptionsystem). Signetursarenotyet standardizedintheCDM,andprovided verbatim. ROUTE_CONCEPT_ID 4132161 Thisconceptismeanttorepresentthe routeofadministrationoftheDrugthe patientwasexposedto. Laurentookher acetaminophenorallysotheconceptID 4132161(“Oral”)isused. LOT_NUMBER NULL Anidentifierassignedtoaparticular quantityorlotofDrugproductfromthe manufacturer. Thisinformationisrarely captured. PROVIDER_ID NULL Ifthedrugrecordhasaprescribing Providerlisted,theIDforthatProvider goesinthisfield. Inthatcasethiscontains thePROVIDER_IDfromthePROVIDER table. VISIT_OCCURRENCE_ ID509 Aforeignkeytothe VISIT_OCCURRENCEtableduring whichtheDrugwasprescribed. VISIT_DETAIL_ID NULL AforeignkeytotheVISIT_DETAILtable duringwhichtheDrugwasprescribed. DRUG_SOURCE_ VALUE69842087651 ThisisthesourcecodefortheDrugasit appearsinthesourcedata. InLauren’s casetheNDCcodeisstoredhere. DRUG_SOURCE_ CONCEPT_ID750264 ThisistheConceptthatrepresentsthedrug sourcevalue. TheConcept 750264 standingfortheNDCcodefor “Acetaminophen325MGOralTablet”. ROUTE_SOURCE_ VALUENULL Theverbatiminformationabouttheroute ofadministrationasdetailedinthesource. 4.3.7 PROCEDURE_OCCURRENCE ThePROCEDURE_OCCURRENCEtablecontainsrecordsofactivitiesorprocessesor­ deredorcarriedoutbyahealthcareProvideronthepatientwithadiagnosticortherapeutic purpose. Procedures are present in various data sources in different forms with varying levelsofstandardization. Forexample:\n",
      "page text: 50 Chapter 4. The Common Data Model •Medical Claims include procedure codes that are submitted as part of a claim for healthservicesrendered,includingproceduresperformed. •ElectronicHealthRecordsthatcaptureproceduresasorders. What Procedures Did Lauren Have? From her description we know she had an ultrasound of her left ovary on 2013­ 01­14 that showed a 4x5cm cyst. Here’s how that would look in the PROCE­ DURE_OCCURRENCEtable: Table4.9: ThePROCEDURE_OCCURRENCEtable. Columnname Value Explanation PROCEDURE_ OCCURRENCE_ID1277 Thisistypicallyanautogeneratedvalue creatingauniqueidentifierforeachrecord. PERSON_ID 1 ThisisaforeignkeytoLaura’srecordin thePERSONtableandlinksPERSONto PROCEDURE_OCCURRENCE PROCEDURE_ CONCEPT_ID4127451 TheSNOMEDprocedurecodeforapelvic ultrasoundis304435002whichis representedbyConcept 4127451. PROCEDURE_DATE 2013­01­14 ThedateonwhichtheProcedurewas performed. PROCEDURE_ DATETIME2013­01­14 00:00:00Thedateandtimeonwhichtheprocedure wasperformed. Midnightisusedastimeis unknown. PROCEDURE_TYPE_ CONCEPT_ID38000275 Thiscolumnisintendedtoprovide informationabouttheprovenanceofthe procedurerecord,i.e.doesitcomefroman insuranceclaim,EHRorder,etc. Forthis exampletheconceptID 38000275 (“EHR orderlistentry”)isusedastheprocedure recordisfromanEHRrecord. MODIFIER_CONCEPT_ ID0 ThisismeantforaconceptIDrepresenting themodifierontheprocedure. For example,iftherecordindicatedthata CPT4procedurewasperformedbilaterally thentheconceptID 42739579 (“Bilateral procedure”)wouldbeused. QUANTITY 0 ThequantityofProceduresorderedor administered. AmissingQuantity,the numbers0and1allmeanthesamething.\n",
      "page text: 4.4. Additional Information 51 Columnname Value Explanation PROVIDER_ID NULL IftheProcedurerecordhasaProvider listed,theIDforthatProvidergoesinthis field. Thisshouldbeaforeignkeytothe PROVIDER_IDfromthePROVIDER table. VISIT_OCCURRENCE_ ID740 Ifknown,thisistheVisit(representedas VISIT_occurrence_idtakenfromthe VISIT_OCCURRENCEtable)during whichtheprocedurewasperformed. VISIT_DETAIL_ID NULL Ifknown,thisistheVisitdetail (representedasVISIT_detail_idtaken fromtheVISIT_DETAILtable)during whichtheprocedurewasperformed. PROCEDURE_SOURCE_ VALUE304435002 ThecodeorinformationfortheProcedure asitappearsinthesourcedata. PROCEDURE_SOURCE_ CONCEPT_ID4127451 ThisistheConceptthatrepresentsthe proceduresourcevalue. MODIFIER_SOURCE_ VALUENULL Thesourcecodeforthemodifierasit appearsinthesourcedata. 4.4 Additional Information ThischaptercoversonlyaportionofthetablesavailableintheCDMasexamplesofhow dataisrepresented. Youareencouragedtovisitthewikisite2formoreinformation. 4.5 Summary –The CDM is designed to support a wide range of observational research ac­ tivities. –TheCDMisaperson­centricmodel. –TheCDMnotonlystandardizesthestructureofthedata,butthroughtheStan­ dardizedVocabulariesitalsostandardizestherepresentationofthecontent. –SourcecodesaremaintainedintheCDMforfulltraceability. 2https://github.com/OHDSI/CommonDataModel/wiki\n",
      "page text: 52 Chapter 4. The Common Data Model 4.6 Exercises Prerequisites ForthesefirstexercisesyouwillneedtoreviewtheCDMtablesdiscussedearlier,andyou willhavetolookupconceptsintheVocabulary, whichcanbedonethroughATHENA3 orATLAS.4 Exercise 4.1. JohnisanAfricanAmericanmanbornonAugust4,1974. Defineanentry inthePERSONtablethatencodesthisinformation. Exercise 4.2. JohnenrolledinhiscurrentinsuranceonJanuary1st,2015. Thedatafrom hisinsurancedatabasewereextractedonJuly1st,2019. DefineanentryintheOBSER­ VATION_PERIODtablethatencodesthisinformation. Exercise 4.3. John was prescribed a 30­day supply of Ibuprofen 200 MG Oral tablets (NDC code: 76168009520) on May 1st, 2019. Define an entry in the DRUG_EXPOSUREtablethatencodesthisinformation. Prerequisites For these last three exercises we assume R, R­Studio and Java have been installed as described in Section 8.4.5. Also required are the SqlRender,DatabaseConnector , and Eunomiapackages,whichcanbeinstalledusing: install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. ThisisaSQLqueryexampletoretrieveonerow oftheCONDITION_OCCURRENCEtable: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT * FROM @cdm.condition_occurrence LIMIT 1;\" result <- renderTranslateQuerySql (connection, sql, cdm =\"main\") 3http://athena.ohdsi.org/ 4http://atlas­demo.ohdsi.org\n",
      "page text: 4.6. Exercises 53 Exercise 4.4. Using SQL and R, retrieve all records of the condition “Gastrointestinal hemorrhage”(withconceptID 192671). Exercise 4.5. Using SQL and R, retrieve all records of the condition “Gastrointestinal hemorrhage” using source codes. This database uses ICD­10, and the relevant ICD­10 codeis“K92.2”. Exercise 4.6. UsingSQLandR,retrievetheobservationperiodofthepersonwithPER­ SON_ID61. SuggestedanswerscanbefoundinAppendix E.1.\n",
      "page text: 54 Chapter 4. The Common Data Model\n",
      "page text: Chapter 5 Standardized Vocabularies Chapter leads: Christian Reich & Anna Ostropolets TheOMOPStandardizedVocabularies,oftenreferredtosimplyas“theVocabulary”,are afoundationalpartoftheOHDSIresearchnetwork,andanintegralpartoftheCommon Data Model (CDM). They allow standardization of methods, definitions and results by defining the content of the data, paving the way for true remote (behind the firewall) networkresearchandanalytics. Usually,findingandinterpretingthecontentofobserva­ tionalhealthcaredata,whetheritisstructureddatausingcodingschemesorlaiddownin free text, is passed all the way through to the researcher, who is faced with a myriad of different ways to describe clinical events. OHDSI requires harmonization not only to a standardizedformat,butalsotoarigorousstandardcontent. In this chapter we first describe the main principles of the Standardized Vocabularies, theircomponents,andtherelevantrules,conventionsandsometypicalsituations,allof whicharenecessarytounderstandandutilizingthisfoundationalresource. Wealsopoint outwherethesupportofthecommunityisrequiredtocontinuouslyimproveit. 5.1 Why Vocabularies, and Why Standardizing Medical vocabularies go back to the Bills of Mortality in medieval London to manage outbreaksoftheplagueandotherdiseases(seeFigure 5.1). Since then, the classifications have greatly expanded in size and complexity and spread intootheraspectsofhealthcare,suchasproceduresandservices,drugs,medicaldevices, etc. The main principles have remained the same: they are controlled vocabularies, ter­ minologies, hierarchies or ontologies that some healthcare communities agree upon for thepurposeofcapturing, classifyingandanalyzingpatientdata. Manyofthesevocabu­ laries are maintained by public and government agencies with a long­term mandate for doingso. Forexample,theWorldHealthOrganization(WHO)producestheInternational ClassificationofDisease(ICD)withtherecentadditionofits11threvision(ICD11). Lo­ calgovernmentscreatecountry­specificversions,suchasICD10CM(USA),ICD10GM 55\n",
      "page text: 56 Chapter 5. Standardized Vocabularies Figure 5.1: 1660 London Bill of Mortality, showing the cause of death for deceased in­ habitantsusingaclassificationsystemof62diseasesknownatthetime.\n",
      "page text: 5.1. Why Vocabularies, and Why Standardizing 57 (Germany),etc. Governmentsalsocontrolthemarketingandsaleofdrugsandmaintain national repositories of such certified drugs. Vocabularies are also used in the private sector,eitherascommercialproductsorforinternaluse,suchaselectronichealthrecord (EHR)systemsorformedicalinsuranceclaimreporting. As a result, each country, region, healthcare system and institution tends to have their ownclassificationsthatwouldmostlikelyonlyberelevantwhereitisused. Thismyriad ofvocabulariespreventsinteroperabilityofthesystemstheyareusedin. Standardization is the key that enables patient data exchange, unlocks health data analysis on a global levelandallowssystematicandstandardizedresearch,includingperformancecharacteri­ zationandqualityassessment. Toaddressthatproblem,multinationalorganizationshave sprungupandstartedcreatingbroadstandards, suchastheWHOmentionedaboveand theStandardNomenclatureofMedicine(SNOMED)orLogicalObservationIdentifiers NamesandCodes(LOINC).IntheUS,theHealthITStandardsCommittee(HITAC)rec­ ommends the use of SNOMED, LOINC and the drug vocabulary RxNorm as standards to the National Coordinator for Health IT (ONC) for use in a common platform for na­ tionwidehealthinformationexchangeacrossdiverseentities. OHDSIdevelopedtheOMOPCDM,aglobalstandardforobservationalresearch. Aspart oftheCDM,theOMOPStandardizedVocabulariesareavailablefortwomainpurposes: •Commonrepositoryofallvocabulariesusedinthecommunity •Standardizationandmappingforuseinresearch The Standardized Vocabularies are available to the community free of charge and must be usedforOMOPCDMinstance as its mandatory reference table . 5.1.1 Building the Standardized Vocabularies All vocabularies of the Standardized Vocabularies are consolidated into the same com­ monformat. Thisrelievestheresearchersfromhavingtounderstandandhandlemultiple differentformatsandlife­cycleconventionsoftheoriginatingvocabularies. Allvocabu­ lariesareregularlyrefreshedandincorporatedusingthePallassystem.1Itisbuiltandrun by the OHDSI Vocabulary Team, which is part of the overall OMOP CDM Workgroup. Ifyoufindmistakespleasereportandhelpimproveourresourcebypostingineitherthe OHDSIForums2orCDMGithubpage.3 5.1.2 Access to the Standardized Vocabularies InordertoobtaintheStandardizedVocabularies,youdonothavetorunPallasyourself. Instead,youcandownloadthelatestversionfromATHENA4andloaditintoyourlocal database. ATHENAalsoallowsfacetedsearchoftheVocabularies. 1https://github.com/OHDSI/Vocabulary­v5.0 2https://forums.ohdsi.org 3https://github.com/OHDSI/CommonDataModel/issues 4http://athena.ohdsi.org\n",
      "page text: 58 Chapter 5. Standardized Vocabularies TodownloadazipfilewithallStandardizedVocabulariestablesselectallthevocabular­ ies you need for your OMOP CDM. Vocabularies with Standard Concepts (see Section 5.2.6) and very common usage are preselected. Add vocabularies that are used in your source data. Vocabularies that are proprietary have no select button. Click on the “Li­ cense required” button to incorporate such a vocabulary into your list. The Vocabulary Teamwillcontactyouandrequestyoudemonstrateyourlicenseorhelpyouconnectto therightfolkstoobtainone. 5.1.3 Source of Vocabularies: Adopt Versus Build OHDSI generally prefers adopting existing vocabularies, rather than de­novo construc­ tion, because (i) many vocabularies have already been utilized in observational data in the community, and (ii) construction and maintenance of vocabularies is complex and requires the input of many stakeholders over long periods of time to mature. For that reason,dedicatedorganizationsprovidevocabularies,whicharesubjecttoalife­cycleof generation, deprecation, merging and splitting (see Section 5.2.10). Currently, OHDSI only produces internal administrative vocabularies like Type Concepts (e.g. condition type concepts). The only exception is RxNorm Extension, a vocabulary covering drugs thatareonlyusedoutsidetheUnitedStates(seeSection 5.6.9). 5.2 Concepts All clinical events in the OMOP CDM are expressed as concepts, which represent the semantic notion of each event. They are the fundamental building blocks of the data records, making almost all tables fully normalized with few exceptions. Concepts are storedintheCONCEPTtable(seeFigure 5.2). This system is meant to be comprehensive , i.e. there are enough concepts to cover any event relevant to the patient’s healthcare experience (e.g. conditions, procedures, expo­ sures to drug, etc.) as well as some of the administrative information of the healthcare system(e.g.visits,caresites,etc.). 5.2.1 Concept IDs Each concept is assigned a concept ID to be used as a primary key. This meaningless integerID,ratherthantheoriginalcodefromthevocabulary,isusedtorecorddatainthe CDMeventtables. 5.2.2 Concept Names Eachconcepthasonename. NamesarealwaysinEnglish. Theyareimportedfromthe source of the vocabulary. If the source vocabulary has more than one name, the most expressiveisselectedandtheremainingonesarestoredintheCONCEPT_SYNONYM table under the same CONCEPT_ID key. Non­English names are recorded in CONCEPT_SYNONYM as well, with the appropriate language concept ID in the\n",
      "page text: 5.2. Concepts 59 Figure 5.2: Standard representation of vocabulary concepts in the OMOP CDM. The exampleprovidedistheCONCEPTtablerecordfortheSNOMEDcodeforAtrialFibril­ lation. LANGUAGE_CONCEPT_IDfield. Thenameis255characterslong,whichmeansthat verylongnamesgettruncatedandthefull­lengthversionrecordedasanothersynonym, whichcanholdupto1000characters. 5.2.3 Domains EachconceptisassignedadomainintheDOMAIN_IDfield,whichincontrasttothenu­ mericalCONCEPT_IDisashortcase­sensitiveuniquealphanumericIDforthedomain. Examplesofsuchdomainidentifiersare“Condition,”“Drug,”“Procedure,”“Visit,”“De­ vice,” “Specimen,” etc. Ambiguous or pre­coordinated (combination) concepts can be­ longtoacombinationdomain,butStandardConcepts(seeSection 5.2.6)arealwaysas­ signed a singular domain. Domains also direct to which CDM table and field a clinical eventoreventattributeisrecorded. DomainassignmentsareanOMOP­specificfeature doneduringvocabularyingestionusingaheuristiclaidoutin Pallas. Sourcevocabularies tendtocombinecodesofmixeddomains,buttoavaryingdegree(seeFigure 5.3). The domain heuristic follows the definitions of the domains. These definitions are de­ rived from the table and field definitions in the CDM (see Chapter 4). The heuristic is notperfect; therearegreyzones(seeSection 5.6“SpecialSituations”). Ifyoufindcon­ ceptdomainsassignedincorrectlypleasereportandhelpimprovetheprocessthrougha ForumsorCDMissue post. 5.2.4 Vocabularies Eachvocabularyhasashortcase­sensitiveuniquealphanumericID,whichgenerallyfol­ lowstheabbreviatednameofthevocabulary,omittingdashes. Forexample,ICD­9­CM\n",
      "page text: 60 Chapter 5. Standardized Vocabularies Figure 5.3: Domain assignment in procedure vocabularies CPT4 and HCPCS. By intu­ ition, these vocabularies should contain codes and concepts of a single domain, but in realitytheyaremixed.\n",
      "page text: 5.2. Concepts 61 has the vocabulary ID “ICD9CM”. There are 111 vocabularies currently supported by OHDSI,ofwhich78areadoptedfromexternalsources,whiletherestareOMOP­internal vocabularies. These vocabularies are typically refreshed at a quarterly schedule. The source and the version of the vocabularies is defined in the VOCABULARY reference file. 5.2.5 Concept Classes Somevocabulariesclassifytheircodesorconcepts,denotedthroughtheircase­sensitive uniquealphanumericalIDs. Forexample,SNOMEDhas33suchconceptclasses,which SNOMEDreferstoas“semantictags”: clinicalfinding,socialcontext,bodystructure,etc. Theseareverticaldivisionsoftheconcepts. Others,suchasMedDRAorRxNorm,have concept classes classifying horizontal levels in their stratified hierarchies. Vocabularies withoutanyconceptclasses,suchasHCPCS,usethevocabularyIDastheConceptClass ID. Table5.1: Vocabularieswithorwithouthorizontalandverticalsub­ classificationprinciplesinconceptclass. Conceptclass subdivision principle Vocabulary Horizontal alldrugvocabularies,ATC,CDТ,Episode,HCPCS,HemOnc, ICDs,MedDRA,OSM,Census Vertical CIEL,HESSpecialty,ICDO3,MeSH,NAACCR,NDFRT, OPCS4,PCORNET,Plan,PPI,Provider,SNOMED,SPL,UCUM Mixed CPT4,ISBT,LOINC None APC,allTypeConcepts,Ethnicity,OXMIS,Race,RevenueCode, Sponsor,Supplier,UB04s,Visit Horizontal concept classes allow you to determine a specific hierarchical level. For ex­ ample, in the drug vocabulary RxNorm the concept class “Ingredient” defines the top level of the hierarchy. In the vertical model, members of a concept class can be of any hierarchicallevelfromthetoptotheverybottom. 5.2.6 Standard Concepts OneconceptrepresentingthemeaningofeachclinicaleventisdesignatedtheStandard. For example, MESH code D001281, CIEL code 148203, SNOMED code 49436004, ICD9CMcode427.31andReadcodeG573000alldefine“Atrialfibrillation”inthecon­ dition domain, but only the SNOMED concept is Standard and represents the condition in the data. The others are designated non­standard or source concepts and mapped to the Standard ones. Standard Concepts are indicated through an “S” in the STAN­ DARD_CONCEPT field. And only these Standard Concepts are used to record data in theCDMfieldsendingin”_CONCEPT_ID”.\n",
      "page text: 62 Chapter 5. Standardized Vocabularies 5.2.7 Non-Standard Concepts Non­standardconceptsarenotusedtorepresenttheclinicalevents,buttheyarestillpart oftheStandardizedVocabularies,andareoftenfoundinthesourcedata. Forthatreason, they are also called “source concepts”. The conversion of source concepts to Standard Conceptsisaprocesscalled“mapping”(seeSection 5.3.1). Non­standardconceptshave novalue(NULL)IntheSTANDARD_CONCEPTfield. 5.2.8 Classification Concepts TheseconceptsarenotStandard,andhencecannotbeusedtorepresentthedata. Butthey areparticipatinginthehierarchywiththeStandardConcepts,andcanthereforebeused toperformhierarchicalqueries. Forexample,queryingforalldescendantsofMedDRA code10037908(notvisibleforuserswhohavenotobtainedaMedDRAlicense,seeSec­ tion5.1.2foraccessrestrictions)willretrievetheStandardSNOMEDconceptforAtrial Fibrillation(seeSection 5.4forhierarchicalqueriesusingtheCONCEPT_ANCESTOR table)­seeFigure 5.4. Figure5.4: Standard,non­standardsourceandclassificationconceptsandtheirhierarchi­ calrelationshipsintheconditiondomain. SNOMEDisusedformoststandardcondition concepts (with some oncology­related concepts derived from ICDO3), MedDRA con­ ceptsareusedforhierarchicalclassificationconcepts,andallothervocabulariescontain non­standardorsourceconcepts,whichdonotparticipateinthehierarchy. ThechoiceofconceptdesignationasStandard,non­standardandclassificationistypically doneforeachdomainseparatelyatthevocabularylevel. Thisisbasedonthequalityof theconcepts,thebuilt­inhierarchyandthedeclaredpurposeofthevocabulary. Also,not allconceptsofavocabularyareusedasStandardConcepts. Thedesignationisseparate for each domain, each concept has to be active (see Section 5.2.10) and there might be anorderofprecedenceifmorethanoneconceptfromdifferentvocabulariescompetefor\n",
      "page text: 5.2. Concepts 63 the same meaning. In other words, there is no such a thing as a “standard vocabulary.” SeeTable5.2forexamples. Table 5.2: List of vocabularies to utilize for Standard/non­ standard/classificationconceptassignments. Domain forStandardConcepts forsourceconceptsforclassification concepts Condition SNOMED,ICDO3 SNOMEDVeterinary MedDRA Procedure SNOMED,CPT4, HCPCS,ICD10PCS, ICD9Proc,OPCS4SNOMEDVeterinary, HemOnc,NAACCRNoneatthispoint Measurement SNOMED,LOINC SNOMEDVeterinary, NAACCR,CPT4, HCPCS,OPCS4,PPINoneatthispoint Drug RxNorm,RxNorm Extension,CVXHCPCS,CPT4, HemOnc,NAAACCRATC Device SNOMED Others,currentlynot normalizedNoneatthispoint Observation SNOMED Others Noneatthispoint Visit CMSPlaceofService, ABMT,NUCCSNOMED,HCPCS, CPT4,UB04Noneatthispoint 5.2.9 Concept Codes Conceptcodesaretheidentifiersusedinthesourcevocabularies. Forexample,ICD9CM or NDC codes are stored in this field, while the OMOP tables use the concept ID as a foreignkeyintotheCONCEPTtable. Thereasonisthatthenamespaceoverlapsacross vocabularies, i.e. the same code can exist in different vocabularies with completely dif­ ferentmeanings(seeTable 5.3) Table5.3: Conceptswithidenticalconceptcode1001,butdifferent vocabularies,domainsandconceptclasses. ConceptIDConcept Code ConceptName DomainIDVocabulary IDConcept Class 35803438 1001 Granulocyte colony­ stimulating factorsDrug HemOnc Component Class 35942070 1001 AJCCTNM ClinTMeasurement NAACCR NAACCR Variable 1036059 1001 Antipyrine Drug RxNorm Ingredient\n",
      "page text: 64 Chapter 5. Standardized Vocabularies ConceptIDConcept Code ConceptName DomainIDVocabulary IDConcept Class 38003544 1001 Residential Treatment­ PsychiatricRevenue CodeRevenue CodeRevenue Code 43228317 1001 Aceprometazine maleateDrug BDPM Ingredient 45417187 1001 Brompheniramine Maleate,10 mg/mL injectable solutionDrug Multum Multum 45912144 1001 Serum Specimen CIEL Specimen 5.2.10 Life-Cycle Vocabulariesarerarelypermanentcorporawithafixedsetofcodes. Instead, codesand concepts are added and get deprecated. The OMOP CDM is a model to support lon­ gitudinal patient data, which means it needs to support concepts that were used in the pastandmightnolongerbeactive,aswellassupportingnewconceptsandplacingthem intocontext. TherearethreefieldsintheCONCEPTtablethatdescribethepossiblelife­ cyclestatuses: VALID_START_DATE,VALID_END_DATE,andINVALID_REASON. Theirvaluesdifferdependingontheconceptlife­cyclestatus: •Active or new concept –Description: Conceptinuse. –VALID_START_DATE:Dayofinstantiationofconcept,ifthatisnotknown dayofincorporationofconceptinVocabularies,ifthatisnotknown1970­1­1. –VALID_END_DATE:Setto2099­12­31asaconventiontoindicate“Might becomeinvalidinanundefinedfuture,butactiverightnow”. –INVALID_REASON:NULL •Deprecated Concept with no successor –Description: Concept inactive and cannot be used as Standard (see Section 5.2.6). –VALID_START_DATE:Dayofinstantiationofconcept,ifthatisnotknown dayofincorporationofconceptinVocabularies,ifthatisnotknown1970­1­1. –VALID_END_DATE:Dayinthepastindicatingdeprecation,orifthatisnot knowndayofvocabularyrefreshwhereconceptinvocabularywentmissing orsettoinactive. –INVALID_REASON:“D” •Upgraded Concept with successor –Description: Conceptinactive,buthasdefinedsuccessor. Thesearetypically conceptswhichwentthroughde­duplication. –VALID_START_DATE:Dayofinstantiationofconcept,ifthatisnotknown\n",
      "page text: 5.3. Relationships 65 dayofincorporationofconceptinVocabularies,ifthatisnotknown1970­1­1. –VALID_END_DATE:Dayinthepastindicatinganupgrade,orifthatisnot knowndayofvocabularyrefreshwheretheupgradewasincluded. –INVALID_REASON:“U” •Reused code for another new concept –Description: Thevocabularyreusedtheconceptcodeofthisdeprecatedcon­ ceptforanewconcept. –VALID_START_DATE:Dayofinstantiationofconcept,ifthatisnotknown dayofincorporationofconceptinVocabularies,ifthatisnotknown1970­1­1. –VALID_END_DATE:Dayinthepastindicatingdeprecation,orifthatisnot knowndayofvocabularyrefreshwhereconceptinvocabularywentmissing orsettoinactive. –INVALID_REASON:“R” In general, concept codes are not reused. But there are a few vocabularies that deviate fromthisrule,inparticularHCPCS,NDCandDRG.Forthose,thesameconceptcodeap­ pearsinmorethanoneconceptofthesamevocabulary. TheirCONCEPT_IDvaluestays unique. Thesereusedconceptcodesaremarkedwithan“R”intheINVALID_REASON field, and the VALID_START_DATE to VALID_END_DATE period should be used to distinguishconceptswiththesameconceptcodes. 5.3 Relationships Anytwoconceptscanhaveadefinedrelationship,regardlessofwhetherthetwoconcepts belongtothesamedomainorvocabulary. Thenatureoftherelationshipsisindicatedin itsshortcase­sensitive uniquealphanumeric IDin theRELATIONSHIP_IDfieldofthe CONCEPT_RELATIONSHIPtable. Relationshipsaresymmetrical,i.e.foreachrelation­ ship an equivalent relationship exists, where the content of the fields CONCEPT_ID_1 and CONCEPT_ID_2 are swapped, and the RELATIONHSIP_ID is changed to its op­ posite. For example, the “Maps to” relationship has an opposite relationship “Mapped from.” CONCEPT_RELATIONSHIP table records also have life­cycle fields RELATION­ SHIP_START_DATE, RELATIONSHIP_END_DATE and INVALID_REASON. However, only active records with INVALID_REASON = NULL are available through ATHENA. Inactive relationships are kept in the Pallas system for internal processing only. TheRELATIONSHIPtableservesasthereferencewiththefulllistofrelationship IDsandtheirreversecounterparts. 5.3.1 Mapping Relationships These relationships provide translations from non­standard to Standard concepts, sup­ portedbytworelationshipIDpairs(seeTable 5.4).\n",
      "page text: 66 Chapter 5. Standardized Vocabularies Table5.4: Typeofmappingrelationships. RelationshipID pair Purpose “Mapsto”and “Mappedfrom”MappingtoStandardConcepts. StandardConceptsaremapped tothemselves,non­standardconceptstoStandardConcepts. Mostnon­standardandallStandardConceptshavethis relationshiptoaStandardConcept. Theformerarestoredin *_SOURCE_CONCEPT_ID,andthelatterinthe *_CONCEPT_IDfields. Classificationconceptsarenotmapped. “Mapstovalue” and“Value mappedfrom”MappingtoaconceptthatrepresentsaValuetobeplacedinto theVALUE_AS_CONCEPT_IDfieldsoftheMEASUREMENT andOBSERVATIONtables. The purpose of these mapping relationships is to allow a crosswalk between equivalent conceptstoharmonizehowclinicaleventsarerepresentedintheOMOPCDM.Thisisa mainachievementoftheStandardizedVocabularies. “Equivalentconcepts”meansitcarriesthesamemeaning,and,importantly,thehierarchi­ caldescendantscoverthesamesemanticspace. Ifanequivalentconceptisnotavailable and the concept is not Standard, it is still mapped, but to a slightly broader concept (so­ called “up­hill mappings”). For example, ICD10CM W61.51 “Bitten by goose” has no equivalent in the SNOMED vocabulary, which is generally used for standard condition concepts. Instead,itismappedtoSNOMED217716004“Peckbybird,”losingthecon­ textofthebirdbeingagoose. Up­hillmappingsareonlyusedifthelossofinformation isconsideredirrelevanttostandardresearchusecases. Some mappings connect a source concept to more than one Standard Concept. For ex­ ample, ICD9CM 070.43 “Hepatitis E with hepatic coma” is mapped to both SNOMED 235867002 “Acute hepatitis E” as well as SNOMED 72836002 “Hepatic Coma.” The reasonforthisisthattheoriginalsourceconceptisapre­coordinatedcombinationoftwo conditions,hepatitisandcoma. SNOMEDdoesnothavethatcombination,whichresults intworecordswrittenfortheICD9CMrecord,onewitheachmappedStandardConcept. Relationships“Mapstovalue”havethepurposeofsplittingofavalueforOMOPCDM tablesfollowinganentity­attribute­value(EAV)model. Thisistypicallythecaseinthe followingsituations: •Measurementsconsistingofatestandaresultvalue •Personalorfamilydiseasehistory •Allergytosubstance •Needforimmunization In these situations, the source concept is a combination of the attribute (test or history) andthevalue(testresultordisease). The“Mapsto”relationshipmapsthissourcetothe\n",
      "page text: 5.3. Relationships 67 attribute concept, and the “Maps to value” to the value concept. See Figure 5.5for an example. Figure 5.5: One­to­many mapping between source concept and Standard Concepts. A pre­coordinated concept is split into two concepts, one of which is the attribute (here historyofclinicalfinding)andtheotheroneisthevalue(pepticulcer). While”Mapsto” relationshipwillmaptoconceptsofthemeasurementorobservationdomains,the‘Maps tovalue”conceptshavenodomainrestriction. MappingofconceptsisanothercentralfeatureoftheOMOPStandardizedVocabularies providedforfreeandsupportingtheeffortsofthecommunityconductingNetworkStud­ ies. Mappingrelationshipsarederivedfromexternalsourcesormaintainedmanuallyby theVocabularyTeam. Thismeanstheyarenotperfect. Ifyoufindwrongorobjectionable mappingrelationshipsitiscrucialthatyoureportandhelpimprovetheprocessthrough aForumsorCDMissue post. AmoredetaileddescriptionofmappingconventionscanbefoundintheOHDSIWiki.5 5.3.2 Hierarchical Relationships Relationships which indicate a hierarchy are defined through the “Is a” ­ “Subsumes” relationship pair. Hierarchical relationships are defined such that the child concept has all the attributes of the parent concept, plus one or more additional attributes or a more precisely defined attribute. For example, SNOMED 49436004 “Atrial fibrillation” is related to SNOMED 17366009 “Atrial arrhythmia” through a “Is a” relationship. Both conceptshaveanidenticalsetofattributesexceptthetypeofarrhythmia,whichisdefined asfibrillationinonebutnottheother. Conceptscanhavemorethanoneparentandmore thanonechildconcept. Inthisexample,SNOMED49436004“Atrialfibrillation”isalso an“Isa”toSNOMED40593004“Fibrillation.” 5.3.3 Relationships Between Concepts of Different Vocabularies Theserelationshipsaretypically ofthetype “VocabularyA­ VocabularyBequivalent”, whichiseithersuppliedbytheoriginalsourceofthevocabularyorisbuiltbytheOHDSI 5https://www.ohdsi.org/web/wiki/doku.php?id=documentation:vocabulary:mapping\n",
      "page text: 68 Chapter 5. Standardized Vocabularies Vocabularyteam. Theymayserveasapproximatemappingsbutoftentimesarelesspre­ cisethanthebettercuratedmappingrelationships. High­qualityequivalencerelationships (suchas“Source­RxNormequivalent”)arealwaysduplicatedby“Mapsto”relationship. 5.3.4 Relationships Between Concepts of the Same Vocabulary Internalvocabularyrelationshipsareusuallysuppliedbythevocabularyprovider. Fullde­ scriptionscanbefoundinthevocabularydocumentationundertheindividualvocabulary attheOHDSIWiki.6 Many of these define relationships between clinical events and can be used for infor­ mation retrieval. For example, disorders of the urethra can be found by following the “Findingsiteof”relationship(seeTable 5.5): Table5.5: “Findingsiteof”relationshipofthe“Urethra,” indicat­ ingconditionsthataresituatedallinthethisanatomicalstructure. CONCEPT_ID_1 CONCEPT_ID_2 4000504“Urethrapart” 36713433“Partialduplicationofurethra” 4000504“Urethrapart” 433583“Epispadias” 4000504“Urethrapart” 443533“Epispadias,male” 4000504“Urethrapart” 4005956“Epispadias,female” The quality and comprehensiveness of these relationships varies depending on the qual­ ity in the original vocabulary. Generally, vocabularies that are used to draw Standard Conceptsfrom,suchasSNOMED,arechosenforthereasonoftheirbettercurationand thereforetendtohavehigherqualityinternalrelationshipsaswell. 5.4 Hierarchy Withinadomain,standardandclassificationconceptsareorganizedinahierarchicalstruc­ tureandstoredintheCONCEPT_ANCESTORtable. Thisallowsqueryingandretriev­ ing concepts and all their hierarchical descendants. These descendants have the same attributesastheirancestor,butalsoadditionalormoredefinedones. TheCONCEPT_ANCESTORtableisbuiltautomaticallyfromtheCONCEPT_RELATIONSHIP tabletraversingallpossibleconceptsconnectedthroughhierarchicalrelationships. These are the “Is a” ­ “Subsumes” pairs (see Figure 5.6), and other relationships connecting hierarchiesacrossvocabularies. Thechoicewhetherarelationshipparticipatesinthehier­ archyconstructorisdefinedforeachrelationshipIDbytheflagDEFINES_ANCESTRY intheRELATIONSHIPreferencetable. Theancestraldegree,orthenumberofstepsbetweenancestoranddescendant,iscaptured in the MIN_LEVELS_OF_SEPARATION and MAX_LEVELS_OF_SEPARATION 6https://www.ohdsi.org/web/wiki/doku.php?id=documentation:vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████▉                                                                                                            | 98/464 [00:00<00:03, 109.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 5.4. Hierarchy 69 Figure 5.6: Hierarchy of the condition “Atrial fibrillation.” First degree ancestry is de­ finedthrough“Isa”and“Subsumes”relationships,whileallhigherdegreerelationsare inferred and stored in the CONCEPT_ANCESTOR table. Each concept is also its own descendantwithbothlevelsofseparationequalto0.\n",
      "page text: 70 Chapter 5. Standardized Vocabularies fields, defining the shortest or longest possible connection. Not all hierarchical rela­ tionships contribute equally to the levels­of­separation calculation. A step counted for the degree is determined by the IS_HIERARCHICAL flag in the RELATIONSHIP referencetableforeachrelationshipID. Atthemoment,ahigh­qualitycomprehensivehierarchyexistsonlyfortwodomains: drug andcondition. Procedure,measurementandobservationdomainsareonlypartiallycov­ ered and in the process of construction. The ancestry is particularly useful for the drug domainasitallowsbrowsingalldrugswithagiveningredientormembersofdrugclasses irrespectiveofthecountryoforigin,brandnameorotherattributes. 5.5 Internal Reference T ables DOMAIN_ID, VOCABULARY_ID, CONCEPT_CLASS_ID (all in CONCEPT records) and CONCEPT_RELATIONSHIP_ID (in CONCEPT_RELATIONSHIP) are all controlled by their own vocabularies. They are defined in the four reference tables DOMAIN, VOCABULARY, CONCEPT_CLASS and RELATIONSHIP, containing the*_IDfieldsasprimarykeys,amoredetailed*_NAMEfieldanda*_CONCEPT_ID field with a reference back to the CONCEPT table, which contains a concept for each of the reference table records. The purpose of these duplicate records is to support an informationmodelallowingforautomaticnavigationengines. The VOCABULARY table also contains the VOCABULARY_REFERENCE and VOCABULARY_VERSIONfieldsreferringtothesourceandversionoftheoriginalvo­ cabulary. The RELATIONSHIP table has the additional fields DEFINES_ANCESTRY, IS_HIERARCHICAL and REVERSE_RELATIONSHIP_ID. The latter defines the counterrelationshipIDforapairofrelationships. 5.6 Special Situations 5.6.1 Gender GenderintheOMOPCDMandStandardizedVocabulariesdenotesthebiologicalsexat birth. Often,questionsareposedhowtodefinealternativegenders. Theseusecaseshave tobecoveredthroughrecordsintheOBSERVATIONtable,wheretheself­definedgender ofapersonisstored(ifthedataassetcontainssuchinformation). 5.6.2 Race and Ethnicity These follow the definitions of how the US government defines this. Ethnicity is a dif­ ferentiationofHispanicornon­Hispanicpopulations,whichcanhaveanyrace. Raceis dividedintothecommon5topraces,whichhaveethnicitiesastheirhierarchicaldescen­ dants. Mixedracesarenotincluded.\n",
      "page text: 5.6. Special Situations 71 5.6.3 Diagnostic Coding Schemes and OMOP Conditions Commonly used coding schemes such as ICD­9 or ICD­10 define more or less well­ defined diagnoses based on a proper diagnostic work­up. The condition domain is not identical with this semantic space, but partially overlapping. For example, conditions alsocontainsignsandsymptomsthatarerecordedbeforeadiagnosisisderived,andICD codescontainconceptsthatbelongtootherdomains(e.g.procedures). 5.6.4 Procedure Coding Systems Similarly, coding schemes like HCPCS and CPT4 are thought to be listings of medical procedures. Inreality,theyaremorelikeamenuofjustificationsforpaymentformedical service. Many of these services are subsumed under the procedure domain, but many conceptsfalloutsidethisrealm. 5.6.5 Devices DeviceconceptshavenostandardizedcodingschemethatcouldbeusedtosourceStan­ dard Concepts. In many source data, devices are not even coded or contained in an ex­ ternal coding scheme. For this same reason, there is currently no hierarchical system available. 5.6.6 Visits and Services Visitsconceptsdefinethenatureofhealthcareencounters. Inmanysourcesystemsthey are called Place of Service, denoting some organization or physical structure, such as a hospital. Inothers,theyarecalledservices. Thesealsodifferbetweencountries,andtheir definition is hard to obtain. Care sites are often specializing on one of few visits (XYZ Hospital), but still should not be defined by them (even in XYZ hospital patients might encounternon­hospitalvisits). 5.6.7 Providers and Specialties Any human provider is defined in the provider domain. These can be medical profes­ sionals such as doctors and nurses, but also non­medical providers like optometrists or shoemakers. Specialtiesaredescendantsoftheprovider“Physician.” CareSitescannot carryaspecialty, eventhoughtheyareoftendefinedbythespecialtyoftheirmainstaff (“Surgicaldepartment”). 5.6.8 Therapeutic Areas With Special Requirements The Standardized Vocabularies cover all aspects of healthcare in a comprehensive fash­ ion. However,sometherapeuticareashavespecialneedsandrequirespecialvocabularies. Examples are oncology, radiology, and genomics. Special OHDSI Working Groups de­ veloptheseextensions. Asaresult,theOMOPStandardizedVocabulariesconstitutesan\n",
      "page text: 72 Chapter 5. Standardized Vocabularies integrated system, where concepts from different origins and purposes all reside in the samedomain­specifichierarchies. 5.6.9 Standard Concepts in the Drug Domain ManyconceptsofthedrugdomainaresourcedfromRxNorm,apubliclyavailablevocab­ ularyproducedbytheUSNationalLibraryofMedicine. However,drugsoutsidetheUS mayormaynotbecovered,dependingonwhetherornotthecombinationofingredient, formandstrengthismarketedintheUS.DrugsthatarenotontheUSmarketareadded bytheOHDSIVocabularyTeamunderavocabularycalled RxNormExtension ,whichis theonlylargedomainvocabularyproducedbyOHDSI. 5.6.10 Flavors of NULL Manyvocabulariescontaincodesaboutabsenceofinformation. Forexample,ofthefive gender concepts 8507 “Male,” 8532 “Female,” 8570 “Ambiguous,” 8551 “Unknown,” and8521“Other”,onlythefirsttwoareStandard,andtheotherthreearesourceconcepts with no mapping. In the Standardized Vocabularies, there is no distinction made why a piece of information is not available; it might be because of an active withdrawal of informationbythepatient,amissingvalue,avaluethatisnotdefinedorstandardizedin someway,ortheabsenceofamappingrecordinCONCEPT_RELATIONSHIP.Anysuch conceptisnotmapped,whichcorrespondstoadefaultmappingtotheStandardConcept withtheconceptID=0. 5.7 Summary –All events and administrative facts are represented in the OMOP Standard­ ized Vocabularies as concepts, concept relationships, and concept ancestor hierarchy. –Most of these are adopted from existing coding schemes or vocabularies, whilesomeofthemarecuratedde­novobytheOHDSIVocabularyTeam. –Allconceptsareassignedadomain,whichcontrolswherethefactrepresented bytheconceptisstoredintheCDM. –Conceptsofequivalentmeaningindifferentvocabulariesaremappedtoone of them, which is designated the Standard Concept. The others are source concepts. –Mappingisdonethroughtheconceptrelationships“Mapsto”and“Mapsto value”. –Thereisanadditionalclassofconceptscalledclassificationconcepts,which are non­standard, but in contrast to source concepts they participate in the hierarchy. –Conceptshavealife­cycleovertime.\n",
      "page text: 5.8. Exercises 73 –Conceptswithinadomainareorganizedintohierarchies. Thequalityofthe hierarchy differs between domains, and the completion of the hierarchy sys­ temisanongoingtask. –You are strongly encouraged to engage with the community if you believe youfoundamistakeorinaccuracy. 5.8 Exercises Prerequisites ForthesefirstexercisesyouwillneedtolookupconceptsintheStandardizedVocabular­ ies,whichcanbedonethroughATHENA7orATLAS.8 Exercise 5.1. WhatistheStandardConceptIDfor“Gastrointestinalhemorrhage”? Exercise 5.2. WhichICD­10CMcodesmaptotheStandardConceptfor“Gastrointestinal hemorrhage”? WhichICD­9CMcodesmaptothisStandardConcept? Exercise 5.3. WhataretheMedDRApreferredtermsthatareequivalenttotheStandard Conceptfor“Gastrointestinalhemorrhage”? SuggestedanswerscanbefoundinAppendix E.2. 7http://athena.ohdsi.org/ 8http://atlas­demo.ohdsi.org\n",
      "page text: 74 Chapter 5. Standardized Vocabularies\n",
      "page text: Chapter 6 Extract T ransform Load Chapter leads: Clair Blacketer & Erica Voss 6.1 Introduction Inordertogetfromthenative/rawdatatotheOMOPCommonDataModel(CDM)we havetocreateanextract,transform,andload(ETL)process. Thisprocessshouldrestruc­ ture the data to the CDM, and add mappings to the Standardized Vocabularies, and is typicallyimplementedasasetofautomatedscripts,forexampleSQLscripts. Itisimpor­ tantthatthisETLprocessisrepeatable,sothatitcanbererunwheneverthesourcedata isrefreshed. CreatinganETLisusuallyalargeundertaking. Overtheyears,wehavedevelopedbest practices,consistingoffourmajorsteps: 1.DataexpertsandCDMexpertstogetherdesigntheETL. 2.Peoplewithmedicalknowledgecreatethecodemappings. 3.AtechnicalpersonimplementstheETL. 4.Allareinvolvedinqualitycontrol. In this chapter we will discuss each of these steps in detail. Several tools have been developed by the OHDSI community to support some of these steps, and these will be discussedaswell. WeclosethischapterwithadiscussionofCDMandETLmaintenance. 6.2 Step 1: Design the ETL ItisimportanttoclearlyseparatethedesignoftheETLfromtheimplementationofthe ETL.DesigningtheETLrequiresextensiveknowledgeofboththesourcedata,aswellas the CDM. Implementing the ETL on the other hand typically relies mostly on technical expertiseonhowtomaketheETLcomputationallyefficient. Ifwetrytodobothatonce, 75\n",
      "page text: 76 Chapter 6. Extract Transform Load wearelikelytogetstuckinnitty­grittydetails,whileweshouldbefocusingontheoverall picture. Two closely­integrated tools have been developed to support the ETL design process: WhiteRabbit,andRabbit­in­a­Hat. 6.2.1 White Rabbit To initiate an ETL process on a database you need to understand your data, including the tables, fields, and content. This is where the White Rabbit tool comes in. White Rabbit is a software tool to help prepare for ETLs of longitudinal healthcare databases into theOMOP CDM . White Rabbit scans your data and creates a report containing all the information necessary to begin designing the ETL. All source code and installation instructions,aswellasalinktothemanual,areavailableonGitHub.1 Scope and Purpose WhiteRabbit’smainfunctionistoperformascanofthesourcedata,providingdetailed information on the tables, fields, and values that appear in a field. The source data can be in comma­separated text files, or in a database (MySQL, SQL Server, Oracle, Post­ greSQL,MicrosoftAPS,MicrosoftAccess,AmazonRedshift). Thescanwillgeneratea reportthatcanbeusedasareferencewhendesigningtheETL,forinstancebyusingitin conjunctionwiththeRabbit­In­a­Hattool. WhiteRabbitdiffersfromstandarddatapro­ filingtoolsinthatitattemptstopreventthedisplayofpersonallyidentifiableinformation (PII)datavaluesinthegeneratedoutputdatafile. Process Overview Thetypicalsequenceforusingthesoftwaretoscansourcedata: 1.Set working folder, the location on the local desktop computer where results will beexported. 2.ConnecttothesourcedatabaseorCSVtextfileandtestconnection. 3.Selectthetablesofinterestforthescanandscanthetables. 4.WhiteRabbitcreatesanexportofinformationaboutthesourcedata. Setting a Working Folder After downloading and installing the White Rabbit application, the first thing you need todoissetaworkingfolder. AnyfilesthatWhiteRabbitcreateswillbeexportedtothis localfolder. Usethe“PickFolder”buttonshowninFigure 6.1tonavigateinyourlocal environmentwhereyouwouldlikethescandocumenttogo. 1https://github.com/OHDSI/WhiteRabbit .\n",
      "page text: 6.2. Step 1: Design the ETL 77 Figure6.1: The”PickFolder”buttonallowsthespecificationofaworkingfolderforthe WhiteRabbitapplication.\n",
      "page text: 78 Chapter 6. Extract Transform Load Connection to a Database White Rabbit supports delimited text files and various database platforms. Hover the mouse over the various fields to get a description of what is required. More detailed informationcanbefoundinthemanual. Scanning the Tables in a Database Afterconnectingtoadatabase,youcanscanthetablescontainedtherein. Ascangenerates a report containing information on the source data that can be used to help design the ETL. Using the Scan tab shown in Figure 6.2you can either select individual tables in theselectedsourcedatabasebyclickingon“Add”(Ctrl+mouseclick),orautomatically selectalltablesinthedatabasebyclickingon“AddallinDB”. Figure6.2: WhiteRabbitScantab. Thereareafewsettingoptionsaswellwiththescan: •Checkingthe“Scanfieldvalues”tellsWhiteRabbitthatyouwouldliketoinvesti­ gatewhichvaluesappearinthecolumns. •“Mincellcount”isanoptionwhenscanningfieldvalues. Bydefault,thisissetto 5,meaningvaluesinthesourcedatathatappearlessthan5timeswillnotappearin thereport. Individualdatasetsmayhavetheirownrulesaboutwhatthisminimum cellcountcanbe.\n",
      "page text: 6.2. Step 1: Design the ETL 79 •“Rowspertable”isanoptionwhenscanningfieldvalues. Bydefault,WhiteRabbit willscan100,000randomlyselectedrowsinthetable. Once all settings are completed, press the “Scan tables” button. After the scan is com­ pletedthereportwillbewrittentotheworkingfolder. Interpreting the Scan Report Oncethescaniscomplete, anExcelfileisgeneratedintheselectedfolderwithonetab presentforeachtablescannedaswellasanoverviewtab. Theoverviewtablistsalltables scanned,eachfieldineachtable,thedatatypeofeachfield,themaximumlengthofthe field,thenumberofrowsinthetable,thenumberofrowsscanned,andhowofteneach fieldwasfoundtobeempty. Figure 6.3. showsanexampleoverviewtab. Figure6.3: Exampleoverviewtabfromascanreport. Thetabsforeachofthetablesshoweachfield,thevaluesineachfield,andthefrequency of each value. Each source table column will generate two columns in the Excel. One columnwilllistalldistinctvaluesthathavea“Mincellcount”greaterthanwhatwasset attimeofthescan. Ifalistofuniquevalueswastruncated,thelastvalueinthelistwillbe “Listtruncated”;thisindicatesthatthereareoneormoreadditionaluniquesourcevalues that appear less than the number entered in the “Min cell count”. Next to each distinct valuewillbeasecondcolumnthatcontainsthefrequency(thenumberoftimesthatvalue occursinthesample). Thesetwocolumns(distinctvaluesandfrequency)willrepeatfor allthesourcecolumnsinthetableprofiledintheworkbook. Thereportispowerfulinunderstandingyoursourcedatabyhighlightingwhatexists. For example,iftheresultsshowninFigure 6.4weregivenbackonthe“Sex”columnwithin oneofthetablesscanned,wecanseethatthereweretwocommonvalues(1and2)that\n",
      "page text: 80 Chapter 6. Extract Transform Load Figure6.4: Examplevaluesforasinglecolumn. appeared 61,491 and 35,401 times respectively. White Rabbit will not define 1 as male and2asfemale;thedataholderwilltypicallyneedtodefinesourcecodesuniquetothe source system. However, these two values (1 & 2) are not the only values present in thedatabecauseweseethislistwastruncated. Theseothervaluesappearwithverylow frequency(definedby“Mincellcount”)andoftenrepresentincorrectorhighlysuspicious values. WhengeneratinganETLweshouldnotonlyplantohandlethehigh­frequency genderconcepts1and2buttheotherlow­frequencyvaluesthatexistwithinthiscolumn. Forexample,ifthoselowerfrequencygenderswere“NULL”wewanttomakesurethe ETLcanhandleprocessingthatdataandknowswhattodointhatsituation. 6.2.2 Rabbit-In-a-Hat WiththeWhiteRabbitscaninhand,wehaveaclearpictureofthesourcedata. Wealso knowthefullspecificationoftheCDM.Nowweneedtodefinethelogictogofromone to the other. This design activity requires thorough knowledge of both the source data and the CDM. The Rabbit­in­a­Hat tools that comes with the White Rabbit software is specificallydesignedtosupportateamofexpertsintheseareas. Inatypicalsetting,the ETLdesignteamsitstogetherinaroom,whileRabbit­in­a­Hatisprojectedonascreen. In a first round, the table­to­table mappings can be collaboratively decided, after which field­to­fieldmappingscanbedesigned,whiledefiningthelogicbywhichvalueswillbe transformed. Scope and Purpose Rabbit­In­a­Hat is designed to read and display a White Rabbit scan document. White Rabbit generates information about the source data while Rabbit­In­a­Hat uses that in­ formation and through a graphical user interface to allow a user to connect source data totablesandcolumnswithintheCDM.Rabbit­In­a­Hatgeneratesdocumentationforthe ETLprocess,itdoesnotgeneratecodetocreateanETL. Process Overview ThetypicalsequenceforusingthissoftwaretogeneratedocumentationofanETL: 1.ScannedresultsfromWhiteRabbitcompleted. 2.Openscannedresults;interfacedisplayssourcetablesandCDMtables. 3.ConnectsourcetablestoCDMtableswherethesourcetableprovidesinformation forthatcorrespondingCDMtable.\n",
      "page text: 6.2. Step 1: Design the ETL 81 4.ForeachsourcetabletoCDMtableconnection,furtherdefinetheconnectionwith sourcecolumntoCDMcolumndetail. 5.SaveRabbit­In­a­HatworkandexporttoaMSWorddocument. Writing ETL Logic Once you have opened your White Rabbit scan report in Rabbit­In­a­Hat you are ready tobegindesigningandwritingthelogicforhowtoconvertthesourcedatatotheOMOP CDM. As an example, the next few sections will depict how some of the tables in the Synthea2databasemightlookduringconversion. General Flow of an ETL Since the CDM is a person­centric model it is always a good idea to start mapping the PERSON table first. Every clinical event table (CONDITION_OCCURRENCE, DRUG_EXPOSURE, PROCEDURE_OCCURRENCE, etc.) refers to the PERSON table by way of the person_id so working out the logic for the PERSON table first makes it easier later on. After the PERSON table a good rule of thumb is to convert the OBSERVATION_PERIOD table next. Each person in a CDM database should have at least one OBSERVATION_PERIOD and, generally, most events for a person fall within this timeframe. Once the PERSON and OBSERVATION_PERIOD tables are done the dimensional tables like PROVIDER, CARE_SITE, and LOCATION are typicallynext. Thefinaltablelogicthatshouldbeworkedoutpriortotheclinicaltables is VISIT_OCCURRENCE. Often this is the most complicated logic in the entire ETL and it is some of the most crucial since most events that occur during the course of a person’s patient journey will happen during visits. Once those tables are finished it is yourchoicewhichCDMtablestomapandinwhichorder. It is often the case that, during CDM conversion, you will need to make provisions for intermediatetables. ThiscouldbeforassigningthecorrectVISIT_OCCURRENCE_IDs to events, or for mapping source codes to standard concepts (doing this step on the fly isoftenveryslow). Intermediatetablesare100%allowedandencouraged. Whatisdis­ couragedisthepersistenceandrelianceontheseintermediatetablesoncetheconversion iscomplete. Mapping Example: Person Table The Synthea data structure contains 20 columns in the patients table but not all were neededtopopulatethePERSONtable, asseeninFigure 6.6. Thisisverycommonand should not be cause for alarm. In this example many of the data points in the Synthea patientstablethatwerenotusedintheCDMPERSONtablewereadditionalidentifiers likepatientname,driver’slicensenumber,andpassportnumber. 2SyntheaTMisapatientgeneratorthataimstomodelrealpatients. Dataarecreatedbasedonparameters passed to the application.The structure of the data can be found here: https://github.com/synthetichealth/ synthea/wiki .\n",
      "page text: 82 Chapter 6. Extract Transform Load Figure6.5: GeneralflowofanETLandwhichtablestomapfirst. Figure6.6: MappingofSyntheaPatientstabletoCDMPERSONtable.\n",
      "page text: 6.2. Step 1: Design the ETL 83 Table6.1belowshowsthelogicthatwasimposedontheSyntheapatientstabletoconvert ittotheCDMPERSONtable. The‘DestinationField’discusseswhereintheCDMdata is being mapped to. The ‘Source field’ highlights the column from the source table (in thiscasepatients)thatwillbeusedtopopulatetheCDMcolumn. Finally,the‘Logic& comments’columngivesexplanationsforthelogic. Table6.1: ETLlogictoconverttheSyntheaPatientstabletoCDM PERSONtable. DestinationFieldSource field Logic&comments PERSON_ID Autogenerate. ThePERSON_IDwillbe generatedatthetimeofimplementation. Thisisbecausetheidvaluefromthesource isavarcharvaluewhilethePERSON_IDis aninteger. Theidfieldfromthesourceisset asthePERSON_SOURCE_VALUEto preservethatvalueandallowfor error­checkingifnecessary. GENDER_CONCEPT_ID gender Whengender=‘M’thenset GENDER_CONCEPT_IDto8507,when gender=‘F’thensetto8532. Dropanyrows withmissing/unknowngender. Thesetwo conceptswerechosenastheyaretheonly twostandardconceptsinthegenderdomain. Thechoicetodroppatientswithunknown genderstendstobesite­based,thoughitis recommendedtheyareremovedaspeople withoutagenderareexcludedfromanalyses. YEAR_OF_BIRTH birthdate Takeyearfrombirthdate MONTH_OF_BIRTH birthdate Takemonthfrombirthdate DAY_OF_BIRTH birthdate Takedayfrombirthdate BIRTH_DATETIME birthdate Withmidnightastime00:00:00. Here,the sourcedidnotsupplyatimeofbirthsothe choicewasmadetosetitatmidnight. RACE_CONCEPT_ID race Whenrace=‘WHITE’thensetas8527, whenrace=‘BLACK’thensetas8516, whenrace=‘ASIAN’thensetas8515, otherwisesetas0. Theseconceptswere chosenbecausetheyarethestandard conceptsbelongingtotheracedomainthat mostcloselyalignwiththeracecategoriesin thesource.\n",
      "page text: 84 Chapter 6. Extract Transform Load DestinationFieldSource field Logic&comments ETHNICITY_ CONCEPT_IDrace ethnicityWhenrace=‘HISPANIC’,orwhenethnicity in(‘CENTRAL_AMERICAN’, ‘DOMINICAN’,‘MEXICAN’, ‘PUERTO_RICAN’, ‘SOUTH_AMERICAN’)thensetas 38003563,otherwisesetas0. Thisisagood exampleofhowmultiplesourcecolumns cancontributetooneCDMcolumn. Inthe CDMethnicityisrepresentedaseither HispanicornotHispanicsovaluesfrom boththesourcecolumnraceandsource columnethnicitywilldeterminethisvalue. LOCATION_ID PROVIDER_ID CARE_SITE_ID PERSON_SOURCE_ VALUEid GENDER_SOURCE_ VALUEgender GENDER_SOURCE_ CONCEPT_ID RACE_SOURCE_ VALUErace RACE_SOURCE_ CONCEPT_ID ETHNICITY_ SOURCE_VALUEethnicity Inthiscasethe ETHNICITY_SOURCE_VALUEwillhave moregranularitythanthe ETHNICITY_CONCEPT_ID. ETHNICITY_ SOURCE_CONCEPT_ID FormoreexamplesonhowtheSyntheadatasetwasmappedtotheCDMpleaseseethe fullspecificationdocument.3 6.3 Step 2: Create the Code Mappings MoreandmoresourcecodesarebeingaddedtotheOMOPVocabularyallthetime. This means that the coding systems in the data being transformed to the CDM may already 3https://ohdsi.github.io/ETL­Synthea/\n",
      "page text: 6.3. Step 2: Create the Code Mappings 85 beincludedandmapped. ChecktheVOCABULARYtableintheOMOPVocabularyto see which vocabularies are included. To extract the mapping from non­standard source codes (e.g. ICD­10CM codes) to standard concepts (e.g. SNOMED codes), we can use the records in the CONCEPT_RELATIONSHIP table having relationship_id = “Maps to”. Forexample,tofindthestandardconceptIDfortheICD­10CMcode‘I21’(“Acute MyocardialInfarction”),wecanusethefollowingSQL: SELECTconcept_id_2 standard_concept_id FROMconcept_relationship INNERJOINconcept source_concept ONconcept_id =concept_id_1 WHEREconcept_code ='I21' ANDvocabulary_id ='ICD10CM' ANDrelationship_id ='Maps to' ; STANDARD_CONCEPT_ID 312327 Unfortunately,sometimesthesourcedatausescodingsystemsthatarenotintheVocabu­ lary. Inthiscase,amappingmustbecreatedfromthesourcecodingsystemtotheStan­ dard Concepts. Code mapping can be a daunting task, especially when there are many codesinthesourcecodingsystem. Thereareseveralthingsthatcanbedonetomakethe taskeasier: •Focusonthemostfrequentlyusedcodes. Acodethatisneverusedorinfrequently usedisnotworththeeffortofmapping,sinceitwillneverbeusedinarealstudy. •Makeuseofexistinginformationwheneverpossible. Forexample,manynational drug coding systems have been mapped to ATC. Although ATC is not detailed enough for many purposes, the concept relationships between ATC and RxNorm canbeusedtomakegoodguessesofwhattherightRxNormcodesare. •UseUsagi. 6.3.1 Usagi Usagi is a tool to aid the manual process of creating a code mapping. It can make sug­ gestedmappingsbasedontextualsimilarityofcodedescriptions. Ifthesourcecodesare only available in a foreign language, we have found that Google Translate4often gives surprisingly good translation of the terms into English. Usagi allows the user to search fortheappropriatetargetconceptsiftheautomatedsuggestionisnotcorrect. Finally,the usercanindicatewhichmappingsareapprovedtobeusedintheETL.Usagiisavailable onGitHub.5 4https://translate.google.com/ 5https://github.com/OHDSI/Usagi\n",
      "page text: 86 Chapter 6. Extract Transform Load Scope and Purpose Source codes that need mapping are loaded into the Usagi (if the codes are not in En­ glishadditionaltranslationscolumnsareneeded). Atermsimilarityapproachisusedto connectsourcecodestoVocabularyconcepts. However,thesecodeconnectionsneedto bemanuallyreviewedandUsagiprovidesaninterfacetofacilitatethat. Usagiwillonly proposeconceptsthataremarkedasStandardconceptsintheVocabulary. Process Overview Thetypicalsequenceforusingthissoftwareis: 1.Loadcodesfromyoursourcessystem(“sourcecodes”)thatyouwouldliketomap toVocabularyconcepts. 2.UsagiwillrunatermsimilarityapproachtomapsourcecodestoVocabularycon­ cepts. 3.Leverage Usagi interface to check, and where needed, improve suggested map­ pings. Preferably an individual who has experience with the coding system and medicalterminologyshouldbeusedforthisreview. 4.ExportmappingtotheVocabulary’sSOURCE_TO_CONCEPT_MAP. Importing Source Codes into Usagi ExportsourcecodesfromsourcesystemintoaCSVorExcel(.xlsx)file. Thisshouldat least have columns containing the source code and an English source code description, howeveradditionalinformationaboutcodescanbebroughtoveraswell(e.g.doseunit, orthedescriptionintheoriginallanguageiftranslated). Inadditiontoinformationabout thesourcecodes,thefrequencyofthecodeshouldpreferablyalsobebroughtover,since thiscanhelpprioritizewhichcodesshouldreceivethemosteffortinmapping(e.g.you canhave1,000sourcecodesbutonly100aretrulyusedwithinthesystem). Ifanysource codeinformationneedstranslatingtoEnglish,useGoogleTranslate. Note: sourcecodeextractsshouldbebrokenoutbydomain(i.e.drugs,procedures,con­ ditions,observations)andnotlumpedintoonelargefile. Source codes are loaded into Usagi from the File –> Import codes menu. From here an “Importcodes…”willdisplayasseeninFigure 6.7. Inthisfigure,thesourcecodeterms were in Dutch and were also translated into English. Usagi will leverage the English translationstomaptothestandardvocabulary. The “Column mapping” section (bottom left) is where you define for Usagi how to use theimportedtable. Ifyoumousehoveroverthedropdowns,apop­upwillappeardefin­ ing each column. Usagi will not use the “Additional info” column(s) as information to associatesourcecodestoVocabularyconceptcodes;however,thisadditionalinformation mayhelptheindividualreviewingthesourcecodemappingandshouldbeincluded. Finally, in the “Filters” section (bottom right) you can set some restrictions for Usagi whenmapping. Forexample,inFigure 6.7,theuserismappingthesourcecodesonlyto\n",
      "page text: 6.3. Step 2: Create the Code Mappings 87 Figure6.7: Usagisourcecodeinputscreen. concepts in the Condition domain. By default, Usagi only maps to Standard Concepts, butiftheoption“Filterstandardconcepts”isturnedoff,UsagiwillalsoconsiderClassi­ ficationConcepts. Hoveryourmouseoverthedifferentfiltersforadditionalinformation aboutthefilter. One special filter is “Filter by automatically selected concepts / ATC code”. If there is information that you can use to restrict the search, you can do so by providing a list of CONCEPT_IDsoranATCcodeinthecolumnindicatedintheAutoconceptIDcolumn (semicolon­delimited). For example, in the case of drugs there might already be ATC codes assigned to each drug. Even though an ATC code does not uniquely identify a singleRxNormdrugcode,itdoeshelplimitthesearchspacetoonlythoseconceptsthat fallundertheATCcodeintheVocabulary. TousetheATCcode,followthesesteps: 1.IntheColumnmappingsection,switchfrom“AutoconceptIDcolumn”to“ATC column” 2.In the Column mapping section, select the column containing the ATC code as “ATCcolumn”. 3.Turnonthe“Filterbyuserselectedconcepts/ATCcode”onintheFilterssection. You can also use other sources of information than the ATC code to restrict as well. In theexampleshowninthefigureabove,weusedapartialmappingderivedfromUMLS torestricttheUsagisearch. Inthatcasewewillneedtouse“AutoconceptIDcolumn”. Onceallyoursettingsarefinalized,clickthe“Import”buttontoimportthefile. Thefile importwilltakeafewminutesasitisrunningthetermsimilarityalgorithmtomapsource codes.\n",
      "page text: 88 Chapter 6. Extract Transform Load Reviewing Source Code to Vocabulary Concept Maps Onceyouhaveimportedyourinputfileofsourcecodes,themappingprocessbegins. In Figure6.8,youseetheUsagiscreenismadeupof3mainsections: anoverviewtable,the selected mapping section, and place to perform searches. Note that in any of the tables, you can right­click to select the columns that are shown or hidden to reduce the visual complexity. Figure6.8: Usagisourcecodeinputscreen. Approving a Suggested Mapping The“OverviewTable”showsthecurrentmappingofsourcecodestoconcepts. Rightaf­ terimportingsourcecodes,thismappingcontainstheautomaticallygeneratedsuggested mappingsbasedontermsimilarityandanysearchoptions. IntheexampleinFigure 6.8, the English names of Dutch condition codes were mapped to standard concepts in the Conditiondomain,becausetheuserrestrictedthesearchtothatdomain. Usagicompared thesourcecodedescriptionstoconceptnamesandsynonymstofindthebestmatch. Be­ causetheuserhadselected“Includesourceterms”Usagialsoconsideredthenamesand synonyms of all source concepts in the vocabulary that map to a particular concept. If Usagiisunabletomakeamapping,itwillmaptotheCONCEPT_ID=0. Itissuggestedthatsomeonewithexperiencewithcodingsystemshelpmapsourcecodes totheirassociatedstandardvocabulary. Thatindividualwillworkthroughcodebycode in the “Overview Table” to either accept the mapping Usagi has suggested or choose a new mapping. For example in Figure 6.8we see that the Dutch term “Hoesten” which was translated to the English term “Cough”. Usagi used “Cough” and mapped it to the Vocabularyconceptof“4158493­C/O­cough”. Therewasamatchingscoreof0.58asso­\n",
      "page text: 6.3. Step 2: Create the Code Mappings 89 ciatedtothismatchedpair(matchingscoresaretypically0to1with1beingaconfident match), a score of 0.58 signifies that Usagi is not very sure of how well it has mapped thisDutchcodetoSNOMED.Letussayinthiscase,weareokaywiththismapping,we canapproveitbyhittingthegreen“Approve”buttoninthebottomrighthandportionof thescreen. Searching for a New Mapping TherewillbecaseswhereUsagisuggestsamapandtheuserwillbelefttoeithertrytofind abettermappingorsetthemaptonoconcept(CONCEPT_ID=0). Intheexamplegiven in Figure6.8, we see for the Dutch Term “Hoesten”, which was translated to “Cough”. Usagi’ssuggestionwasrestrictedbytheconceptidentifiedinourautomaticallyderived mapping from UMLS, and the result might not be optimal. In the Search Facility, we couldsearchforotherconceptsusingeithertheactualtermitselforasearchboxquery. When using the manual search box, one should keep in mind that Usagi uses a fuzzy search, and does not support structured search queries, so for example not supporting BooleanoperatorslikeANDandOR. To continue our example, suppose we used the search term “Cough” to see if we could find a better mapping. On the right of the Query section of the Search Facility, there is a Filters section, this provides options to trim down the results from the Vocabulary whensearchingforthesearchterm. Inthiscaseweknowwewanttoonlyfindstandard concepts,andweallowconceptstobefoundbasedonthenamesandsynonymsofsource conceptsinthevocabularythatmaptothosestandardconcepts. When we apply these search criteria we find “254761­Cough” and feel this may be an appropriateVocabularyconcepttomaptoourDutchcode. Inordertodothatwecanhit the“Replaceconcept”button,whichyouwillseeinthe“SelectedSourceCode”section update,followedbythe“Approve”button. Thereisalsoan“Addconcept”button,thisal­ lowsformultiplestandardizedVocabularyconceptstomaptoonesourcecode(e.g.some source codes may bundle multiple diseases together while the standardized vocabulary maynot). Concept Information Whenlookingforappropriateconceptstomapto, itisimportanttoconsiderthe“social life” of a concept. The meaning of a concept might depend partially on its place in the hierarchy, and sometimes there are “orphan concepts” in the vocabulary with few or no hierarchicalrelationships,whichwouldbeill­suitedastargetconcepts. Usagiwilloften report the number of parents and children a concept has, and it also possible to show moreinformationbypressingALT+Corselectingview–>Conceptinformationinthe topmenubar. Figure6.9shows the concept information panel. It shows general information about a concept, aswellasitsparents, children, andothersourcecodesthatmaptotheconcept.\n",
      "page text: 90 Chapter 6. Extract Transform Load Figure6.9: Usagiconceptinformationpanel.\n",
      "page text: 6.3. Step 2: Create the Code Mappings 91 Userscanusethispaneltonavigatethehierarchyandpotentiallychooseadifferenttarget concept. Continuetomovethroughthisprocess,codebycode,untilallcodeshavebeenchecked. Inthelistofsourcecodesatthetopofthescreen,byselectingthecolumnheadingyoucan sortthecodes. Often, wesuggestgoingfromthehighestfrequencycodestothelowest. In the bottom left of the screen you can see the number of codes that have approved mappings,andhowmanycodeoccurrencesthatcorrespondsto. It is possible to add comments to mappings, which could be used to document why a mappingdecisionwasmade. Best Practices •Usesomeonewhohasexperiencewithcodingschemes. •Byclickingonacolumnname,youcansortthecolumnsinthe“OverviewTable”. It may be valuable to sort on “Match Score”; reviewing codes that Usagi is most confidentonfirstmayquicklyknockoutasignificantchunkofcodes. Alsosorting on “Frequency” is valuable, spending more effort on frequent codes versus non­ frequentisimportant. •ItisokaytomapsomecodestoCONCEPT_ID=0,somecodesmaynotbeworth ittofindagoodmapandothersmayjustlackapropermap. •It is important to consider the context of a concept, specifically its parents and children. Export the Usagi Map Created OnceyouhavecreatedyourmapwithinUSAGI,thebestwaytouseitmovingforward istoexportitandappendittotheVocabularySOURCE_TO_CONCEPT_MAPtable. To export your mappings, go to File –> Export source_to_concept_map. A pop­ up will appear asking you which SOURCE_VOCABULARY_ID you would like to use, type in a short identifier. Usagi will use this identifier. as the SOURCE_VOCABULARY_ID which will allow you to identify your specific mappingintheSOURCE_TO_CONCEPT_MAPtable. After selecting the SOURCE_VOCABULARY_ID, you give your export CSV a name andsavetolocation. TheexportCSVstructureisinthatoftheSOURCE_TO_CONCEPT_MAP table. ThismappingcouldbeappendedtotheVocabulary’sSOURCE_TO_CONCEPT_MAP table. It would also make sense to append a single row to the VOCABULARY table definingtheSOURCE_VOCABULARY_IDyoudefinedinthestepabove. Finally,itis important to note that only mappings with the “Approved” status will be exported into theCSVfile;themappingneedstobecompletedinUSAGIinordertoexportit.\n",
      "page text: 92 Chapter 6. Extract Transform Load Updating an Usagi Mapping Often a mapping is not a one­time effort. As data is updated perhaps new source codes are added, and the vocabulary is updated regularly, perhaps requiring an update of the mapping. Whenthesetofsourcecodesisupdatedthefollowingstepscansupporttheupdate: 1.Importthenewsourcecodefile 2.ChooseFile–>Applypreviousmapping,andselecttheoldUsagimappingfile 3.Identifycodesthathaven’tinheritedapprovedmappingsfromtheoldmapping,and mapthemasusual. Whenthevocabularyisupdated,followthesesteps: 1.DownloadthenewvocabularyfilesfromAthena 2.RebuildtheUsagiindex(Help–>Rebuildindex) 3.Openthemappingfile 4.Identify codes that map to concepts that in the new vocabulary version no longer areStandardconcepts,andfindmoreappropriatetargetconcepts. 6.4 Step 3: Implement the ETL Oncethedesignandcodemappingsarecompleted,theETLprocesscanbeimplemented inapieceofsoftware. WhentheETLwasbeingdesignedwerecommendedthatpeople whoareknowledgeableaboutthesourceandCDMworktogetheronthetask. Similarly, whentheETLisbeingimplementeditispreferredtousepeoplewhohaveexperiencewith workingwithdata(particularlylargedata)andexperiencewithimplementingETLs. This maymeanworkingwithindividualsoutsideofyourimmediategrouporhiringtechnical consultants to execute the implementation. It is also important to note that this is not aone­timeexpense. Movingforwarditwouldbegoodtohavesomeoneorateamwho spendsatleastsomededicatedtimetomaintainingandrunningtheETL(thiswillbecome clearerinSection 6.7). Implementationusuallyvariessitetositeanditlargelydependsonmanyfactorsincluding infrastructure,sizeofthedatabase,thecomplexityoftheETL,andthetechnicalexpertise available. Because it depends on many factors the OHDSI community does not make a formal recommendation on how best to implement an ETL. There have been groups thatusesimpleSQLbuilders,SAS,C#,Java,andKettle. Allhavetheiradvantagesand disadvantages,andnoneareusableifthereisnobodyatthesitewhoisfamiliarwiththe technology. AfewexamplesofdifferentETLs(listedinorderofcomplexity): •ETL­Synthea­ASQLbuilderwrittentoconverttheSyntheadatabase –https://github.com/OHDSI/etl­synthea •ETL­CDMBuilder­A.NETapplicationdesignedtotransformmultipledatabases –https://github.com/OHDSI/etl­cdmbuilder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████████████████▊                                                                                                    | 122/464 [00:01<00:03, 108.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 6.5. Step 4: Quality Control 93 •ETL­LambdaBuilder­AbuilderusingtheAWSlambdafunctionality –https://github.com/OHDSI/etl­lambdabuilder Itshouldbenotedthatafterseveralindependentattempts,wehavegivenupondeveloping the‘ultimate’user­friendlyETLtool. Itisalwaysthecasethattoolslikethatworkwell for80%oftheETL,butfortheremaining20%oftheETLsomelow­levelcodeneedsto bewrittenthatisspecifictoasourcedatabase Oncethetechnicalindividualsarereadytostartimplementing,theETLdesigndocument shouldbesharedwiththem. Thereshouldbeenoughinformationinthedocumentation forthemtogetstartedhoweveritshouldbeexpectedthatthedevelopershaveaccessto the ETL designers to ask questions during their development process. Logic that may becleartothedesignersmaybelesscleartoanimplementerwhomightnotbefamiliar with the data and CDM. The implementation phase should remain a team effort. It is considered acceptable practice to go through the process of CDM creation and testing betweentheimplementersanddesigners,respectively,untilbothgroupsareinagreement thatalllogichasbeenexecutedcorrectly. 6.5 Step 4: Quality Control Fortheextract,transform,loadprocess,qualitycontrolisiterative. Thetypicalpatternis towritelogic­>implementlogic­>testlogic­>fix/writelogic. Therearemanywaysto goabouttestingaCDMbutbelowarerecommendstepsthathavebeendevelopedacross thecommunitythroughyearsofETLimplementation. •ReviewoftheETLdesigndocument,computercode,andcodemappings. Anyone personcanmakemistakes,soalwaysatleastoneotherpersonshouldreviewwhat thewhatwasdone. –The largest issues in the computer code tend to come from how the source codesinthenativedataaremappedtoStandardConcepts. Mappingcanget tricky,especiallywhenitcomestodate­specificcodeslikeNDCs. Besureto doublecheckanyareawheremappingsaredonetoensurethecorrectsource vocabulariesaretranslatedtotheproperconceptid. •Manuallycompareallinformationonasampleofpersonsinthesourceandtarget data. –It can be helpful to walk through one person’s data, ideally a person with a largenumberofuniquerecords. Tracingthroughasinglepersoncanhighlight issues if the data in the CDM is not how you expect it to look based on the agreeduponlogic. •Compareoverallcountsinthesourceandtargetdata. –There may be some expected differences in counts depending on how you chose to address certain issues. For instance, some collaborators choose to dropanypeoplewithaNULLgendersincethosepeoplewillnotbeincluded in analyses anyway. It may also be the case that visits in the CDM are con­ structed differently than visits or encounters in the native data. Therefore,\n",
      "page text: 94 Chapter 6. Extract Transform Load whencomparingoverallcountsbetweenthesourceandCDMdatabesureto accountforandexpectthesedifferences. •ReplicateastudythathasalreadybeenperformedonthesourcedataontheCDM version. –This is a good way to understand any major differences between the source dataandCDMversion,thoughitisalittlemoretime­intensive. •Create unit tests meant to replicate a pattern in the source data that should be ad­ dressedintheETL.Forexample,ifyourETLspecifiesthatpatientswithoutgender informationshouldbedropped,createaunittestofapersonwithoutagenderand assesshowthebuilderhandlesit. –UnittestingisveryhandywhenevaluatingthequalityandaccuracyofanETL conversion. It usually involves creating a much smaller dataset that mimics thestructureofthesourcedatayouareconverting. Eachpersonorrecordin the dataset should test a specific piece of logic as written in the ETL docu­ ment. Usingthismethod,itiseasytotracebackissuesandtoidentifyfailing logic. Thesmallsizealsoenablesthecomputercodetoexecuteveryquickly allowingforfasteriterationsanderroridentification. Thesearehigh­levelwaystoapproachqualitycontrolfromanETLstandpoint. Formore detailonthedataqualityeffortsgoingonwithinOHDSI,pleaseseeChapter 15. 6.6 ETL Conventions and THEMIS AsmoregroupsconverteddatatotheCDMitbecameapparentthatconventionsneededto bespecified. Forexample,whatshouldtheETLdoinasituationwhereapersonrecord lacks a birth year? The goal of the CDM is to standardized healthcare data however if every group handles data specific scenarios differently it makes it more difficult to systematicallyusedataacrossthenetwork. TheOHDSIcommunitystarteddocumentingconventionstoimproveconsistencyacross CDMs. Thesedefinedconventions,thattheOHDSIcommunityhasagreedupon,canbe found on the CDM Wiki.6Each CDM table has its own set of conventions that can be referredtowhendesigninganETL.Forexample,personsareallowedtobemissingabirth monthorday,butiftheylackabirthyearthepersonshouldbedropped. Indesigningan ETL,refertotheconventionstohelpmakecertaindesigndecisionsthatwillbeconsistent withthecommunity. Whileitwillneverbepossibletodocumentallpossibledatascenariosthatexistandwhat todowhentheyoccur,thereisanOHDSIworkgrouptryingtodocumentcommonsce­ narios. THEMIS7is made up of individuals in the community who gather conventions, clarifythem,sharethemwiththecommunityforcomment,andthendocumentfinalized conventionsintheCDMWiki. ThemisisanancientGreekTitanessofdivineorder,fair­ ness,law,naturallaw,andcustomwhichseemedagoodfitforthisgroupsremit. When 6https://github.com/OHDSI/CommonDataModel/wiki ]. 7https://github.com/OHDSI/Themis\n",
      "page text: 6.7. CDM and ETL Maintenance 95 performing an ETL, if there is a scenario that you are unsure how to handle, THEMIS recommends that a question about the scenario is posed on the OHDSI Forums.8Most likelyifyouhaveaquestion,othersinthecommunityprobablyhaveitaswell. THEMIS uses these discussions, as well as work group meetings and face­to­face discussions, to helpinformwhatotherconventionsneedtobedocumented. 6.7 CDM and ETL Maintenance It is no small effort to design the ETL, create the mappings, implement the ETL, and build out quality control measures. Unfortunately, the effort does not stop there. There is a cycle of ETL maintenance that is a continuous process after the first CDM is built. Somecommontriggersthatrequiremaintenanceare: changesinthesourcedata,abugin theETL,anewOMOPVocabularyisreleased,ortheCDMitselfhaschangedorupdated. Ifoneofthesetriggersoccurthefollowingmightneedupdating: theETLdocumentation, thesoftwareprogrammingrunningtheETL,andtestcasesandqualitycontrols. Oftenahealthcaredatasourceisforeverchanging. Newdatamightbeavailable(e.g.a new column in the data might exist). Patients’ scenarios that never existed before sud­ denlydo(e.g.anewpatientwhohasadeathrecordbeforetheywereborn). Yourunder­ standing of the data may improve (e.g. some of the records around inpatient child birth comeacrossasoutpatientduetohowclaimsareprocessed). Notallchangesinthesource data may trigger a change in the ETL processing of it, however at a bare minimum the changesthatbreaktheETLprocessingwillneedtobeaddressed. If bugs are found, they should be addressed. However, it is important to keep in mind thatnotallbugsarecreatedequal. Forexample,let’ssayintheCOSTtablethecolumn costwasbeingroundedtoawholedigit(e.g.thesourcedatahad$3.82andthisbecame $4.00 in the CDM). If the primary researchers using the data were mostly performing characterizationsofpatient’sdrugexposuresandconditions,abugsuchasthisisoflittle importanceandcanbeaddressedinthefuture. Iftheprimaryresearchersusingthedata also included health economists, this would be a critical bug that need to be addressed immediately. The OMOP Vocabulary is also ever changing just as our source data may be. In fact, the Vocabulary can have multiple releases in one given month as vocabularies update. EachCDMisrunonaspecificversionofaVocabularyandrunningonanewerimproved Vocabularycouldresultinchangesinhowsourcescodesgetmappedtointhestandardized vocabularies. OftendifferencesbetweenVocabulariesareminor,sobuildinganewCDM everytimeanewVocabularyisreleasedisnotnecessary. However,itisgoodpracticeto adoptanewVocabularyonceortwiceayearwhichwouldrequirereprocessingtheCDM again. It is rare that changes in a new version of a Vocabulary would require the ETL codeitselftobeupdated. ThefinaltriggerthatcouldrequireCDMorETLmaintenanceiswhenthecommondata modelitselfupdates. Asthecommunitygrowsandnewdatarequirementsarefoundthis 8http://forums.ohdsi.org/\n",
      "page text: 96 Chapter 6. Extract Transform Load may lead to additional data being stored in the CDM. This might mean data that you previously were not storing in the CDM might have a location in a new CDM version. Less frequently are changes to existing CDM structure, however it is a possibility. For example,theCDMhasadoptedDATETIMEfieldsovertheoriginalDATEfieldswhich could cause an error in ETL processing. CDM versions are not released often and sites canchoosewhentheymigrate. 6.8 Final Thoughts on ETL The ETL process is diff for many reasons, not the least of which is the fact that we are allprocessing uniquesource data, making ithard tocreate a“one­size­fits­all” solution. However,overtheyearswehavelearnedthefollowinghard­wonlessons. •The80/20rule. Ifyoucanavoiditdonotspendtoomuchtimemanuallymapping sourcecodestoconceptssets. Ideally,mapthesourcecodesthatcoverthemajority of your data. This should be enough to get you started and you can address any remainingcodesinthefuturebasedonusecases. •It’s ok if you lose data that is not of research quality. Often these are the records that would be discarded before starting an analysis anyway, we just remove them duringtheETLprocessinstead. •ACDMrequiresmaintenance. JustbecauseyoucompleteanETLdoesnotmean youdonotneedtotouchiteveragain. Yourrawdatamightchange,theremightbe abuginthecode,theremaybenewvocabularyoranupdatetotheCDM.Planto allocateresourcesforthesechangessoyourETLisalwaysup­to­date. •For support starting the OHDSI CDM, performing your database conversion, or runningtheanalyticstools,pleasevisitourImplementersForum.9 6.9 Summary –ThereisagenerallyagreeduponprocessforhowtoapproachanETL,includ­ ing *DataexpertsandCDMexpertstogetherdesigntheETL *Peoplewithmedicalknowledgecreatethecodemappings *AtechnicalpersonimplementstheETL *Allareinvolvedinqualitycontrol –ToolshavebeendevelopedbytheOHDSIcommunitytofacilitatethesesteps andarefreelyavailableforuse –TherearemanyETLexamplesandagreeduponconventionsyoucanuseas aguide 9https://forums.ohdsi.org/c/implementers\n",
      "page text: 6.10. Exercises 97 6.10 Exercises Exercise 6.1. PutthestepsoftheETLprocessintheproperorder: A)DataexpertsandCDMexpertstogetherdesigntheETL B)AtechnicalpersonimplementstheETL C)Peoplewithmedicalknowledgecreatethecodemappings D)Allareinvolvedinqualitycontrol Exercise 6.2. UsingOHDSIresourcesofyourchoice,spotfourissueswiththePERSON recordshowinTable 6.3(tableabbreviatedforspace): Table6.3: APERSONtable. Column Value PERSON_ID A123B456 GENDER_CONCEPT_ID 8532 YEAR_OF_BIRTH NULL MONTH_OF_BIRTH NULL DAY_OF_BIRTH NULL RACE_CONCEPT_ID 0 ETHNICITY_CONCEPT_ID 8527 PERSON_SOURCE_VALUE A123B456 GENDER_SOURCE_VALUE F RACE_SOURCE_VALUE WHITE ETHNICITY_SOURCE_VALUE NONEPROVIDED Exercise 6.3. LetustrytogenerateVISIT_OCCURRENCErecords. Hereissomeexam­ ple logic written for Synthea: Sort data in ascending order by PATIENT, START, END. Then by PERSON_ID, collapse lines of claim as long as the time between the END of onelineandtheSTARTofthenextis<=1day. Eachconsolidatedinpatientclaimisthen consideredasoneinpatientvisit,set: •MIN(START)asVISIT_START_DATE •MAX(END)asVISIT_END_DATE •“IP”asPLACE_OF_SERVICE_SOURCE_VALUE If you see a set of visits as shown in Figure 6.10in your source data, how would you expecttheresultingVISIT_OCCURRENCErecord(s)tolookintheCDM? SuggestedanswerscanbefoundinAppendix E.3.\n",
      "page text: 98 Chapter 6. Extract Transform Load Figure6.10: Examplesourcedata.\n",
      "page text: Part III Data Analytics 99\n",
      "page text: Chapter 7 Data Analytics Use Cases Chapter lead: David Madigan TheOHDSIcollaborationfocusesongeneratingreliableevidencefromreal­worldhealth­ caredata,typicallyintheformofclaimsdatabasesorelectronichealthrecorddatabases. TheusecasesthatOHDSIfocusesonfallintothreemajorcategories: •Characterization •Population­levelestimation •Patient­levelprediction We describe these in detail below. Note, for all the use cases, the evidence we generate inherits the limitations of the data; we discuss these limitations at length in the book sectiononEvidenceQuality(Chapters 14­18) 7.1 Characterization Characterizationattemptstoanswerthequestion Whathappenedtothem? Wecanusethedatatoprovideanswerstoquestionsaboutthecharacteristicsofthepersons inacohortortheentiredatabase,thepracticeofhealthcare,andstudyhowthesethings changeovertime. Thedatacanprovideanswerstoquestionslike: •Forpatientsnewlydiagnosedwithatrialfibrillation,howmanyreceiveaprescrip­ tionforwarfarin? •Whatistheaverageageofpatientswhoundergohiparthroplasty? •Whatistheincidencerateofpneumoniainpatientsover65yearsold? Typicalcharacterizationquestionsareformulatedas: 101\n",
      "page text: 102 Chapter 7. Data Analytics Use Cases •Howmanypatients…? •Howoftendoes…? •Whatproportionofpatients…? •Whatisthedistributionofvaluesforlab…? •WhataretheHbA1clevelsforpatientswith…? •Whatarethelabvaluesforpatients…? •Whatisthemedianlengthofexposureforpatientson….? •Whatarethetrendsovertimein…? •Whatareotherdrugsthatthesepatientsareusing? •Whatareconcomitanttherapies? •Dowehaveenoughcasesof…? •WoulditbefeasibletostudyX…? •Whatarethedemographicsof…? •Whataretheriskfactorsof…? (ifidentifyingaspecificriskfactor,maybeestima­ tion,notprediction) •Whatarethepredictorsof…? Andthedesiredoutputis: •Countorpercentage •Averages •Descriptivestatistics •Incidencerate •Prevalence •Cohort •Rule­basedphenotype •Drugutilization •Diseasenaturalhistory •Adherence •Co­morbidityprofile •Treatmentpathways •Lineoftherapy 7.2 Population-Level Estimation Toalimitedextent,thedatacansupportcausalinferencesabouttheeffectsofhealthcare interventions,answeringthequestion Whatarethecausaleffects? We would like to understand causal effects to understand consequences of actions. For example,ifwedecidetotakesometreatment,howdoesthatchangewhathappenstous inthefuture? Thedatacanprovideanswerstoquestionslike: •Forpatientsnewlydiagnosedwithatrialfibrillation, inthefirstyearaftertherapy\n",
      "page text: 7.3. Patient­Level Prediction 103 initiation,doeswarfarincausemoremajorbleedsthandabigatran? •Doesthecausaleffectofmetforminondiarrheavarybyage? Typicalpopulation­leveleffectestimationquestionsareformulatedas: •Whatistheeffectof…? •WhatifIdointervention…? •Whichtreatmentworksbetter? •WhatistheriskofXonY? •Whatisthetime­to­eventof…? Andthedesiredoutputis: •Relativerisk •Hazardsratio •Oddsratio •Averagetreatmenteffect •Causaleffect •Association •Correlation •Safetysurveillance •Comparativeeffectiveness 7.3 Patient-Level Prediction Basedonthecollectedpatienthealthhistoriesinthedatabase,wecanmakepatient­level predictionsaboutfuturehealthevents,answeringthequestion Whatwillhappentome? Thedatacanprovideanswerstoquestionslike: •Foraspecificpatientnewlydiagnosedwithmajordepressivedisorder,whatisthe probabilitythepatientwillattemptsuicideinthefirstyearfollowingdiagnosis? •For a specific patient newly diagnosed with atrial fibrillation, in the first year af­ ter therapy initiation with warfarin, what is the probability the patient suffers an ischemicstroke? Typicalpatient­levelpredictionquestionsareformulatedas: •Whatisthechancethatthispatientwill…? •Whoarecandidatesfor…? Andthedesiredoutputis: •Probabilityforanindividual •Predictionmodel •High/lowriskgroups •Probabilisticphenotype\n",
      "page text: 104 Chapter 7. Data Analytics Use Cases Population­level estimation and patient­level prediction overlap to a certain extent. For example, an important use case for prediction is to predict an outcome for a specific patienthaddrugAbeenprescribedandalsopredictthesameoutcomehaddrugBbeen prescribed. Let’s assume that in reality only one of these drugs is prescribed (say drug A) so we get to see whether the outcome following treatment with A actually occurs. SincedrugBwasnotprescribed,theoutcomefollowingtreatmentB,whilepredictable, is“counterfactual”sinceitisnoteverobserved. Eachofthesepredictiontasksfallsunder patient­levelprediction. However,thedifferencebetween(orratioof)thetwooutcomesis aunit­level causaleffect,andshouldbeestimatedusingcausaleffectestimationmethods instead. Peoplehaveanaturaltendencytoerroneouslyinterpretpredictivemodelsasifthey are causal models. But a predictive model can only show correlation, never cau­ sation. Forexample,diabeticdrugusemightbeastrongpredictorformyocardial infarction(MI)becausediabetesisastrongriskfactorforMI.However,thatdoes notmeanthatstoppingthediabeticdrugswillpreventMI! 7.4 Example Use Cases in Hypertension You’re a researcher interested in studying the effects of ACE inhibitor monotherapy vs. thiazide diuretic monotherapy on the outcomes of acute myocardial infarction and angioedema as first­line treatment for hypertension. You understand that based on the OHDSI literature, you are asking a population­level effect estimation question but first, you need to do some homework on how to characterize this particular treatment of interest. 7.4.1 Characterization Questions Acute myocardial infarction is a cardiovascular complication that can occur in patients withhighbloodpressure, soeffectivetreatmentforhypertensionshouldreducetherisk. AngioedemaisaknownsideeffectofACEinhibitors,whichisrarebutpotentiallyseri­ ous. Youstartbycreatingcohorts(seeChapter 10)fortheexposuresofinterest(newusers of ACE inhibitors and new users of thiazide diuretics). You perform a characterization (seeChapter 11)analysistosummarizebaselinecharacteristicsoftheseexposurepopula­ tions,includingdemographics,comorbidconditions,andconcomitantmedications. You performanothercharacterizationanalysistoestimatetheincidenceofselectedoutcomes within these exposure populations. Here, you ask ‘how often does 1) acute myocardial infarctionand2)angioedemaoccurduringtheperiodofexposuretoACEinhibitorsand thiazidediuretics?’ Thesecharacterizationsallowustoassessthefeasibilityofconduct­ ingapopulation­levelestimationstudy,toevaluatewhetherthetwotreatmentgroupsare comparable,andtoidentify‘riskfactors’thatmightpredictwhichtreatmentchoicethat patientsmade.\n",
      "page text: 7.5. Limitations of Observational Research 105 7.4.2 Population-Level Estimation Question The population­level effect estimation study (see Chapter 12) estimates the relative risk of ACE inhibitor vs, thiazide use for the outcomes of AMI and angioedema. Here, you furtherevaluatethroughstudydiagnosticsandnegativecontrolswhetherwecanproduce areliableestimateoftheaveragetreatmenteffect. 7.4.3 Patient-Level Prediction Question Independentofwhetherthereisacausaleffectoftheexposures, youarealsointerested intryingtodeterminewhichpatientsareathighestriskoftheoutcomes. Thisisapatient­ level prediction problem (see Chapter 13). Here, you develop a prediction model that evaluates: amongstthepatientswhoarenewusersofACEinhibitors,whichpatientsare athighestriskofdevelopingacutemyocardialinfarctionduringthe1yearafterstarting treatment. Themodelallowsustopredict,forapatientwhohasjustbeenprescribedACE forthefirsttime,basedoneventsobservedfromtheirmedicalhistory,whatisthechance thattheywillexperienceAMIinthenext1year. 7.5 Limitations of Observational Research There are many important healthcare questions for which OHDSI databases cannot pro­ videanswers. Theseinclude: •Causal effects of interventions compared to placebo. Sometimes it is possible to consider the causal effect of a treatment as compared with non­treatment but not placebotreatment. •Anythingrelatedtoover­the­countermedications. •Many outcomes and other variables are sparsely recorded if at all. These include mortality,behavioraloutcomes,lifestyle,andsocioeconomicstatus. •Sincepatientstendtoencounterthehealthcaresystemonlywhentheyareunwell, measurementofthebenefitsoftreatmentscanproveelusive. 7.5.1 Erroneous Data ClinicaldatarecordedinOHDSIdatabasescandeviatefromclinicalreality. Forexample, a patient’s record may include a code for myocardial infarction even though the patient neverexperiencedamyocardialinfarction. Similarly,alabvaluemaybeerroneousoran incorrect code for a procedure may appear in the database. Chapters 15and16discuss severaloftheseissuesandgoodpracticeaimstoidentifyandcorrectforasmanyofthese kindsofissuesaspossible. Nonetheless,erroneousdatainevitablypersisttosomeextent andcanunderminethevalidityofsubsequentanalyses. Anextensiveliteraturefocuseson adjustmentofstatisticalinferencestoaccountforerrors­in­data­see,forexample, Fuller (2009).\n",
      "page text: 106 Chapter 7. Data Analytics Use Cases 7.5.2 Missing Data Missingness in OHDSI databases presents subtle challenges. A health event (e.g., pre­ scription,laboratoryvalue,etc.) thatshouldberecordedinadatabase,butisn’t,is“miss­ ing.” Thestatisticsliteraturedistinguishesbetweentypesofmissingnesssuchas“missing completelyatrandom,”“missingatrandom,”and“missingnotatrandom”andmethods of increasing complexity attempt to address these types. Perkins et al. (2017) provide a usefulintroductiontothistopic. 7.6 Summary –Inobservationalresearchwedistinguishthreelargecategoriesofusescases. –Characterization aimstoanswerthequestions“Whathappenedtothem?” –Population­level estimation attempts to answer the question “What are the causaleffects?” –Patient­level prediction triestoanswer“Whatwillhappentome?” –Prediction models are not causal models; There is no reason to believe that interveningonastrongpredictorwillimpacttheoutcome. –There are questions that cannot be answered using observational healthcare data. 7.7 Exercises Exercise 7.1. Whichusecasecategoriesdothesequestionsbelongto? 1.Compute the rate of gastrointestinal (GI) bleeding in patients recently exposed to NSAIDs. 2.Computetheprobabilitythataspecificpatient experiencesaGIbleedinthenext year,basedontheirbaselinecharacteristics. 3.EstimatetheincreasedriskofGIbleedingduetodiclofenaccomparedtocelecoxib. Exercise 7.2. You wish to estimate the increased risk of GI bleeding due to diclofenac comparedtonoexposure(placebo). Canthisbedoneusingobservationalhealthcaredata? SuggestedanswerscanbefoundinAppendix E.4.\n",
      "page text: Chapter 8 OHDSI Analytics T ools Chapter leads: Martijn Schuemie & Frank DeFalco OHDSI offers a wide range of open source tools to support various data­analytics use casesonobservationalpatient­leveldata. Whatthesetoolshaveincommonisthatthey canallinteractwithoneormoredatabasesusingtheCommonDataModel(CDM).Fur­ thermore,thesetoolsstandardizetheanalyticsforvarioususecases;Ratherthanhavingto startfromscratch,ananalysiscanbeimplementedbyfillinginstandardtemplates. This makes performing analysis easier, and also improves reproducibility and transparency. Forexample,thereappeartobeanear­infinitenumberofwaystocomputeanincidence rate,butthesecanbespecifiedintheOHDSItoolswithafewchoices,andanyonemaking thosesamechoiceswillcomputeincidenceratesthesameway. In this chapter we first describe various ways in which we can choose to implement an analysis,andwhatstrategiestheanalysiscanemploy. WethenreviewthevariousOHDSI toolsandhowtheyfitthevarioususecases. 8.1 Analysis Implementation Figure8.1showsthevariouswaysinwhichwecanchoosetoimplementastudyagainst adatabaseusingtheCDM. There are three main approaches to implementing a study. The first is to write custom codethatdoesnotmakeuseofanyofthetoolsOHDSIhastooffer. Onecouldwriteade novoanalysisinR,SAS,oranyotherlanguage. Thisprovidesthemaximumflexibility, andmayinfactbetheonlyoptionifthespecificanalysisisnotsupportedbyanyofour tools. However, this path requires a lot of technical skill, time, and effort, and as the analysisincreasesincomplexityitbecomeshardertoavoiderrorsinthecode. ThesecondapproachinvolvesdevelopingtheanalysisinR,andmakinguseofthepack­ ages in the OHDSI Methods Library . At a minimum, one could use the SqlRender and DatabaseConnector packages described in more detail in Chapter 9that allow the same 107\n",
      "page text: 108 Chapter 8. OHDSI Analytics Tools Figure8.1: DifferentwaystoimplementananalysisagainstdataintheCDM. code to be executed on various database platforms, such as PostgreSQL, SQL Server, and Oracle. Other packages such as CohortMethod andPatientLevelPrediction offer R functions for advanced analytics against the CDM that can be called on in one’s code. This still requires a lot of technical expertise, but by re­using the validated components oftheMethodsLibrarywecanbemoreefficientandlesspronetoerrorthanwhenusing completelycustomcode. Thethirdapproachreliesonourinteractiveanalysisplatform ATLAS,aweb­basedtool that allows non­programmers to perform a wide range of analyses efficiently. ATLAS makes use of the Methods Libraries but provides a simple graphical interface to design analysesandinmanycasesgeneratethenecessaryRcodetoruntheanalysis. However, ATLASdoesnotsupportalloptionsavailableintheMethodsLibrary. Whileitisexpected thatthemajorityofstudiescanbeperformedthroughATLAS,somestudiesmayrequire theflexibilityofferedbythesecondapproach. ATLAS and the Methods Library are not independent. Some of the more complicated analyticsthatcanbeinvokedinATLASareexecutedthroughcallstothepackagesinthe Methods Library. Similarly, cohorts used in the Methods Library are often designed in ATLAS. 8.2 Analysis Strategies InadditiontothestrategyusedtoimplementouranalysisagainsttheCDM,forexample throughcustomcodingoruseofstandardanalyticcodeintheMethodsLibrary,thereare alsomultiplestrategiesforusingthoseanalytictechniquestogenerateevidence. Figure 8.2highlightsthreestrategiesthatareemployedinOHDSI. Thefirststrategyviewseveryanalysisasasingleindividualstudy. Theanalysismustbe pre­specifiedinaprotocol,implementedascode,executedagainstthedata,afterwhich theresultcanbecompiledandinterpreted. Foreveryquestion,allstepsmustberepeated. An example of such an analysis is the OHDSI study into the risk of angioedema associ­ ated with levetiracetam compared with phenytoin. ( Duke et al. ,2017) Here, a protocol\n",
      "page text: 8.3. ATLAS 109 Figure8.2: Strategiesforgeneratingevidencefor(clinical)questions. was first written, analysis code using the OHDSI Methods Library was developed and executed across the OHDSI network, and results were compiled and disseminated in a journalpublication. Thesecondstrategydevelopsanapplicationthatallowsuserstoansweraspecificclassof questionsinrealtimeornear­realtime. Oncetheapplicationhasbeendeveloped,users can interactively define queries, submit them, and view the results. An example of this strategy is the cohort definition and generation tool in ATLAS. This tool allows users tospecifycohortdefinitionsofvaryingcomplexity, andexecutethedefinitionagainsta databasetoseehowmanypeoplemeetthevariousinclusionandexclusioncriteria. Thethirdstrategysimilarlyfocusesonaclassofquestions,butthenattemptstoexhaus­ tivelygeneratealltheevidenceforthequestionswithintheclass. Userscanthenexplore theevidenceasneededthroughavarietyofinterfaces. OneexampleistheOHDSIstudy into the effects of depression treatments. ( Schuemie et al. ,2018b) In this study all de­ pressiontreatmentsarecomparedforalargesetofoutcomesofinterestacrossfourlarge observational databases. The full set of results, including 17,718 empirically calibrated hazard ratios along with extensive study diagnostics, is available in an interactive web app.1 8.3 A TLAS ATLASisafree,publiclyavailable,web­basedtooldevelopedbytheOHDSIcommunity thatfacilitatesthedesignandexecutionofanalysesonstandardized,patient­level,obser­ vationaldataintheCDMformat. ATLASisdeployedasawebapplicationincombination withtheOHDSIWebAPIandistypicallyhostedonApacheTomcat. Performingrealtime analyses requires access to the patient­level data in the CDM and is therefore typically installedbehindanorganization’sfirewall. However,thereisalsoapublicATLAS2,and 1http://data.ohdsi.org/SystematicEvidence/ 2http://www.ohdsi.org/web/atlas\n",
      "page text: 110 Chapter 8. OHDSI Analytics Tools although this ATLAS instance only has access to a few small simulated datasets, it can stillbeusedformanypurposesincludingtestingandtraining. Itisevenpossibletofully defineaneffectestimationorpredictionstudyusingthepublicinstanceofATLAS,and automatically generate the R code for executing the study. That code can then be run in any environment with an available CDM without needing to install ATLAS and the WebAPI. Figure8.3: ATLASuserinterface. AscreenshotofATLASisprovidedinFigure 8.3. Ontheleftisanavigationbarshowing thevariousfunctionsprovidedbyATLAS: Data Sources Datasourcesprovidesthecapabilityreviewdescriptive,standardizedre­ porting for each of the data sources that you have configured within your Atlas platform. Thisfeatureusesthelarge­scaleanalyticsstrategy: alldescriptiveshave beenpre­computed. DatasourcesisdiscussedinChapter 11. Vocabulary Search Atlas provides the ability to search and explore the OMOP stan­ dardized vocabulary to understand what concepts exist within those vocabularies and how to apply those concepts in your standardized analysis against your data sources. ThisfeatureisdiscussedinChapter 5. Concept Sets Concept sets provides the ability to create collections of logical expres­ sionsthatcanbeusedtoidentifyasetofconceptstobeusedthroughoutyourstan­ dardized analyses. Concept sets provide more sophistication than a simple list of codesorvalues. Aconceptsetiscomprisedofmultipleconceptsfromthestandard­ izedvocabularyincombinationwithlogicalindicatorsthatallowausertospecify thattheyareinterestedinincludingorexcludingrelatedconceptsinthevocabulary hierarchy. Searching the vocabulary, identifying the set of concepts, and specify­\n",
      "page text: 8.3. ATLAS 111 ingthelogictobeusedtoresolveaconceptsetprovidesapowerfulmechanismfor definingtheoftenobscuremedicallanguageusedinanalysisplans. Theseconcept setscanbesavedwithinATLASandthenusedthroughoutyouranalysisaspartof cohortdefinitionsoranalysisspecifications. Cohort Definitions Cohort definitions is the ability to construct a set of persons who satisfyoneormorecriteriaforadurationoftimeandthesecohortscanthenserve asthebasisofinputsforallofyoursubsequentanalyses. Thisfeatureisdiscussed inChapter 10. Characterizations Characterizations is an analytic capability that allows you to look atoneormorecohortsthatyou’vedefinedandtosummarizecharacteristicsabout those patient populations. This feature uses the real­time query strategy, and is discussedinChapter 11. Cohort Pathways Cohort pathways is an analytic tool that allows you to look at the sequenceofclinicaleventsthatoccurwithinoneormorepopulations. Thisfeature usesthereal­timequerystrategy,andisdiscussedinChapter 11. Incidence Rates Incidence rates is a tool that allows you to estimate the incidence of outcomeswithintargetpopulationsofinterest. Thisfeatureusesthereal­timequery strategy,andisdiscussedinChapter 11. ProfilesProfilesisatoolthatallowsyoutoexploreanindividualpatientslongitudinal observationaldatatosummarizewhatisgoingonwithinagivenindividual. This featureusesthereal­timequerystrategy. Population Level Estimation Estimation is a capability to allow you to define a pop­ ulation level effect estimation study using a comparative cohort design whereby comparisonsbetweenoneormoretargetandcomparatorcohortscanbeexplored foraseriesofoutcomes. Thisfeaturecanbesaidtoimplementthereal­timequery strategy,asnocodingisrequired,andisdiscussedinChapter 12. Patient Level Prediction Predictionisacapabilitytoallowyoutoapplymachinelearn­ ingalgorithmstoconductpatientlevelpredictionanalyseswherebyyoucanpredict an outcome within any given target exposures. This feature can be said to imple­ ment the real­time query strategy, as no coding is required, and is discussed in Chapter13. JobsSelecttheJobsmenuitemtoexplorethestateofprocessesthatarerunningthrough theWebAPI.Jobsareoftenlongrunningprocessessuchasgeneratingacohortor computingcohortcharacterizationreports. Configuration SelecttheConfigurationmenuitemtoreviewthedatasourcesthathave beenconfiguredinthesourceconfigurationsection. Feedback TheFeedbacklinkwilltakeyoutotheissuelogforAtlassothatyoucanlog anewissueortosearchthroughexistingissues. Ifyouhaveideasfornewfeatures orenhancements,thisisalsoaplacenotetheseforthedevelopmentcommunity. 8.3.1 Security ATLASandtheWebAPIprovideagranularsecuritymodeltocontrolaccesstofeatures or data sources within the overall platform. The security system is built leveraging the ApacheShirolibrary. Additionalinformationonthesecuritysystemcanbefoundinthe\n",
      "page text: 112 Chapter 8. OHDSI Analytics Tools onlineWebAPIsecuritywiki.3 8.3.2 Documentation DocumentationforATLAScanbefoundonlineintheATLASGitHubrepositorywiki.4 This wiki includes information on the various application features as well as links to onlinevideotutorials. 8.3.3 How to Install Installation of ATLAS is done in combination with the OHDSI WebAPI. Installation guides for each component are available online in the ATLAS GitHub repository Setup Guide5andWebAPIGitHubrepositoryInstallationGuide.6 8.4 Methods Library TheOHDSIMethodsLibrary isthecollectionofopensourceRpackagesshowinFigure 8.4. The packages offer R functions that together can be used to perform a complete obser­ vationalstudy,startingfromdataintheCDM,andresultinginestimatesandsupporting statistics,figures,andtables. Thepackagesinteractdirectlywithobservationaldatainthe CDM,andcanbeusedsimplytoprovidecross­platformcompatibilitytocompletelycus­ tomanalysesasdescribedinChapter 9, orcanprovideadvancedstandardizedanalytics forpopulationcharacterization(Chapter 11),population­leveleffectestimation(Chapter 12), andpatient­levelprediction(Chapter 13). TheMethodsLibrarysupportsbestprac­ ticesforuseofobservationaldataandobservationalstudydesignaslearnedfromprevi­ ousandongoingresearch,suchastransparency,reproducibility,aswellasmeasuringof theoperatingcharacteristicsofmethodsinaparticularcontextandsubsequentempirical calibrationofestimatesproducedbythemethods. The Methods Library has already been used in many published clinical studies ( Boland et al.,2017;Duke et al. ,2017;Ramcharran et al. ,2017;Weinstein et al. ,2017;Wang et al.,2017;Ryan et al. ,2017,2018;Vashisht et al. ,2018;Yuan et al. ,2018;Johnston etal.,2019),aswellasmethodologicalstudies. ( Schuemieetal. ,2014,2016;Repsetal., 2018;Tian et al.,2018;Schuemie et al. ,2018a,b;Reps et al. ,2019) The validity of the implementationsofmethodsintheMethodslibraryisdescribedinChapter 17. 8.4.1 Support for Large-Scale Analytics Onekeyfeatureincorporatedinallpackagesistheabilitytoefficientlyrunmanyanalyses. Forexample, whenperformingpopulation­levelestimation, theCohortMethodpackage 3https://github.com/OHDSI/WebAPI/wiki/Security­Configuration 4https://github.com/OHDSI/ATLAS/wiki 5https://github.com/OHDSI/Atlas/wiki/Atlas­Setup­Guide 6https://github.com/OHDSI/WebAPI/wiki/WebAPI­Installation­Guide\n",
      "page text: 8.4. Methods Library 113 Figure8.4: PackagesintheOHDSIMethodsLibrary.\n",
      "page text: 114 Chapter 8. OHDSI Analytics Tools allowsforcomputingeffect­sizeestimatesformanyexposuresandoutcomes,usingvari­ ousanalysissettings,andthepackagewillautomaticallychoosetheoptimalwaytocom­ putealltherequiredintermediaryandfinaldatasets. Stepsthatcanbere­used,suchasex­ tractionofcovariates,orfittingapropensitymodelthatisusedforonetarget­comparator pair but multiple outcomes, will be executed only once. Where possible, computations willtakeplaceinparalleltomaximizetheuseofcomputationalresources. Thiscomputationalefficiencyallowsforlarge­scaleanalytics,answeringmanyquestions atonce,andisalsoessentialforincludingcontrolhypotheses(e.g.negativecontrols)to measuretheoperatingcharacteristicsofourmethods,andperformempiricalcalibration asdescribedinChapter 18. 8.4.2 Support for Big Data TheMethodsLibraryisalsodesignedtorunagainstverylargedatabasesandbeableto performcomputationsinvolvinglargeamountsofdata. Thisachievedinthreeways: 1.Most data manipulation is performed on the database server. An analysis usually only requires a small fraction of the entire data in the database, and the Methods Library, through the SqlRender and DatabaseConnector packages, allows for ad­ vancedoperationstobeperformedontheservertopreprocessandextracttherele­ vantdata. 2.Largelocaldataobjectsarestoredinamemory­efficientmanner. Forthedatathat is downloaded to the local machine, the Methods Library uses the ffpackage to store and work with large data objects. This allows us to work with data much largerthanfitsinmemory. 3.High­performancecomputingisappliedwhereneeded. Forexample,the Cyclops package implements a highly efficient regression engine that is used throughout theMethodsLibrarytoperformlarge­scaleregressions(largenumberofvariables, largenumberofobservations)thatwouldnotbepossibletofitotherwise. 8.4.3 Documentation Rprovidesastandardwaytodocumentpackages. Eachpackagehasa package manual thatdocumentseveryfunctionanddatasetcontainedinthepackage. Allpackagemanuals areavailableonlinethroughtheMethodsLibrarywebsite7,throughthepackageGitHub repositories,andforthosepackagesavailablethroughCRANtheycanbefoundinCRAN. Furthermore,fromwithinRthepackagemanualcanbeconsultedbyusingthequestion mark. Forexample,afterloadingtheDatabaseConnectorpackage,typingthecommand ?connect bringsupthedocumentationonthe“connect”function. Inadditiontothepackagemanual,manypackagesprovide vignettes. Vignettesarelong­ formdocumentationthatdescribehowapackagecanbeusedtoperformcertaintasks. For example,onevignette8describeshowtoperformmultipleanalysesefficientlyusingthe 7https://ohdsi.github.io/MethodsLibrary 8https://ohdsi.github.io/CohortMethod/articles/MultipleAnalyses.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████████████▊                                                                                              | 145/464 [00:01<00:03, 99.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 8.4. Methods Library 115 CohortMethodpackage. VignettescanalsobefoundthroughtheMethodsLibraryweb­ site,throughthepackageGitHubrepositories, andforthosepackagesavailablethrough CRANtheycanbefoundinCRAN. 8.4.4 System Requirements Twocomputingenvironmentsarerelevantwhendiscussingthesystemrequirements: The databaseserver,andtheanalyticsworkstation. The database server must hold the observational healthcare data in CDM format. The MethodsLibrarysupportsawidearrayofdatabasemanagementsystemsincludingtradi­ tional database systems (PostgreSQL, Microsoft SQL Server, and Oracle), parallel data warehouses (Microsoft APS, IBM Netezza, and Amazon Redshift), as well as Big Data platforms(HadoopthroughImpala,andGoogleBigQuery). The analytics workstation is where the Methods Library is installed and run. This can eitherbealocalmachine,suchassomeone’slaptop,oraremoteserverrunningRStudio Server. InallcasestherequirementsarethatRisinstalled,preferablytogetherwithRStu­ dio. TheMethodsLibraryalsorequiresthatJavaisinstalled. Theanalyticsworkstation should also be able to connect to the database server, specifically, any firewall between themshouldhavethedatabaseserveraccessportsopenedtheworkstation. Someofthe analyticscanbecomputationallyintensive,sohavingmultipleprocessingcoresandam­ ple memory can help speed up the analyses. We recommend having at least four cores and16gigabytesofmemory. 8.4.5 How to Install HerearethestepsforinstallingtherequiredenvironmenttoruntheOHDSIRpackages. Fourthingsneedtobeinstalled: 1.Risastatisticalcomputingenvironment. Itcomeswithabasicuserinterfacethat isprimarilyacommand­lineinterface. 2.RtoolsisasetofprogramsthatisrequiredonWindowstobuildRpackagesfrom source. 3.RStudioisanIDE(IntegratedDevelopmentEnvironment)thatmakesReasierto use. It includes a code editor, debugging and visualization tools. Please use it to obtainaniceRexperience. 4.Javaisacomputingenvironmentthatisneededtorunsomeofthecomponentsin theOHDSIRpackages,forexamplethoseneededtoconnecttoadatabase. BelowwedescribehowtoinstalleachoftheseinaWindowsenvironment. In Windows, both R and Java come in 32­bit and 64­bits architectures. If you installR in botharchitectures, you mustalsoinstall Java inboth architectures. It isrecommendedtoonlyinstallthe64­bitversionofR.\n",
      "page text: 116 Chapter 8. OHDSI Analytics Tools Installing R 1.Gotohttps://cran.r­project.org/ ,clickon“DownloadRforWindows”,then“base”, thenclicktheDownloadlinkindicatedinFigure 8.5. Figure8.5: DownloadingRfromCRAN. 2.After the download has completed, run the installer. Use the default options ev­ erywhere, with two exceptions: First, it is better not to install into program files. Instead, just make R a subfolder of your C drive as shown in Figure 8.6. Second, to avoid problems due to differing architectures between R and Java, disable the 32­bitarchitectureasshowninFigure 8.7. Figure8.6: SettingsthedestinationfolderforR. Oncecompleted,youshouldbeabletoselectRfromyourStartMenu.\n",
      "page text: 8.4. Methods Library 117 Figure8.7: Disablingthe32­bitversionofR. Installing Rtools 1.Go tohttps://cran.r­project.org/ , click on “Download R for Windows”, then “Rtools”,andselecttheverylatestversionofRtoolstodownload. 2.After downloading has completed run the installer. Select the default options ev­ erywhere. Installing RStudio 1.Go tohttps://www.rstudio.com/ , select “Download RStudio” (or the “Download” button under “RStudio”), opt for the free version, and download the installer for WindowsasshowninFigure 8.8. Figure8.8: DownloadingRStudio. 2.Afterdownloading,starttheinstaller,andusethedefaultoptionseverywhere.\n",
      "page text: 118 Chapter 8. OHDSI Analytics Tools Installing Java 1.Gotohttps://java.com/en/download/manual.jsp ,andselecttheWindows64­bitin­ staller as shown in Figure 8.9. If you also installed the 32­bit version of R, you mustalsoinstalltheother(32­bit)versionofJava. Figure8.9: DownloadingJava. 2.Afterdownloadingjustruntheinstaller. Verifying the Installation Youshouldnowbereadytogo,butweshouldmakesure. StartRStudio,andtype install.packages (\"SqlRender\" ) library(SqlRender) translate (\"SELECT TOP 10 * FROM person;\" ,\"postgresql\" ) ## [1] \"SELECT * FROM person LIMIT 10;\" ThisfunctionusesJava,soifallgoeswellweknowbothRandJavahavebeeninstalled correctly! Anothertestistoseeifsourcepackagescanbebuilt. RunthefollowingRcodetoinstall theCohortMethod packagefromtheOHDSIGitHubrepository: install.packages (\"drat\") drat::addRepo(\"OHDSI\") install.packages (\"CohortMethod\" ) 8.5 Deployment Strategies Deploying the entire OHDSI tool stack, including ATLAS and the Methods Library, in an organization is a daunting task. There are many components with dependencies that have to be considered, and configurations to set. For this reason, two initiatives have developed integrated deployment strategies that allow the entire stack to be installed as one package, using some forms of virtualization: Broadsea and Amazon Web Services (AWS).\n",
      "page text: 8.5. Deployment Strategies 119 8.5.1 Broadsea Broadsea9uses Docker container technology.10The OHDSI tools are packaged along with dependencies into a single portable binary file called a Docker Image. This image canthenberunonaDockerengineservice, creatingavirtualmachinewithallthesoft­ wareinstalledandreadytorun. Dockerenginesareavailableformostoperatingsystems, includingMicrosoftWindows,MacOS,andLinux. TheBroadseaDockerimagecontains themainOHDSItools,includingtheMethodsLibraryandATLAS. 8.5.2 Amazon A WS AmazonhaspreparedtwoenvironmentsthatcanbeinstantiatedintheAWScloudcom­ putingenvironmentwithaclickofthebutton: OHDSI­in­a­Box11andOHDSIonAWS.12 OHDSI­in­a­Boxisspecificallycreatedasalearningenvironment,andisusedinmostof thetutorialsprovidedbytheOHDSIcommunity. ItincludesmanyOHDSItools,sample datasets,RStudioandothersupportingsoftwareinasingle,lowcostWindowsvirtualma­ chine. APostgreSQLdatabaseisusedtostoretheCDMandalsotostoretheintermediary resultsfromATLAS.TheOMOPCDMdatamappingandETLtoolsarealsoincludedin OHDSI­in­a­Box. ThearchitectureforOHDSI­in­a­BoxisdepictedinFigure 8.10. Figure8.10: TheAmazonWebServicesarchitectureforOHDSI­in­a­Box. OHDSIonAWS is a reference architecture for enterprise class, multi­user, scalable and faulttolerantOHDSIenvironmentsthatcanbeusedbyorganizationstoperformtheirdata analytics. Itincludesseveralsampledatasetsandcanalsoautomaticallyloadyourorgani­ zation’srealhealthcaredata. ThedataisplacedintheAmazonRedshiftdatabaseplatform, which is supported by the OHDSI tools. Intermediary results of ATLAS are stored in a PostgreSQL database. On the front end, users have access to ATLAS and to RStudio through a web interface (leveraging RStudio Server). In RStudio the OHDSI Methods Libraryhasalreadybeeninstalled,andcanbeusedtoconnecttothedatabases. Theau­ tomationtodeployOHDSIonAWSisopen­source,andcanbecustomizedtoincludeyour 9https://github.com/OHDSI/Broadsea 10https://www.docker.com/ 11https://github.com/OHDSI/OHDSI­in­a­Box 12https://github.com/OHDSI/OHDSIonAWS\n",
      "page text: 120 Chapter 8. OHDSI Analytics Tools organization’smanagementtoolsandbestpractices. ThearchitectureforOHDSIonAWS isdepictedinFigure 8.11. Figure8.11: TheAmazonWebServicesarchitectureforOHDSIonAWS. 8.6 Summary –WecanperformanalysesagainstdataintheCDMby *writingcustomcode *writingcodethatusestheRpackagesintheOHDSIMethodsLibrary *usingtheinteractiveanalysisplatformATLAS –OHDSItoolsusedifferentanalysisstrategies *Singlestudies *Real­timequeries *Large­scaleanalytics –ThemajorityofOHDSIanalyticstoolareembeddedin *TheinteractiveanalysisplatformATLAS *TheOHDSIMethodsLibraryRpackages –SeveralstrategiesexistfacilitatingthedeploymentoftheOHDSItools.\n",
      "page text: Chapter 9 SQL and R Chapter leads: Martijn Schuemie & Peter Rijnbeek TheCommonDataModel(CDM)isarelationaldatabasemodel(alldataisrepresented as records in tables that have fields), which means that the data will typically be stored inarelationaldatabaseusingasoftwareplatformlikePostgreSQL,Oracle,orMicrosoft SQL Server. The various OHDSI tools such as ATLAS and the Methods Library work by querying the database behind the scene, but we can also query the database directly ourselvesifwehaveappropriateaccessrights. Themainreasontodothisistoperform analysesthatcurrentlyarenotsupportedbyanyexistingtool. However,directlyquerying the database also comes with greater risk of making mistakes, as the OHDSI tools are often designed to help guide the user to appropriate analysis of the data. Direct queries donotprovidesuchguidance. The standard language for querying relational databases is SQL (Structured Query Lan­ guage),whichcanbeusedbothtoquerythedatabaseaswellastomakechangestothe data. AlthoughthebasiccommandsinSQLareindeedstandard,meaningthesameacross softwareplatforms,eachplatformhasitsowndialect,withsubtlechanges. Forexample, toretrievethetop10rowsofthePERSONtableonSQLServer,onewouldtype: SELECTTOP10*FROMperson; WhereasthesamequeryonPostgreSQLwouldbe: SELECT*FROMpersonLIMIT10; InOHDSI,wewouldliketobeagnostictothespecificdialectaplatformuses;wewould like to ‘speak’ the same SQL language across all OHDSI databases. For this reason OHDSIdevelopedthe SqlRender package,anRpackagethatcantranslatefromonestan­ dard dialect to any of the supported dialects that will be discussed later in this chapter. Thisstandarddialect­ OHDSI SQL ­ismainlyasubsetoftheSQLServerSQLdialect. 121\n",
      "page text: 122 Chapter 9. SQL and R TheexampleSQLstatementsprovidedthroughoutthischapterwillalluseOHDSISQL. Eachdatabaseplatformalsocomeswithitsownsoftwaretoolsforqueryingthedatabase usingSQL.InOHDSIwedevelopedthe DatabaseConnector package,oneRpackagethat canconnecttomanydatabaseplatforms. DatabaseConnectorwillalsobediscussedlater inthischapter. So although one can query a database that conforms to the CDM without using any OHDSI tools, the recommended path is to use the DatabaseConnector and SqlRender packages. Thisallowsqueriesthataredevelopedatonesitetobeusedatanyothersite without modification. R itself also immediately provides features to further analyze the data extracted from the database, such as performing statistical analyses and generating (interactive)plots. InthischapterweassumethereaderhasabasicunderstandingofSQL.Wefirstreview howtouseSqlRenderandDatabaseConnector. Ifthereaderdoesnotintendtousethese packages these sections can be skipped. In Section 9.3we discuss how to use SQL (in this case OHDSI SQL) to query the CDM. The following section highlights how to use theOHDSIStandardizedVocabularywhenqueryingtheCDM.WehighlighttheQueryLi­ brary,acollectionofcommonly­usedqueriesagainsttheCDMthatispubliclyavailable. We close this chapter with an example study estimating incidence rates, and implement thisstudyusingSqlRenderandDatabaseConnector. 9.1 SqlRender TheSqlRender packageisavailableonCRAN(theComprehensiveRArchiveNetwork), andcanthereforebeinstalledusing: install.packages (\"SqlRender\" ) SqlRendersupportsawidearrayoftechnicalplatformsincludingtraditionaldatabasesys­ tems(PostgreSQL,MicrosoftSQLServer,SQLite,andOracle),paralleldatawarehouses (Microsoft APS, IBM Netezza, and Amazon Redshift), as well as Big Data platforms (HadoopthroughImpala,andGoogleBigQuery). TheRpackagecomeswithapackage manualandavignettethatexploresthefullfunctionality. Herewedescribersomeofthe mainfeatures. 9.1.1 SQL Parameterization OneofthefunctionsofthepackageistosupportparameterizationofSQL.Often,small variations of SQL need to be generated based on some parameters. SqlRender offers a simplemarkupsyntaxinsidetheSQLcodetoallowparameterization. RenderingtheSQL basedonparametervaluesisdoneusingthe render() function.\n",
      "page text: 9.1. SqlRender 123 Substituting Parameter Values The@character can be used to indicate parameter names that need to be exchanged for actual parameter values when rendering. In the following example, a variable called a ismentionedintheSQL.Inthecalltotherenderfunctionthevalueofthisparameteris defined: sql <-\"SELECT * FROM concept WHERE concept_id = @a;\" render(sql,a =123) ## [1] \"SELECT * FROM concept WHERE concept_id = 123;\" Notethat,unliketheparameterizationofferedbymostdatabasemanagementsystems,it isjustaseasytoparameterizetableorfieldnamesasvalues: sql <-\"SELECT * FROM @x WHERE person_id = @a;\" render(sql,x =\"observation\" ,a =123) ## [1] \"SELECT * FROM observation WHERE person_id = 123;\" The parameter values can be numbers, strings, booleans, as well as vectors, which are convertedtocomma­delimitedlists: sql <-\"SELECT * FROM concept WHERE concept_id IN (@a);\" render(sql,a =c(123,234,345)) ## [1] \"SELECT * FROM concept WHERE concept_id IN (123,234,345);\" If­Then­Else Sometimes blocks of codes need to be turned on or off based on the values of one or moreparameters. Thisisdoneusingthe {Condition} ? {if true} : {if false} syntax. If the conditionevaluates to true or 1, the if trueblock is used, else the if false blockisshown(ifpresent). sql <-\"SELECT * FROM cohort {@x} ? {WHERE subject_id = 1}\" render(sql,x =FALSE) ## [1] \"SELECT * FROM cohort \" render(sql,x =TRUE) ## [1] \"SELECT * FROM cohort WHERE subject_id = 1\" Simplecomparisonsarealsosupported:\n",
      "page text: 124 Chapter 9. SQL and R sql <-\"SELECT * FROM cohort {@x == 1} ? {WHERE subject_id = 1};\" render(sql,x =1) ## [1] \"SELECT * FROM cohort WHERE subject_id = 1;\" render(sql,x =2) ## [1] \"SELECT * FROM cohort ;\" Aswellasthe INoperator: sql <-\"SELECT * FROM cohort {@x IN (1,2,3)} ? {WHERE subject_id = 1};\" render(sql,x =2) ## [1] \"SELECT * FROM cohort WHERE subject_id = 1;\" 9.1.2 T ranslation to Other SQL Dialects Anotherfunctionofthe SqlRender packageistotranslatefromOHDSISQLtootherSQL dialects. Forexample: sql <-\"SELECT TOP 10 * FROM person;\" translate (sql,targetDialect = \"postgresql\" ) ## [1] \"SELECT * FROM person LIMIT 10;\" ThetargetDialect parameter can have the following values: “oracle”, “postgresql”, “pdw”,“redshift”,“impala”,“netezza”,“bigquery”,“sqlite”,and“sqlserver”. There are limits to what SQL functions and constructs can be translated properly, both because only a limited set of translation rules have been implemented in the package,butalsosomeSQLfeaturesdonothaveanequivalentinalldialects. This istheprimaryreasonwhyOHDSISQLwasdevelopedasitsown,newSQLdialect. However,wheneverpossiblewehavekepttotheSQLServersyntaxtoavoidrein­ ventingthewheel. Despite our best efforts, there are quite a few things to consider when writing OHDSI SQL that will run without error on all supported platforms. In what follows we discuss theseconsiderationsindetail. Functions and Structures Supported By Translate These SQL Server functions have been tested and were found to be translated correctly tothevariousdialects:\n",
      "page text: 9.1. SqlRender 125 Table9.1: Functionssupportedbytranslate. Function Function Function ABS EXP RAND ACOS FLOOR RANK ASIN GETDATE RIGHT ATAN HASHBYTES* ROUND AVG ISNULL ROW_NUMBER CAST ISNUMERIC RTRIM CEILING LEFT SIN CHARINDEX LEN SQRT CONCAT LOG SQUARE COS LOG10 STDEV COUNT LOWER SUM COUNT_BIG LTRIM TAN DATEADD MAX UPPER DATEDIFF MIN VAR DATEFROMPARTS MONTH YEAR DATETIMEFROMPARTS NEWID DAY PI EOMONTH POWER *RequiresspecialprivilegesonOracle. HasnoequivalentonSQLite. Similarly, many SQL syntax structures are supported. Here is a non­exhaustive list of expressionsthatweknowwilltranslatewell: -- Simple selects: SELECT*FROMtable; -- Selects with joins: SELECT*FROMtable_1 INNERJOINtable_2 ONa=b; -- Nested queries: SELECT*FROM(SELECT*FROMtable_1) tmp WHEREa=b; -- Limiting to top rows: SELECTTOP10*FROMtable; -- Selecting into a new table: SELECT*INTOnew_table FROMtable; -- Creating tables: CREATETABLEtable(fieldINT);\n",
      "page text: 126 Chapter 9. SQL and R -- Inserting verbatim values: INSERTINTOother_table (field_1) VALUES(1); -- Inserting from SELECT: INSERTINTOother_table (field_1) SELECTvalueFROMtable; -- Simple drop commands: DROPTABLEtable; -- Drop table if it exists: IFOBJECT_ID( 'ACHILLES_analysis' ,'U')ISNOTNULL DROPTABLEACHILLES_analysis; -- Drop temp table if it exists: IFOBJECT_ID( 'tempdb..#cohorts' ,'U')ISNOTNULL DROPTABLE#cohorts; -- Common table expressions: WITHcteAS(SELECT*FROMtable)SELECT*FROMcte; -- OVER clauses: SELECTROW_NUMBER ()OVER(PARTITION BYaORDERBYb) AS\"Row Number\" FROMtable; -- CASE WHEN clauses: SELECTCASEWHENa=1THENaELSE0ENDASvalueFROMtable; -- UNIONs: SELECT*FROMaUNIONSELECT*FROMb; -- INTERSECTIONs: SELECT*FROMaINTERSECT SELECT*FROMb; -- EXCEPT: SELECT*FROMaEXCEPTSELECT*FROMb; String Concatenation String concatenation is one area where SQL Server is less specific than other dialects. In SQL Server, one would write SELECT first_name + ' ' + last_name AS full_name FROM table , but this should be SELECT first_name || ' ' || last_name AS full_name FROM table in PostgreSQL and Oracle. SqlRender tries to guess when values that are being concatenated are strings. In the example above, because we have an explicit string (the space surrounded by single quotation marks), the translation will be correct. However, if the query had been SELECT first_name + last_name AS full_name FROM table , SqlRender would have had no clue the two fields were strings, and would incorrectly leave the plus sign. Another clue that a\n",
      "page text: 9.1. SqlRender 127 valueisastringisanexplicitcasttoVARCHAR,so SELECT last_name + CAST(age AS VARCHAR(3)) AS full_name FROM table would also be translated correctly. To avoid ambiguity altogether, it is probable best to use the CONCAT() function to concatenatetwoormorestrings. Table Aliases and the AS Keyword ManySQLdialectsallowtheuseofthe ASkeywordwhendefiningatablealias,butwill alsoworkfinewithoutthekeyword. Forexample,boththeseSQLstatementsarefinefor SQLServer,PostgreSQL,Redshift,etc.: -- Using AS keyword SELECT* FROMmy_table AStable_1 INNERJOIN( SELECT*FROMother_table )AStable_2 ONtable_1.person_id =table_2.person_id; -- Not using AS keyword SELECT* FROMmy_table table_1 INNERJOIN( SELECT*FROMother_table ) table_2 ONtable_1.person_id =table_2.person_id; However,Oraclewillthrowanerrorwhenthe ASkeywordisused. Intheaboveexample, the first query will fail. It is therefore recommended to not use the ASkeyword when aliasingtables. (Note: wecan’tmakeSqlRenderhandlethis,becauseitcan’teasilydis­ tinguishbetweentablealiaseswhereOracledoesn’tallow AStobeused,andfieldaliases, whereOraclerequires AStobeused.) Temp Tables Temp tables can be very useful to store intermediate results, and when used correctly candramaticallyimproveperformance ofqueries. On mostdatabaseplatformstemp ta­ bleshaveveryniceproperties: they’reonlyvisibletothecurrentuser,areautomatically dropped when the session ends, and can be created even when the user has no write ac­ cess. Unfortunately, inOracletemptablesarebasicallypermanenttables, withtheonly differencethatthedatainsidethetableisonlyvisibletothecurrentuser. Thisiswhy,in Oracle,SqlRenderwilltrytoemulatetemptablesby 1.Adding a random string to the table name so tables from different users will not conflict. 2.Allowingtheusertospecifytheschemawherethetemptableswillbecreated.\n",
      "page text: 128 Chapter 9. SQL and R Forexample: sql <-\"SELECT * FROM #children;\" translate (sql,targetDialect = \"oracle\" ,oracleTempSchema = \"temp_schema\" ) ## [1] \"SELECT * FROM temp_schema.i9bg8xexchildren ;\" Notethattheuserwillneedtohavewriteprivilegeson temp_schema . Also note that because Oracle has a limit on table names of 30 characters. Temp table names are only allowed to be at most 22 characters long , becauseelsethenamewill becometoolongafterappendingthesessionID. Furthermore,rememberthattemptablesarenotautomaticallydroppedonOracle,soyou will need to explicitly TRUNCATE andDROPall temp tables once you’re done with them topreventorphantablesaccumulatingintheOracletempschema. Implicit Casts OneofthefewpointswhereSQLServerislessexplicitthanotherdialectsisthatitallows implicitcasts. Forexample,thiscodewillworkonSQLServer: CREATETABLE#temp (txt VARCHAR); INSERTINTO#temp SELECT'1'; SELECT*FROM#tempWHEREtxt=1; Even though txtis a VARCHAR field and we are comparing it with an integer, SQL Serverwillautomaticallycastoneofthetwotothecorrecttypetoallowthecomparison. Incontrast,otherdialectssuchasPostgreSQLwillthrowanerrorwhentryingtocompare aVARCHARwithanINT. Youshouldthereforealwaysmakecastsexplicit. Intheaboveexample,thelaststatement shouldbereplacedwitheither SELECT*FROM#tempWHEREtxt=CAST(1ASVARCHAR); or SELECT*FROM#tempWHERECAST(txtASINT)=1;\n",
      "page text: 9.1. SqlRender 129 Case Sensitivity in String Comparisons SomeDBMSplatformssuchasSQLServeralwaysperformstringcomparisonsinacase­ insensitiveway,whileotherssuchasPostgreSQLarealwayscasesensitive. Itistherefore recommendedtoalwaysassumecase­sensitivecomparisons,andtoexplicitlymakecom­ parisonscase­insensitivewhenunsureaboutthecase. Forexample,insteadof SELECT*FROMconcept WHEREconcept_class_id ='Clinical Finding' itispreferredtouse SELECT*FROMconcept WHERELOWER(concept_class_id) ='clinical finding' Schemas and Databases In SQL Server, tables are located in a schema, and schemas reside in a database. For example, cdm_data.dbo.person refers to the persontable in the dboschema in the cdm_data database. Inother dialects, eventhough a similarhierarchy often existsthey areusedverydifferently. InSQLServer,thereistypicallyoneschemaperdatabase(often calleddbo),anduserscaneasilyusedataindifferentdatabases. Onotherplatforms,for exampleinPostgreSQL,itisnotpossibletousedataacrossdatabasesinasinglesession, but there are often many schemas in a database. In PostgreSQL one could say that the equivalentofSQLServer’sdatabaseistheschema. WethereforerecommendconcatenatingSQLServer’sdatabaseandschemaintoasingle parameter,whichwetypicallycall @databaseSchema . Forexample,wecouldhavethe parameterizedSQL SELECT*FROM@databaseSchema.person where on SQL Server we can include both database and schema names in the value: databaseSchema = \"cdm_data.dbo\" . On other platforms, we can use the same code, but now only specify the schema as the parameter value: databaseSchema = \"cdm_data\" . The one situation where this will fail is the USEcommand, since USE cdm_data.dbo; will throw an error. It is therefore preferred not to use the USEcommand, but always specifythedatabase/schemawhereatableislocated. Debugging Parameterized SQL DebuggingparameterizedSQLcanbeabitcomplicated. OnlytherenderedSQLcanbe tested against a database server, but changes to the code should be made in the parame­ terized(pre­rendered)SQL.\n",
      "page text: 130 Chapter 9. SQL and R A Shiny app is included in the SqlRender package for interactively editing source SQL andgeneratingrenderedandtranslatedSQL.Theappcanbestartedusing: launchSqlRenderDeveloper () That will open the default browser with the app shown in Figure 9.1. The app is also publiclyavailableontheweb.1 Figure9.1: TheSqlDeveloperShinyapp. IntheappyoucanenterOHDSISQL,selectthetargetdialectaswellasprovidevalues fortheparametersthatappearinyourSQL,andthetranslationwillautomaticallyappear atthebottom. 9.2 DatabaseConnector DatabaseConnector is an R package for connecting to various database platforms using Java’sJDBCdrivers. TheDatabaseConnectorpackageisavailableonCRAN(theCom­ prehensiveRArchiveNetwork),andcanthereforebeinstalledusing: install.packages (\"DatabaseConnector\" ) DatabaseConnector supports a wide array of technical platforms including traditional databasesystems(PostgreSQL,MicrosoftSQLServer,SQLite,andOracle),paralleldata warehouses(MicrosoftAPS,IBMNetezza,andAmazon),aswellasBigDataplatforms (Hadoop through Impala, and Google BigQuery). The package already contains most 1http://data.ohdsi.org/SqlDeveloper/\n",
      "page text: 9.2. DatabaseConnector 131 drivers, but because of licensing reasons the drivers for BigQuery, Netezza and Impala arenotincludedbutmustbeobtainedbytheuser. Type ?jdbcDrivers forinstructions on how to download these drivers. Once downloaded, you can use the pathToDriver argumentofthe connect,dbConnect ,andcreateConnectionDetails functions. 9.2.1 Creating a Connection Toconnecttoadatabaseanumberofdetailsneedtobespecified,suchasthedatabaseplat­ form,thelocationoftheserver,theusername,andpassword. Wecancallthe connect functionandspecifythesedetailsdirectly: conn <- connect(dbms =\"postgresql\" , server = \"localhost/postgres\" , user =\"joe\", password = \"secret\" , schema = \"cdm\") ## Connecting using PostgreSQL driver See?connect for information on which details are required for each platform. Don’t forgettocloseanyconnectionafterwards: disconnect (conn) Note that, instead of providing the server name, it is also possible to provide the JDBC connectionstringifthisismoreconvenient: connString <- \"jdbc:postgresql://localhost:5432/postgres\" conn <- connect(dbms =\"postgresql\" , connectionString = connString, user =\"joe\", password = \"secret\" , schema = \"cdm\") ## Connecting using PostgreSQL driver Sometimes we may want to first specify the connection details, and defer connecting until later. This may be convenient for example when the connection is established inside a function, and the details need to be passed as an argument. We can use the createConnectionDetails functionforthispurpose: details <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/postgres\" , user =\"joe\", password = \"secret\" ,\n",
      "page text: 132 Chapter 9. SQL and R schema = \"cdm\") conn <- connect(details) ## Connecting using PostgreSQL driver 9.2.2 Querying Themainfunctionsforqueryingdatabasearethe querySql andexecuteSql functions. Thedifferencebetweenthesefunctionsisthat querySql expectsdatatobereturnedby thedatabase,andcanhandleonlyoneSQLstatementatatime. Incontrast, executeSql doesnotexpectdatatobereturned,andacceptsmultipleSQLstatementsinasingleSQL string. Someexamples: querySql (conn,\"SELECT TOP 3 * FROM person\" ) ## person_id gender_concept_id year_of_birth ## 1 1 8507 1975 ## 2 2 8507 1976 ## 3 3 8507 1977 executeSql (conn,\"TRUNCATE TABLE foo; DROP TABLE foo;\" ) Bothfunctionsprovideextensiveerrorreporting: Whenanerroristhrownbytheserver, theerrormessageandtheoffendingpieceofSQLarewrittentoatextfiletoallowbetter debugging. The executeSql functionalsobydefaultshowsaprogressbar,indicatingthe percentageofSQLstatementsthathasbeenexecuted. Ifthoseattributesarenotdesired, thepackagealsooffersthe lowLevelQuerySql andlowLevelExecuteSql functions. 9.2.3 Querying Using Ffdf Objects Sometimes the data to be fetched from the database is too large to fit into memory. As mentioned in Section 8.4.2, in such a case we can use the ffpackage to store R data objects on file, and use them as if they are available in memory. DatabaseConnector candownloaddatadirectlyintoffdfobjects: x <-querySql.ffdf (conn,\"SELECT * FROM person\" ) xisnowanffdfobject.\n",
      "page text: 9.3. Querying the CDM 133 9.2.4 Querying Different Platforms Using the Same SQL The following convenience functions are available that first call the renderand translate functions in the SqlRender package: renderTranslateExecuteSql , renderTranslateQuerySql ,renderTranslateQuerySql.ffdf . Forexample: x <-renderTranslateQuerySql (conn, sql =\"SELECT TOP 10 * FROM @schema.person\" , schema = \"cdm_synpuf\" ) Note that the SQL Server­specific ‘TOP 10’ syntax will be translated to for example ‘LIMIT 10’ on PostgreSQL, and that the SQL parameter @schemawill be instantiated withtheprovidedvalue‘cdm_synpuf’. 9.2.5 Inserting T ables AlthoughitisalsopossibletoinsertdatainthedatabasebysendingSQLstatementsusing theexecuteSql function,itisoftenmoreconvenientandfaster(duetosomeoptimiza­ tion)tousethe insertTable function: data(mtcars) insertTable (conn,\"mtcars\" , mtcars, createTable = TRUE) Inthisexample,we’reuploadingthemtcarsdataframetoatablecalled‘mtcars’onthe server,whichwillbeautomaticallycreated. 9.3 Querying the CDM In the following examples we use OHDSI SQL to query a database that adheres to the CDM.Thesequeriesuse @cdmtodenotethedatabaseschemawherethedatainCDMcan befound. Wecanstartbyjustqueryinghowmanypeopleareinthedatabase: SELECTCOUNT(*)ASperson_count FROM@cdm.person; PERSON_COUNT 26299001 Orperhapswe’reinterestedintheaveragelengthofanobservationperiod:\n",
      "page text: 134 Chapter 9. SQL and R SELECTAVG(DATEDIFF( DAY, observation_period_start_date, observation_period_end_date) /365.25)ASnum_years FROM@cdm.observation_period; NUM_YEARS 1.980803 Wecanjointablestoproduceadditionalstatistics. Ajoincombinesfieldsfrommultiple tables, typically by requiring specific fields in the tables to have the same value. For example,herewejointhePERSONtabletotheOBSERVATION_PERIODtableonthe PERSON_IDfieldsinbothtables. Inotherwords,theresultofthejoinisanewtable­like setthathasallthefieldsofthetwotables,butinallrowsthePERSON_IDfieldsfromthe two tables must have the same value. We can now for example compute the maximum ageatobservationendbyusingtheOBSERVATION_PERIOD_END_DATEfieldfrom theOBSERVATION_PERIODtabletogetherwiththeyear_of_birthfieldofthePERSON table: SELECTMAX(YEAR(observation_period_end_date) - year_of_birth) ASmax_age FROM@cdm.person INNERJOIN@cdm.observation_period ONperson.person_id =observation_period.person_id; MAX_AGE 90 Amuchmorecomplicatedqueryisneededtodeterminethedistributionofageatthestart ofobservation. Inthisquery,wefirstjointhePERSONtotheOBSERVATION_PERIOD tabletocomputeageatstartofobservation. Wealsocomputetheorderingforthisjoined setbasedonage,andstoreitasorder_nr. Becausewewanttousetheresultofthisjoin multiple times, we define it as a common table expression (CTE) (defined using WITH ... AS) that we call “ages,” meaning we can refer to ages as if it is an existing table. Wecountthenumberofrowsinagestoproduce“n,”andthenforeachquantilefindthe minimum age where the order_nr is smaller than the fraction times n. For example, to findthemedianweusetheminimumagewhere 𝑜𝑟𝑑𝑒𝑟_𝑛𝑟 < .50 ∗ 𝑛 . Theminimumand maximumagearecomputedseparately: WITHages AS(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████████████████████▎                                                                                       | 167/464 [00:01<00:02, 99.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 9.3. Querying the CDM 135 SELECTage, ROW_NUMBER ()OVER( ORDERBYage ) order_nr FROM( SELECTYEAR(observation_period_start_date) -year_of_birth ASage FROM@cdm.person INNERJOIN@cdm.observation_period ONperson.person_id =observation_period.person_id ) age_computed ) SELECTMIN(age)ASmin_age, MIN(CASE WHENorder_nr <.25*n THEN9999 ELSEage END)ASq25_age, MIN(CASE WHENorder_nr <.50*n THEN9999 ELSEage END)ASmedian_age, MIN(CASE WHENorder_nr <.75*n THEN9999 ELSEage END)ASq75_age, MAX(age)ASmax_age FROMages CROSSJOIN( SELECTCOUNT(*)ASn FROMages ) population_size; MIN_AGE Q25_AGE MEDIAN_AGE Q75_AGE MAX_AGE 0 6 17 34 90 MorecomplexcomputationscanalsobeperformedinRinsteadofusingSQL.Forexam­ ple,wecangetthesameanswerusingthisRcode: sql <-\"SELECT YEAR(observation_period_start_date) - year_of_birth AS age FROM @cdm.person INNER JOIN @cdm.observation_period ON person.person_id = observation_period.person_id;\"\n",
      "page text: 136 Chapter 9. SQL and R age <-renderTranslateQuerySql (conn, sql, cdm =\"cdm\") quantile (age[,1],c(0,0.25,0.5,0.75,1)) ## 0% 25% 50% 75% 100% ## 0 6 17 34 90 Herewecomputeageontheserver,downloadallages,andthencomputetheagedistribu­ tion. However,thisrequiresmillionsofrowsofdatatobedownloadedfromthedatabase server,andisthereforenotveryefficient. Youwillneedtodecideonacase­by­casebasis whetheracomputationisbestperformedinSQLorinR. QueriescanusethesourcevaluesintheCDM.Forexample, wecanretrievethetop10 mostfrequentconditionsourcecodesusing: SELECTTOP10condition_source_value, COUNT(*)AScode_count FROM@cdm.condition_occurrence GROUPBYcondition_source_value ORDERBY-COUNT(*); CONDITION_SOURCE_VALUE CODE_COUNT 4019 49094668 25000 36149139 78099 28908399 319 25798284 31401 22547122 317 22453999 311 19626574 496 19570098 I10 19453451 3180 18973883 Here we grouped records in the CONDITION_OCCURRENCE table by values of the CONDITION_SOURCE_VALUEfield,andcountedthenumberofrecordsineachgroup. WeretrievetheCONDITION_SOURCE_VALUEandthecount,andreverse­orderitby thecount. 9.4 Using the Vocabulary When Querying Manyoperationsrequirethevocabularytobeuseful. TheVocabularytablesarepartofthe CDM,andarethereforeavailableusingSQLqueries. Hereweshowhowqueriesagainst theVocabularycanbecombinedwithqueriesagainsttheCDM.ManyfieldsintheCDM containconceptIDswhichcanberesolvedusingtheCONCEPTtable. Forexample,we\n",
      "page text: 9.5. QueryLibrary 137 maywishtocountthenumberofpersonsinthedatabasestratifiedbygender,anditwould beconvenienttoresolvetheGENDER_CONCEPT_IDfieldtoaconceptname: SELECTCOUNT(*)ASsubject_count, concept_name FROM@cdm.person INNERJOIN@cdm.concept ONperson.gender_concept_id =concept.concept_id GROUPBYconcept_name; SUBJECT_COUNT CONCEPT_NAME 14927548 FEMALE 11371453 MALE AverypowerfulfeatureoftheVocabularyisitshierarchy. Averycommonquerylooks foraspecificconcept and all of its descendants . Forexample,imaginewewishtocount thenumberofprescriptionscontainingtheingredientibuprofen: SELECTCOUNT(*)ASprescription_count FROM@cdm.drug_exposure INNERJOIN@cdm.concept_ancestor ONdrug_concept_id =descendant_concept_id INNERJOIN@cdm.concept ingredient ONancestor_concept_id =ingredient.concept_id WHERELOWER(ingredient.concept_name) ='ibuprofen' ANDingredient.concept_class_id ='Ingredient' ANDingredient.standard_concept ='S'; PRESCRIPTION_COUNT 26871214 9.5 QueryLibrary QueryLibraryisalibraryofcommonly­usedSQLqueriesfortheCDM.Itisavailableas anonlineapplication2showninFigure 9.2,andasanRpackage.3 ThepurposeofthelibraryistohelpnewuserslearnhowtoquerytheCDM.Thequeries in the library have been reviewed and approved by the OHDSI community. The query library is primarily intended for training purposes, but it is also a valuable resource for experiencedusers. 2http://data.ohdsi.org/QueryLibrary 3https://github.com/OHDSI/QueryLibrary\n",
      "page text: 138 Chapter 9. SQL and R Figure9.2: QueryLibrary: alibraryofSQLqueriesagainsttheCDM. The QueryLibrary makes use of SqlRender to output the queries in the SQL dialect of choice. UserscanalsospecifytheCDMdatabaseschema, vocabularydatabaseschema (ifseparate),andtheOracletempschema(ifneeded),sothequerieswillbeautomatically renderedwiththesesettings. 9.6 Designing a Simple Study 9.6.1 Problem Definition Angioedema is a well­known side­effect of ACE inhibitors (ACEi). Slater et al. (1988) estimatetheincidencerateofangioedemainthefirstweekofACEitreatmenttobeone caseper3,000 patientsper week. Herewe seekto replicatethis finding, andstratify by age and gender. For simplicity, we focus on one ACEi: lisinopril. We thus answer the question Whatistherateofangioedemainthefirstweekfollowinglisinopriltreatment initiation,stratifiedbyageandgender? 9.6.2 Exposure We’ll define exposure as first exposure to lisinopril. By first we mean no earlier expo­ sure to lisinopril. We require 365 days of continuous observation time prior to the first\n",
      "page text: 9.7. Implementing the Study Using SQL and R 139 exposure. 9.6.3 Outcome We define angioedema as any occurrence of an angioedema diagnosis code during an inpatientoremergencyroom(ER)visit. 9.6.4 Time-At-Risk We will compute the incidence rate in the first week following treatment initiation, irre­ spectiveofwhetherpatientswereexposedforthefullweek. 9.7 Implementing the Study Using SQL and R AlthoughwearenotboundtoanyoftheOHDSItoolconventions,itishelpfultofollow the same principles. In this case, we will use SQL to populate a cohort table, similarly to how the OHDSI tools work. The COHORT table is defined in the CDM, and has a predefinedsetoffieldsthatwewillalsouse. WefirstmustcreatetheCOHORTtableina databaseschemawherewehavewriteaccess,whichlikelyisnotthesameasthedatabase schemathatholdsthedatainCDMformat. library(DatabaseConnector) conn <- connect(dbms =\"postgresql\" , server = \"localhost/postgres\" , user =\"joe\", password = \"secret\" ) cdmDbSchema <- \"cdm\" cohortDbSchema <- \"scratch\" cohortTable <- \"my_cohorts\" sql <-\" CREATE TABLE @cohort_db_schema.@cohort_table ( cohort_definition_id INT, cohort_start_date DATE, cohort_end_date DATE, subject_id BIGINT ); \" renderTranslateExecuteSql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable) Herewehaveparameterizedthedatabaseschemaandtablenames,sowecaneasilyadapt themtodifferentenvironments. Theresultisanemptytableonthedatabaseserver.\n",
      "page text: 140 Chapter 9. SQL and R 9.7.1 Exposure Cohort Nextwecreateourexposurecohort,andinsertitintoourCOHORTtable: sql <-\" INSERT INTO @cohort_db_schema.@cohort_table ( cohort_definition_id, cohort_start_date, cohort_end_date, subject_id ) SELECT 1 AS cohort_definition_id, cohort_start_date, cohort_end_date, subject_id FROM ( SELECT drug_era_start_date AS cohort_start_date, drug_era_end_date AS cohort_end_date, person_id AS subject_id FROM ( SELECT drug_era_start_date, drug_era_end_date, person_id, ROW_NUMBER() OVER ( PARTITION BY person_id ORDER BY drug_era_start_date ) order_nr FROM @cdm_db_schema.drug_era WHERE drug_concept_id = 1308216 -- Lisinopril ) ordered_exposures WHERE order_nr = 1 ) first_era INNER JOIN @cdm_db_schema.observation_period ON subject_id = person_id AND observation_period_start_date < cohort_start_date AND observation_period_end_date > cohort_start_date WHERE DATEDIFF(DAY, observation_period_start_date, cohort_start_date) >= 365; \" renderTranslateExecuteSql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable, cdm_db_schema = cdmDbSchema) Here we use the DRUG_ERA table, a standard table in the CDM that is automatically derived from the DRUG_EXPOSURE table. The DRUG_ERA table contains eras of continuous exposure at the ingredient level. We can thus search for lisinopril, and this\n",
      "page text: 9.7. Implementing the Study Using SQL and R 141 willautomaticallyidentifyallexposurestodrugscontaininglisinopril. Wetakethefirst drugexposureperperson, andthenjointotheOBSERVATION_PERIODtable, andbe­ causeapersoncanhaveseveralobservationperiodswemustmakesureweonlyjointo the period containing the drug exposure. We then require at least 365 days between the OBSERVATION_PERIOD_START_DATEandtheCOHORT_START_DATE. 9.7.2 Outcome Cohort Finally,wemustcreateouroutcomecohort: sql <-\" INSERT INTO @cohort_db_schema.@cohort_table ( cohort_definition_id, cohort_start_date, cohort_end_date, subject_id ) SELECT 2 AS cohort_definition_id, cohort_start_date, cohort_end_date, subject_id FROM ( SELECT DISTINCT person_id AS subject_id, condition_start_date AS cohort_start_date, condition_end_date AS cohort_end_date FROM @cdm_db_schema.condition_occurrence INNER JOIN @cdm_db_schema.concept_ancestor ON condition_concept_id = descendant_concept_id WHERE ancestor_concept_id = 432791 -- Angioedema ) distinct_occurrence INNER JOIN @cdm_db_schema.visit_occurrence ON subject_id = person_id AND visit_start_date <= cohort_start_date AND visit_end_date >= cohort_start_date WHERE visit_concept_id IN (262, 9203, 9201) -- Inpatient or ER; \" renderTranslateExecuteSql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable, cdm_db_schema = cdmDbSchema) Here we join the CONDITION_OCCURRENCE table to the CONCEPT_ANCESTOR tabletofindalloccurrencesofangioedemaoranyofitsdescendants. WeuseDISTINCT to make sure we only select one record per day, as we believe multiple angioedema di­ agnosesonthesamedayaremorelikelytobethesameoccurrenceratherthanmultiple angioedema events. We join these occurrences to the VISIT_OCCURRENCE table to\n",
      "page text: 142 Chapter 9. SQL and R ensurethediagnosiswasmadeinandinpatientorERsetting. 9.7.3 Incidence Rate Calculation Now that our cohorts are in place, we can compute the incidence rate, stratified by age andgender: sql <-\" WITH tar AS ( SELECT concept_name AS gender, FLOOR((YEAR(cohort_start_date) - year_of_birth) / 10) AS age, subject_id, cohort_start_date, CASE WHEN DATEADD(DAY, 7, cohort_start_date) > observation_period_end_date THEN observation_period_end_date ELSE DATEADD(DAY, 7, cohort_start_date) END AS cohort_end_date FROM @cohort_db_schema.@cohort_table INNER JOIN @cdm_db_schema.observation_period ON subject_id = observation_period.person_id AND observation_period_start_date < cohort_start_date AND observation_period_end_date > cohort_start_date INNER JOIN @cdm_db_schema.person ON subject_id = person.person_id INNER JOIN @cdm_db_schema.concept ON gender_concept_id = concept_id WHERE cohort_definition_id = 1 -- Exposure ) SELECT days.gender, days.age, days, CASE WHEN events IS NULL THEN 0 ELSE events END AS events FROM ( SELECT gender, age, SUM(DATEDIFF(DAY, cohort_start_date, cohort_end_date)) AS days FROM tar GROUP BY gender, age ) days LEFT JOIN ( SELECT gender, age, COUNT(*) AS events FROM tar INNER JOIN @cohort_db_schema.@cohort_table angioedema\n",
      "page text: 9.7. Implementing the Study Using SQL and R 143 ON tar.subject_id = angioedema.subject_id AND tar.cohort_start_date <= angioedema.cohort_start_date AND tar.cohort_end_date >= angioedema.cohort_start_date WHERE cohort_definition_id = 2 -- Outcome GROUP BY gender, age ) events ON days.gender = events.gender AND days.age = events.age; \" results <- renderTranslateQuerySql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable, cdm_db_schema = cdmDbSchema, snakeCaseToCamelCase = TRUE) Wefirstcreate“tar,”aCTEthatcontainsallexposureswiththeappropriatetime­at­risk. Notethatwetruncatethetime­at­riskattheOBSERVATION_PERIOD_END_DATE.We also compute the age in 10­year bins, and identify the gender. The advantage of using a CTE is that we can use the same set of intermediate results several times in a query. Inthiscaseweuseittocountthetotalamountoftime­at­risk, aswellasthenumberof angioedemaeventsthatoccurduringthetime­at­risk. WeusesnakeCaseToCamelCase = TRUE becauseinSQLwetendtousesnake_casefor field names (because SQL in case­insensitive), whereas in R we tend to use camelCase (because R is case­sensitive). The resultsdata frame column names will now be in camelCase. Withthehelpoftheggplot2packagewecaneasilyplotourresults: # Compute incidence rate (IR) : results$ir <-1000*results$events/results$days/7 # Fix age scale: results$age <-results$age*10 library(ggplot2) ggplot(results, aes(x =age,y =ir,group = gender, color = gender)) + geom_line ()+ xlab(\"Age\")+ ylab(\"Incidence (per 1,000 patient weeks)\" )\n",
      "page text: 144 Chapter 9. SQL and R 9.7.4 Clean Up Don’tforgettocleanupthetablewecreated,andtoclosetheconnection: sql <-\" TRUNCATE TABLE @cohort_db_schema.@cohort_table; DROP TABLE @cohort_db_schema.@cohort_table; \" renderTranslateExecuteSql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable) disconnect (conn) 9.7.5 Compatibility BecauseweuseOHDSISQLtogetherwithDatabaseConnectorandSqlRenderthrough­ out,thecodewereviewedherewillrunonanydatabaseplatformsupportedbyOHDSI. Notethatfordemonstrationpurposeswechosetocreateourcohortsusinghand­crafted SQL.ItwouldprobablyhavebeenmoreconvenienttoconstructcohortdefinitioninAT­ LAS, and use the SQL generated by ATLAS to instantiate the cohorts. ATLAS also produced OHDSI SQL, and can therefore easily be used together with SqlRender and DatabaseConnector.\n",
      "page text: 9.8. Summary 145 9.8 Summary –SQL(Structured Query Language) is a standard language for querying databases,includingthosethatconformtotheCommonDataModel(CDM). –Different database platforms have different SQL dialects, and require differ­ enttoolstoquerythem. –TheSqlRender andDatabaseConnector Rpackagesprovideaunifiedway to query data in the CDM, allowing the same analysis code to be run in dif­ ferentenvironmentswithoutmodification. –ByusingRandSQLtogetherwecanimplementcustomanalysesthatarenot supportedbytheOHDSItools. –The QueryLibrary provides a collection of re­usable SQL queries for the CDM. 9.9 Exercises Prerequisites For these exercises we assume R, R­Studio and Java have been installed as described in Section 8.4.5. Also required are the SqlRender,DatabaseConnector , andEunomia packages,whichcanbeinstalledusing: install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. Exercise 9.1. UsingSQLandR,computehowmanypeopleareinthedatabase. Exercise 9.2. UsingSQLandR,computehowmanypeoplehaveatleastoneprescription ofcelecoxib. Exercise 9.3. UsingSQLandR,computehowmanydiagnosesofgastrointestinalhem­ orrhage occur during exposure to celecoxib. (Hint: the concept ID for gastrointestinal hemorrhageis 192671.)\n",
      "page text: 146 Chapter 9. SQL and R SuggestedanswerscanbefoundinAppendix E.5.\n",
      "page text: Chapter 10 Defining Cohorts Chapter lead: Kristin Kostka Observational health data, also referred to real world data , are the data related to pa­ tient health status and/or the delivery of health care routinely collected from a variety of sources. As such, OHDSI data stewards (OHDSI collaborators who maintain data inCDMfortheirsites)maycapturedatafromanumberofsourcesincludingElectronic HealthRecords(EHR),healthinsuranceclaimsandbillingactivities,productanddisease registries,patient­generateddataincludinginhome­usesettings,anddatagatheredfrom othersourcesthatcaninformonhealthstatus,suchasmobiledevices. Asthesedatawere not collected for research purposes, the data may not explicitly capture the clinical data elementsweareinterestedin. Forexample,ahealthinsuranceclaimsdatabaseisdesignedtocaptureallcareprovided for some condition (e.g. angioedema) so the associated costs can appropriately be reim­ bursed, and information on the actual condition is captured only as part of this aim. If wewishtousesuchobservationaldataforresearchpurposes,wewilloftenhavetowrite some logic that uses what is captured in the data to infer what we are really interested in. Inotherwords,weoftenneedtocreateacohortusingsomedefinitionofhowaclin­ ical event manifests. Thus, if we want to identify angioedema events in an insurance claims database, we may define logic requiring an angioedema diagnose code recorded inanemergencyroomsetting,todistinguishfromclaimsthatmerelydescribefollow­up care for some past angioedema occurrence. Similar considerations may apply for data capturedduringroutinehealthcareinteractionsloggedinanEHR.Asdataarebeingused forasecondarypurpose,wemustbecognizantofwhateachdatabasewasoriginallyde­ signed to do. Each time we design a study, we must think through the nuances of how ourcohortexistsinavarietyofhealthcaresettings. The chapter serves to explain what is meant by creating and sharing cohort definitions, themethodsfordevelopingcohorts,andhowtobuildyourowncohortsusingATLASor SQL. 147\n",
      "page text: 148 Chapter 10. Defining Cohorts 10.1 What Is a Cohort? InOHDSIresearch,wedefineacohortasasetofpersonswhosatisfyoneormoreinclu­ sioncriteriaforadurationoftime. Thetermcohortisofteninterchangedwiththeterm phenotype. CohortsareusedthroughoutOHDSIanalyticaltoolsandnetworkstudiesas the primary building blocks for executing a research question. For instance, in a study aiming to predict the risk of angioedema in a group of people initiation ACE inhibitors, we define two cohorts: the outcome cohort (angioedema), and the target cohort (people initiatingACEinhibitors). AnimportantaspectofcohortsinOHDSIisthattheyaretypi­ callydefinedindependentlyfromtheothercohortsinthestudy,thusallowingre­use. For example,inourexampletheangioedemacohortwouldidentifyallangioedemaeventsin thepopulation,includingthoseoutsidethetargetpopulation. Ouranalyticstoolswilltake theintersectionofthesetwocohortswhenneededatanalysistime. Theadvantageofthis isthatthesameangioedemacohortdefinitioncannowalsobeusedinotheranalyses,for exampleanestimationstudycomparingACEinhibitorstosomeotherexposure. Cohort definitionscanvaryfromstudytostudydependingontheresearchquestionofinterest. Acohortisasetofpersonswhosatisfyoneormoreinclusioncriteriaforaduration oftime. It is important to realize that this definition of a cohort used in OHDSI might differ from that used by others in the field. For example, in many peer­reviewed scientific manuscripts,acohortissuggestedtobeanalogoustoacodesetofspecificclinicalcodes (e.g. ICD­9/ICD­10, NDC, HCPCS, etc). While code sets are an important piece in as­ semblingacohort,acohortisnotdefinedbycodeset. Acohortrequiresspecificlogicfor howtousethecodesetforthecriteria(e.g.isitthefirstoccurrenceoftheICD­9/ICD­10 code? any occurrence?). A well­defined cohort specifies how a patient enters a cohort andhowapatientexitsacohort. ThereareuniquenuancestoutilizingOHDSI’sdefinitionofacohort,including: •Onepersonmaybelongtomultiplecohorts •Onepersonmaybelongtothesamecohortformultipledifferenttimeperiods •One person may not belong to the same cohort multiple times during the same periodoftime •Acohortmayhavezeroormoremembers Therearetwomainapproachestoconstructingacohort: 1.Rule­based cohort definitions use explicit rules to describe when a patient is in thecohort. Definingtheserulestypicallyreliesheavilyonthedomainexpertiseof theindividualdesigning thecohortto usetheirknowledge ofthetherapeutic area ofinteresttobuildrulesforcohortinclusioncriteria. 2.Probabilistic cohort definitions useaprobabilisticmodeltocomputeaprobabil­ itybetween0and100%ofthepatientbeinginthecohort. Thisprobabilitycanbe turnedintoayes­noclassificationusingsomethreshold,orinsomestudydesigns\n",
      "page text: 10.2. Rule­Based Cohort Definitions 149 canbeusedasis. Theprobabilisticmodelistypicallytrainedusingmachinelearn­ ing (e.g. logistic regression) on some example data to automatically identify the relevantpatientcharacteristicsthatarepredictive. Thenextsectionswilldiscusstheseapproachesinfurtherdetail. 10.2 Rule-Based Cohort Definitions Arule­basedcohortdefinitionbeginswithexplicitlystatingoneormoreinclusioncriteria (e.g.“peoplewithangioedema”)inaspecificdurationoftime(e.g.“whodevelopedthis conditionwithinthelast6months”). Thestandardcomponentsweusetoassemblethesecriteriaare: •Domain: The CDM domain(s) where the data are stored (e.g. “Procedure Occur­ rence”,“DrugExposure”)definethetypeofclinicalinformationandtheallowable conceptsthatcanberepresentedinsidethatCDMtable. Domainsarediscussedin moredetailinSection 4.2.4. •Concept set : A data­agnostic expression that defines one or more Standard Con­ ceptsencompassingtheclinicalentityofinterest. Theseconceptsetsareinteroper­ ableacrossdifferentobservationalhealthdataastheyrepresentthestandardterms theclinicalentitymapstointheVocabulary. ConceptsetsarediscussedinSection 10.3. •Domain­specific attribute : Additional attributes related to the clinical entity of interest (E.g. DAYS_SUPPLY for a DRUG_EXPOSURE, or VALUE_AS_NUMBERorRANGE_HIGHforaMEASUREMENT.) •Temporal logic : Thetimeintervalswithinwhichtherelationshipbetweenaninclu­ sioncriteriaandaneventisevaluated(E.g. Indicatedconditionmustoccurduring 365dayspriortooronexposurestart.) Asyouarebuildingyourcohortdefinition, youmayfindithelpfultothinkofDomains analogoustobuildingblocks(seeFigure 10.1)thatrepresentcohortattributes. Ifyouare confusedaboutallowablecontentineachdomain,youcanalwaysrefertotheCommon DataModelchapter(Chapter 4)forhelp. Whencreatingacohortdefinition,youneedtoaskyourselfthefollowingquestions: •What initial event defines the time of cohort entry? •What inclusion criteria are applied to the initial events? •What defines the time of cohort exit? Cohort entry event : Thecohortentryevent(initialevent)definesthetimewhenpeople enter the cohort, called the cohort index date . A cohort entry event can be any event recordedintheCDMsuchasdrugexposures,conditions,procedures,measurementsand visits. InitialeventsaredefinedbytheCDMdomainwherethedataarestored(e.g.PRO­ CEDURE_OCCURRENCE,DRUG_EXPOSURE,etc),theconceptsetsbuilttoidentify\n",
      "page text: 150 Chapter 10. Defining Cohorts Figure10.1: BuildingBlocksofCohortdefinitions. the clinical activity (e.g. SNOMED codes for conditions, RxNorm codes for drugs) as wellasanyotherspecificattributes(e.g.ageatoccurrence,firstdiagnosis/procedure/etc, specifyingstartandenddate,specifyingvisittypeorcriteria,dayssupply,etc). Theset ofpeoplehavinganentryeventisreferredtoasthe initial event cohort . Inclusion criteria : Inclusioncriteriaareappliedtotheinitialeventcohorttofurtherre­ strictthesetofpeople. EachinclusioncriterionisdefinedbytheCDMdomain(s)where the data are stored, concept set(s) representing the clinical activity, domain­specific at­ tributes (e.g. days supply, visit type, etc), and the temporal logic relative to the cohort indexdate. Eachinclusioncriterioncanbeevaluatedtodeterminetheimpactofthecri­ teria on the attrition of persons from the initial event cohort. The qualifying cohort is definedasallpeopleintheinitialeventcohortthatsatisfyallinclusioncriteria. Cohort exit criteria : The cohort exit event signifies when a person no longer qualifies for cohort membership. Cohort exit can be defined in multiple ways such as the end of the observation period, a fixed time interval relative to the initial entry event, the last event in a sequence of related observations (e.g. persistent drug exposure) or through othercensoringofobservationperiod. Cohortexitstrategywillimpactwhetheraperson canbelongtothecohortmultipletimesduringdifferenttimeintervals. IntheOHDSItoolsthereisnodistinctionbetweeninclusionandexclusioncriteria. All criteria are formulated as inclusion criteria. For example, the exclusion crite­ rion“Excludepeoplewithpriorhypertension”canbeformulatedastheinclusion criterion“Includepeoplewith0occurrencesofpriorhypertension”.\n",
      "page text: 10.3. Concept Sets 151 10.3 Concept Sets A concept set is an expression representing a list of concepts that can be used as a reusable component in various analyses. It can be thought of as a standardized, computer­executable equivalent of the code lists often used in observational studies. A conceptsetexpressionconsistsofalistofconceptswiththefollowingattributes: •Exclude: Exclude this concept (and any of its descendants if selected) from the conceptset. •Descendants : Considernotonlythisconcept,butalsoallofitsdescendants. •Mapped: Allowtosearchfornon­standardconcepts. Forexample,aconceptsetexpressioncouldcontainstwoconceptsasdepictedinTable 10.1. Hereweincludeconcept 4329847(“Myocardialinfarction”)andallofitsdescen­ dants, but exclude concept 314666(“Old myocardial infarction”) and all of its descen­ dants. Table10.1: Anexampleconceptsetexpression. ConceptId ConceptName Excluded Descendants Mapped 4329847 Myocardialinfarction NO YES NO 314666 Oldmyocardialinfarction YES YES NO AsshowninFigure 10.2,thiswillinclude“Myocardialinfarction”andallofitsdescen­ dants except “Old myocardial infarction” and its descendants. In total, this concept set expressionimpliesnearlyahundredStandardConcepts. TheseStandardConceptsinturn reflect hundreds of source codes (e.g. ICD­9 and ICD­10 codes) that may appear in the variousdatabases. Figure 10.2: A concept set including ”Myocardial infarction” (with descendants), but excluding”Oldmyocardialinfarction”(withdescendants).\n",
      "page text: 152 Chapter 10. Defining Cohorts 10.4 Probabilistic Cohort Definitions Rule­based cohort definitions are a popular method for assembling cohort definitions. However, assembling necessary expert consensus to create a study cohort can be pro­ hibitivelytimeconsuming. Probabilisticcohortdesignisanalternative,machine­driven method to expedite the selection of cohort attributes. In this approach, supervised ma­ chine learning allows a phenotyping algorithm to learn from a set of labeled examples (cases) of what attributes contribute to cohort membership. This algorithm can then be used to better ascertain the defining characteristics of a phenotype and what trade­offs occurinoverallstudyaccuracywhenchoosingtomodifyphenotypecriteria. An example of applying this approach on data in the CDM is the APHRODITE (Au­ tomated PHenotype Routine for Observational Definition, Identification, Training and Evaluation)R­package1. Thispackageprovidesacohortbuildingframeworkthatcom­ binestheabilityoflearningfromimperfectlylabeleddata. ( Bandaetal. ,2017) 10.5 Cohort Definition Validity When you are building a cohort, you should consider which of these is more important toyou: finding all the eligible patients? versus Getting only the ones you are confident about? Yourstrategytoconstructyourcohortwilldependontheclinicalstringencyofhowyour expertconsensusdefinesthedisease. Thisistosay, therightcohortdesignwilldepend onthequestionyou’retryingtoanswer. Youmayopttobuildacohortdefinitionthatuses everythingyoucanget,usesthelowestcommondenominatorsoyoucanshareitacross OHDSIsitesorisacompromiseofthetwo. Itisultimatelyattheresearcher’sdiscretion whatthresholdofstringencyisnecessarytoadequatelystudythecohortofinterest. As mentioned at the beginning of the chapter, a cohort definition is an attempt to infer somethingwewouldliketoobservefromthedatathatisrecorded. Thisbegsthequestion howwellwesucceededinthatattempt. Ingeneral,thevalidationofarule­basedcohort definition or probabilistic algorithm can be thought of as a test of the proposed cohort comparedtosomeformof“goldstandard”reference(e.g.manualchartreviewofcases). ThisisdiscussedindetailinChapter 16(“ClinicalValidity”). 10.5.1 OHDSI Gold Standard Phenotype Library Toassistthecommunityintheinventoryandoverallevaluationofexistingcohortdefini­ tionsandalgorithms,theOHDSIGoldStandardPhenotypeLibrary(GSPL)Workgroup wasformed. ThepurposeoftheGSPLworkgroupistodevelopacommunity­backedphe­ notype library from rules­based and probabilistic methods. The GSPL enable members oftheOHDSIcommunitytofind,evaluate,andutilizecommunity­validatedcohortdefi­ nitionsforresearchandotheractivities. These“goldstandard”definitionswillresideina 1https://github.com/OHDSI/Aphrodite\n",
      "page text: 10.6. Defining a Cohort for Hypertension 153 library,theentriesofwhichareheldtospecificstandardsofdesignandevaluation. Forad­ ditionalinformationrelatedtotheGSPL,consulttheOHDSIworkgrouppage.2Research within this workgroup includes APHRODITE ( Banda et al. ,2017) and the PheValuator tool(Swerdeletal. ,2019),discussedinthepriorsection,aswellasworkdonetoshare the Electronic Medical Records and Genomics eMERGE Phenotype Library across the OHDSInetwork( Hripcsaketal. ,2019). Ifphenotypecurationisyourinterest,consider contributingtothisworkgroup. 10.6 Defining a Cohort for Hypertension Webegintopracticeourcohortskillsbyputtingtogetheracohortdefinitionusingarule­ based approach. In this example, we want to find patients who initiate ACE inhibitors monotherapy as first­line treatments for hypertension Withthiscontextinmind,wearenowgoingtobuildourcohort. Aswegothroughthis exercise,wewillapproachbuildingourcohortsimilartostandardattritionchart. Figure 10.3showsthelogicalframeworkforhowwewanttobuildthiscohort. Figure10.3: LogicalDiagramofIntendedCohort YoucanbuildacohortintheuserinterfaceofATLASoryoucanwriteaquerydirectly againstyourCDM.Wewillbrieflydiscussbothinthischapter. 2https://www.ohdsi.org/web/wiki/doku.php?id=projects:workgroups:gold­library­wg\n",
      "page text: 154 Chapter 10. Defining Cohorts 10.7 Implementing a Cohort Using A TLAS TobegininATLAS,clickonthe module. Whenthemoduleloads, clickon“Newcohort”. Thenextscreenyouwillseewillbeanemptycohortdefinition. Figure10.4showswhatyouwillseeonyourscreen. Figure10.4: NewCohortDefinition Beforeyoudoanythingelse,youareencouragedtochangethenameofthecohortfrom “New Cohort Definition” to your own unique name for this cohort. You may opt for a namelike“NewusersofACEinhibitorsasfirst­linemonotherapyforhypertension”. ATLASwillnotallowtwocohortstohavethesameexactnames. ATLASwillgive youapop­uperrormessageifyouchooseanamealreadyusedbyanotherATLAS cohort. Onceyouhavechosenaname,youcansavethecohortbyclicking . 10.7.1 Initial Event Criteria Now we can proceed with defining the initial cohort event. You will click “Add initial event”. Younowhavetopickwhichdomainyouarebuildingacriteriaaround. Youmay askyourself,“howdoIknowwhichdomainistheinitialcohortevent?” Let’sfigurethat out. AsweseeinFigure 10.5,ATLASprovidesdescriptionsbeloweachcriteriatohelpyou. If wewerebuildingaCONDITION_OCCURRENCEbasedcriteria,ourquestionwouldbe lookingforpatientswithaspecificdiagnosis. IfwewerebuildingaDRUG_EXPOSURE\n",
      "page text: 10.7. Implementing a Cohort Using ATLAS 155 Figure10.5: AddinganInitialEvent based criteria, our question would be looking for patients with a specific drug or drug class. SincewewanttofindpatientswhoinitiateACEinhibitorsmonotherapyasfirst­line treatmentsforhypertension,wewanttochooseaDRUG_EXPOSUREcriteria. Youmay say,“butwealsocareabouthypertensionasadiagnosis”. Youarecorrect. Hypertension isanothercriterionwewillbuild. However,thecohortstartdateisdefinedbytheinitiation of the ACE inhibitor treatment, which is therefore the initial event. The diagnosis of hypertensioniswhatwecallan additional qualifying criteria . Wewillreturntothisonce webuildthiscriteria. Wewillclick“AddDrugExposure”. Thescreenwillupdatewithyourselectedcriteriabutyouarenotdoneyet. Asweseein Figure10.6,ATLASdoesnotknowwhatdrugwearelookingfor. WeneedtotellATLAS whichconceptsetisassociatedtoACEinhibitors. Figure10.6: DefiningaDrugExposure\n",
      "page text: 156 Chapter 10. Defining Cohorts 10.7.2 Defining the Concept Set Youwillneedtoclick toopenthedialogueboxthatwillallowyoutoretrieveaconcept settodefineACEInhibitors. Scenario 1: You Have Not Built a Concept Set Ifyouhavenotassembledyourconceptsetstoapplytoyourcriteria,youwillneedtodo sobeforeyoumoveforward. Youmaybuildaconceptsetwithinthecohortdefinitionby navigating to the “Concept set” tab and clicking “New Concept Set”. You will need to renametheconceptsetfrom“UnnamedConceptSet”toanameofyourchoosing. From thereyoucanusethe moduletolookforclinicalconceptsthatrepresentACE inhibitors(Figure 10.7). Figure10.7: SearchingtheVocabulary­ACEInhibitors Whenyouhavefoundtermsthatyouwouldliketousetodefinethisdrugexposure,you canselecttheconceptbyclickingon . Youcanreturntoyourcohortdefinitionbyusing theleftarrowinthetopleftofFigure 10.7. YoucanreferbacktoChapter 5(Standardized Vocabularies)onhowtonavigatethevocabulariestofindclinicalconceptsofinterest. Figure10.8showsourconceptsetexpression. WeselectedallACEinhibitoringredients weareinterestedin,andincludealltheirdescendants,thusincludingalldrugsthatcontain anyoftheseingredients. Wecanclickon“Includedconcepts”toseeall21,536concepts implied by this expression, or we can click on “Included Source Codes” to explore all sourcecodesinthevariouscodingsystemsthatareimplied. Scenario 2: You Have Already Built a Concept Set IfyouhavealreadycreatedaconceptsetandsaveditinATLAS,youcanclickto“Import ConceptSet”. Adialogueboxwillopenthatwillbepromptyoutofindyourconceptin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████                                                                                 | 188/464 [00:01<00:02, 102.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 10.7. Implementing a Cohort Using ATLAS 157 Figure10.8: AconceptsetcontainingACEinhibitordrugs.\n",
      "page text: 158 Chapter 10. Defining Cohorts theconceptsetrepositoryofyourATLASasshowninFigure 10.9. Intheexamplefigure theuserisretrievingconceptsetsstoredinATLAS.Theusertypedinthenamegivento thisconceptset“aceinhibitors”intherighthandsearch. Thisshortenedtheconceptset listtoonlyconceptswithmatchingnames. Fromthere,theusercanclickontherowof theconceptsettoselectit. (Note: thedialogueboxwilldisappearonceyouhaveselected aconceptset.) YouwillknowthisactionissuccessfulwhentheAnyDrugboxisupdated withthenameoftheconceptsetyouselected. Figure10.9: ImportingaConceptSetfromATLASRepository 10.7.3 Additional Initial Event Criteria Nowthatyou’veattachedaconceptset, youarenotdoneyet. Yourquestionislooking for new users or the first time in someone’s history they are exposed to ACE inhibitors. Thistranslatestothe first exposure ofACEinhibitorsinthepatient’srecord. Tospecify this,youneedtoclick“+Addattribute”. Youwillwanttoselectthe“Addfirstexposure criteria”. Notice, you could specify other attributes of a criteria you build. You could specifyanattributeofageatoccurrence,thedateofoccurrence,genderorotherattributes relatedtothedrug. Criteriaavailableforselectionwilllookdifferentforeachdomain. Fromthere,thewindowwillautomaticallyclose. Onceselected,thisadditionalattribute willshowupinthesameboxastheinitialcriteria(seeFigure 10.10). The current design of ATLASmay confuse some. Despite its appearance, the isnotintendedtomean“No”. Itisanactionablefeaturetoallowtheusertodelete thecriteria. Ifyouclick ,thiscriteriawillgoaway. Thus,youneedtoleavethe criteriawiththe tokeepthecriteriaactive. Now you have built an initial qualifying event. To ensure you are capturing the first observeddrugexposure,youwillwanttoaddalook­backwindowtoknowthatyouare looking at enough of the patient’s history to know what comes first. It is possible that apatientwitha shortobservationperiod mayhavereceivedan exposureelsewherethat\n",
      "page text: 10.7. Implementing a Cohort Using ATLAS 159 we do not see. We cannot control this but we can mandate a minimum amount of time the patient must be in the data prior to the index date You can do this by adjusting the continuousobservationdropdowns. Youcouldalsoclicktheboxandtypeinavalueto these windows. We will require 365 days of continuous observation prior to the initial event. You will update your observation period to: with continuous observation of 365 days before ,asshowninFigure 10.10. Thislook­backwindowisthediscretionofyour studyteam. Youmaychoosedifferentlyinothercohorts. Thiscreates,asbestasweare able, a minimum period of time we see the patient to ensure we are capturing the first record. Thiscriteriaisaboutpriorhistoryanddoesnotinvolvetimeaftertheindexevent. Therefore,werequire0daysaftertheindexevent. Ourqualifyingeventisthefirst­ever useofACEinhibitors. Thus,welimitinitialeventstothe“earliestevent”perperson. Figure10.10: Settingtherequiredcontinuousobservationbeforetheindexdate. Tofurtherexplainhowthislogiccomestogether,youcanthinkaboutassemblingpatient timelines. InFigure10.11,eachlinerepresentsasinglepatientthatmaybeeligibletojointhecohort. Thefilledinstarsrepresentatimethepatientfulfillsthespecifiedcriteria. Asadditional criteria is applied, you may see some stars are a lighter shade. This means that these patientshaveotherrecordsthatsatisfythecriteriabutthereisanotherrecordthatproceeds that. By the time we get to the last criteria, we are looking at the cumulative view of patients who have ACE inhibitors for the first time and have 365 days prior to the first­ timeoccurrence. Logically,limitingtotheinitialeventisredundantthoughitishelpful to maintain our explicit logic in every selection we make. When you are building your owncohorts,youmayopttoengagetheResearcherssectionofthe OHDSIForum toget asecondopiniononhowtoconstructyourcohortlogic. 10.7.4 Inclusion Criteria Oncewehavespecifiedacohortentryevent,youcouldproceedtooneoftwoplacestoadd youradditionalqualifyingevents: “Restrictinitialevents”and“Newinclusioncriteria”. The fundamental difference between these two options is what interim information you wantATLAStoservebacktoyou. IfyouaddadditionalqualifyingcriteriaintotheCohort Entry Event box by selecting “Restrict initial events”, when you choose to generate a count in ATLAS, you will only get back the number of people who meet ALL of these\n",
      "page text: 160 Chapter 10. Defining Cohorts Figure10.11: Explainingpatienteligibilitybycriteriaapplied\n",
      "page text: 10.7. Implementing a Cohort Using ATLAS 161 criteria. Ifyouopttoaddcriteriaintothe“Newinclusioncriteria”,youwillgetanattrition charttoshowyouhowmanypatientsarelostbyapplyingadditionalinclusioncriteria. It is highly encouraged to utilize the Inclusion Criteria section so you can understand the impactofeachruleontheoverallsuccessofthecohortdefinition. Youmayfindacertain inclusion criteria severely limits the number of people who end up in the cohort. You may choose to relax this criterion to get a larger cohort. This will ultimately be at the discretionoftheexpertconsensusassemblingthiscohort. You will now want to click “New inclusion criteria” to add a subsequent piece of logic aboutmembershiptothiscohort. Thefunctionalityinthissectionisidenticaltotheway wediscussedbuildingcohortcriteriaabove. Youmayspecificthecriteriaandaddspecific attributes. Our first additional criteria is to subset the cohort to only patients: With at least 1 occurrence of hypertension disorder between 365 and 0 days after index date (first initiation of an ACE inhibitor) . Youwillclick“Newinclusioncriteria”toaddanew criteria. Youshouldnameyourcriteriaand,ifdesired,putalittledescriptionofwhatyou arelookingfor. Thisisforyourownpurposestorecallwhatyoubuild–itwillnotimpact theintegrityofthecohortyouaredefining. Onceyouhaveannotatedthisnewcriteria,youwillclickonthe“+Addcriteriatogroup” button to build your actual criteria for this rule. This button functions similar to the “Add Initial Event” except we are no longer specifying an initial event. We could add multiple criteria to this – which is why it specifies “add criteria to group”. An exam­ ple would be if you have multiple ways of finding a disease (e.g. logic for a CONDI­ TION_OCCURRENCE,logicusingaDRUG_EXPOSUREasaproxyforthiscondition, logicforusingaMEASUREMENTasaproxyforthiscondition). Thesewouldbesep­ arate domains and require different criteria but can be grouped into one criteria looking forthiscondition. Inthiscase,wewanttofindadiagnosisofhypertensionsowe“Add condition occurrence”. We will follow similar steps as we did with the initial event by attaching a concept set to this record. We also want to specify the event starts between 365daysbeforeand0daysaftertheindexdate(theoccurrenceofthefirstACEinhibitor use). NowcheckyourlogicagainstFigure 10.12. Youwillthenwanttoaddanothercriteriontolookforpatients: with exactly 0 occurrences of hypertension drugs ALL days before and 1 day before index start date (no exposure to HT drugs before an ACE inhibitor) . This process begins as we did before by clicking the “New inclusion criteria” button, adding your annotations to this criterion and then clicking“+Addcriteriatogroup”. ThisisaDRUG_EXPOSUREsoyouwillclick“Add DrugExposure”,attachaconceptsetforhypertensivedrugs,andwillspecifyALLdays beforeand0daysafter(or“1daysbefore”isequivalentasseeninfigure)theindexdate. Make sure to confirm you have exactly 0occurrence selected. Now check your logic againstFigure 10.13. Youmaybeconfusedwhy“havingnooccurrences”iscodedas“exactly0occurrences.” ThisisanuanceofhowATLASconsumesknowledge. ATLASonlyconsumesinclusion criteria. Youmustuselogicaloperatorstoindicatewhenyouwanttheabsenceofaspe­ cific attribute such as: “Exactly 0.” Over time you will become more familiar with the\n",
      "page text: 162 Chapter 10. Defining Cohorts Figure10.12: AdditionalInclusioncriteria1 Figure10.13: AdditionalInclusionCriteria2\n",
      "page text: 10.7. Implementing a Cohort Using ATLAS 163 logicaloperatorsavailableinATLAScriteria. Lastly, you will want to add your another criterion to look for patients: with exactly 1 occurrence of hypertension drugs between 0 days before and 7 days after index start date AND can only start one HT drug (an ACE inhibitor) . This process begins as we did before by clicking the “New inclusion criteria” button, adding your annotations to this criterionandthenclicking“+Addcriteriatogroup”. ThisisaDRUG_ERAsoyouwill click“AddDrugEra”,attachaconceptsetforhypertensivedrugs,andwillspecify0days beforeand7daysaftertheindexdate. NowcheckyourlogicagainstFigure 10.14. Figure10.14: AdditionalInclusionCriteria3 10.7.5 Cohort Exit Criteria Youhavenowaddedallofyourqualifyinginclusioncriteria. Youmustnowspecifyyour cohort exit criteria. You will ask yourself, “when are people no longer eligible to be in­ cludedinthiscohort?” Inthiscohort,wearefollowingnew­usersofadrugexposure. We wanttolookatcontinuousobservationperiodasitrelatestothedrugexposure. Assuch, the exit criterion is specified to follow for the entirety of the continuous drug exposure. Ifthereisasubsequentbreakinthedrugexposure,thepatientwillexitthecohortatthis time. We do this as we cannot determine what happened to the person during the break inthedrugexposure. Wecanalsosetacriteriaonthepersistencewindowtospecifyan allowable gap between drug exposures. In this case, our experts leading this study con­ cludedthatamaximumof30daysbetweenexposurerecordsisallowablewheninferring theeraofpersistenceexposure. Why are gaps allowed? Insomedatasets,weseeonlyportionsofclinicalinteractions. Drugexposures,inparticular,mayrepresentadispenseofaprescriptionthatcancovera certainperiodoftime. Thus,weallowacertainamountoftimebetweendrugexposures asweknowthepatientmaylogicallystillhaveaccesstotheinitialdrugexposurebecause theunitofdispenseexceededoneday. WecanconfigurethisbyselectingtheEventwillpersist“endofacontinuousdrugexpo­ sure”. We then will add our persistence window to “allow for a maximum of 30 days”\n",
      "page text: 164 Chapter 10. Defining Cohorts and append the concept set for “ACE inhibitors”. Now check your logic against Figure 10.15. Figure10.15: CohortExitCriteria Inthecaseofthiscohort, therearenoothercensoringevents. However, youmaybuild othercohortswhereyouneedtospecifythiscriteria. Youwouldproceedsimilarlytothe waywehaveaddedotherattributestothiscohortdefinition. Youhavenowsuccessfully finishedcreatingyourcohort. Makesuretohitthe button. Congratulations! Building acohortisthemostimportantbuildingblockofansweringaquestionintheOHDSItools. You can now use the “Export” tab to share your cohort definition to other collaborators intheformofSQLcodeorJSONfilestoloadintoATLAS. 10.8 Implementing the Cohort Using SQL Herewedescribehowtocreatethesamecohort, butusingSQLandR.Asdiscussedin Chapter9, OHDSI provides two R packages, called SqlRender and DatabaseConnector, whichtogetherallowwritingSQLcodethatcanbeautomaticallytranslatedandexecuted againstawidevarietyofdatabaseplatforms. Forclarity,wewillsplittheSQLintoseveralchunks,eachchunkgeneratingatemptable thatisusedinthenext. Thisislikelynotthemostcomputationallyefficientwaytodoit, butitiseasiertoreadthanasingleverylongstatement. 10.8.1 Connecting to the Database We first need to tell R how to connect to the server. We use the DatabaseConnec­ torpackage, which provides a function called createConnectionDetails . Type ?createConnectionDetails forthespecificsettingsrequiredforthevariousdatabase management systems (DBMS). For example, one might connect to a PostgreSQL databaseusingthiscode:\n",
      "page text: 10.8. Implementing the Cohort Using SQL 165 library(CohortMethod) connDetails <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) cdmDbSchema <- \"my_cdm_data\" cohortDbSchema <- \"scratch\" cohortTable <- \"my_cohorts\" Thelastthreelinesdefinethe cdmDbSchema ,cohortDbSchema ,andcohortTable vari­ ables. We will use these later to tell R where the data in CDM format live, and where thecohortsofinteresthavetobecreated. NotethatforMicrosoftSQLServer,database schemasneedtospecifyboththedatabaseandtheschema,soforexample cdmDbSchema <- \"my_cdm_data.dbo\" . 10.8.2 Specifying the Concepts ForreadabilitywewilldefinetheconceptIDsweneedinR,andpassthemtotheSQL: aceI <- c(1308216,1310756,1331235,1334456,1335471,1340128,1341927, 1342439,1363749,1373225) hypertension <- 316866 allHtDrugs <- c(904542,907013,932745,942350,956874,970250,974166, 978555,991382,1305447,1307046,1307863,1308216, 1308842,1309068,1309799,1310756,1313200,1314002, 1314577,1317640,1317967,1318137,1318853,1319880, 1319998,1322081,1326012,1327978,1328165,1331235, 1332418,1334456,1335471,1338005,1340128,1341238, 1341927,1342439,1344965,1345858,1346686,1346823, 1347384,1350489,1351557,1353766,1353776,1363053, 1363749,1367500,1373225,1373928,1386957,1395058, 1398937,40226742 ,40235485 ) 10.8.3 Finding First Use WewillfirstfindfirstuseofACEinhibitorsforeachpatient: conn <- connect(connectionDetails) sql <-\"SELECT person_id AS subject_id, MIN(drug_exposure_start_date) AS cohort_start_date INTO #first_use\n",
      "page text: 166 Chapter 10. Defining Cohorts FROM @cdm_db_schema.drug_exposure INNER JOIN @cdm_db_schema.concept_ancestor ON descendant_concept_id = drug_concept_id WHERE ancestor_concept_id IN (@ace_i) GROUP BY person_id;\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, ace_i = aceI) NotethatwejointheDRUG_EXPOSUREtabletotheCONCEPT_ANCESTORtableto findalldrugsthatcontainanACEinhibitor. 10.8.4 Require 365 Days of Prior Observation Next, we require 365 of continuous prior observation by joining to the OBSERVA­ TION_PERIODtable: sql <-\"SELECT subject_id, cohort_start_date INTO #has_prior_obs FROM #first_use INNER JOIN @cdm_db_schema.observation_period ON subject_id = person_id AND observation_period_start_date <= cohort_start_date AND observation_period_end_date >= cohort_start_date WHERE DATEADD(DAY, 365, observation_period_start_date) < cohort_start_date;\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema) 10.8.5 Require Prior Hypertension Werequireahypertensiondiagnosisinthe365daysprior: sql <-\"SELECT DISTINCT subject_id, cohort_start_date INTO #has_ht FROM #has_prior_obs INNER JOIN @cdm_db_schema.condition_occurrence ON subject_id = person_id AND condition_start_date <= cohort_start_date AND condition_start_date >= DATEADD(DAY, -365, cohort_start_date) INNER JOIN @cdm_db_schema.concept_ancestor ON descendant_concept_id = condition_concept_id WHERE ancestor_concept_id = @hypertension;\"\n",
      "page text: 10.8. Implementing the Cohort Using SQL 167 renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, hypertension = hypertension) Notethatwe SELECT DISTINCT ,becauseelseifapersonhasmultiplehypertensiondi­ agnosesintheirpast,wewouldcreateduplicatecohortentries. 10.8.6 No Prior T reatment Werequirenopriorexposuretoanyhypertensiontreatment: sql <-\"SELECT subject_id, cohort_start_date INTO #no_prior_ht_drugs FROM #has_ht LEFT JOIN ( SELECT * FROM @cdm_db_schema.drug_exposure INNER JOIN @cdm_db_schema.concept_ancestor ON descendant_concept_id = drug_concept_id WHERE ancestor_concept_id IN (@all_ht_drugs) ) ht_drugs ON subject_id = person_id AND drug_exposure_start_date < cohort_start_date WHERE person_id IS NULL;\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, all_ht_drugs = allHtDrugs) Notethatweusealeftjoin,andonlyallowrowswheretheperson_id,whichcomesfrom theDRUG_EXPOSUREtableisNULL,meaningnomatchingrecordwasfound. 10.8.7 Monotherapy Werequiretheretobeonlyoneexposuretohypertensiontreatmentinthefirstsevendays ofthecohortentry: sql <-\"SELECT subject_id, cohort_start_date INTO #monotherapy FROM #no_prior_ht_drugs INNER JOIN @cdm_db_schema.drug_exposure ON subject_id = person_id\n",
      "page text: 168 Chapter 10. Defining Cohorts AND drug_exposure_start_date >= cohort_start_date AND drug_exposure_start_date <= DATEADD(DAY, 7, cohort_start_date) INNER JOIN @cdm_db_schema.concept_ancestor ON descendant_concept_id = drug_concept_id WHERE ancestor_concept_id IN (@all_ht_drugs) GROUP BY subject_id, cohort_start_date HAVING COUNT(*) = 1;\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, all_ht_drugs = allHtDrugs) 10.8.8 Cohort Exit Wehavenowfullyspecifiedourcohortexceptthecohortenddate. Thecohortisdefined toendwhentheexposurestops,allowingforamaximum30­daygapbetweensubsequent exposures. Thismeansweneedtonotonlyconsiderthefirstdrugexposure,butalsosub­ sequentdrugexposurestoACEinhibitors. TheSQLforcombiningsubsequentexposures into eras can be highly complex. Luckily, standard code has been defined that can effi­ cientlycreateeras. (ThiscodewaswrittenbyChrisKnoll,andisoftenreferredtowithin OHDSIas‘themagic’). Wefirstcreateatemptablecontainingallexposureswewishto merge: sql <-\" SELECT person_id, CAST(1 AS INT) AS concept_id, drug_exposure_start_date AS exposure_start_date, drug_exposure_end_date AS exposure_end_date INTO #exposure FROM @cdm_db_schema.drug_exposure INNER JOIN @cdm_db_schema.concept_ancestor ON descendant_concept_id = drug_concept_id WHERE ancestor_concept_id IN (@ace_i);\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, ace_i = aceI) Wethenrunthestandardcodeformergingsequentialexposures: sql <-\" SELECT ends.person_id AS subject_id, ends.concept_id AS cohort_definition_id, MIN(exposure_start_date) AS cohort_start_date,\n",
      "page text: 10.8. Implementing the Cohort Using SQL 169 ends.era_end_date AS cohort_end_date INTO #exposure_era FROM ( SELECT exposure.person_id, exposure.concept_id, exposure.exposure_start_date, MIN(events.end_date) AS era_end_date FROM #exposure exposure JOIN ( --cteEndDates SELECT person_id, concept_id, DATEADD(DAY, - 1 * @max_gap, event_date) AS end_date FROM ( SELECT person_id, concept_id, event_date, event_type, MAX(start_ordinal) OVER ( PARTITION BY person_id ,concept_id ORDER BY event_date, event_type ROWS UNBOUNDED PRECEDING ) AS start_ordinal, ROW_NUMBER() OVER ( PARTITION BY person_id, concept_id ORDER BY event_date, event_type ) AS overall_ord FROM ( -- select the start dates, assigning a row number to each SELECT person_id, concept_id, exposure_start_date AS event_date, 0 AS event_type, ROW_NUMBER() OVER ( PARTITION BY person_id, concept_id ORDER BY exposure_start_date ) AS start_ordinal FROM #exposure exposure UNION ALL -- add the end dates with NULL as the row number, padding the end dates by -- @max_gap to allow a grace period for overlapping ranges. SELECT person_id, concept_id, DATEADD(day, @max_gap, exposure_end_date), 1 AS event_type, NULL FROM #exposure exposure ) rawdata ) events\n",
      "page text: 170 Chapter 10. Defining Cohorts WHERE 2 * events.start_ordinal - events.overall_ord = 0 ) events ON exposure.person_id = events.person_id AND exposure.concept_id = events.concept_id AND events.end_date >= exposure.exposure_end_date GROUP BY exposure.person_id, exposure.concept_id, exposure.exposure_start_date ) ends GROUP BY ends.person_id, concept_id, ends.era_end_date;\" renderTranslateExecuteSql (conn, sql, cdm_db_schema = cdmDbSchema, max_gap = 30) This code merges all subsequent exposures, allowing for a gap between exposures as defined by the max_gapargument. The resulting drug exposure eras are written to a temptablecalled #exposure_era . Next,wesimplyjointheseACEinhibitorexposureerastoouroriginalcohorttousethe eraenddatesasourcohortenddates: sql <-\"SELECT ee.subject_id, CAST(1 AS INT) AS cohort_definition_id, ee.cohort_start_date, ee.cohort_end_date INTO @cohort_db_schema.@cohort_table FROM #monotherapy mt INNER JOIN #exposure_era ee ON mt.subject_id = ee.subject_id AND mt.cohort_start_date = ee.cohort_start_date;\" renderTranslateExecuteSql (conn, sql, cohort_db_schema = cohortDbSchema, cohort_table = cohortTable) Here we store the final cohort in schema and table we defined earlier. We assign it a cohortdefinitionIDof1,todistinguishitfromothercohortswemaywishtostoreinthe sametable.\n",
      "page text: 10.9. Summary 171 10.8.9 Cleanup Finally, it is always recommend to clean up any temp tables that were created, and dis­ connectfromthedatabaseserver: sql <-\"TRUNCATE TABLE #first_use; DROP TABLE #first_use; TRUNCATE TABLE #has_prior_obs; DROP TABLE #has_prior_obs; TRUNCATE TABLE #has_ht; DROP TABLE #has_ht; TRUNCATE TABLE #no_prior_ht_drugs; DROP TABLE #no_prior_ht_drugs; TRUNCATE TABLE #monotherapy; DROP TABLE #monotherapy; TRUNCATE TABLE #exposure; DROP TABLE #exposure; TRUNCATE TABLE #exposure_era; DROP TABLE #exposure_era;\" renderTranslateExecuteSql (conn, sql) disconnect (conn) 10.9 Summary –A cohort is set of persons who satisfy one or more inclusion criteria for a durationoftime. –Acohortdefinitionisthedescriptionoflogicusedforidentifyingaparticular cohort. –Cohortsareused(andre­used)throughouttheOHDSIanalyticstoolstodefine forexampletheexposuresandoutcomesofinterest. –There are two major approaches to building a cohort: rule­based and proba­ bilistic. –Rule­basedcohortdefinitionscanbecreatedinATLAS,orusingSQL\n",
      "page text: 172 Chapter 10. Defining Cohorts 10.10 Exercises Prerequisites Forthefirstexercise,accesstoanATLASinstanceisrequired. Youcanusetheinstance athttp://atlas­demo.ohdsi.org ,oranyotherinstanceyouhaveaccessto. Exercise 10.1. UseATLAStocreateacohortdefinitionfollowingthesecriteria: •Newusersofdiclofenac •Ages16orolder •Withatleast365daysofcontinuousobservationpriortoexposure •WithoutpriorexposuretoanyNSAID(Non­SteroidalAnti­InflammatoryDrug) •Withoutpriordiagnosisofcancer •Withcohortexitdefinedasdiscontinuationofexposure(allowingfora30­daygap) Prerequisites ForthesecondexerciseweassumeR,R­StudioandJavahavebeeninstalledasdescribed in Section 8.4.5. Also required are the SqlRender,DatabaseConnector , andEunomia packages,whichcanbeinstalledusing: install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. Exercise 10.2. UseSQLandRtocreateacohortforacutemyocardialinfarction(AMI) intheexistingCOHORTtable,followingthesecriteria: •Anoccurrenceofamyocardialinfarctiondiagnose(concept4329847“Myocardial infarction”andallofitsdescendants,excludingconcept314666“Oldmyocardial infarction”andanyofitsdescendants). •DuringaninpatientorERvisit(concepts9201,9203,and262for“Inpatientvisit”, “Emergency Room Visit”, and “Emergency Room and Inpatient Visit”, respec­ tively). SuggestedanswerscanbefoundinAppendix E.6.\n",
      "page text: Chapter 11 Characterization Chapter leads: Anthony Sena & Daniel Prieto­Alhambra Observationalhealthcaredatabasesprovideavaluableresourcetounderstandvariations inpopulationsbasedonahostofcharacteristics. Characterizingpopulationsthroughthe use of descriptive statistics is an important first step in generating hypotheses about the determinantsofhealthanddisease. Inthischapterwecovermethodsforcharacterization: •Database­level characterization : providesatop­levelsetofsummarystatisticsto understandthedataprofileofadatabaseinitstotality. •Cohort characterization : describesapopulationintermsofitsaggregatemedical history. •Treatment pathways : describes the sequence of interventions a person received foradurationoftime. •Incidence: measurestheoccurrencerateofanoutcomeinapopulationforatime atrisk. With the exception of database­level characterization, these methods aim to describe a population relative to an event referred to as the index date. This population of interest is defined as a cohort as described in chapter 10. The cohort defines the index date for each person in the population of interest. Using the index date as an anchor, we define the time preceding the index date as baselinetime. The index date and all time after is calledthe post­index time. Use­cases for characterization include disease natural history, treatment utilization and qualityimprovement. Inthischapterwilldescribethemethodsforcharacterization. We will use a population of hypertensive persons to demonstrate how to use ATLAS and R toperformthesecharacterizationtasks. 173\n",
      "page text: 174 Chapter 11. Characterization 11.1 Database Level Characterization Before we can answer any characterization question about a population of interest, we must first understand the characteristics of the database we intend to utilize. Database levelcharacterizationseekstodescribethetotalityofadatabaseintermsofthetemporal trendsanddistributions. Thisquantitativeassessmentofadatabasewilltypicallyinclude questionssuchas: •Whatisthetotalcountofpersonsinthisdatabase? •Whatisthedistributionofageforpersons? •Howlongarepersonsinthisdatabaseobservedfor? •What is the proportion of persons having a {treatment, condition, procedure, etc} recorded/prescribedovertime? Thesedatabase­leveldescriptivestatisticsalsohelparesearchertounderstandwhatdata maybemissinginadatabase. Chapter 15goesintofurtherdetailondataquality. 11.2 Cohort Characterization Cohort characterization describes the baseline and post­index characteristics of people inacohort. OHDSIapproachescharacterizationthroughdescriptivestatisticsofallcon­ ditions, drug and device exposures, procedures and other clinical observations that are presentintheperson’shistory. Wealsosummarizethesocio­demographicsofmembers ofthecohortattheindexdate. Thisapproachprovidesacompletesummaryofthecohort ofinterest. Importantly,thisenablesafullexplorationofthecohortwithaneyetowards variationinthedatawhilealsoallowingforidentificationofpotentiallymissingvalues. Cohort characterization methods can be used for person­level drug utilization studies (DUS) to estimate the prevalence of indications and contraindications amongst users of a given treatment. The dissemination of this cohort characterization is a recommended best practice for observational studies as detailed in the Strengthening the Reporting of ObservationStudiesinEpidemiology(STROBE)guidelines. ( vonElmetal. ,2008) 11.3 T reatment Pathways Anothermethodtocharacterizeapopulationistodescribethetreatmentsequenceduring the post­index time window. For example, Hripcsak et al. (2016) utilized the OHDSI commondatastandardstocreatedescriptivestatisticstocharacterizetreatmentpathways fortype2diabetes,hypertensionanddepression. Bystandardizingthisanalyticapproach, Hripcsak and colleagues were able to run the same analysis across the OHDSI network todescribethecharacteristicsofthesepopulationsofinterest. The pathway analysis aims to summarize the treatments (events) received by persons diagnosedwithaspecificconditionfromthefirstdrugprescription/dispensation. Inthis study,treatmentsweredescribedafterthediagnosisoftype2diabetes,hypertensionand\n",
      "page text: 11.4. Incidence 175 depression respectively. The events for each person were then aggregated to a set of summarystatisticsandvisualizedforeachconditionandforeachdatabase. Figure11.1: OHDSITreatmentPathways”sunburst”visualizationforhypertension As an example, figure 11.1represents a population of persons initiating treatment for hypertension. Thefirstringinthecentershowstheproportionofpersonsbasedontheir first­line therapy. In this example, Hydrochlorothiazide is the most common first­line therapyforthispopulation. TheboxesthatextendfromtheHydrochlorothiazidesection representthe2ndand3rdlinetherapiesrecordedforpersonsinthecohort. A pathways analysis provides important evidence about treatment utilization amongst a population. Fromthisanalysiswecandescribethemostprevalentfirst­linetherapiesuti­ lized,theproportionofpersonsthatdiscontinuetreatment,switchtreatmentsoraugment theirtherapy. Usingthepathwayanalysis, Hripcsaketal. (2016)foundthatmetforminis themostcommonlyprescribedmedicationfordiabetesthusconfirminggeneraladoption of the first­line recommendation of the American Association of Clinical Endocrinolo­ gistsdiabetestreatmentalgorithm. Additionally,theynotedthat10%ofdiabetespatients, 24%ofhypertensionpatients,and11%ofdepressionpatientsfollowedatreatmentpath­ waythatwassharedwithnooneelseinanyofthedatasources. In classic DUS terminology, treatment pathway analyses include some population­level DUSestimatessuchasprevalenceofuseofoneormoremedicationsinaspecifiedpopu­ lation,aswellassomeperson­levelDUSincludingmeasuresofpersistenceandswitching betweendifferenttherapies. 11.4 Incidence Incidence rates and proportions are statistics that are used in public health to assess the occurrence of a new outcome in a population during a time­at­risk (TAR). Figure 11.2 aimstoshowthecomponentsofanincidencecalculationforasingleperson: Infigure11.2,apersonhasaperiodoftimewheretheyareobservedinthedatadenoted bytheirobservationstartandendtime. Next, thepersonhasapointintimewherethey enterandexitacohortbymeetingsomeeligibilitycriteria. Thetimeatriskwindowthen denoteswhenweseektounderstandtheoccurrenceofanoutcome. Iftheoutcomefalls intotheTAR,wecountthatasanincidenceoftheoutcome.\n",
      "page text: 176 Chapter 11. Characterization Figure 11.2: Person­level view of incidence calculation components. In this example, time­at­riskisdefinedtostartonedayaftercohortstart,andendatcohortend. Therearetwometricsforcalculatingincidence: 𝐼 𝑛𝑐𝑖𝑑𝑒𝑛𝑐𝑒 𝑃 𝑟𝑜𝑝𝑜𝑟𝑡𝑖𝑜𝑛 =# 𝑝𝑒𝑟𝑠𝑜𝑛𝑠 𝑖𝑛 𝑐𝑜ℎ𝑜𝑟𝑡 𝑤𝑖𝑡ℎ 𝑛𝑒𝑤 𝑜𝑢𝑡𝑐𝑜𝑚𝑒 𝑑𝑢𝑟𝑖𝑛𝑔 𝑇 𝐴𝑅 # 𝑝𝑒𝑟𝑠𝑜𝑛𝑠 𝑖𝑛 𝑐𝑜ℎ𝑜𝑟𝑡 𝑤𝑖𝑡ℎ 𝑇 𝐴𝑅 Anincidenceproportionprovidesameasureofthenewoutcomesperpersoninthepopu­ lationduringthetime­at­risk. Statedanotherway,thisistheproportionofthepopulation ofinterestthatdevelopedtheoutcomeinadefinedtimeframe. 𝐼 𝑛𝑐𝑖𝑑𝑒𝑛𝑐𝑒 𝑅𝑎𝑡𝑒 =# 𝑝𝑒𝑟𝑠𝑜𝑛𝑠 𝑖𝑛 𝑐𝑜ℎ𝑜𝑟𝑡 𝑤𝑖𝑡ℎ 𝑛𝑒𝑤 𝑜𝑢𝑡𝑐𝑜𝑚𝑒 𝑑𝑢𝑟𝑖𝑛𝑔 𝑇 𝐴𝑅 𝑝𝑒𝑟𝑠𝑜𝑛 𝑡𝑖𝑚𝑒 𝑎𝑡 𝑟𝑖𝑠𝑘 𝑐𝑜𝑛𝑡𝑟𝑖𝑏𝑢𝑡𝑒𝑑 𝑏𝑦 𝑝𝑒𝑟𝑠𝑜𝑛𝑠 𝑖𝑛 𝑐𝑜ℎ𝑜𝑟𝑡 AnincidencerateisameasureofthenumberofnewoutcomesduringthecumulativeTAR forthepopulation. WhenapersonexperiencestheoutcomeintheTAR,theircontribution tothetotalperson­timestopsattheoccurrenceoftheoutcomeevent. ThecumulativeTAR isreferredtoas person­time andisexpressedindays,monthsoryears. Whencalculatedfortherapies,incidenceproportionsandincidenceratesofuseofagiven therapyareclassicpopulation­levelDUS. 11.5 Characterizing Hypertensive Persons Per the World Health Organization’s (WHO) global brief on hypertension ( Who,2013), therearesignificanthealthandeconomicgainsattachedtoearlydetection,adequatetreat­ mentandgoodcontrolofhypertension. TheWHObriefprovidesanoverviewofhyperten­ sionandcharacterizestheburdenofthediseaseacrossdifferentcountries. TheWHOpro­ vides descriptive statistics around hypertension for geographic regions, socio­economic classandgender. Observationaldatasourcesprovideawaytocharacterizehypertensivepopulationsaswas donebytheWHO.Inthesubsequentsectionsofthischapter,we’llexplorethewaysthat\n",
      "page text: 11.6. Database Characterization in ATLAS 177 we make use of ATLAS and R to explore a database to understand its composition for studying hypertensive populations. Then, we will use these same tools to describe the naturalhistoryandtreatmentpatternsofhypertensivepopulations. 11.6 Database Characterization in A TLAS HerewedemonstratehowtousethedatasourcesmoduleinATLAStoexploredatabase characterizationstatisticscreatedwith ACHILLES tofinddatabaselevelcharacteristics related to hypertensive persons. Start by clicking on in the left bar of ATLAS to start. In the first drop down list shown in ATLAS, select the database to explore. Next,usethedropdownbelowthedatabasetostartexploringreports. Todothis, selecttheConditionOccurrencefromthereportdropdownwhichwillrevealatreemap visualizationofallconditionspresentinthedatabase: Figure11.3: AtlasDataSources: ConditionOccurrenceTreemap Tosearchforaspecificconditionofinterest,clickontheTabletabtorevealthefulllistof conditionsinthedatabasewithpersoncount, prevalenceandrecordsperperson. Using thefilterboxonthetop,wecanfilterdowntheentriesinthetablebasedonconceptname containingtheterm“hypertension”: We can explore a detailed drill­down report of a condition by clicking on a row. In this case, we will select “essential hypertension” to get a breakdown of the trends of the se­ lectedconditionovertimeandbygender,theprevalenceoftheconditionbymonth,the typerecordedwiththeconditionandtheageatfirstoccurrenceofthediagnosis: Nowthatwehavereviewedthedatabase’scharacteristicsforthepresenceofhypertension concepts and the trends over time, we can also explore drugs used to treat hypertensive persons. TheprocesstodothisfollowsthesamestepsexceptweusetheDrugErareportto\n",
      "page text: 178 Chapter 11. Characterization Figure 11.4: Atlas Data Sources: Conditions with ”hypertension” found in the concept name\n",
      "page text: 11.6. Database Characterization in ATLAS 179 Figure11.5: AtlasDataSources: Essentialhypertensiondrilldownreport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████████████████████████▋                                                                         | 214/464 [00:02<00:02, 115.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 180 Chapter 11. Characterization review characteristics of drugs summarized to their RxNorm Ingredient. Once we have explored the database characteristics to review items of interest, we are ready to move forwardwithconstructingcohortstoidentifythehypertensivepersonstocharacterize. 11.7 Cohort Characterization in A TLAS Here we demonstrate how to use ATLAS to perform large­scale cohort characterization for several cohorts. Click on the in the left bar of ATLAS and create a new characterization analysis. Give the analysis a name a save using the button. 11.7.1 Design Acharacterizationanalysisrequiresatleastonecohortandatleastonefeaturetocharac­ terize. For this example, we will use two cohorts. The first cohort will define persons initiating a treatment for hypertension as their index date with at least one diagnosis of hypertension in the year prior. We will also require that persons in this cohort have at leastoneyearofobservationafterinitiatingthehypertensivedrug(Appendix B.6). The secondcohortisidenticaltothefirstcohortdescribedwitharequirementhavingatleast threeyearsofobservationinsteadofone(Appendix B.7). Cohort Definitions Figure11.6: Characterizationdesigntab­cohortdefinitionselection WeassumethecohortshavealreadybeencreatedinATLASasdescribedinChapter 10. Click on and select the cohorts as shown in figure 11.6. Next, we’ll define the featurestouseforcharacterizingthesetwocohorts.\n",
      "page text: 11.7. Cohort Characterization in ATLAS 181 Feature Selection ATLAS comes with nearly 100 preset feature analyses that are used to perform charac­ terizationacrosstheclinicaldomainsmodeledintheOMOPCDM.Eachofthesepreset feature analyses perform aggregation and summarization functions on clinical observa­ tionsfortheselectedtargetcohorts. Thesecalculationsprovidepotentiallythousandsof featurestodescribethecohortsbaselineandpost­indexcharacteristics. Underthehood, ATLASisutilizingtheOHDSIFeatureExtractionRpackagetoperformthecharacteriza­ tionforeachcohort. WewillcovertheuseofFeatureExtractionandRinmoredetailin thenextsection. Clickon toselectthefeaturetocharacterize. Belowisalistoffeatureswewilluse tocharacterizethesecohorts: Figure11.7: Characterizationdesigntab­featureselection. Thefigureaboveshowsthelistoffeaturesselectedalongwithadescriptionofwhateach feature will characterize for each cohort. The features that start with the name “Demo­ graphics”willcalculatethedemographicinformationforeachpersonatthecohortstart date. For the features that start with a domain name (i.e. Visit, Procedure, Condition,\n",
      "page text: 182 Chapter 11. Characterization Drug,etc),thesewillcharacterizeallrecordedobservationsinthatdomain. Eachdomain featurehasfouroptionsoftimewindowprecedingthecohortstar,namely: •Any time prior : uses all available time prior to cohort start that fall into the per­ son’sobservationperiod •Long term : 365daysprioruptoandincludingthecohortstartdate. •Medium term : 180daysprioruptoandincludingthecohortstartdate. •Short term : 30daysprioruptoandincludingthecohortstartdate. Subgroup Analysis Whatifwewereinterestedincreatingdifferentcharacteristicsbasedongender? Wecan use the “subgroup analyses” section to define new subgroups of interest to use in our characterization. Tocreateasubgroup,clickonandaddyourcriteriaforsubgroupmembership. Thisstep issimilartothecriteriausedtoidentifycohortenrollment. Inthisexample,we’lldefine asetofcriteriatoidentifyfemalesamongstourcohorts: Figure11.8: Characterizationdesignwithfemalesubgroupanalysis. SubgroupanalysesinATLASarenotthesameasstrata. Strataaremutuallyexclu­ sivewhilesubgroupsmayincludethesamepersonsbasedonthecriteriachosen. 11.7.2 Executions Once we have our characterization designed, we can execute this design against one or more databases in our environment. Navigate to the Executions tab and click on the Generatebuttontostarttheanalysisonadatabase: Once the analysis is complete, we can view reports by clicking on the “All Executions”\n",
      "page text: 11.7. Cohort Characterization in ATLAS 183 Figure11.9: Characterizationdesignexecution­CDMsourceselection. buttonandfromthelistofexecutions,select“ViewReports”. Alternatively,youcanclick “Viewlatestresult”toviewthelastexecutionperformed. 11.7.3 Results Figure11.10: Characterizationresults­conditionoccurrencelongterm. Theresultsprovideatabularviewofthedifferentfeaturesforeachcohortselectedinthe design. In figure 11.10, a table provides a summary ofall conditions present in the two cohortsinthepreceding365daysfromthecohortstart. Eachcovariatehasacountand percentageforeachcohortandthefemalesubgroupwedefinedwithineachcohort. We used the search box to filter the results to see what proportion of persons have a cardiac arrhythmia in their history in an effort to understand what cardiovascular­ relateddiagnosesareobservedinthepopulations. Wecanusethe Explorelinknextto thecardiacarrhythmiaconcepttoopenanewwindowwithmoredetailsabouttheconcept forasinglecohortasshowninfigure 11.11: Since we have characterized all condition concepts for our cohorts, the explore option enables a view of all ancestor and descendant concepts for the selected concept, in this casecardiacarrhythmia. Thisexplorationallowsustonavigatethehierarchyofconcepts to explore other cardiac diseases that may appear for our hypertensive persons. Like in thesummaryview,thecountandpercentagearedisplayed.\n",
      "page text: 184 Chapter 11. Characterization Figure11.11: Characterizationresults­exploringasingleconcept. We can also use the same characterization results to find conditions that are contraindi­ catedforsomeanti­hypertensivetreatmentsuchasangioedema. Todothis,we’llfollow thesamestepsabovebutthistimesearchfor‘edema’asshowninfigure 11.12: Figure11.12: Characterizationresults­exploringacontraindicatedcondition. Onceagain,we’llusetheexplorefeaturetoseethecharacteristicsofEdemainthehyper­ tensionpopulationtofindtheprevalenceofangioedema: Herewefindthataportionofthispopulationhasarecordofangioedemaintheyearprior tostartingananti­hypertensivemedication.\n",
      "page text: 11.7. Cohort Characterization in ATLAS 185 Figure11.13: Characterizationresults­exploringacontraindicatedconditiondetails. Figure11.14: Characterizationresultsofageforeachcohortandsubgroup.\n",
      "page text: 186 Chapter 11. Characterization Whiledomaincovariatesarecomputedusingabinaryindicator(i.e.wasarecordofthe codepresentinthepriortimeframe),somevariablesprovideacontinuousvaluesuchas theageofpersonsatcohortstart. Intheexampleabove,weshowtheageforthe2cohorts characterized expressed with the count of persons, mean age, median age and standard deviation. 11.7.4 Defining Custom Features In addition to the preset features, ATLAS supports the ability to allow for user­defined customfeatures. Todothis,clickthe Characterization left­handmenuitem,thenclick theFeature Analysis tab and click the New Feature Analysis button. Provide a name forthecustomfeatureandsaveitusingthe button. Inthisexample,wewilldefineacustomfeaturethatwillidentifythecountofpersonsin eachcohortthathaveadrugeraofACEinhibitorsintheirhistoryaftercohortstart: Figure11.15: CustomfeaturedefinitioninATLAS. Thecriteriadefinedaboveassumesthatitwillbeappliedtoacohortstartdate. Oncewe have defined the criteria and saved it, we can apply it to the characterization design we createdintheprevioussection. Todothis,openthecharacterizationdesignandnavigate to the Feature Analysis section. Click the button and from the menu select the new custom features. They will now appear in the feature list for the characterization design. Asdescribedearlier,wecanexecutethisdesignagainstadatabasetoproducethe characterizationforthiscustomfeature:\n",
      "page text: 11.8. Cohort Characterization in R 187 Figure11.16: Customfeatureresultsdisplay. 11.8 Cohort Characterization in R We may also choose to characterize cohorts using R. Here we’ll describe how to use the OHDSI R package FeatureExtraction to generate baseline features (covariates) for ourhypertensioncohorts. FeatureExtractionprovidesuserswiththeabilityto construct covariatesinthreeways: •Choosethedefaultsetofcovariates •Choosefromasetofpre­specifiedanalyses •Createasetofcustomanalyses FeatureExtraction creates covariates in two distinct ways: person­level features and ag­ gregate features. Person­level features are useful for machine learning applications. In thissection,we’llfocusonusingaggregatefeaturesthatareusefulforgeneratingbaseline covariatesthatdescribethecohortofinterest. Additionally,we’llfocusonthesecondtwo ways of constructing covariates: pre­specified and custom analyses and leave using the defaultsetasanexerciseforthereader. 11.8.1 Cohort Instantiation Wefirstneedtoinstantiatethecohorttocharacterizeit. Instantiatingcohortsisdescribed in Chapter 10. In this example, we’ll use the persons initiating a first­line therapy for hypertension with 1 year follow up (Appendix B.6). We leave characterizing the other cohortsinAppendix Basanexerciseforthereader. Wewillassumethecohorthasbeen instantiatedinatablecalled scratch.my_cohorts withcohortdefinitionIDequalto1. 11.8.2 Data Extraction WefirstneedtotellRhowtoconnecttotheserver. FeatureExtractionusestheDatabaseC­ onnectorpackage,whichprovidesafunctioncalled createConnectionDetails . Type ?createConnectionDetails forthespecificsettingsrequiredforthevariousdatabase\n",
      "page text: 188 Chapter 11. Characterization management systems (DBMS). For example, one might connect to a PostgreSQL databaseusingthiscode: library(FeatureExtraction) connDetails <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) cdmDbSchema <- \"my_cdm_data\" cohortsDbSchema <- \"scratch\" cohortsDbTable <- \"my_cohorts\" cdmVersion <- \"5\" Thelastfourlinesdefinethe cdmDbSchema ,cohortsDbSchema ,andcohortsDbTable variables,aswellastheCDMversion. WewillusetheselatertotellRwherethedatain CDMformatlive,wherethecohortsofinteresthavebeencreated,andwhatversionCDM isused. NotethatforMicrosoftSQLServer,databaseschemasneedtospecifyboththe databaseandtheschema,soforexample cdmDbSchema <- \"my_cdm_data.dbo\" . 11.8.3 Using Prespecified Analyses The function createCovariateSettings allow the user to choose from a large set of predefined covariates. Type ?createCovariateSettings to get an overview of the availableoptions. Forexample: settings <- createCovariateSettings ( useDemographicsGender = TRUE, useDemographicsAgeGroup = TRUE, useConditionOccurrenceAnyTimePrior = TRUE) Thiswillcreatebinarycovariatesforgender,age(in5yearagegroups),andeachconcept observed in the condition_occurrence table any time prior to (and including) the cohort startdate. Many of the prespecified analyses refer to a short, medium, or long term time window. Bydefault,thesewindowsaredefinedas: •Long term : 365daysprioruptoandincludingthecohortstartdate. •Medium term : 180daysprioruptoandincludingthecohortstartdate. •Short term : 30daysprioruptoandincludingthecohortstartdate. However,theusercanchangethesevalues. Forexample: settings <- createCovariateSettings (useConditionEraLongTerm = TRUE, useConditionEraShortTerm = TRUE,\n",
      "page text: 11.8. Cohort Characterization in R 189 useDrugEraLongTerm = TRUE, useDrugEraShortTerm = TRUE, longTermStartDays = -180, shortTermStartDays = -14, endDays = -1) Thisredefinesthelong­termwindowas180dayspriorupto(butnotincluding)thecohort startdate,andredefinestheshorttermwindowas14dayspriorupto(butnotincluding) thecohortstartdate. Again,wecanalsospecifywhichconceptIDsshouldorshouldnotbeusedtoconstruct covariates: settings <- createCovariateSettings (useConditionEraLongTerm = TRUE, useConditionEraShortTerm = TRUE, useDrugEraLongTerm = TRUE, useDrugEraShortTerm = TRUE, longTermStartDays = -180, shortTermStartDays = -14, endDays = -1, excludedCovariateConceptIds = 1124300, addDescendantsToExclude = TRUE, aggregated = TRUE) Theuseof aggregated = TRUE foralloftheexamplesaboveindicatetoFeature­ Extractiontoprovidesummarystatistics. Excludingthisflagwillcomputecovari­ atesforeachpersoninthecohort. 11.8.4 Creating Aggregated Covariates Thefollowingcodeblockwillgenerateaggregatedstatisticsforacohort: covariateSettings <- createDefaultCovariateSettings () covariateData2 <- getDbCovariateData ( connectionDetails = connectionDetails, cdmDatabaseSchema = cdmDatabaseSchema, cohortDatabaseSchema = resultsDatabaseSchema, cohortTable = \"cohorts_of_interest\" , cohortId = 1, covariateSettings = covariateSettings, aggregated = TRUE) summary(covariateData2)\n",
      "page text: 190 Chapter 11. Characterization Andtheoutputwilllooksimilartothefollowing: ## CovariateData Object Summary ## ## Number of Covariates: 41330 ## Number of Non-Zero Covariate Values: 41330 11.8.5 Output Format The two main components of the aggregated covariateData object are covariates andcovariatesContinuous forbinaryandcontinuouscovariatesrespectively: covariateData2 $covariates covariateData2 $covariatesContinuous 11.8.6 Custom Covariates FeatureExtractionalsoprovidestheabilitytodefineandutilizecustomcovariates. These detailsareanadvancedtopicandcoveredintheuserdocumentation: http://ohdsi.github. io/FeatureExtraction/ . 11.9 Cohort Pathways in A TLAS Thegoalwithapathwayanalysisistounderstandthesequencingoftreatmentsalongin oneormorecohortsofinterest. Themethodsappliedarebasedonthedesignreportedby Hripcsaketal. (2016). Thesemethodsweregeneralizedandcodifiedintoafeaturecalled CohortPathwaysinATLAS. Cohortpathwaysaimstoprovideanalyticcapabilitiestosummarizetheeventsfollowing thecohortstartdateofoneormoretargetcohorts. Todothis,wecreateasetofcohorts to identify the clinical events of interest for the target population called event cohort. Focusingonhowthismightlookforapersoninthetargetcohort: Figure11.17: Pathwaysanalysisinthecontextofasingleperson. In figure11.17, the person is part of the target cohort with a defined start and end date. Then, the numbered line segments represent where that person also is identified in an eventcohortforadurationoftime. Eventcohortsallowustodescribeanyclinicalevent\n",
      "page text: 11.9. Cohort Pathways in ATLAS 191 ofinterestthatisrepresentedintheCDMsuchthatwearenotconstrainedtocreatinga pathwayforasingledomainorconcept. Tostart,clickon intheleftbarofATLAStocreateanewcohort pathwaysstudy. Provideadescriptivenameandpressthesavebutton. 11.9.1 Design Tostart,wewillcontinuetousethecohortsinitiatingafirst­linetherapyforhypertension with1and3yearsfollowup(Appendix B.6,B.7). Usethebuttontoimportthe2cohorts. Figure11.18: Pathwaysanalysiswithtargetcohortsselected. Next we’ll define the event cohorts by creating a cohort for each first­line hypertensive drug of interest. For this, we’ll start by creating a cohort of ACE inhibitor users and define the cohort end date as the end of continuous exposure. We’ll do the same for 8 otherhypertensivemedicationsandnotethatthesedefinitionsarefoundinAppendix B.8­ B.16. Oncecompleteusethe buttontoimporttheseintotheEventCohortsection ofthepathwaydesign: Whencomplete,yourdesignshouldlookliketheoneabove. Next,we’llneedtodecide onafewadditionalanalysissettings: •Combination window : Thissettingallowsyoutodefineawindowoftime,indays, inwhichoverlapbetweeneventsisconsideredacombinationofevents. Forexam­ ple, if two drugs represented by 2 event cohorts (event cohort 1 and event cohort 2) overlap within the combination window the pathways algorithm will combine theminto“eventcohort1+eventcohort2”. •Minimum cell count : Eventcohortswithlessthanthisnumberofpeoplewillbe censored(removed)fromtheoutputtoprotectprivacy.\n",
      "page text: 192 Chapter 11. Characterization Figure11.19: Eventcohortsforpathwaydesignforinitiatingafirst­lineantihypertensive therapy.\n",
      "page text: 11.9. Cohort Pathways in ATLAS 193 •Max path length : This refers to the maximum number of sequential events to considerfortheanalysis. 11.9.2 Executions Oncewehaveourpathwayanalysisdesigned,wecanexecutethisdesignagainstoneor moredatabasesinourenvironment. Thisworksthesamewayaswedescribedforcohort characterizationinATLAS.Oncecomplete,wecanreviewtheresultsoftheanalysis. 11.9.3 Viewing Results Figure11.20: Pathwaysresultslegendandsunburstvisualization. Theresultsofapathwayanalysisarebrokeninto3sections: Thelegendsectiondisplays thetotalnumberofpersonsinthetargetcohortalongwiththenumberofpersonsthathad 1ormoreeventsinthepathwayanalysis. Belowthatsummaryarethecolordesignations foreachofthecohortsthatappearinthesunburstplotinthecentersection. The sunburst plot is a visualization that represents the various event pathways taken by persons over time. The center of the plot represents the cohort entry and the first color­ coded ring shows the proportion of persons in each event cohort. In our example, the center of the circle represents hypertensive persons initiating a first line therapy. Then, thefirstringinthesunburstplotshowstheproportionofpersonsthatinitiatedatypeof\n",
      "page text: 194 Chapter 11. Characterization first­linetherapydefinedbytheeventcohorts(i.e.ACEinhibitors,Angiotensinreceptor blockers, etc). The second set of rings represents the 2nd event cohort for persons. In certaineventsequences,apersonmayneverhavea2ndeventcohortobservedinthedata andthatproportionisrepresentedbythegreyportionofthering. Figure11.21: Pathwaysresultsdisplayingpathdetails. Clickingonasectionofthesunburstplotwilldisplaythepathdetailsontheright. Here we can see that the largest proportion of people in our target cohort initiated a first­line therapywithACEinhibitorsandfromthatgroup,asmallerproportionstartedaThiazide orthiazidediuretics. 11.10 Incidence Analysis in A TLAS In an incidence calculation, we describe: amongst the persons in the target cohort, who experienced the outcome cohort during the time at risk period. Here we will design an incidenceanalysistocharacterizeangioedemaandacutemyocardialinfarctionoutcomes amongst new users of ACE inhibitors (ACEi) and Thiazides and thiazide­like diuretics (THZ).WewillassesstheseoutcomesduringtheTARthatapersonwasexposedtothe drug. Additionally, we will add an outcome of drug exposure to Angiotensin receptor blockers (ARBs) to measure the incidence of new use of ARBs during exposure to the target cohorts (ACEi and THZ). This outcome definition provides an understanding of howARBsareutilizedamongstthetargetpopulations. Tostart,clickon intheleftbarofATLAStocreateanewincidence\n",
      "page text: 11.10. Incidence Analysis in ATLAS 195 analysis. Provideadescriptivenameandpressthesavebutton . 11.10.1 Design We assume the cohorts used in this example have already been created in ATLAS as describedinChapter 10. TheAppendixprovidesthefulldefinitionsofthetargetcohorts (Appendix B.2,B.5),andoutcomes(Appendix B.4,B.3,B.9)cohorts. Figure11.22: IncidenceRatetargetandoutcomedefinition. On the definition tab, click to choose the New users of ACE inhibitors cohort and the New users of Thiazide or Thiazide­like diuretics cohort. Close the dialog to view that thesecohortsareaddedtothedesign. Nextweaddouroutcomecohortsbyclickingon andfromthedialogbox,selecttheoutcomecohortsof acute myocardial infarction events , angioedema events andAngiotensin receptor blocker (ARB) use . Again,closethewindow toviewthatthesecohortsareaddedtotheoutcomecohortssectionofthedesign. Figure11.23: IncidenceRatetargetandoutcomedefinition. Next,wewilldefinethetimeatriskwindowfortheanalysis. Asshownabove,thetime atriskwindowisdefinedrelativetothecohortstartandenddates. Herewewilldefine thetimeatriskstartas1dayaftercohortstartforourtargetcohorts. Next,we’lldefine thetimeatrisktoendatthecohortenddate. Inthiscase,thedefinitionoftheACEiand THZcohortshaveacohortenddatewhenthedrugexposureends. ATLASalsoprovidesawaytostratifythetargetcohortsaspartoftheanalysisspecifica­ tion: To do this, click the New Stratify Criteria button and follow the same steps described in Chapter 11. Now that we have completed the design, we can move to executing our designagainstoneormoredatabases.\n",
      "page text: 196 Chapter 11. Characterization Figure11.24: IncidenceRatestratadefinitionforfemales. 11.10.2 Executions ClicktheGenerationtabandthenthe buttontorevealalistofdatabasestouse toexecutetheanalysis: Figure11.25: IncidenceRateanalysisexecution. SelectoneormoredatabasesandclicktheGeneratebuttontostarttheanalysistoanalyze allcombinationsoftargetsandoutcomesspecifiedinthedesign. 11.10.3 Viewing Results On the Generation tab, the top portion of the screen allows you to select a target and outcometousewhenviewingtheresults. Justbelowthisasummaryoftheincidenceis shownforeachdatabaseusedintheanalysis. SelectthetargetcohortofACEiusersandtheAcuteMyocardialInfarction(AMI)from therespectivedropdownlists. Clickthe buttontorevealtheincidenceanalysis results: A summary for the database shows the total persons in the cohort that were observed duringtheTARalongwiththetotalnumberofcases. Theproportionshowsthenumber\n",
      "page text: 11.11. Summary 197 Figure11.26: IncidenceRateanalysisoutput­NewACEiuserswithAMIoutcome. of cases per 1000 people. The time at risk, in years, is calculated for the target cohort. Theincidencerateisexpressedasthenumberofcasesper1000person­years. Wecanalsoviewtheincidencemetricsforthestratathatwedefinedinthedesign. The same metrics mentioned above are calculated for each stratum. Additionally, a treemap visualization provides a representation of the proportion of each stratum represented by theboxedareas. Thecolorrepresentstheincidencerateasshowninthescalealongthe bottom. We can gather the same information to see the incidence of new use of ARBs amongst theACEipopulation. Usingthe dropdownatthe top, changethe outcometoARBs use andclickthe buttontorevealthedetails. Asshown,themetricscalculatedarethesamebuttheinterpretationisdifferentsincethe input(ARBuse)referencesadrugutilizationestimateinsteadofahealthoutcome. 11.11 Summary –OHDSIofferstoolstocharacterizeanentiredatabase,oracohortofinterest. –Cohortcharacterizationdescribesacohortofinterestduringthetimepreced­ ingtheindexdate( baseline)andthetimeafterindex( post­index ). –ATLAS’scharacterizationmoduleandtheOHDSIMethodsLibraryprovide\n",
      "page text: 198 Chapter 11. Characterization Figure 11.27: Incidence Rate ­ New users of ACEi receiving ARBs treatment during ACEiexposure. thecapabilitytocalculatebaselinecharacteristicsformultipletimewindows. –ATLAS’spathwaysandincidenceratemodulesprovidedescriptivestatistics duringthepost­indextimeperiod. 11.12 Exercises Prerequisites Fortheseexercises,accesstoanATLASinstanceisrequired. Youcanusetheinstanceat http://atlas­demo.ohdsi.org ,oranyotherinstanceyouhaveaccessto. Exercise 11.1. Wewouldliketounderstandhowcelecoxibisusedintherealworld. To start,wewouldliketounderstandwhatdataadatabasehasonthisdrug. UsetheATLAS DataSourcesmoduletofindinformationoncelecoxib. Exercise 11.2. Wewouldliketobetterunderstandthediseasenaturalhistoryofcelecoxib users. Createasimplecohortofnewusersofcelecoxibusinga365­daywashoutperiod (seeChapter 10fordetailsonhowtodothis),anduseATLAStocreateacharacterization ofthiscohort,showingco­morbidconditionsanddrug­exposures.\n",
      "page text: 11.12. Exercises 199 Exercise 11.3. Weareinterestedinunderstandhowoftengastrointestinal(GI)bleedsoc­ curanytimeafterpeopleinitiatecelecoxibtreatment. CreateacohortofGIbleedevents, simplydefinedasanyoccurrenceofconcept 192671(“Gastrointestinalhemorrhage”)or any of its descendants. Compute the incidence rate of these GI events after celecoxib initiation,usingtheexposurecohortdefinedinthepreviousexercise. SuggestedanswerscanbefoundinAppendix E.7.\n",
      "page text: 200 Chapter 11. Characterization\n",
      "page text: Chapter 12 Population-Level Estimation Chapter leads: Martijn Schuemie, David Madigan, Marc Suchard & Patrick Ryan Observationalhealthcaredata,suchasadministrativeclaimsandelectronichealthrecords, offeropportunitiestogeneratereal­worldevidenceabouttheeffectoftreatmentsthatcan meaningfullyimprovethelivesofpatients. Inthischapterwefocusonpopulation­level effect estimation, which refers to the estimation of average causal effects of exposures (e.g.medicalinterventionssuchasdrugexposuresorprocedures)onspecifichealthout­ comesofinterest. Inwhatfollows,weconsidertwodifferentestimationtasks: •Direct effect estimation : estimating the effect of an exposure on the risk of an outcome,ascomparedtonoexposure. •Comparative effect estimation : estimating the effect of an exposure (the target exposure) on the risk of an outcome, as compared to another exposure (the com­ paratorexposure). In both cases, the patient­level causal effect contrasts a factual outcome, i.e., what hap­ penedtotheexposedpatient, withacounterfactualoutcome, i.e., whatwouldhavehap­ penedhadtheexposurenotoccurred(direct)orhadadifferentexposureoccurred(com­ parative). Sinceanyonepatientrevealsonlythefactualoutcome(thefundamentalprob­ lemofcausalinference),thevariouseffectestimationdesignsemploydifferentanalytic devicestoshedlightonthecounterfactualoutcomes. Use­cases for population­level effect estimation include treatment selection, safety surveillance, and comparative effectiveness. Methods can test specific hypotheses one at a time (e.g. ‘signal evaluation’) or explore multiple­hypotheses­at­once (e.g. ‘signal detection’). In all cases, the objective remains the same: to produce a high­quality estimateofthecausaleffect. Inthischapterwefirstdescribevariouspopulation­levelestimationstudydesigns,allof whichareimplementedasRpackagesinthe OHDSIMethodsLibrary . Wethendetailthe designofanexampleestimationstudy,followedbystep­by­stepguidesofhowtoimple­ ment the design using ATLAS and R. Finally, we review the various outputs generated 201\n",
      "page text: 202 Chapter 12. Population­Level Estimation bythestudy,includingstudydiagnosticsandeffectsizeestimates. 12.1 The Cohort Method Design Figure 12.1: The new­user cohort design. Subjects observed to initiate the target treat­ mentarecomparedtothoseinitiatingthecomparatortreatment. Toadjustfordifferences betweenthetwotreatmentgroupsseveraladjustmentstrategiescanbeused,suchasstrat­ ification, matching, or weighting by the propensity score, or by adding baseline charac­ teristics to the outcome model. The characteristics included in the propensity model or outcomemodelarecapturedpriortotreatmentinitiation. Thecohortmethodattemptstoemulatearandomizedclinicaltrial. ( HernanandRobins , 2016)Subjectsthatareobservedtoinitiateonetreatment(thetarget)arecomparedtosub­ jectsinitiatinganothertreatment(thecomparator)andarefollowedforaspecificamount of time following treatment initiation, for example the time they stay on the treatment. We can specify the questions we wish to answer in a cohort study by making the five choiceshighlightedinTable 12.1. Table12.1: Maindesignchoicesinacomparativecohortdesign. Choice Description Targetcohort Acohortrepresentingthetargettreatment Comparatorcohort Acohortrepresentingthecomparatortreatment Outcomecohort Acohortrepresentingtheoutcomeofinterest Time­at­risk Atwhattime(oftenrelativetothetargetandcomparatorcohort startandenddates)doweconsidertheriskoftheoutcome? Model Themodelusedtoestimatetheeffectwhileadjustingfor differencesbetweenthetargetandcomparator Thechoiceofmodelspecifies, amongothers, thetypeofoutcomemodel. Forexample, we could use a logistic regression, which evaluates whether or not the outcome has oc­ curred, and produces an odds ratio. A logistic regression assumes the time­at­risk is of thesamelengthforbothtargetandcomparator,orisirrelevant. Alternatively,wecould\n",
      "page text: 12.1. The Cohort Method Design 203 chooseaPoissonregressionwhichestimatestheincidencerateratio,assumingaconstant incidence rate. Often a Cox regression is used which considers time to first outcome to estimatethehazardratio,assumingproportionalhazardsbetweentargetandcomparator. The new­user cohort method inherently is a method for comparative effect esti­ mation, comparing one treatment to another. It is difficult to use this method to compareatreatmentagainstnotreatment, sinceitishardtodefineagroupofun­ exposed people that is comparable with the exposed group. If one wants to use thisdesignfordirecteffectestimation,thepreferredwayistoselectacomparator treatment for the same indication as the exposure of interest, where the compara­ tor treatment is believed to have no effect on the outcome. Unfortunately, such a comparatormightnotalwaysbeavailable. Akeyconcernisthatthepatientsreceivingthetargettreatmentmaysystematicallydiffer fromthosereceivingthecomparatortreatment. Forexample,supposethetargetcohortis onaverage60yearsold,whereasthecomparatorcohortisonaverage40yearsold. Com­ paring target to comparator with respect to any age­related health outcome (e.g. stroke) mightthenshowsubstantialdifferencesbetweenthecohorts. Anuninformedinvestigator mightreachtheconclusionthereisacausalassociationbetweenthetargettreatmentand strokeascomparedtothecomparator. Moreprosaicallyorcommonplace,theinvestiga­ tormightconcludethatthereexisttargetpatientsthatexperiencedstrokethatwouldnot have done so had they received the comparator. This conclusion could well be entirely incorrect! Maybe those target patients disproportionately experienced stroke simply be­ cause they are older; maybe the target patients that experienced stroke might well have donesoeveniftheyhadreceivedthecomparator. Inthiscontext,ageisa“confounder.” Onemechanismtodealwithconfoundersinobservationalstudiesisthroughpropensity scores. 12.1.1 Propensity Scores Inarandomizedtrial,a(virtual)cointossassignspatientstotheirrespectivegroups. Thus, bydesign, theprobabilitythatapatientreceivesthetargettreatmentasagainstthecom­ parator treatment does not relate in any way to patient characteristics such as age. The coinhasnoknowledgeofthepatient, and, what’smore, weknowwithcertaintytheex­ act probability that a patient receives the target exposure. As a consequence, and with increasing confidence as the number of patients in the trial increases, the two groups of patientsessentially cannotdiffersystematicallywithrespectto anypatientcharacteristic. Thisguaranteedbalanceholdstrueforcharacteristicsthatthetrialmeasured(suchasage) aswellascharacteristicsthatthetrialfailedtomeasure,suchaspatientgeneticfactors. Foragivenpatient,the propensity score (PS)istheprobabilitythatthatpatientreceived the target treatment as against the comparator. ( Rosenbaum and Rubin ,1983) In a bal­ ancedtwo­armrandomizedtrial,thepropensityscoreis0.5foreverypatient. Inapropen­ sityscore­adjustedobservationalstudy,weestimatetheprobabilityofapatientreceiving\n",
      "page text: 204 Chapter 12. Population­Level Estimation thetargettreatmentbasedonwhatwecanobserveinthedataonandbeforethetimeof treatmentinitiation(irrespectiveofthetreatmenttheyactuallyreceived). Thisisastraight­ forward predictive modeling application; we fit a model (e.g. a logistic regression) that predicts whether a subject receives the target treatment, and use this model to generate predicted probabilities (the PS) for each subject. Unlike in a standard randomized trial, different patients will have different probabilities of receiving the target treatment. The PScanbeusedinseveralwaysincludingmatchingtargetsubjectstocomparatorsubjects with similar PS, stratifying the study population based on the PS, or weighting subjects using Inverse Probability of Treatment Weighting (IPTW) derived from the PS. When matching we can select just one comparator subject for each target subject, or we can allowmorethanonecomparatorsubjectpertargetsubject,atechniqueknowasvariable­ ratiomatching. ( Rassenetal. ,2012) For example, suppose we use one­on­one PS matching, and that Jan has a priori proba­ bilityof0.4ofreceivingthetargettreatmentandinfactreceivesthetargettreatment. If wecanfindapatient(namedJun)thatalsohadanaprioriprobabilityof0.4ofreceiving thetargettreatmentbutinfactreceivedthecomparator,thecomparisonofJanandJun’s outcomesislikeamini­randomizedtrial, atleastwithrespecttomeasuredconfounders. This comparison will yield an estimate of the Jan­Jun causal contrast that is as good as the one randomization would have produced. Estimation then proceeds as follows: for every patient that received the target, find one or more matched patients that received the comparator but had the same prior probability of receiving the target. Compare the outcomeforthetargetpatientwiththeoutcomesforthecomparatorpatientswithineach ofthesematchedgroups. Propensity scoring controls for measured confounders. In fact, if treatment assignment is “strongly ignorable” given measured characteristics, propensity scoring will yield an unbiasedestimateofthecausaleffect. “Stronglyignorable”essentiallymeansthatthere arenounmeasuredconfounders,andthatthemeasuredconfoundersareadjustedforap­ propriately. Unfortunately this is not a testable assumption. See Chapter 18for further discussionofthisissue. 12.1.2 Variable Selection Inthepast,PSwerecomputedbasedonmanuallyselectedcharacteristics,andalthough theOHDSItoolscansupportsuchpractices,wepreferusingmanygenericcharacteristics (i.e.characteristicsthatarenotselectedbasedonthespecificexposuresandoutcomesin thestudy). ( Tianetal.,2018)Thesecharacteristicsincludedemographics,aswellasall diagnoses,drugexposures,measurement,andmedicalproceduresobservedpriortoand onthedayoftreatmentinitiation. Amodeltypicallyinvolves10,000to100,000unique characteristics,whichwefitusinglarge­scaleregularizedregression( Suchardetal. ,2013) implementedinthe Cyclopspackage. Inessence,weletthedatadecidewhichcharacter­ isticsarepredictiveofthetreatmentassignmentandshouldbeincludedinthemodel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████████████████████████████████▏                                                                     | 226/464 [00:02<00:02, 104.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 12.1. The Cohort Method Design 205 Wetypicallyincludethedayoftreatmentinitiationinthecovariatecapturewindow becausemanyrelevantdatapointssuchasthediagnosisleadingtothetreatmentare recordedonthatdate. Onthisdaythetargetandcomparatortreatmentthemselves arealsorecorded,buttheseshould notbeincludedinthepropensitymodel,because theyaretheverythingwearetryingtopredict. Wemustthereforeexplicitlyexclude thetargetandcomparatortreatmentfromthesetofcovariates Somehavearguedthatadata­drivenapproachtocovariateselectionthatdoesnotdepend on clinical expertise to specify the “right” causal structure runs the risk of erroneously includingso­calledinstrumentalvariablesandcolliders,thusincreasingvarianceandpo­ tentially introducing bias. ( Hernan et al. ,2002) However, these concerns are unlikely to have a large impact in real­world scenarios. ( Schneeweiss ,2018) Furthermore, in medicine the true causal structure is rarely known, and when different researchers are askedtoidentifythe‘right’covariatestoincludeforaspecificresearchquestion,eachre­ searcherinvariablycomesupwithadifferentlist,thusmakingtheprocessirreproducible. Mostimportantly,ourdiagnosticssuchasinspectionofthepropensitymodel,evaluating balanceonallcovariates,andincludingnegativecontrolswouldidentifymostproblems relatedtocollidersandinstrumentalvariables. 12.1.3 Caliper Sincepropensityscoresfallonacontinuumfrom0to1,exactmatchingisrarelypossible. Instead, the matching process finds patients that match the propensity score of a target patient(s)withinsometoleranceknownasa“caliper.” Following Austin(2011),weuse adefaultcaliperof0.2standarddeviationsonthelogitscale. 12.1.4 Overlap: Preference Scores The propensity method requires that matching patients exist! As such, a key diagnostic showsthedistributionofthepropensityscoresinthetwogroups. Tofacilitateinterpreta­ tion,theOHDSItoolsplotatransformationofthepropensityscorecalledthe“preference score”. (Walker et al. ,2013) The preference score adjusts for the “market share” of the two treatments. For example, if 10% of patients receive the target treatment (and 90% receivethecomparatortreatment),thenpatientswithapreferencescoreof0.5havea10% probabilityofreceivingthetargettreatment. Mathematically,thepreferencescoreis ln(𝐹 1 − 𝐹) =ln(𝑆 1 − 𝑆) −ln(𝑃 1 − 𝑃) Where 𝐹is the preference score, 𝑆is the propensity score, and 𝑃is the proportion of patientsreceivingthetargettreatment. Walkeretal. (2013)discusstheconceptof“empiricalequipoise.” Theyacceptexposure pairsasemergingfromempiricalequipoiseifatleasthalfoftheexposuresaretopatients withapreferencescoreofbetween0.3and0.7.\n",
      "page text: 206 Chapter 12. Population­Level Estimation Table12.2: Maindesignchoicesinaself­controlledcohortdesign. Choice Description Targetcohort Acohortrepresentingthetreatment Outcomecohort Acohortrepresentingtheoutcomeofinterest Time­at­risk Atwhattime(oftenrelativetothetargetcohortstartand enddates)doweconsidertheriskoftheoutcome? Controltime Thetimeperiodusedasthecontroltime 12.1.5 Balance GoodpracticealwayschecksthatthePSadjustmentsucceedsincreatingbalancedgroups of patients. Figure 12.19shows the standard OHDSI output for checking balance. For eachpatientcharacteristic,thisplotsthestandardizeddifferencebetweenmeansbetween the two exposure groups before and after PS adjustment. Some guidelines recommend anafter­adjustmentstandardizeddifferenceupperboundof0.1. ( Rubin,2001) 12.2 The Self-Controlled Cohort Design Figure12.2: Theself­controlledcohortdesign. Therateofoutcomesduringexposureto thetargetiscomparedtotherateofoutcomesinthetimepre­exposure. The self­controlled cohort (SCC) design ( Ryan et al. ,2013a) compares the rate of out­ comesduringexposuretotherateofoutcomesinthetimejustpriortotheexposure. The fourchoicesshowninTable 12.2defineaself­controlledcohortquestion. Because the same subject that make up the exposed group are also used as the control group, no adjustment for between­person differences need to be made. However, the method is vulnerable to other differences, such as differences in the baseline risk of the outcomebetweendifferenttimeperiods. 12.3 The Case-Control Design Case­control studies ( Vandenbroucke and Pearce ,2012) consider the question “are per­ sons with a specific disease outcome exposed more frequently to a specific agent than those without the disease?” Thus, the central idea is to compare “cases,” i.e., subjects\n",
      "page text: 12.4. The Case­Crossover Design 207 Figure12.3: Thecase­controldesign. Subjectswiththeoutcome(‘cases’)arecompared tosubjectswithouttheoutcome(‘controls’)intermsoftheirexposurestatus. Often,cases andcontrolsarematchedonvariouscharacteristicssuchasageandsex. Table12.3: Maindesignchoicesinacase­controldesign. Choice Description Outcomecohort Acohortrepresentingthecases(theoutcomeofinterest) Controlcohort Acohortrepresentingthecontrols. Typicallythecontrol cohortisautomaticallyderivedfromtheoutcomecohort usingsomeselectionlogic Targetcohort Acohortrepresentingthetreatment Nestingcohort Optionally,acohortdefiningthesubpopulationfrom whichcasesandcontrolsaredrawn Time­at­risk Atwhattime(oftenrelativetotheindexdate)dowe considerexposurestatus? thatexperiencetheoutcomeofinterest,with“controls,”i.e.,subjectsthatdidnotexperi­ encetheoutcomeofinterest. ThechoicesinTable 12.3defineacase­controlquestion. Often,oneselectscontrolstomatchcasesbasedoncharacteristicssuchasageandsexto makethemmorecomparable. Anotherwidespreadpracticeistonesttheanalysiswithin aspecificsubgroupofpeople,forexamplepeoplethathaveallbeendiagnosedwithone oftheindicationsoftheexposureofinterest. 12.4 The Case-Crossover Design Thecase­crossover( Maclure,1991)designevaluateswhethertherateofexposureisdif­ ferent at the time of the outcome than at some predefined number of days prior to the outcome. It is trying to determine whether there is something special about the day the outcomeoccurred. Table 12.4showsthechoicesthatdefineacase­crossoverquestion. Cases serve as their own controls. As self­controlled designs, they should be robust to confounding due to between­person differences. One concern is that, because the out­\n",
      "page text: 208 Chapter 12. Population­Level Estimation Figure12.4: Thecase­crossoverdesign. Thetimearoundtheoutcomeiscomparedtoa controldatesetatapredefinedintervalpriortotheoutcomedate. Table12.4: Maindesignchoicesinacase­crossoverdesign. Choice Description Outcomecohort Acohortrepresentingthecases(theoutcomeofinterest) Targetcohort Acohortrepresentingthetreatment Time­at­risk Atwhattime(oftenrelativetotheindexdate)dowe considerexposurestatus? Controltime Thetimeperiodusedasthecontroltime come date is always later than the control date, the method will be positively biased if the overall frequency of exposure increases over time (or negatively biased if there is a decrease). To address this, the case­time­control design ( Suissa,1995) was developed, which adds controls, matched for example on age and sex, to the case­crossover design toadjustforexposuretrends. 12.5 The Self-Controlled Case Series Design Figure12.5: TheSelf­ControlledCaseSeriesdesign. Therateofoutcomesduringexpo­ sureiscomparedtotherateofoutcomeswhennotexposed. TheSelf­ControlledCaseSeries(SCCS)design( Farrington,1995;Whitakeretal. ,2006) compares the rate of outcomes during exposure to the rate of outcomes during all unex­ posed time, including before, between, and after exposures. It is a Poisson regression that is conditioned on the person. Thus, it seeks to answer the question: “Given that a patient has the outcome, is the outcome more likely during exposed time compared to\n",
      "page text: 12.6. Designing a Hypertension Study 209 Table12.5: Maindesignchoicesinaself­controlledcaseseriesdesign. Choice Description Targetcohort Acohortrepresentingthetreatment Outcomecohort Acohortrepresentingtheoutcomeofinterest Time­at­risk Atwhattime(oftenrelativetothetargetcohortstartand enddates)doweconsidertheriskoftheoutcome? Model Themodeltoestimatetheeffect,includingany adjustmentsfortime­varyingconfounders non­exposedtime?”. ThechoicesinTable 12.5defineanSCCSquestion. Like other self­controlled designs, the SCCS is robust to confounding due to between­ person differences, but vulnerable to confounding due to time­varying effects. Several adjustments are possible to attempt to account for these, for example by including age andseason. AspecialvariantoftheSCCSincludesnotjusttheexposureofinterest,but all other exposures to drugs recorded in the database ( Simpson et al. ,2013) potentially adding thousands of additional variables to the model. L1­regularization using cross­ validationtoselecttheregularizationhyperparameterisappliedtothecoefficientsofall exposuresexcepttheexposureofinterest. One important assumption underlying the SCCS is that the observation period end is independentofthedateoftheoutcome. Forsomeoutcomes,especiallyonesthatcanbe fatalsuchasstroke,thisassumptioncanbeviolated. AnextensiontotheSCCShasbeen developedthatcorrectsforanysuchdependency. ( Farringtonetal. ,2011) 12.6 Designing a Hypertension Study 12.6.1 Problem Definition ACE inhibitors (ACEi) are widely used in patients with hypertension or ischemic heart disease, especially those with other comorbidities such as congestive heart failure, dia­ betes mellitus, or chronic kidney disease. ( Zaman et al. ,2002) Angioedema, a serious and sometimes life­threatening adverse event that usually manifests as swelling of the lips, tongue, mouth, larynx, pharynx, or periorbital region, has been linked to the use of these medications. ( Sabroe and Black ,1997) However, limited information is avail­ ableabouttheabsoluteandrelativerisksforangioedemaassociatedwiththeuseofthese medications. Existing evidence is primarily based on investigations of specific cohorts (e.g.,predominantlymaleveteransorMedicaidbeneficiaries)whosefindingsmaynotbe generalizabletootherpopulations,orbasedoninvestigationswithfewevents,whichpro­ videunstableriskestimates. ( Powersetal. ,2012)Severalobservationalstudiescompare ACEitobeta­blockersfortheriskofangioedema,( Magidetal. ,2010;Tohetal.,2012)but beta­blockersarenolongerrecommendedasfirst­linetreatmentofhypertension. ( Whel­ tonetal.,2018)Aviablealternativetreatmentcouldbethiazidesorthiazide­likediuretics\n",
      "page text: 210 Chapter 12. Population­Level Estimation (THZ),whichcouldbejustaseffectiveinmanaginghypertensionanditsassociatedrisks suchasacutemyocardialinfarction(AMI),butwithoutincreasingtheriskofangioedema. Thefollowingwilldemonstratehowtoapplyourpopulation­levelestimationframework to observational healthcare data to address the following comparative estimation ques­ tions: WhatistheriskofangioedemainnewusersofACEinhibitorscomparedto newusersofthiazideandthiazide­likediuretics? WhatistheriskofacutemyocardialinfarctioninnewusersofACEinhibitors comparedtonewusersofthiazideandthiazide­likediuretics? Sincethesearecomparativeeffectestimationquestionswewillapplythecohortmethod asdescribedinSection 12.1. 12.6.2 T arget and Comparator We consider patients new­users if their first observed treatment for hypertension was monotherapywithanyactiveingredientineithertheACEiorTHZclass. Wedefinemono therapy as not starting on any other anti­hypertensive drug in the seven days following treatmentinitiation. Werequirepatientstohaveatleastoneyearofpriorcontinuousob­ servationinthe databasebefore firstexposure anda recordedhypertension diagnosisat orintheyearprecedingtreatmentinitiation. 12.6.3 Outcome Wedefineangioedemaasanyoccurrenceofanangioedemaconditionconceptduringan inpatientoremergencyroom(ER)visit,andrequiretheretobenoangioedemadiagnosis recordedinthesevendaysprior. WedefineAMIasanyoccurrenceofanAMIcondition conceptduringaninpatientorERvisit,andrequiretheretobenoAMIdiagnosisrecord inthe180daysprior. 12.6.4 Time-At-Risk Wedefinetime­at­risktostartonthedayaftertreatmentinitiation,andstopwhenexposure stops,allowingfora30­daygapbetweensubsequentdrugexposures. 12.6.5 Model WefitaPSmodelusingthedefaultsetofcovariates,includingdemographics,conditions, drugs, procedures, measurements, observations, and several co­morbidity scores. We exclude ACEi and THZ from the covariates. We perform variable­ratio matching and conditiontheCoxregressiononthematchedsets. 12.6.6 Study Summary\n",
      "page text: 12.7. Implementing the Study Using ATLAS 211 Table12.6: Maindesignchoicesforourcomparativecohortstudy. Choice Value Targetcohort NewusersofACEinhibitorsasfirst­linemonotherapyfor hypertension. Comparatorcohort Newusersofthiazidesorthiazide­likediureticsasfirst­line monotherapyforhypertension. Outcomecohort Angioedemaoracutemyocardialinfarction. Time­at­risk Startingthedayaftertreatmentinitiation,stoppingwhen exposurestops. Model Coxproportionalhazardsmodelusingvariable­ratiomatching. 12.6.7 Control Questions Toevaluatewhetherourstudydesignproducesestimatesinlinewiththetruth,weaddi­ tionally include a set of control questions where the true effect size is known. Control questions can be divided in negative controls, having a hazard ratio of 1, and positive controls,havingaknownhazardratiogreaterthan1. Forseveralreasonsweuserealneg­ ativecontrols,andsynthesizepositivecontrolsbasedonthesenegativecontrols. Howto defineandusecontrolquestionsisdiscussedindetailinChapter 18. 12.7 Implementing the Study Using A TLAS HerewedemonstratehowthisstudycanbeimplementedusingtheEstimationfunctionin ATLAS.Clickon intheleftbarofATLAS,andcreateanewestimation study. Makesuretogivethestudyaneasy­to­recognizename. Thestudydesigncanbe savedatanytimebyclickingthe button. In the Estimation design function, there are three sections: Comparisons, Analysis Set­ tings,andEvaluationSettings. Wecanspecifymultiplecomparisonsandmultipleanaly­ sissettings,andATLASwillexecuteallcombinationsoftheseasseparateanalyses. Here wediscusseachsection: 12.7.1 Comparative Cohort Settings A study can have one or more comparisons. Click on “Add Comparison,” which will openanewdialog. Clickon toselectthetargetandcomparatorcohorts. Byclicking on “Add Outcome” we can add our two outcome cohorts. We assume the cohorts have alreadybeencreatedinATLASasdescribedinChapter 10. TheAppendixprovidesthe full definitions of the target (Appendix B.2), comparator (Appendix B.5), and outcome (Appendix B.4andAppendix B.3)cohorts. Whendone,thedialogshouldlooklikeFigure 12.6.\n",
      "page text: 212 Chapter 12. Population­Level Estimation Figure12.6: Thecomparisondialog Note that we can select multiple outcomes for a target­comparator pair. Each outcome willbetreatedindependently,andwillresultinaseparateanalysis. Negative Control Outcomes Negativecontroloutcomesareoutcomesthatarenotbelievedtobecausedbyeitherthe targetorthecomparator, andwherethereforethetruehazardratioequals1. Ideally, we would have proper cohort definitions for each outcome cohort. However, typically, we onlyhaveaconceptset, withoneconceptpernegativecontroloutcome, andsomestan­ dardlogictoturntheseintooutcomecohorts. Hereweassumetheconceptsethasalready beencreatedasdescribedinChapter 18andcansimplybeselected. Thenegativecontrol concept set should contain a concept per negative control, and not include descendants. Figure12.7showsthenegativecontrolconceptsetusedforthisstudy. Concepts to Include When selecting concept to include, we can specify which covariates we would like to generate,forexampletouseinapropensitymodel. Whenspecifyingcovariateshere,all othercovariates(asidefromthoseyouspecified)areleftout. Weusuallywanttoinclude all baseline covariates, letting the regularized regression build a model that balances all covariates. Theonlyreasonwemightwanttospecifyparticularcovariatesistoreplicate an existing study that manually picked covariates. These inclusions can be specified in this comparison section or in the analysis section, because sometimes they pertain to a specificcomparison(e.g.knownconfoundersinacomparison),orsometimestheypertain toananalysis(e.g.whenevaluatingaparticularcovariateselectionstrategy).\n",
      "page text: 12.7. Implementing the Study Using ATLAS 213 Figure12.7: NegativeControlconceptset. Concepts to Exclude Rather than specifying which concepts to include, we can instead specify concepts to exclude. When we submit a concept set in this field, we use every covariate except for thosethatwesubmitted. Whenusingthedefaultsetofcovariates,whichincludesalldrugs and procedures occurring on the day of treatment initiation, we must exclude the target andcomparatortreatment, aswellasanyconceptsthataredirectlyrelatedtothese. For example,ifthetargetexposureisaninjectable,weshouldnotonlyexcludethedrug,but also the injection procedure from the propensity model. In this example, the covariates we want to exclude are ACEi and THZ. Figure 12.8shows we select a concept set that includesalltheseconcepts,includingtheirdescendants. Figure12.8: Theconceptsetdefiningtheconceptstoexclude. Afterselectingthenegativecontrolsandcovariatestoexclude,thelowerhalfofthecom­\n",
      "page text: 214 Chapter 12. Population­Level Estimation parisonsdialogshouldlooklikeFigure 12.9. Figure 12.9: The comparison window showing concept sets for negative controls and conceptstoexclude. 12.7.2 Effect Estimation Analysis Settings After closing the comparisons dialog we can click on “Add Analysis Settings.” In the box labeled “Analysis Name,” we can give the analysis a unique name that is easy to remember and locate in the future. For example, we could set the name to “Propensity scorematching.” Study Population There are a wide range of options to specify the study population, which is the set of subjectsthatwillentertheanalysis. Manyoftheseoverlapwithoptionsavailablewhen designingthetargetandcomparatorcohortsinthecohortdefinitiontool. Onereasonfor usingtheoptionsinEstimationinsteadofinthecohortdefinitionisre­usability;wecan define the target, comparator, and outcome cohorts completely independently, and add dependenciesbetweentheseatalaterpointintime. Forexample,ifwewishtoremove peoplewhohadtheoutcomebeforetreatmentinitiation,wecoulddosointhedefinitions ofthetargetandcomparatorcohort,butthenwewouldneedtocreateseparatecohortsfor everyoutcome! Instead,wecanchoosetohavepeoplewithprioroutcomesberemoved intheanalysissettings,andnowwecanreuseourtargetandcomparatorcohortsforour twooutcomesofinterest(aswellasournegativecontroloutcomes). Thestudy start and end dates canbeusedtolimittheanalysestoaspecificperiod. The studyenddatealsotruncatesriskwindows,meaningnooutcomesbeyondthestudyend datewillbeconsidered. Onereasonforselectingastudystartdatemightbethatoneofthe drugsbeingstudiedisnewanddidnotexistinanearliertime. Automaticallyadjusting for this can be done by answering “yes” to the question “ Restrict the analysis to the period when both exposures are present in the data? ”. Anotherreasontoadjuststudy\n",
      "page text: 12.7. Implementing the Study Using ATLAS 215 startandenddatesmightbethatmedicalpracticechangedovertime(e.g.,duetoadrug warning)andweareonlyinterestedinthetimewheremedicinewaspracticedaspecific way. Theoption“ Should only the first exposure per subject be included? ” canbeusedto restricttothefirstexposureperpatient. Oftenthisisalreadydoneinthecohortdefinition, asisthecaseinthisexample. Similarly,theoption“ The minimum required continuous observation time prior to index date for a person to be included in the cohort ”isoften alreadysetinthecohortdefinition,andcanthereforebeleftat0here. Havingobserved time (as defined in the OBSERVATION_PERIOD table) before the index date ensures that there is sufficient information about the patient to calculate a propensity score, and isalsooftenusedtoensurethepatientistrulyanewuser,andthereforewasnotexposed before. “Remove subjects that are in both the target and comparator cohort? ” defines, to­ getherwiththeoption“ If a subject is in multiple cohorts, should time­at­risk be cen­ sored when the new time­at­risk starts to prevent overlap? ” what happens when a subjectisinbothtargetandcomparatorcohorts. Thefirstsettinghasthreechoices: •“Keep All”indicatingtokeepthesubjectsinbothcohorts. Withthisoptionitmight bepossibletodouble­countsubjectsandoutcomes. •“Keep First ”indicatingtokeepthesubjectinthefirstcohortthatoccurred. •“Remove All ”indicatingtoremovethesubjectfrombothcohorts. Iftheoptions“keepall”or“keepfirst”areselected,wemaywishtocensorthetimewhen apersonisinbothcohorts. ThisisillustratedinFigure 12.10. Bydefault,thetime­at­risk isdefinedrelativetothecohortstartandenddate. Inthisexample,thetime­at­riskstarts onedayaftercohortentry,andstopsatcohortend. Withoutcensoringthetime­at­riskfor the two cohorts might overlap. This is especially problematic if we choose to keep all, becauseanyoutcomethatoccursduringthisoverlap(asshown)willbecountedtwice. If wechoosetocensor,thefirstcohort’stime­at­riskendswhenthesecondcohort’stime­at­ riskstarts. We can choose to remove subjects that have the outcome prior to the risk window start, because often a second outcome occurrence is the continuation of the first one. Forinstance,whensomeonedevelopsheartfailure,asecondoccurrenceislikely,which means the heart failure probably never fully resolved in between. On the other hand, some outcomes are episodic, and it would be expected for patients to have more than oneindependentoccurrence,likeanupperrespiratoryinfection. Ifwechoosetoremove peoplethathadtheoutcomebefore,wecanselect how many days we should look back when identifying prior outcomes . Our choices for our example study are shown in Figure 12.11. Because our target and comparatorcohortdefinitionsalreadyrestricttothefirstexposureandrequireobservation timepriortotreatmentinitiation,wedonotapplythesecriteriahere.\n",
      "page text: 216 Chapter 12. Population­Level Estimation Figure12.10: Time­at­risk(TAR)forsubjectswhoareinbothcohorts,assumingtime­at­ riskstartsthedayaftertreatmentinitiation,andstopsatexposureend. Figure12.11: Studypopulationsettings.\n",
      "page text: 12.7. Implementing the Study Using ATLAS 217 Covariate Settings Here we specify the covariates to construct. These covariates are typically used in the propensitymodel,butcanalsobeincludedintheoutcomemodel(theCoxproportional hazards model in this case). If we click to view details of our covariate settings, we can select which sets of covariates to construct. However, the recommendation is to use the default set, which constructs covariates for demographics, all conditions, drugs, procedures,measurements,etc. We can modify the set of covariates by specifying concepts to includeand/or exclude. These settings are the same as the ones found in Section 12.7.1on comparison settings. The reason why they can be found in two places is because sometimes these settings are related to a specific comparison, as is the case here because we wish to exclude the drugs we are comparing, and sometimes the settings are related to a specific analysis. When executing an analysis for a specific comparison using specific analysis settings, theOHDSItoolswilltaketheunionofthesesets. Figure12.12showsourchoicesforthisstudy. Notethatwehaveselectedtoadddescen­ dants to the concept to exclude, which we defined in the comparison settings in Figure 12.9. Figure12.12: Covariatesettings. Time At Risk Time­at­risk is defined relative to the start and end dates of our target and comparator cohorts. Inourexample,wehadsetthecohortstartdatetostartontreatmentinitiation,and cohortenddatewhenexposurestops(foratleast30days). Wesetthestartoftime­at­risk toonedayaftercohortstart,soonedayaftertreatmentinitiation. Areasontosetthetime­ at­riskstarttobelaterthanthecohortstartisbecausewemaywanttoexcludeoutcome events that occur on the day of treatment initiation if we do not believe it biologically plausibletheycanbecausedbythedrug. We set the end of the time­at­risk to the cohort end, so when exposure stops. We could choosetosettheenddatelaterifforexamplewebelieveeventscloselyfollowingtreat­\n",
      "page text: 218 Chapter 12. Population­Level Estimation mentendmaystillbeattributabletotheexposure. Intheextremewecouldsetthetime­at­ riskendtoalargenumberofdays(e.g.99999)afterthecohortenddate,meaningwewill effectivelyfollowupsubjectsuntilobservationend. Suchadesignissometimesreferred toasan intent­to­treat design. A patient with zero days at risk adds no information, so the minimum days at risk is normallysetatoneday. Ifthereisaknownlatencyforthesideeffect,thenthismaybe increasedtogetamoreinformativeproportion. Itcanalsobeusedtocreateacohortmore similar to that of a randomized trial it is being compared to (e.g., all the patients in the randomizedtrialwereobservedforatleastNdays). Agoldenruleindesigningacohortstudyistoneveruseinformationthatfallsafter thecohortstartdatetodefinethestudypopulation,asthismayintroducebias. For example, if we require everyone to have at least a year of time­at­risk, we will likely have limited our analyses to those who tolerate the treatment well. This settingshouldthereforebeusedwithextremecare. Figure12.13: Time­at­risksettings. Propensity Score Adjustment Wecanoptto trimthestudypopulation, removingpeoplewithextremePSvalues. We canchoosetoremovethetopandbottompercentage,orwecanremovesubjectswhose preference score falls outside the range we specify. Trimming the cohorts is generally not recommended because it requires discarding observations, which reduces statistical power. Itmaybedesirabletotriminsomecases,forexamplewhenusingIPTW. Inadditionto,orinsteadoftrimming,wecanchooseto stratifyormatchonthepropen­ sity score. When stratifying we need to specify the number of strata and whether to selectthestratabasedonthetarget,comparator,orentirestudypopulation. Whenmatch­ ingweneedtospecifythe maximum number of people from the comparator group to match to each person in the target group . Typicalvaluesare1forone­on­onematch­ ing,oralargenumber(e.g.100)forvariable­ratiomatching. Wealsoneedtospecifythe caliper: the maximum allowed difference between propensity scores to allow a match. Thecalipercanbedefinedondifference caliper scales : •The propensity score scale : thePSitself\n",
      "page text: 12.7. Implementing the Study Using ATLAS 219 •The standardized scale : instandarddeviationsofthePSdistributions •The standardized logit scale : instandarddeviationsofthePSdistributionsafter thelogittransformationtomakethePSmorenormallydistributed. Incaseofdoubt,wesuggestusingthedefaultvalues,orconsulttheworkonthistopicby Austin(2011). Fittinglarge­scalepropensitymodelscanbecomputationallyexpensive,sowemaywant to restrict the data used to fit the model to just a sample of the data. By default the maximumsizeofthetargetandcomparatorcohortissetto250,000. Inmoststudiesthis limit will not be reached. It is also unlikely that more data will lead to a better model. Notethatalthoughasampleofthedatamaybeusedtofitthemodel, themodelwillbe usedtocomputePSfortheentirepopulation. Test each covariate for correlation with the target assignment? If any covariate has anunusuallyhighcorrelation(eitherpositiveornegative),thiswillthrowanerror. This avoids lengthy calculation of a propensity model only to discover complete separation. Findingveryhighunivariatecorrelationallowsyoutoreviewthecovariatetodetermine whyithashighcorrelationandwhetheritshouldbedropped. Use regularization when fitting the model? Thestandardprocedureistoincludemany covariates (typically more than 10,000) in the propensity model. In order to fit such modelssomeregularizationisrequired. Ifonlyafewhand­pickedcovariatesareincluded, itisalsopossibletofitthemodelwithoutregularization. Figure12.14showsourchoicesforthisstudy. Notethatweselectvariable­ratiomatching bysettingthemaximumnumberofpeopletomatchto100. Outcome Model Settings First,weneedto specify the statistical model we will use to estimate the relative risk of the outcome between target and comparator cohorts . WecanchoosebetweenCox, Poisson,andlogisticregression,asdiscussedbrieflyinSection 12.1. Forourexamplewe chooseaCoxproportionalhazardsmodel,whichconsiderstimetofirsteventwithpossi­ blecensoring. Next,weneedtospecify whether the regression should be conditioned on the strata . One way to understand conditioning is to imagine a separate estimate is produced in each stratum, and then combined across strata. For one­to­one matching this is likely unnecessary and would just lose power. For stratification or variable­ratio matchingitisrequired. Wecanalsochooseto add the covariates to the outcome model toadjusttheanalysis. Thiscanbedoneinadditionorinsteadofusingapropensitymodel. However,whereas thereusuallyisampledatatofitapropensitymodel,withmanypeopleinbothtreatment groups,thereistypicallyverylittledatatofittheoutcomemodel,withonlyfewpeople havingtheoutcome. Wethereforerecommendkeepingtheoutcomemodelassimpleas possibleandnotincludeadditionalcovariates. Insteadofstratifyingormatchingonthepropensityscorewecanalsochooseto use in­\n",
      "page text: 220 Chapter 12. Population­Level Estimation Figure12.14: Propensityscoreadjustmentsettings.\n",
      "page text: 12.7. Implementing the Study Using ATLAS 221 verse probability of treatment weighting (IPTW). Ifwechoosetoincludeallcovariatesintheoutcomemodel,itmaymakesensetouseregu­ larizationwhenfittingthemodeliftherearemanycovariates. Notethatnoregularization willbeappliedtothetreatmentvariabletoallowforunbiasedestimation. Figure12.15shows our choices for this study. Because we use variable­ratio matching, wemustconditiontheregressiononthestrata(i.e.thematchedsets). Figure12.15: Outcomemodelsettings. 12.7.3 Evaluation Settings AsdescribedinChapter 18,negativeandpositivecontrolsshouldbeincludedinourstudy toevaluatetheoperatingcharacteristics,andperformempiricalcalibration. Negative Control Outcome Cohort Definition In Section 12.7.1we selected a concept set representing the negative control outcomes. However, we need logic to convert concepts to cohorts to be used as outcomes in our analysis. ATLASprovidesstandardlogicwiththreechoices. Thefirstchoiceiswhether touse all occurrences or just the first occurrence of the concept. The second choice determines whether occurrences of descendant concepts should be considered . For example, occurrences of the descendant “ingrown nail of foot” can also be counted as anoccurrenceoftheancestor“ingrownnail.” Thethirdchoicespecifieswhichdomains shouldbeconsideredwhenlookingfortheconcepts.\n",
      "page text: 222 Chapter 12. Population­Level Estimation Figure12.16: Negativecontroloutcomecohortdefinitionsettings. Positive Control Synthesis Inadditiontonegativecontrolswecanalsoincludepositivecontrols,whichareexposure­ outcomepairswhereacausaleffectisbelievedtoexistwithknowneffectsize. Forvarious reasons real positive controls are problematic, so instead we rely on synthetic positive controls, derived from negative controls as described in Chapter 18. We can choose to perform positive control synthesis . If“yes”,wemustchoosethe model type ,currently being“Poisson”and“survival”. Sinceweuseasurvival(Cox)modelinourestimation study, we should choose “survival”. We define the time­at­risk model for the positive control synthesis to be the same as in our estimation settings, and similarly mimic the choicesforthe minimum required continuous observation prior to exposure ,should only the first exposure be included ,should only the first outcome be included ,aswell asremove people with prior outcomes . Figure12.15showsthesettingsforthepositive controlsynthesis. 12.7.4 Running the Study Package Nowthatwehavefullydefinedourstudy, wecanexport itasanexecutableR package. Thispackagecontainseverythingthatisneededtoexecutethestudyatasitethathasdata in CDM. This includes the cohort definitions that can be used to instantiate the target, comparatorandoutcomecohorts,thenegativecontrolconceptsetandlogictocreatethe negativecontroloutcomecohorts, aswellastheRcodetoexecutetheanalysis. Before generatingthepackagemakesuretosaveyourstudy,thenclickonthe Utilitiestab. Here we can review the set of analyses that will be performed. As mentioned before, every combination of a comparison and an analysis setting will result in a separate analysis. In our example we have specified two analyses: ACEi versus THZ for AMI, and ACEi versusTHZforangioedema,bothusingpropensityscorematching. We must provide a name for our package, after which we can click on “Download” to\n",
      "page text: 12.7. Implementing the Study Using ATLAS 223 Figure12.17: Negativecontroloutcomecohortdefinitionsettings.\n",
      "page text: 224 Chapter 12. Population­Level Estimation downloadthezipfile. ThezipfilecontainsanRpackage,withtheusualrequiredfolder structureforRpackages. ( Wickham,2015)TousethispackagewerecommendusingR Studio. IfyouarerunningRStudiolocally,unzipthefile,anddoubleclickthe.Rprojfile toopenitinRStudio. IfyouarerunningRStudioonanRstudioserver,click touploadandunzipthefile,thenclickonthe.Rprojfiletoopentheproject. OnceyouhaveopenedtheprojectinRStudio,youcanopentheREADMEfile,andfollow theinstructions. Makesuretochangeallfilepathstoexistingpathsonyoursystem. Acommonerrormessagethatmayappearwhenrunningthestudyis“Highcorrelationbe­ tweencovariate(s)andtreatmentdetected.” Thisindicatesthatwhenfittingthepropensity model,somecovariateswereobservedtobehighlycorrelatedwiththeexposure. Please reviewthecovariatesmentionedintheerrormessage,andexcludethemfromthesetof covariatesifappropriate(seeSection 12.1.2). 12.8 Implementing the Study Using R InsteadofusingATLAStowritetheRcodethatexecutesthestudy,wecanalsowritethe R code ourselves. One reason we might want to do this is because R offers far greater flexibilitythanisexposedinATLAS.Ifweforexamplewishtousecustomcovariates,or alinearoutcomemodel,wewillneedtowritesomecustomRcode,andcombineitwith thefunctionalityprovidedbytheOHDSIRpackages. For our example study we will rely on the CohortMethod package to execute our study. CohortMethod extracts the necessary data from a database in the CDM and can use a large set of covariates for the propensity model. In the following example we first only consider angioedema as outcome. In Section 12.8.6we then describe how this can be extendedtoincludeAMIandthenegativecontroloutcomes. 12.8.1 Cohort Instantiation We first need to instantiate the target and outcome cohorts. Instantiating cohorts is de­ scribedinChapter 10. TheAppendixprovidesthefulldefinitionsofthetarget(Appendix B.2), comparator (Appendix B.5), and outcome (Appendix B.4) cohorts. We will as­ sume the ACEi, THZ, and angioedema cohorts have been instantiated in a table called scratch.my_cohorts withcohortdefinitionIDs1,2,and3respectively. 12.8.2 Data Extraction WefirstneedtotellRhowtoconnecttotheserver. CohortMethod usestheDatabaseC­ onnectorpackage,whichprovidesafunctioncalled createConnectionDetails . Type ?createConnectionDetails forthespecificsettingsrequiredforthevariousdatabase management systems (DBMS). For example, one might connect to a PostgreSQL databaseusingthiscode:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████████████████████████████▏                                                               | 248/464 [00:02<00:02, 89.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 12.8. Implementing the Study Using R 225 library(CohortMethod) connDetails <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) cdmDbSchema <- \"my_cdm_data\" cohortDbSchema <- \"scratch\" cohortTable <- \"my_cohorts\" cdmVersion <- \"5\" Thelastfourlinesdefinethe cdmDbSchema ,cohortDbSchema ,andcohortTable vari­ ables,aswellastheCDMversion. WewillusetheselatertotellRwherethedatainCDM format live, where the cohorts of interest have been created, and what version CDM is used. Note that for Microsoft SQL Server, database schemas need to specify both the databaseandtheschema,soforexample cdmDbSchema <- \"my_cdm_data.dbo\" . Now we can tell CohortMethod to extract the cohorts, construct covariates, and extract allnecessarydataforouranalysis: # target and comparator ingredient concepts: aceI <- c(1335471,1340128,1341927,1363749,1308216,1310756,1373225, 1331235,1334456,1342439) thz <-c(1395058,974166,978555,907013) # Define which types of covariates must be constructed: cs <-createDefaultCovariateSettings (excludedCovariateConceptIds = c(aceI, thz), addDescendantsToExclude = TRUE) #Load data: cmData <- getDbCohortMethodData (connectionDetails = connectionDetails, cdmDatabaseSchema = cdmDatabaseSchema, oracleTempSchema = NULL, targetId = 1, comparatorId = 2, outcomeIds = 3, studyStartDate = \"\", studyEndDate = \"\", exposureDatabaseSchema = cohortDbSchema, exposureTable = cohortTable, outcomeDatabaseSchema = cohortDbSchema, outcomeTable = cohortTable, cdmVersion = cdmVersion, firstExposureOnly = FALSE, removeDuplicateSubjects = FALSE, restrictToCommonPeriod = FALSE, washoutPeriod = 0,\n",
      "page text: 226 Chapter 12. Population­Level Estimation covariateSettings = cs) cmData ## CohortMethodData object ## ## Treatment concept ID: 1 ## Comparator concept ID: 2 ## Outcome concept ID(s): 3 There are many parameters, but they are all documented in the CohortMethod manual . ThecreateDefaultCovariateSettings function is described in the FeatureExtrac­ tionpackage. In short, we are pointing the function to the table containing our cohorts andspecifywhichcohortdefinitionIDsinthattableidentifythetarget,comparatorand outcome. We instruct that the default set of covariates should be constructed, including covariatesforallconditions,drugexposures,andproceduresthatwerefoundonorbefore theindexdate. AsmentionedinSection 12.1wemustexcludethetargetandcomparator treatmentsfromthesetofcovariates,andhereweachievethisbylistingallingredientsin thetwoclasses,andtellFeatureExtractiontoalsoexcludealldescendants,thusexcluding alldrugsthatcontaintheseingredients. All data about the cohorts, outcomes, and covariates are extracted from the server and storedinthe cohortMethodData object. Thisobjectusesthepackage fftostoreinfor­ mationinawaythatensuresRdoesnotrunoutofmemory,evenwhenthedataarelarge, asmentionedinSection 8.4.2. Wecanusethegeneric summary() functiontoviewsomemoreinformationofthedata weextracted: summary(cmData) ## CohortMethodData object summary ## ## Treatment concept ID: 1 ## Comparator concept ID: 2 ## Outcome concept ID(s): 3 ## ## Treated persons: 67166 ## Comparator persons: 35333 ## ## Outcome counts: ## Event count Person count ## 3 980 891 ## ## Covariates: ## Number of covariates: 58349\n",
      "page text: 12.8. Implementing the Study Using R 227 ## Number of non-zero covariate values: 24484665 Creating the cohortMethodData file can take considerable computing time, and it is probably a good idea to save it for future sessions. Because cohortMethodData usesff, we cannot use R’s regular save function. Instead, we’ll have to use the saveCohortMethodData() function: saveCohortMethodData (cmData, \"AceiVsThzForAngioedema\" ) Wecanusethe loadCohortMethodData() functiontoloadthedatainafuturesession. Defining New Users Typically, a new user is defined as first time use of a drug (either target or comparator), andtypicallyawashoutperiod(aminimumnumberofdayspriortofirstuse)isusedto increasetheprobabilitythatitistrulyfirstuse. WhenusingtheCohortMethodpackage, youcanenforcethenecessaryrequirementsfornewuseinthreeways: 1.Whendefiningthecohorts. 2.Whenloadingthecohortsusingthe getDbCohortMethodData function,youcan usethefirstExposureOnly ,removeDuplicateSubjects ,restrictToCommonPeriod , andwashoutPeriod arguments. 3.Whendefiningthestudypopulationusingthe createStudyPopulation function (seebelow). The advantage of option 1 is that the input cohorts are already fully defined outside of theCohortMethodpackage,andexternalcohortcharacterizationtoolscanbeusedonthe samecohortsusedinthisanalysis. Theadvantageofoptions2and3isthattheysaveyou thetroubleoflimitingtofirstuseyourself,forexampleallowingyoutodirectlyusethe DRUG_ERAtableintheCDM.Option2ismoreefficientthan3,sinceonlydataforfirst usewillbefetched,whileoption3islessefficientbutallowsyoutocomparetheoriginal cohortstothestudypopulation. 12.8.3 Defining the Study Population Typically, the exposure cohorts and outcome cohorts will be defined independently of eachother. Whenwewanttoproduceaneffectsizeestimate,weneedtofurtherrestrict thesecohortsandputthemtogether,forexamplebyremovingexposedsubjectsthathad theoutcomepriortoexposure,andonlykeepingoutcomesthatfallwithinadefinedrisk window. Forthiswecanusethe createStudyPopulation function: studyPop <- createStudyPopulation (cohortMethodData = cmData, outcomeId = 3, firstExposureOnly = FALSE, restrictToCommonPeriod = FALSE, washoutPeriod = 0,\n",
      "page text: 228 Chapter 12. Population­Level Estimation removeDuplicateSubjects = \"remove all\" , removeSubjectsWithPriorOutcome = TRUE, minDaysAtRisk = 1, riskWindowStart = 1, startAnchor = \"cohort start\" , riskWindowEnd = 0, endAnchor = \"cohort end\" ) Notethatwe’veset firstExposureOnly andremoveDuplicateSubjects toFALSE, andwashoutPeriod to0becausewealreadyappliedthosecriteriainthecohortdefini­ tions. We specify the outcome ID we will use, and that people with outcomes prior to theriskwindowstartdatewillberemoved. Theriskwindowisdefinedasstartingonthe dayafterthecohortstartdate( riskWindowStart = 1 andstartAnchor = \"cohort start\"), and the risk windows ends when the cohort exposure ends ( riskWindowEnd = 0andendAnchor = \"cohort end\" ), which was defined as the end of exposure in the cohort definition. Note that the risk windows are automatically truncated at the end of observation or the study end date. We also remove subjects who have no time at risk. To see how many people are left in the study population we can always use the getAttritionTable function: getAttritionTable (studyPop) ## description targetPersons comparatorPersons ... ## 1 Original cohorts 67212 35379 ... ## 2 Removed subs in both cohorts 67166 35333 ... ## 3 No prior outcome 67061 35238 ... ## 4 Have at least 1 days at risk 66780 35086 ... 12.8.4 Propensity Scores Wecanfitapropensitymodelusingthecovariatesconstructedby getDbcohortMethodData() , andcomputeaPSforeachperson: ps <-createPs (cohortMethodData = cmData, population = studyPop) ThecreatePs functionusesthe Cyclopspackagetofitalarge­scaleregularizedlogistic regression. Tofitthepropensitymodel,Cyclopsneedstoknowthehyperparametervalue whichspecifiesthevarianceoftheprior. BydefaultCyclopswillusecross­validationto estimatetheoptimalhyperparameter. However,beawarethatthiscantakeareallylong time. Youcanusethe priorandcontrolparametersofthe createPs functiontospec­ ifyCyclops’behavior,includingusingmultipleCPUstospeed­upthecross­validation. HereweusethePStoperformvariable­ratiomatching:\n",
      "page text: 12.8. Implementing the Study Using R 229 matchedPop <- matchOnPs (population = ps,caliper = 0.2, caliperScale = \"standardized logit\" ,maxRatio = 100) Alternatively,wecouldhaveusedthePSinthe trimByPs,trimByPsToEquipoise ,or stratifyByPs functions. 12.8.5 Outcome Models The outcome model is a model describing which variables are associated with the out­ come. Under strict assumptions, the coefficient for the treatment variable can be inter­ preted as the causal effect. In this case we fit a Cox proportional hazards model, condi­ tioned(stratified)onthematchedsets: outcomeModel <- fitOutcomeModel (population = matchedPop, modelType = \"cox\", stratified = TRUE) outcomeModel ## Model type: cox ## Stratified: TRUE ## Use covariates: FALSE ## Use inverse probability of treatment weighting: FALSE ## Status: OK ## ## Estimate lower .95 upper .95 logRr seLogRr ## treatment 4.3203 2.4531 8.0771 1.4633 0.304 12.8.6 Running Multiple Analyses Often we want to perform more than one analysis, for example for multiple outcomes including negative controls. The CohortMethod offers functions for performing such studiesefficiently. Thisisdescribedindetailinthe packagevignetteonrunningmultiple analyses. Briefly,assumingtheoutcomeofinterestandnegativecontrolcohortshaveal­ readybeencreated,wecanspecifyalltarget­comparator­outcomecombinationswewish toanalyze: # Outcomes of interest: ois <-c(3,4) # Angioedema, AMI # Negative controls: ncs <-c(434165,436409,199192,4088290,4092879,44783954 ,75911,137951,77965, 376707,4103640,73241,133655,73560,434327,4213540,140842,81378, 432303,4201390,46269889 ,134438,78619,201606,76786,4115402, 45757370 ,433111,433527,4170770,4092896,259995,40481632 ,4166231,\n",
      "page text: 230 Chapter 12. Population­Level Estimation 433577,4231770,440329,4012570,4012934,441788,4201717,374375, 4344500,139099,444132,196168,432593,434203,438329,195873,4083487, 4103703,4209423,377572,40480893 ,136368,140648,438130,4091513, 4202045,373478,46286594 ,439790,81634,380706,141932,36713918 , 443172,81151,72748,378427,437264,194083,140641,440193,4115367) tcos <- createTargetComparatorOutcomes (targetId = 1, comparatorId = 2, outcomeIds = c(ois, ncs)) tcosList <- list(tcos) Next, wespecifywhatargumentsshouldbeusedwhencallingthevariousfunctionsde­ scribedpreviouslyinourexamplewithoneoutcome: aceI <- c(1335471,1340128,1341927,1363749,1308216,1310756,1373225, 1331235,1334456,1342439) thz <-c(1395058,974166,978555,907013) cs <-createDefaultCovariateSettings (excludedCovariateConceptIds = c(aceI, thz), addDescendantsToExclude = TRUE) cmdArgs <- createGetDbCohortMethodDataArgs ( studyStartDate = \"\", studyEndDate = \"\", firstExposureOnly = FALSE, removeDuplicateSubjects = FALSE, restrictToCommonPeriod = FALSE, washoutPeriod = 0, covariateSettings = cs) spArgs <- createCreateStudyPopulationArgs ( firstExposureOnly = FALSE, restrictToCommonPeriod = FALSE, washoutPeriod = 0, removeDuplicateSubjects = \"remove all\" , removeSubjectsWithPriorOutcome = TRUE, minDaysAtRisk = 1, startAnchor = \"cohort start\" , addExposureDaysToStart = FALSE, endAnchor = \"cohort end\" , addExposureDaysToEnd = TRUE) psArgs <- createCreatePsArgs () matchArgs <- createMatchOnPsArgs ( caliper = 0.2,\n",
      "page text: 12.8. Implementing the Study Using R 231 caliperScale = \"standardized logit\" , maxRatio = 100) fomArgs <- createFitOutcomeModelArgs ( modelType = \"cox\", stratified = TRUE) Wethencombinetheseintoasingleanalysissettingsobject,whichweprovideaunique analysisIDandsomedescription. Wecancombineoneormoreanalysissettingsobjects intoalist: cmAnalysis <- createCmAnalysis ( analysisId = 1, description = \"Propensity score matching\" , getDbCohortMethodDataArgs = cmdArgs, createStudyPopArgs = spArgs, createPs = TRUE, createPsArgs = psArgs, matchOnPs = TRUE, matchOnPsArgs = matchArgs fitOutcomeModel = TRUE, fitOutcomeModelArgs = fomArgs) cmAnalysisList <- list(cmAnalysis) Wecannowrunthestudyincludingallcomparisonsandanalysissettings: result <- runCmAnalyses (connectionDetails = connectionDetails, cdmDatabaseSchema = cdmDatabaseSchema, exposureDatabaseSchema = cohortDbSchema, exposureTable = cohortTable, outcomeDatabaseSchema = cohortDbSchema, outcomeTable = cohortTable, cdmVersion = cdmVersion, outputFolder = outputFolder, cmAnalysisList = cmAnalysisList, targetComparatorOutcomesList = tcosList) Theresultobjectcontainsreferencestoalltheartifactsthatwerecreated. Forexample, wecanretrievetheoutcomemodelforAMI: omFile <- result$outcomeModelFile[result $targetId ==1& result$comparatorId ==2& result$outcomeId ==4& result$analysisId ==1]\n",
      "page text: 232 Chapter 12. Population­Level Estimation outcomeModel <- readRDS(file.path (outputFolder, omFile)) outcomeModel ## Model type: cox ## Stratified: TRUE ## Use covariates: FALSE ## Use inverse probability of treatment weighting: FALSE ## Status: OK ## ## Estimate lower .95 upper .95 logRr seLogRr ## treatment 1.1338 0.5921 2.1765 0.1256 0.332 Wecanalsoretrievetheeffectsizeestimatesforalloutcomeswithonecommand: summ <- summarizeAnalyses (result, outputFolder = outputFolder) head(summ) ## analysisId targetId comparatorId outcomeId rr ... ## 1 1 1 2 72748 0.9734698 ... ## 2 1 1 2 73241 0.7067981 ... ## 3 1 1 2 73560 1.0623951 ... ## 4 1 1 2 75911 0.9952184 ... ## 5 1 1 2 76786 1.0861746 ... ## 6 1 1 2 77965 1.1439772 ... 12.9 Study Outputs Ourestimatesareonlyvalidifseveralassumptionshavebeenmet. Weuseawidesetof diagnosticstoevaluatewhetherthisisthecase. Theseareavailableintheresultsproduced by the R package generated by ATLAS, or can be generated on the fly using specific R functions. 12.9.1 Propensity Scores and Model We first need to evaluate whether the target and comparator cohort are to some extent comparable. ForthiswecancomputetheAreaUndertheReceiverOperatorCurve(AUC) statisticforthepropensitymodel. AnAUCof1indicatesthetreatmentassignmentwas completelypredictablebasedonbaselinecovariates,andthatthetwogroupsaretherefore incomparable. Wecanusethe computePsAuc functiontocomputetheAUC,whichinour exampleis0.79. Usingthe plotPsfunction, wecan alsogeneratethe preferencescore distribution as shown in Figure 12.18. Here we see that for many people the treatment theyreceivedwaspredictable,butthereisalsoalargeamountofoverlap,indicatingthat adjustmentcanbeusedtoselectcomparablegroups.\n",
      "page text: 12.9. Study Outputs 233 Figure12.18: Preferencescoredistribution. In general it is a good idea to also inspect the propensity model itself, and especially so if the model is very predictive. That way we may discover which variables are most predictive. Table 12.7shows the top predictors in our propensity model. Note that if a variable is too predictive, the CohortMethod package will throw an informative error ratherthanattempttofitamodelthatisalreadyknowntobeperfectlypredictive. Table12.7: Top10predictorsinthepropensitymodelforACEiand THZ. Positive values mean subjects with the covariate are more likely to receive the target treatment. “(Intercept)” indicates the interceptofthislogisticregressionmodel. Beta Covariate ­1.42 condition_eragroupduringday­30through0daysrelativetoindex: Edema ­1.11 drug_eragroupduringday0through0daysrelativetoindex: Potassium Chloride 0.68 agegroup: 05­09 0.64 measurementduringday­365through0daysrelativetoindex: Renin 0.63 condition_eragroupduringday­30through0daysrelativetoindex: Urticaria 0.57 condition_eragroupduringday­30through0daysrelativetoindex: Proteinuria 0.55 drug_eragroupduringday­365through0daysrelativetoindex: INSULINS ANDANALOGUES ­0.54 race=BlackorAfricanAmerican 0.52 (Intercept)\n",
      "page text: 234 Chapter 12. Population­Level Estimation Beta Covariate 0.50 gender=MALE If a variable is found to be highly predictive, there are two possible conclusions: Eitherwefindthatthevariableisclearlypartoftheexposureitselfandshouldbe removedbeforefittingthemodel,orelsewemustconcludethatthetwopopulations aretrulyincomparable,andtheanalysismustbestopped. 12.9.2 Covariate Balance The goal of using PS is to make the two groups comparable (or at least to select com­ parable groups). We must verify whether this is achieved, for example by checking whether the baseline covariates are indeed balanced after adjustment. We can use the computeCovariateBalance andplotCovariateBalanceScatterPlot functionsto generateFigure 12.19. Onerule­of­thumbtouseisthatnocovariatemayhaveanabsolute standardizeddifferenceofmeansgreaterthan0.1afterpropensityscoreadjustment. Here weseethatalthoughtherewassubstantialimbalancebeforematching,aftermatchingwe meetthiscriterion. Figure 12.19: Covariate balance, showing the absolute standardized difference of mean beforeandafterpropensityscorematching. Eachdotrepresentsacovariate.\n",
      "page text: 12.9. Study Outputs 235 12.9.3 Follow Up and Power Before fitting an outcome model, we might be interested to know whether we have suf­ ficient power to detect a particular effect size. It makes sense to perform these power calculationsoncethestudypopulationhasbeenfullydefined,sotakingintoaccountloss tothevariousinclusionandexclusioncriteria(suchasnoprioroutcomes),andlossdue tomatchingand/ortrimming. Wecanviewtheattritionofsubjectsinourstudyusingthe drawAttritionDiagram functionasshowninFigure 12.20. Figure 12.20: Attrition diagram. The counts shown at the top are those that meet our target and comparator cohort definitions. The counts at the bottom are those that enter ouroutcomemodel,inthiscaseaCoxregression. Since the sample size is fixed in retrospective studies (the data has already been col­ lected), and the true effect size is unknown, it is therefore less meaningful to compute the power given an expected effect size. Instead, the CohortMethod package provides thecomputeMdrr functiontocomputetheminimumdetectablerelativerisk(MDRR).In ourexamplestudytheMDRRis1.69. Togainabetterunderstandingoftheamountoffollow­upavailablewecanalsoinspect thedistributionoffollow­uptime. Wedefinedfollow­uptimeastimeatrisk,sonotcen­ soredbytheoccurrenceoftheoutcome. The getFollowUpDistribution canprovide\n",
      "page text: 236 Chapter 12. Population­Level Estimation asimpleoverviewasshowninFigure 12.21,whichsuggeststhefollow­uptimeforboth cohortsiscomparable. Figure12.21: Distributionoffollow­uptimeforthetargetandcomparatorcohorts. 12.9.4 Kaplan-Meier One last check is to review the Kaplan­Meier plot, showing the survival over time in bothcohorts. Usingthe plotKaplanMeier functionwecancreate 12.22,whichwecan check for example if our assumption of proportionality of hazards holds. The Kaplan­ MeierplotautomaticallyadjustsforstratificationorweightingbyPS.Inthiscase,because variable­ratiomatchingisused,thesurvivalcurveforthecomparatorgroupsisadjusted to mimic what the curve had looked like for the target group had they been exposed to thecomparatorinstead. 12.9.5 Effect Size Estimate Weobserveahazardratioof4.32(95%confidenceinterval: 2.45­8.08)forangioedema, which tells us that ACEi appears to increase the risk of angioedema compared to THZ. Similarly, we observe a hazard ratio of 1.13 (95% confidence interval: 0.59 ­ 2.18) for AMI, suggesting little or no effect for AMI. Our diagnostics, as reviewed earlier, give no reason for doubt. However, ultimately the quality of this evidence, and whether we choosetotrustit,dependsonmanyfactorsthatarenotcoveredbythestudydiagnostics asdescribedinChapter 14.\n",
      "page text: 12.10. Summary 237 Figure12.22: Kaplan­Meierplot. 12.10 Summary –Population­level estimation aims to infer causal effects from observational data. –Thecounterfactual , what would have happened if the subject had received analternativeexposureornoexposure,cannotbeobserved. –Differentdesignsaimtoconstructthecounterfactualindifferentways. –ThevariousdesignsasimplementedintheOHDSIMethodsLibraryprovide diagnostics to evaluate whether the assumptions for creating an appropriate counterfactualhavebeenmet. 12.11 Exercises Prerequisites For these exercises we assume R, R­Studio and Java have been installed as described in Section 8.4.5. Also required are the SqlRender,DatabaseConnector ,Eunomiaand CohortMethod packages,whichcanbeinstalledusing:\n",
      "page text: 238 Chapter 12. Population­Level Estimation install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) remotes::install_github (\"ohdsi/CohortMethod\" ) TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. Theseexercisesalsomakeuseofseveralcohorts. ThecreateCohorts functionintheEunomiapackagewillcreatetheseintheCOHORT table: Eunomia::createCohorts (connectionDetails) Problem Definition Whatistheriskofgastrointestinal(GI)bleedinnewusersofcelecoxibcom­ paredtonewusersofdiclofenac? The celecoxib new­user cohort has COHORT_DEFINITION_ID = 1. The diclofenac new­user cohort has COHORT_DEFINITION_ID = 2. The GI bleed cohort has CO­ HORT_DEFINITION_ID=3. TheingredientconceptIDsforcelecoxibanddiclofenac are1118084and1124300,respectively. Time­at­riskstartsondayoftreatmentinitiation, andstopsattheendofobservation(aso­calledintent­to­treatanalysis). Exercise 12.1. UsingtheCohortMethodRpackage,usethedefaultsetofcovariatesand extracttheCohortMethodDatafromtheCDM.CreatethesummaryoftheCohortMethod­ Data. Exercise 12.2. Createastudypopulationusingthe createStudyPopulation function, requiring a 180­day washout period, excluding people who had a prior outcome, and removingpeoplethatappearinbothcohorts. Didwelosepeople? Exercise 12.3. Fit a Cox proportional hazards model without using any adjustments. Whatcouldgowrongifyoudothis? Exercise 12.4. Fitapropensitymodel. Arethetwogroupscomparable? Exercise 12.5. PerformPSstratificationusing5strata. Iscovariatebalanceachieved? Exercise 12.6. Fit a Cox proportional hazards model using the PS strata. Why is the resultdifferentfromtheunadjustedmodel? SuggestedanswerscanbefoundinAppendix E.8.\n",
      "page text: Chapter 13 Patient-Level Prediction Chapter leads: Peter Rijnbeek & Jenna Reps Clinicaldecisionmakingisacomplicatedtaskinwhichtheclinicianhastoinferadiag­ nosisortreatmentpathwaybasedontheavailablemedicalhistoryofthepatientandthe current clinical guidelines. Clinical prediction models have been developed to support thisdecision­makingprocessandareusedinclinicalpracticeinawidespectrumofspe­ cialties. Thesemodelspredictadiagnosticorprognosticoutcomebasedonacombination of patient characteristics, e.g. demographic information, disease history, and treatment history. Thenumberofpublicationsdescribingclinicalpredictionmodelshasincreasedstrongly over the last 10 years. Most currently­used models are estimated using small datasets and consider only a small set of patient characteristics. This low sample size, and thus lowstatisticalpower,forcesthedataanalysttomakestrongmodellingassumptions. The selectionofthelimitedsetofpatientcharacteristicsisstronglyguidedbytheexpertknowl­ edgeathand. Thiscontrastssharplywiththerealityofmodernmedicinewhereinpatients generate a rich digital trail, which is well beyond the power of any medical practitioner tofullyassimilate. Presently,healthcareisgeneratingahugeamountofpatient­specific information stored in Electronic Health Records (EHRs). This includes structured data in the form of diagnosis, medication, laboratory test results, and unstructured data con­ tainedinclinicalnarratives. Itisunknownhowmuchpredictiveaccuracycanbegained byleveragingthelargeamountofdataoriginatingfromthecompleteEHRofapatient. Advancesinmachinelearningforlargedatasetanalysishaveledtoincreasedinterestin applying patient­level prediction on this type of data. However, many published efforts in patient­level prediction do not follow the model development guidelines, fail to per­ formextensiveexternalvalidation,orprovideinsufficientmodeldetailswhichlimitsthe ability of independent researchers to reproduce the models and perform external valida­ tion. Thismakesithardtofairlyevaluatethepredictiveperformanceofthemodelsand reducesthelikelihoodofthemodelbeingusedappropriatelyinclinicalpractice. Toim­ provestandards,severalpapershavebeenwrittendetailingguidelinesforbestpracticesin 239\n",
      "page text: 240 Chapter 13. Patient­Level Prediction developingandreportingpredictionmodels. Forexample,theTransparentReportingof amultivariablepredictionmodelforIndividualPrognosisOrDiagnosis(TRIPOD)state­ ment1providesclearrecommendationsforreportingpredictionmodeldevelopmentand validationandaddressessomeoftheconcernsrelatedtotransparency. Massive­scale, patient­specific predictive modeling has become reality due to OHDSI, where the Common Data Model (CDM) allows for uniform and transparent analysis at an unprecedented scale. The growing network of databases standardized to the CDM enablesexternalvalidationofmodelsindifferenthealthcaresettingsonaglobalscale. We believethisprovidesimmediateopportunitytoservelargecommunitiesofpatientswho areinmostneedofimprovedqualityofcare. Suchmodelscaninformtrulypersonalized medicalcare,leadinghopefullytosharplyimprovedpatientoutcomes. InthischapterwedescribeOHDSI’sstandardizedframeworkforpatient­levelprediction, (Reps et al. ,2018) and discuss the PatientLevelPrediction R package that implements established best practices for development and validation. We start with providing the necessary theory behind the development and evaluation of patient­level prediction and provideahigh­leveloverviewoftheimplementedmachinelearningalgorithms. Wethen discussanexamplepredictionproblemandprovidestep­by­stepguidanceonitsdefinition andimplementationusingATLASorcustomRcode. Finally,wediscusstheuseofShiny applicationsforthedisseminationofstudyresults. 13.1 The Prediction Problem Figure13.1illustrates the prediction problem we address. Among a population at risk, we aim to predict which patients at a defined moment in time (t = 0) will experience someoutcomeduringatime­at­risk. Predictionisdoneusingonlyinformationaboutthe patientsinanobservationwindowpriortothatmomentintime. Figure13.1: Thepredictionproblem. AsshowninTable 13.1,todefineapredictionproblemwehavetodefinet=0byatarget cohort, the outcome we like to predict by an outcome cohort, and the time­at­risk. We 1https://www.equator­network.org/reporting­guidelines/tripod­statement/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████████████████████████████████████▏                                                            | 258/464 [00:02<00:02, 90.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 13.1. The Prediction Problem 241 definethestandardpredictionquestionas: Among [target cohort definition] , who will go on to have [outcome cohort definition] within [time­at­risk period] ? Furthermore, we have to make design choices for the model we like to develop, and determinetheobservationaldatasetstoperforminternalandexternalvalidation. Table13.1: Maindesignchoicesinapredictiondesign. Choice Description Targetcohort Howdowedefinethecohortofpersonsforwhomwewishto predict? Outcomecohort Howdowedefinetheoutcomewewanttopredict? Time­at­risk Inwhichtimewindowrelativetot=0dowewanttomakethe prediction? Model Whatalgorithmsdowewanttouse,andwhichpotential predictorvariablesdoweinclude? Thisconceptualframeworkworksforalltypesofpredictionproblems,forexample: •Diseaseonsetandprogression –Structure: Amongpatientswhoarenewlydiagnosedwith [a disease] ,who will go on to have [another disease or complication] within [time horizon from diagnosis] ? –Example: Among newly diagnosed atrial fibrillation patients, who will go ontohaveischemicstrokeinthenextthreeyears? •Treatmentchoice –Structure: Among patients with [indicated disease] who are treated with either [treatment 1] or[treatment 2] ,whichpatientsweretreatedwith [treat­ ment 1]? –Example: Amongpatientswithatrialfibrillationwhotookeitherwarfarinor rivaroxaban,whichpatientsgetwarfarin? (e.g.forapropensitymodel) •Treatmentresponse –Structure: Among new users of [a treatment] , who will experience [some effect]in[time window] ? –Example: Whichpatientswithdiabeteswhostartonmetforminstayonmet­ forminforthreeyears? •Treatmentsafety –Structure: Amongnewusersof [a treatment] ,whowillexperience [adverse event]in[time window] ? –Example: Among new users of warfarin, who will have a gastrointestinal bleedinoneyear? •Treatmentadherence\n",
      "page text: 242 Chapter 13. Patient­Level Prediction –Structure: Amongnewusersof [a treatment] ,whowillachieve [adherence metric]at[time window] ? –Example: Which patients with diabetes who start on metformin achieve >=80%proportionofdayscoveredatoneyear? 13.2 Data Extraction When creating a predictive model we use a process known as supervised learning — a form of machine learning — that infers the relationship between the covariates and the outcomestatusbasedonalabelledsetofexamples. Therefore,weneedmethodstoextract the covariates from the CDM for the persons in the target cohort and we need to obtain theiroutcomelabels. Thecovariates (alsoreferredtoas“predictors”,“features”or“independentvariables”)de­ scribethecharacteristicsofthepatients. Covariatescanincludeage,gender,presenceof specificconditionsandexposurecodesinapatient’srecord,etc. Covariatesaretypically constructedusingthe FeatureExtraction package,describedinmoredetailinChapter 11. Forpredictionwecanonlyusedatapriorto(andon)thedatethepersonentersthetarget cohort. Thisdatewewillcalltheindexdate. Wealsoneedtoobtainthe outcome status (alsoreferredtoasthe“labels”or“classes”) of all the patients during the time­at­risk. If the outcome occurs within the time­at­risk, theoutcomestatusisdefinedas“positive.” 13.2.1 Data Extraction Example Table13.2showsanexampleCOHORTtablewithtwocohorts. Thecohortwithcohort definition ID 1 is the target cohort (e.g. “people recently diagnosed with atrial fibrilla­ tion”). CohortdefinitionID2definestheoutcomecohort(e.g.“stroke”). Table 13.2: Example COHORT table. For simplicity the CO­ HORT_END_DATEhasbeenomitted. COHORT_DEFINITION_ID SUBJECT_ID COHORT_START_DATE 1 1 2000­06­01 1 2 2001­06­01 2 2 2001­07­01 Table13.3provides an example CONDITION_OCCURRENCE table. Concept ID 320128refersto“Essentialhypertension.”\n",
      "page text: 13.3. Fitting the Model 243 Table 13.3: Example CONDITION_OCCURRENCE table. For simplicityonlythreecolumnsareshown. PERSON_ID CONDITION_CONCEPT_ID CONDITION_START_DATE 1 320128 2000­10­01 2 320128 2001­05­01 Basedonthisexampledata,andassumingthetimeatriskistheyearfollowingtheindex date(thetargetcohortstartdate),wecanconstructthecovariatesandtheoutcomestatus. A covariate indicating “Essential hypertension in the year prior” will have the value 0 (notpresent)forpersonID1(theconditionoccurred aftertheindexdate),andthevalue 1(present)forpersonID2. Similarly,theoutcomestatuswillbe0forpersonID1(this personhadnoentryintheoutcomecohort),and1forpersonID2(theoutcomeoccurred withinayearfollowingtheindexdate). 13.2.2 Negative vs Missing Observational healthcare data rarely reflects whether a value is negative or missing. In thepriorexample,wesimplyobservedthepersonwithID1hadnoessentialhypertension occurrencepriortotheindexdate. Thiscouldbebecausetheconditionwasnotpresent (negative)atthattime,orbecauseitwasnotrecorded(missing). Itisimportanttorealize thatthemachinelearningalgorithmcannotdistinguishbetweenthenegativeandmissing andwillsimplyassessthepredictivevalueintheavailabledata. 13.3 Fitting the Model When fitting a prediction model we are trying to learn the relationship between the co­ variatesandtheobservedoutcomestatusfromlabelledexamples. Supposeweonlyhave twocovariates,systolicanddiastolicbloodpressure,thenwecanrepresenteachpatient asaplotintwodimensionalspaceasshowninFigure 13.2. Inthisfiguretheshapeofthe datapointcorrespondstothepatient’soutcomestatus(e.g.stroke). Asupervisedlearningmodelwilltrytofindadecisionboundarythatoptimallyseparates thetwooutcomeclasses. Differentsupervisedlearningtechniquesleadtodifferentdeci­ sion boundaries and there are often hyper­parameters that can impact the complexity of thedecisionboundary. InFigure13.2wecanseethreedifferentdecisionboundaries. Theboundariesareusedto infertheoutcomestatusofanynewdatapoint. Ifanewdatapointfallsintotheshaded area then the model will predict “has outcome”, otherwise it will predict “no outcome”. Ideally a decision boundary should perfectly partition the two classes. However, there is a risk that too complex models “overfit” to the data. This can negatively impact the generalizabilityofthemodeltounseendata. Forexample,ifthedatacontainsnoise,with mislabeled or incorrectly positioned data points, we would not want to fit our model to\n",
      "page text: 244 Chapter 13. Patient­Level Prediction Figure13.2: Decisionboundary. thatnoise. Wethereforemayprefertodefineadecisionboundarythatdoesnotperfectly discriminateinourtrainingdatabutcapturesthe“real”complexity. Techniquessuchas regularizationaimtomaximizemodelperformancewhileminimizingcomplexity. Each supervised learning algorithm has a different way to learn the decision boundary anditisnotstraightforwardwhichalgorithmwillworkbestonyourdata. AstheNoFree Lunch theorem states not one algorithm is always going to outperform the others on all prediction problems. Therefore, we recommend trying multiple supervised learning al­ gorithmswithvarioushyper­parametersettingswhendevelopingpatient­levelprediction models. Thefollowingalgorithmsareavailableinthe PatientLevelPrediction package: 13.3.1 Regularized Logistic Regression LASSO (least absolute shrinkage and selection operator) logistic regression belongs to the family of generalized linear models, where a linear combination of the variables is learnedandfinallyalogisticfunctionmapsthelinearcombinationtoavaluebetween0 and1. TheLASSOregularizationaddsacostbasedonmodelcomplexitytotheobjective functionwhentrainingthemodel. Thiscostisthesumoftheabsolutevaluesofthelinear combinationofthecoefficients. Themodelautomaticallyperformsfeatureselectionby minimizingthiscost. Weusethe Cyclops(Cycliccoordinatedescentforlogistic,Poisson andsurvivalanalysis)packagetoperformlarge­scaleregularizedlogisticregression.\n",
      "page text: 13.3. Fitting the Model 245 Table 13.4: Hyper­parameters for the regularized logistic regres­ sion. Parameter Description Typicalvalues Startingvariance Thestartingvarianceofthepriordistribution. 0.1 Notethatthevarianceisoptimizedbymaximizingtheout­of­samplelikelihoodinacross­ validation, so the starting variance has little impact on the performance of the resulting model. However, picking a starting variance that is too far from the optimal value may leadtolongfittingtime. 13.3.2 Gradient Boosting Machines Gradient boosting machines is a boosting ensemble technique and in our framework it combines multiple decision trees. Boosting works by iteratively adding decision trees but adds more weight to the data­points that are misclassified by prior decision trees in thecostfunctionwhentrainingthenexttree. WeuseExtremeGradientBoosting,which is an efficient implementation of the gradient boosting framework implemented in the xgboostRpackageavailablefromCRAN. Table13.5: Hyper­parametersforgradientboostingmachines. Parameter Description Typicalvalues earlyStopRound Stoppingafterroundswithoutimprovement 25 learningRate Theboostinglearnrate 0.005,0.01,0.1 maxDepth Maxlevelsinatree 4,6,17 minRows Mindatapointsinanode 2 ntrees Numberoftrees 100,1000 13.3.3 Random Forest Random forest is a bagging ensemble technique that combines multiple decision trees. The idea behind bagging is to reduce the likelihood of overfitting by using weak classi­ fiers and combining them into a strong classifier. Random forest accomplishes this by training multiple decision trees but only using a subset of the variables in each tree and thesubsetofvariablesdifferbetweentrees. Ourpackageusesthesklearnimplementation ofRandomForestinPython. Table13.6: Hyper­parametersforrandomforests. Parameter Description Typicalvalues maxDepth Maxlevelsinatree 4,10,17\n",
      "page text: 246 Chapter 13. Patient­Level Prediction Parameter Description Typicalvalues mtries Numberoffeaturesin eachtree­1=squarerootoftotal features,5,20 ntrees Numberoftrees 500 13.3.4 K-Nearest Neighbors K­nearest neighbors (KNN) is an algorithm that uses some distance metric to find the K closest labelled data­points to a new unlabeled data­point. The prediction of the new data­pointsisthenthemostprevalentclassoftheK­nearestlabelleddata­points. Thereis asharinglimitationofKNN,asthemodelrequireslabelleddatatoperformtheprediction onnewdata,anditisoftennotpossibletosharethisdataacrossdatasites. Weincluded theBigKnnpackagedevelopedinOHDSIwhichisalargescaleKNNclassifier. Table13.7: Hyper­parametersforK­nearestneighbors. Parameter Description Typicalvalues k Numberofneighbors 1000 13.3.5 Naive Bayes TheNaiveBayesalgorithmappliestheBayestheoremwiththenaiveassumptionofcon­ ditionalindependencebetweeneverypairoffeaturesgiventhevalueoftheclassvariable. Basedonthelikelihoodthedatabelongstoaclassandthepriordistributionoftheclass, aposteriordistributionisobtained. NaiveBayeshasnohyper­parameters. 13.3.6 AdaBoost AdaBoostisaboostingensembletechnique. Boostingworksbyiterativelyaddingclassi­ fiersbutaddsmoreweighttothedata­pointsthataremisclassifiedbypriorclassifiersin thecostfunctionwhentrainingthenextclassifier. WeusethesklearnAdaboostClassifier implementationinPython. Table13.8: Hyper­parametersforAdaBoost. Parameter Description Typicalvalues nEstimators Themaximumnumberof estimatorsatwhich boostingisterminated4\n",
      "page text: 13.3. Fitting the Model 247 Parameter Description Typicalvalues learningRate Learningrateshrinksthe contributionofeach classifierbylearning_rate. Thereisatrade­off betweenlearningRateand nEstimators1 13.3.7 Decision T ree A decision tree is a classifier that partitions the variable space using individual tests se­ lected using a greedy approach. It aims to find partitions that have the highest informa­ tiongaintoseparatetheclasses. Thedecisiontreecaneasilyoverfitbyenablingalarge number of partitions (tree depth) and often needs some regularization (e.g., pruning or specifyinghyper­parametersthatlimitthecomplexityofthemodel). Weusethesklearn DecisionTreeClassifierimplementationinPython. Table13.9: Hyper­parametersfordecisiontrees. Parameter Description Typicalvalues classWeight “Balance”or“None” None maxDepth Themaximumdepthof thetree10 minImpuritySplit Thresholdforearly stoppingintreegrowth. A nodewillsplitifits impurityisabovethe threshold,otherwiseitisa leaf10^­7 minSamplesLeaf Theminimumnumberof samplesperleaf10 minSamplesSplit Theminimumsamples persplit2 13.3.8 Multilayer Perceptron Multilayer perceptrons are neural networks that contain multiple layers of nodes that weighttheirinputsusinganon­linearfunction. Thefirstlayeristheinputlayer,thelast layeristheoutputlayer,andinbetweenarethehiddenlayers. Neuralnetworksaregen­ erallytrainedusingback­propagation,meaningthetraininginputispropagatedforward throughthenetworktoproduceanoutput,theerrorbetweentheoutputandtheoutcome statusiscomputed,andthiserrorispropagatedbackwardsthroughthenetworktoupdate thelinearfunctionweights.\n",
      "page text: 248 Chapter 13. Patient­Level Prediction Table13.10: Hyper­parametersforMultilayerPerceptrons. Parameter Description Typicalvalues alpha Thel2regularization 0.00001 size Thenumberofhiddennodes 4 13.3.9 Deep Learning Deep learning such as deep nets, convolutional neural networks or recurrent neural net­ works are similar to Multilayer Perceptrons but have multiple hidden layers that aim to learn latent representations useful for prediction. In a separate vignettein thePa­ tientLevelPrediction package we describe these models and hyper­parameters in more detail. 13.3.10 Other Algorithms Other algorithms can be added to the patient­level prediction framework. This is out­ of­scope for this chapter. Details can be found in the “Adding Custom Patient­Level PredictionAlgorithms”vignette inthePatientLevelPrediction package. 13.4 Evaluating Prediction Models 13.4.1 Evaluation T ypes We can evaluate a prediction model by measuring the agreement between the model’s prediction and observed outcome status, which means we need data where the outcome statusisknown. Forevaluationwemustuseadifferentdatasetthanwasusedtodevelopthemodel, orelseweruntheriskoffavoringmodelsthatareover­fitted(seeSection 13.3)and maynotperformwellfornewpatients. Wedistinguishbetween •Internal validation : Usingdifferentsetsofdataextractedfromthesamedatabase todevelopandevaluatethemodel. •External validation : Developing the model in one database, and evaluating in anotherdatabase. Therearetwowaystoperforminternalvalidation: •Aholdout set approach splits the labelled data into two independent sets: a train setandatestset(theholdoutset). Thetrainsetisusedtolearnthemodelandthe test set is used to evaluate it. We can simply divide our patients randomly into a trainandtestset,orwemaychooseto:\n",
      "page text: 13.4. Evaluating Prediction Models 249 –Split the data based on time (temporal validation), for example training on data before a specific date, and evaluating on data after that date. This may informusonwhetherourmodelgeneralizestodifferenttimeperiods. –Splitthedatabasedongeographiclocation(spatialvalidation). •Cross validation isusefulwhenthedataarelimited. Thedataissplitinto 𝑛equally­ sized sets, where 𝑛needs to be prespecified (e.g. 𝑛 = 10). For each of these sets a model is trained on all data except the data in that set and used to generate predictions for the hold­out set. In this way, all data is used once to evaluate the model­buildingalgorithm. Inthepatient­levelpredictionframeworkweusecross validationtopicktheoptimalhyper­parameters. External validation aims to assess model performance on data from another database, i.e.outsideofthesettingsitwasdevelopedin. Thismeasureofmodeltransportabilityis important because we want to apply our models not only on the database it was trained on. Differentdatabasesmayrepresentdifferentpatientpopulations,differenthealthcare systems and different data­capture processes. We believe that the external validation of prediction models on a large set of databases is a crucial step in model acceptance and implementationinclinicalpractice. 13.4.2 Performance Metrics Threshold Measures Apredictionmodelassignsavaluebetween0and1foreachpatientcorrespondingtothe risk of the patient having the outcome during the time at risk. A value of 0 means 0% risk,avalueof0.5means50%riskandavalueof1means100%risk. Commonmetrics such as accuracy, sensitivity, specificity, positive predictive value can be calculated by firstspecifyingathresholdthatisusedtoclassifypatientsashavingtheoutcomeornot during the time at risk. For example, given Table 13.11, if we set the threshold as 0.5, patients1,3,7and10haveapredictedriskgreaterthanorequaltothethresholdof0.5 so they would be predicted to have the outcome. All other patients had a predicted risk lessthan0.5,sotheywouldbepredictedtonothavetheoutcome. Table13.11: Exampleofusingathresholdonthepredictedproba­ bility. PatientID PredictedriskPredictedclass at0.5thresholdHasoutcome during time­at­risk Type 1 0.8 1 1 TP 2 0.1 0 0 TN 3 0.7 1 0 FP 4 0 0 0 TN 5 0.05 0 0 TN 6 0.1 0 0 TN 7 0.9 1 1 TP\n",
      "page text: 250 Chapter 13. Patient­Level Prediction PatientID PredictedriskPredictedclass at0.5thresholdHasoutcome during time­at­risk Type 8 0.2 0 1 FN 9 0.3 0 0 TN 10 0.5 1 0 FP Ifapatientispredictedtohavetheoutcomeandhastheoutcome(duringthetime­at­risk) then this is called a true positive (TP). If a patient is predicted to have the outcome but doesnothavetheoutcomethenthisiscalledafalsepositive(FP).Ifapatientispredicted tonothavetheoutcomeanddoesnothavetheoutcomethenthisiscalledatruenegative (TN).Finally,ifapatientispredictedtonothavetheoutcomebutdoeshavetheoutcome thenthisiscalledafalsenegative(FN). Thefollowingthreshold­basedmetricscanbecalculated: •accuracy: (𝑇 𝑃 + 𝑇 𝑁 )/(𝑇 𝑃 + 𝑇 𝑁 + 𝐹 𝑃 + 𝐹 𝑁 ) •sensitivity: 𝑇 𝑃 /(𝑇 𝑃 + 𝐹 𝑁 ) •specificity: 𝑇 𝑁 /(𝑇 𝑁 + 𝐹 𝑃 ) •positivepredictivevalue: 𝑇 𝑃 /(𝑇 𝑃 + 𝐹 𝑃 ) Notethatthesevaluescaneitherdecreaseorincreaseifthethresholdislowered. Lower­ ingthethresholdofaclassifiermayincreasethedenominatorbyincreasingthenumber ofresultsreturned. Ifthethresholdwaspreviouslysettoohigh,thenewresultsmayall betruepositives,whichwillincreasepositivepredictivevalue. Ifthepreviousthreshold was about right or too low, further lowering the threshold will introduce false positives, decreasingpositivepredictivevalue. Forsensitivitythedenominatordoesnotdependon theclassifierthreshold( 𝑇 𝑃 + 𝐹 𝑁 isaconstant). Thismeansthatloweringtheclassifier threshold may increase sensitivity by increasing the number of true positive results. It is also possible that lowering the threshold may leave sensitivity unchanged, while the positivepredictivevaluefluctuates. Discrimination Discrimination is the ability to assign a higher risk to patients who will experience the outcomeduringthetimeatrisk. TheReceiverOperatingCharacteristics(ROC)curveis createdbyplotting1–specificityonthex­axisandsensitivityonthey­axisatallpossible thresholds. AnexampleROCplotispresentedlaterinthischapterinFigure 13.17. The area under the receiver operating characteristic curve (AUC) gives an overall measure ofdiscriminationwhereavalueof0.5correspondstorandomlyassigningtheriskanda valueof1meansperfectdiscrimination. MostpublishedpredictionmodelsobtainAUCs between0.6­0.8. TheAUCprovidesawaytodeterminehowdifferentthepredictedriskdistributionsare betweenthepatientswhoexperiencetheoutcomeduringthetimeatriskandthosewho\n",
      "page text: 13.4. Evaluating Prediction Models 251 donot. IftheAUCishigh,thenthedistributionswillbemostlydisjointed,whereaswhen thereisalotofoverlap,theAUCwillbecloserto0.5,asshowninFigure 13.3. Figure 13.3: How the ROC plots are linked to discrimination. If the two classes have similardistributionsofpredictedrisk,theROCwillbeclosetothediagonal,withAUC closeto0.5. ForrareoutcomesevenamodelwithahighAUCmaynotbepractical,becauseforevery positiveaboveagiventhresholdtherecouldalsobemanynegatives(i.e.thepositivepre­ dictivevaluewillbelow). Dependingontheseverityoftheoutcomeandcost(healthrisk and/ormonetary)ofsomeintervention,ahighfalsepositiveratemaybeunwanted. When the outcome is rare another measure known as the area under the precision­recall curve (AUPRC)isthereforerecommended. TheAUPRCistheareaunderthelinegeneratedby plottingthesensitivityonthex­axis(alsoknownastherecall)andthepositivepredictive value(alsoknownastheprecision)onthey­axis. Calibration Calibrationistheabilityofthemodeltoassignthecorrectrisk. Forexample,ifthemodel assigned one hundred patients a risk of 10% then ten of the patients should experience the outcome during the time at risk. If the model assigned 100 patients a risk of 80% then eighty of the patients should experience the outcome during the time at risk. The calibration is generally calculated by partitioning the patients into deciles based on the predicted risk and in each group calculating the mean predicted risk and the fraction of thepatientswhoexperiencedtheoutcomeduringthetimeatrisk. Wethenplottheseten points(predictedriskonthey­axisandobservedriskonthex­axis)andseewhetherthey fallonthex=yline,indicatingthemodeliswellcalibrated. Anexamplecalibrationplot\n",
      "page text: 252 Chapter 13. Patient­Level Prediction ispresentedlaterinthischapterinFigure 13.18. Wealsofitalinearmodelusingthepoints tocalculatetheintercept(whichshouldbeclosetozero)andthegradient(whichshould beclosetoone). Ifthegradientisgreaterthanonethenthemodelisassigningahigher riskthanthetrueriskandifthegradientislessthanonethemodelisassigningalower riskthanthetruerisk. NotethatwealsoimplementedSmoothCalibrationCurvesinour R­package to better capture the non­linear relationship between predicted and observed risk. 13.5 Designing a Patient-Level Prediction Study Inthissectionwewilldemonstratehowtodesignapredictionstudy. Thefirststepisto clearlydefinethepredictionproblem. Interestingly,inmanypublishedpapersthepredic­ tionproblemispoorlydefined,forexampleitisunclearhowtheindexdate(startofthe targetcohort)isdefined. Apoorlydefinedpredictionproblemdoesnotallowforexternal validationbyothers,letaloneimplementationinclinicalpractice. Inthepatient­levelpre­ dictionframeworkweenforceproperspecificationofthepredictionproblembyrequiring thekeychoicesdefinedinTable 13.1tobeexplicitlydefined. Herewewillwalkthrough thisprocessusinga“treatmentsafety”typepredictionproblemasanexample. 13.5.1 Problem Definition Angioedema is a well­known side­effect of ACE inhibitors, and the incidence of an­ gioedema reported in the labeling for ACE inhibitors is in the range of 0.1% to 0.7%. (Byrd et al. ,2006) Monitoring patients for this adverse effect is important, because al­ though angioedema is rare, it may be life­threatening, leading to respiratory arrest and death. (Norman et al. ,2013) Further, if angioedema is not initially recognized, it may leadtoextensiveandexpensiveworkupsbeforeitisidentifiedasacause. ( Normanetal. , 2013;ThompsonandFrable ,1993)OtherthanthehigherriskamongAfrican­American patients, therearenoknownpredisposingfactorsforthedevelopmentofACEinhibitor related angioedema. ( Byrd et al. ,2006) Most reactions occur within the first week or monthofinitialtherapyandoftenwithinhoursoftheinitialdose. ( Cicardietal. ,2004) However, some cases may occur years after therapy has begun. ( O’Mara and O’Mara , 1996)Nodiagnostictestisavailablethatspecificallyidentifiesthoseatrisk. Ifwecould identifythoseatrisk,doctorscouldact,forexamplebydiscontinuingtheACEinhibitor infavorofanotherhypertensiondrug. Wewillapplythepatient­levelpredictionframeworktoobservationalhealthcaredatato addressthefollowingpatient­levelpredictionquestion: AmongpatientswhohavejuststartedonanACEinhibitorforthefirsttime, whowillexperienceangioedemainthefollowingyear? 13.5.2 Study Population Definition Thefinalstudypopulationinwhichwewilldevelopourmodelisoftenasubsetofthetar­ getcohort,becausewemayforexampleapplycriteriathataredependentontheoutcome,\n",
      "page text: 13.5. Designing a Patient­Level Prediction Study 253 orwewanttoperformsensitivityanalyseswithsub­populationsofthetargetcohort. For thiswehavetoanswerthefollowingquestions: •What is the minimum amount of observation time we require before the start of the target cohort? This choice could depend on the available patient time in the trainingdata,butalsoonthetimeweexpecttobeavailableinthedatasourceswe want to apply the model on in the future. The longer the minimum observation time,themorebaselinehistorytimeisavailableforeachpersontouseforfeature extraction, but the fewer patients will qualify for analysis. Moreover, there could beclinicalreasonstochooseashortorlongerlook­backperiod. Forourexample, wewillusea365­daypriorhistoryaslook­backperiod(washoutperiod). •Can patients enter the target cohort multiple times? Inthetargetcohortdefinition, apersonmayqualifyforthecohortmultipletimesduringdifferentspansoftime,for exampleiftheyhaddifferentepisodesofadiseaseorseparateperiodsofexposure toamedicalproduct. Thecohortdefinitiondoesnotnecessarilyapplyarestriction to only let the patients enter once, but in the context of a particular patient­level predictionproblemwemaywanttorestrictthecohorttothefirstqualifyingepisode. Inourexample,apersoncanonlyenterthetargetcohortoncesinceourcriteriawas basedonfirstuseofanACEinhibitor. •Do we allow persons to enter the cohort if they experienced the outcome before? Do we allow persons to enter the target cohort if they experienced the outcome before qualifying for the target cohort? Depending on the particular patient­level predictionproblem,theremaybeadesiretopredictincidentfirstoccurrenceofan outcome,inwhichcasepatientswhohavepreviouslyexperiencedtheoutcomeare notatriskforhavingafirstoccurrenceandthereforeshouldbeexcludedfromthe target cohort. In other circumstances, there may be a desire to predict prevalent episodes,wherebypatientswithprioroutcomescanbeincludedintheanalysisand theprioroutcomeitselfcanbeapredictoroffutureoutcomes. Forourprediction example,wewillchoosenottoincludethosewithpriorangioedema. •How do we define the period in which we will predict our outcome relative to the target cohort start? Wehavetomaketwodecisionstoanswerthisquestion. First, does the time­at­risk window start at the date of the start of the target cohort or later? Arguments to make it start later could be that we want to avoid outcomes that were entered late in the record that actually occurred before the start of the targetcohortorwewanttoleaveagapwhereinterventionstopreventtheoutcome couldtheoreticallybeimplemented. Second,weneedtodefinethetime­at­riskby setting the risk window end, as some specification of days offset relative to the target cohort start or end dates. For our problem we will predict in a time­at­risk windowstarting1dayafterthestartofthetargetcohortupto365dayslater. •Do we require a minimum amount of time­at­risk? We have to decide if we want toincludepatientsthatdidnotexperiencetheoutcomebutdidleavethedatabase earlierthantheendofourtime­at­riskperiod. Thesepatientsmayexperiencethe outcomewhenwenolongerobservethem. Forourpredictionproblemwedecide\n",
      "page text: 254 Chapter 13. Patient­Level Prediction to answer this question with “yes,” requiring a minimum time­at­risk for that rea­ son. Furthermore,wehavetodecideifthisconstraintalsoappliestopersonswho experiencedtheoutcomeorwewillincludeallpersonswiththeoutcomeirrespec­ tive of their total time at risk. For example, if the outcome is death, then persons withtheoutcomearelikelycensoredbeforethefulltime­at­riskperiodiscomplete. 13.5.3 Model Development Settings To develop the prediction model we have to decide which algorithm(s) we like to train. Weseetheselectionofthebestalgorithmforacertainpredictionproblemasanempirical question, i.e. we prefer to let the data speak for itself and try different approaches to findthebestone. Inourframeworkwehavethereforeimplementedmanyalgorithmsas describedinSection 13.3,andallowotherstobeadded. Inthisexample,tokeepthings simple,weselectjustonealgorithm: GradientBoostingMachines. Furthermore,wehavetodecideonthecovariatesthatwewillusetotrainourmodel. In ourexample,weliketoaddgender,age,allconditions,drugsanddruggroups,andvisit counts. Wewilllookfortheseclinicaleventsintheyearbeforeandanytimepriortothe indexdate. 13.5.4 Model Evaluation Finally,wehavetodefinehowwewillevaluateourmodel. Forsimplicity,weherechoose internal validation. We have to decide how we divide our dataset in a training and test dataset and how we assign patients to these two sets. Here we will use a typical 75% ­ 25%split. Notethatforverylargedatasetswecouldusemoredatafortraining. 13.5.5 Study Summary WehavenowcompletelydefinedourstudyasshowninTable 13.12. Table13.12: Maindesignchoicesforourstudy. Choice Value Targetcohort PatientswhohavejuststartedonanACEinhibitorforthefirst time. Patientsareexcludediftheyhavelessthan365daysof priorobservationtimeorhavepriorangioedema. Outcomecohort Angioedema. Time­at­risk 1dayuntil365daysfromcohortstart. Wewillrequireatleast 364daysatrisk. Model GradientBoostingMachinewithhyper­parametersntree: 5000, maxdepth: 4or7or10andlearningrate: 0.001or0.01or0.1 or0.9. Covariateswillincludegender,age,conditions,drugs, druggroups,andvisitcount. Datasplit: 75%train­25%test, randomlyassignedbyperson.\n",
      "page text: 13.6. Implementing the Study in ATLAS 255 13.6 Implementing the Study in A TLAS The interface for designing a prediction study can be opened by clicking on the button in the left hand side ATLAS menu. Create a new prediction study. Makesuretogivethestudyaneasy­to­recognizename. Thestudydesigncanbe savedatanytimebyclickingthe button. In the Prediction design function, there are four sections: Prediction Problem Settings, AnalysisSettings, ExecutionSettings, andTrainingSettings. Herewediscusseachsec­ tion: 13.6.1 Prediction Problem Settings Here we select the target population cohorts and outcome cohorts for the analysis. A predictionmodelwillbedevelopedforallcombinationsofthetargetpopulationcohorts and the outcome cohorts. For example, if we specify two target populations and two outcomes,wehavespecifiedfourpredictionproblems. ToselectatargetpopulationcohortweneedtohavepreviouslydefineditinATLAS.In­ stantiatingcohortsisdescribedinChapter 10. TheAppendixprovidesthefulldefinitions ofthetarget(Appendix B.1)andoutcome(Appendix B.4)cohortsusedinthisexample. Toaddatargetpopulationtothecohort,clickonthe“AddTargetCohort”button. Adding outcomecohortssimilarlyworksbyclickingthe“AddOutcomeCohort”button. When done,thedialogshouldlooklikeFigure 13.4. Figure13.4: Predictionproblemsettings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████▍                                                      | 279/464 [00:02<00:02, 86.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 256 Chapter 13. Patient­Level Prediction 13.6.2 Analysis Settings Theanalysissettingsenableselectionofthesupervisedlearningalgorithm,thecovariates andpopulationsettings. Model Settings Wecanpickoneormoresupervisedlearningalgorithmsformodeldevelopment. Toadd asupervisedlearningalgorithmclickonthe“AddModelSettings”button. Adropdown containingallthemodelscurrentlysupportedintheATLASinterfacewillappear. Wecan select the supervised learning model we want to include in the study by clicking on the nameinthedropdownmenu. Thiswillthenshowaviewforthatspecificmodel,allowing theselectionofthehyper­parametervalues. Ifmultiplevaluesareprovided,agridsearch isperformedacrossallpossiblecombinationsofvaluestoselecttheoptimalcombination usingcross­validation. For our example we select gradient boosting machines, and set the hyper­parameters as specifiedinFigure 13.5. Covariate Settings Wehavedefinedasetofstandardcovariatesthatcanbeextractedfromtheobservational data in the CDM format. In the covariate settings view, it is possible to select which of thestandardcovariatestoinclude. Wecandefinedifferenttypesofcovariatesettings,and eachmodelwillbecreatedseparatelywitheachspecifiedcovariatesetting. Toaddacovariatesettingintothestudy,clickonthe“AddCovariateSettings”. Thiswill openthecovariatesettingview. Thefirstpartofthecovariatesettingsviewistheexclude/includeoption. Covariatesare generally constructed for any concept. However, we may want to include or exclude specific concepts, for example if a concept is linked to the target cohort definition. To onlyincludecertainconcepts,createaconceptsetinATLASandthenunderthe“ What concepts do you want to include in baseline covariates in the patient­level prediction model? (Leave blank if you want to include everything) ” select the concept set by clickingon . Wecanautomaticallyaddalldescendantconceptstotheconceptsinthe conceptsetbyanswering“yes”tothequestion“ Should descendant concepts be added to the list of included concepts? ” The same process can be repeated for the question “What concepts do you want to exclude in baseline covariates in the patient­level prediction model? (Leave blank if you want to include everything) ”,allowingcovari­ atescorrespondingtotheselectedconceptstoberemoved. Thefinaloption“ A comma delimited list of covariate IDs that should be restricted to ”enablesustoaddasetof covariateIDs(ratherthanconceptIDs)commaseparatedthatwillonlybeincludedinthe model. This option is for advanced users only. Once done, the inclusion and exclusion settingsshouldlooklikeFigure 13.6. Thenextsectionenablestheselectionofnon­timeboundvariables.\n",
      "page text: 13.6. Implementing the Study in ATLAS 257 Figure13.5: Gradientboostingmachinesettings\n",
      "page text: 258 Chapter 13. Patient­Level Prediction Figure13.6: Covariateinclusionandexclusionsettings. •Gender: abinaryvariableindicatingmaleorfemalegender •Age: acontinuousvariablecorrespondingtoageinyears •Agegroup: binaryvariablesforevery5yearsofage(0­4,5­9,10­14,…,95+) •Race: abinaryvariableforeachrace,1meansthepatienthasthatracerecorded,0 otherwise •Ethnicity: abinaryvariableforeachethnicity,1meansthepatienthasthatethnicity recorded,0otherwise •Index year: a binary variable for each cohort start date year, 1 means that was the patients cohort start date year, 0 otherwise. It often does not make sense to include index year, since we would like to apply our model to the future . •Indexmonth­abinaryvariableforeachcohortstartdatemonth,1meansthatwas thepatient’scohortstartdatemonth,0otherwise •Prior observation time: [Not recommended for prediction] a continuous variable correspondingtohowlongindaysthepatientwasinthedatabasepriortothecohort startdate •Post observation time: [Not recommended for prediction] a continuous variable correspondingtohowlongindaysthepatientwasinthedatabasepostcohortstart date •Timeincohort: acontinuousvariablecorrespondingtohowlongindaysthepatient wasinthecohort(cohortenddateminuscohortstartdate) •Indexyearandmonth: [Notrecommendedforprediction]abinaryvariableforeach cohortstartdateyearandmonthcombination,1meansthatwasthepatientscohort startdateyearandmonth,0otherwise Oncedone,thissectionshouldlooklikeFigure 13.7. Thestandardcovariatesenablethreeflexibletimeintervalsforthecovariates: •enddays: whentoendthetimeintervalsrelativetothecohortstartdate[defaultis 0] •longterm[default­365daystoenddayspriortocohortstartdate] •mediumterm[default­180daystoenddayspriortocohortstartdate]\n",
      "page text: 13.6. Implementing the Study in ATLAS 259 Figure13.7: Selectcovariates. •shortterm[default­30daystoenddayspriortocohortstartdate] Oncedone,thissectionshouldlooklikeFigure 13.8. Figure13.8: Timeboundcovariates. Thenextoptionisthecovariatesextractedfromtheeratables: •Condition: Construct covariates for each condition concept ID and time interval selected and if a patient has the concept ID with an era (i.e., the condition starts or ends during the time interval or starts before and ends after the time interval) duringthespecifiedtimeintervalpriortothecohortstartdateintheconditionera table,thecovariatevalueis1,otherwise0. •Conditiongroup: ConstructcovariatesforeachconditionconceptIDandtimein­ tervalselectedandifapatienthastheconceptID or any descendant concept ID with an era during the specified time interval prior to the cohort start date in the conditioneratable,thecovariatevalueis1,otherwise0. •Drug: ConstructcovariatesforeachdrugconceptIDandtimeintervalselectedand ifapatienthastheconceptIDwithaneraduringthespecifiedtimeintervalprior tothecohortstartdateinthedrugeratable,thecovariatevalueis1,otherwise0. •Drug group: Construct covariates for each drug concept ID and time interval se­ lectedandifapatienthastheconceptID or any descendant concept ID withan era during the specified time interval prior to the cohort start date in the drug era table,thecovariatevalueis1,otherwise0. Overlappingtimeintervalsettingmeansthatthedrugorconditionerashouldstartprior to the cohort start date and end after the cohort start date, so it overlaps with the cohort startdate. The era startoptionrestrictstofindingconditionordrugerasthatstartduring thetimeintervalselected. Oncedone,thissectionshouldlooklikeFigure 13.9. The next option selects covariates corresponding to concept IDs in each domain for the\n",
      "page text: 260 Chapter 13. Patient­Level Prediction Figure13.9: Timebounderacovariates. varioustimeintervals: •Condition: Construct covariates for each condition concept ID and time interval selected and if a patient has the concept ID recorded during the specified time in­ tervalpriortothecohortstartdateintheconditionoccurrencetable,thecovariate valueis1,otherwise0. •Condition Primary Inpatient: One binary covariate per condition observed as a primarydiagnosisinaninpatientsettinginthecondition_occurrencetable. •Drug: ConstructcovariatesforeachdrugconceptIDandtimeintervalselectedand ifapatienthastheconceptIDrecordedduringthespecifiedtimeintervalpriorto thecohortstartdateinthedrugexposuretable,thecovariatevalueis1,otherwise 0. •Procedure: Construct covariates for each procedure concept ID and time interval selected and if a patient has the concept ID recorded during the specified time in­ tervalpriortothecohortstartdateintheprocedureoccurrencetable,thecovariate valueis1,otherwise0. •Measurement: Construct covariates for each measurement concept ID and time intervalselectedand ifapatient hastheconcept IDrecordedduringthe specified time interval prior to the cohort start date in the measurement table, the covariate valueis1,otherwise0. •MeasurementValue: ConstructcovariatesforeachmeasurementconceptIDwitha valueandtimeintervalselectedandifapatienthastheconceptIDrecordedduring the specified time interval prior to the cohort start date in the measurement table, thecovariatevalueisthemeasurementvalue,otherwise0. •Measurementrangegroup: Binarycovariatesindicatingwhethermeasurementsare below,within,orabovenormalrange. •Observation: ConstructcovariatesforeachobservationconceptIDandtimeinter­ valselectedandifapatienthastheconceptIDrecordedduringthespecifiedtime intervalpriortothecohortstartdateintheobservationtable,thecovariatevalueis 1,otherwise0. •Device: ConstructcovariatesforeachdeviceconceptIDandtimeintervalselected andifapatienthastheconceptIDrecordedduringthespecifiedtimeintervalprior tothecohortstartdateinthedevicetable,thecovariatevalueis1,otherwise0. •VisitCount: Constructcovariatesforeachvisitandtimeintervalselectedandcount\n",
      "page text: 13.6. Implementing the Study in ATLAS 261 thenumberofvisitsrecordedduringthetimeintervalasthecovariatevalue. •VisitConceptCount: Constructcovariatesforeachvisit,domainandtimeinterval selectedandcountthenumberofrecordsperdomainrecordedduringthevisittype andtimeintervalasthecovariatevalue. ThedistinctcountoptioncountsthenumberofdistinctconceptIDsperdomainandtime interval. Oncedone,thissectionshouldlooklikeFigure 13.10. Figure13.10: Timeboundcovariates. The final option is whether to include commonly used risk scores as covariates. Once done,theriskscoresettingsshouldlooklikeFigure 13.11. Figure13.11: Riskscorecovariatesettings. Population Settings The population settings is where addition inclusion criteria can be applied to the target populationandisalsowherethetime­at­riskisdefined. Toaddapopulationsettinginto thestudy,clickonthe“AddPopulationSettings”button. Thiswillopenupthepopulation settingview. Thefirstsetofoptionsenabletheusertospecifythetime­at­riskperiod. Thisisthetime\n",
      "page text: 262 Chapter 13. Patient­Level Prediction interval where we look to see whether the outcome of interest occurs. If a patient has theoutcomeduringthetime­at­riskperiodthenwewillclassifythemas“Hasoutcome”, otherwisetheyareclassifiedas“Nooutcome”. “ Define the time­at­risk window start, relative to target cohort entry: ” definesthestartofthetime­at­risk,relativetothetarget cohortstartorenddate. Similarly,“ Define the time­at­risk window end: ” definesthe endofthetime­at­risk. “Minimum lookback period applied to target cohort ”specifiestheminimumbaseline period,theminimumnumberofdayspriortothecohortstartdatethatapatientiscontin­ uouslyobserved. Thedefaultis365days. Expandingtheminimumlook­backwillgivea morecompletepictureofapatient(astheymusthavebeenobservedforlonger)butwill filterpatientswhodonothavetheminimumnumberofdayspriorobservation. If “Should subjects without time at risk be removed? ” is set to yes, then a value for “Minimum time at risk: ” isalsorequired. Thisallowsremovingpeoplewhoarelostto follow­up(i.e.thathaveleftthedatabaseduringthetime­at­riskperiod). Forexample,if thetime­at­riskperiodwas1dayfromcohortstartuntil365daysfromcohortstart,then thefulltime­at­riskintervalis364days(365­1). Ifweonlywanttoincludepatientswho are observed the whole interval, then we set the minimum time at risk to be 364. If we are happy as long as people are in the time­at­risk for the first 100 days, then we select minimum time at risk to be 100. In this case as the time­at­risk start is 1 day from the cohortstart,apatientwillbeincludediftheyremaininthedatabaseforatleast101days fromthecohortstartdate. Ifweset“Shouldsubjectswithouttimeatriskberemoved?” to‘No’,thenthiswillkeepallpatients,eventhosewhodropoutfromthedatabaseduring thetime­at­risk. Theoption“ Include people with outcomes who are not observed for the whole at risk period?” is related to the previous option. If set to “yes”, then people who experience theoutcomeduringthetime­at­riskarealwayskept,eveniftheyarenotobservedforthe specifiedminimumamountoftime. The option “ Should only the first exposure per subject be included? ” is only useful if our target cohort contains patients multiple times with different cohort start dates. In thissituation,picking“yes”willresultinonlykeepingtheearliesttargetcohortdateper patientintheanalysis. Otherwiseapatientcanbeinthedatasetmultipletimes. Setting“ Remove patients who have observed the outcome prior to cohort entry? ” to “yes”willremovepatientswhohavetheoutcomepriortothetime­at­riskstartdate,sothe modelisforpatientswhohaveneverexperiencedtheoutcomebefore. If“no”isselected, thenpatientscouldhavehadtheoutcomeprior. Often,havingtheoutcomepriorisvery predictiveofhavingtheoutcomeduringthetime­at­risk. Oncedone,thepopulationsettingsdialogshouldlooklikeFigure 13.12. Now that we are finished with the Analysis Settings, the entire dialog should look like Figure13.13.\n",
      "page text: 13.6. Implementing the Study in ATLAS 263 Figure13.12: Populationsettings. 13.6.3 Execution Settings Therearethreeoptions: •“Perform sampling ”: here we choose whether to perform sampling (default = “no”). Ifsetto“yes”,anotheroptionwillappear: “ How many patients to use for a subset?”, wherethesamplesizecanbespecified. Samplingcanbeanefficient meanstodetermineifamodelforalargepopulation(e.g.10millionpatients)will be predictive by creating and testing the model with a sample of patients. For example,iftheAUCiscloseto0.5inthesample,wemightabandonthemodel. •“Minimum covariate occurrence: If a covariate occurs in a fraction of the target population less than this value, it will be removed: ”: herewechoosethe minimumcovariateoccurrence(default=0.001). Aminimumthresholdvaluefor covariateoccurrenceisnecessarytoremoverareeventsthatarenotrepresentative oftheoverallpopulation. •“Normalize covariate ”: herewechoosewhethertonormalizecovariates(default = “yes”). Normalization of the covariates is usually necessary for successful im­ plementationofaLASSOmodel. ForourexamplewemakethechoicesshowninFigure 13.14. 13.6.4 T raining Settings Therearefouroptions: •“Specify how to split the test/train set: ” Select whether to differentiate the train/testdatabyperson(stratifiedbyoutcome)orbytime(olderdatatotrainthe model,laterdatatoevaluatethemodel).\n",
      "page text: 264 Chapter 13. Patient­Level Prediction Figure13.13: Analysissettings. Figure13.14: Executionsettings.\n",
      "page text: 13.6. Implementing the Study in ATLAS 265 •“Percentage of the data to be used as the test set (0­100%) ”: Selectthepercent­ ageofdatatobeusedastestdata(default=25%). •“The number of folds used in the cross validation ”: Selectthenumberoffolds forcross­validationusedtoselecttheoptimalhyper­parameter(default=3). •“The seed used to split the test/train set when using a person type testSplit (optional): ”: Select the random seed used to split the train/test set when using a persontypetestsplit. ForourexamplewemakethechoicesshowninFigure 13.15. Figure13.15: Trainingsettings. 13.6.5 Importing and Exporting a Study Toexportastudy,clickonthe“Export”tabunder“Utilities.” ATLASwillproduceJSON thatcanbedirectlycopiedandpastedintoafilethatcontainsallofthedata,suchasthe study name, cohort definitions, models selected, covariates, settings, needed to run the study. To import a study, click on the “Import” tab under “Utilities.” Paste the contents of a patient­level prediction study JSON into this window, then click on the Import button below the other tab buttons. Note that this will overwrite all previous settings for that study,sothisistypicallydoneusinganew,emptystudydesign. 13.6.6 Downloading the Study Package Click on the “Review & Download” tab under “Utilities.” In the “Download Study Package” section, enter a descriptive name for the R package, noting that any illegal characters in R will automatically be removed from the file name by ATLAS. Click on todownloadtheRpackagetoalocalfolder. 13.6.7 Running the Study ToruntheRpackagerequireshavingR,RStudio,andJavainstalledasdescribedinSec­ tion8.4.5. Alsorequiredisthe PatientLevelPrediction package,whichcanbeinstalledin\n",
      "page text: 266 Chapter 13. Patient­Level Prediction Rusing: install.packages (\"drat\") drat::addRepo(\"OHDSI\") install.packages (\"PatientLevelPrediction\" ) Someofthemachinelearningalgorithmsrequireadditionalsoftwaretobeinstalled. For a full description of how to install the PatientLevelPrediction package, see the “Patient­ LevelPredictionInstallationGuide”vignette . TousethestudyRpackagewerecommendusingRStudio. IfyouarerunningRStudio locally,unzipthefilegeneratedbyATLAS,anddoubleclickthe.Rprojfiletoopenitin RStudio. IfyouarerunningRStudioonanRstudioserver,click toupload andunzipthefile,thenclickonthe.Rprojfiletoopentheproject. OnceyouhaveopenedtheprojectinRStudio,youcanopentheREADMEfile,andfollow theinstructions. Makesuretochangeallfilepathstoexistingpathsonyoursystem. 13.7 Implementing the Study in R AnalternativetoimplementingourstudydesignusingATLASistowritethestudycode ourselvesinR.Wecanmakeuseofthefunctionsprovidedinthe PatientLevelPrediction package. The package enables data extraction, model building, and model evaluation usingdatafromdatabasesthataretranslatedintotheOMOPCDM. 13.7.1 Cohort Instantiation We first need to instantiate the target and outcome cohorts. Instantiating cohorts is de­ scribedinChapter 10. TheAppendixprovidesthefulldefinitionsofthetarget(Appendix B.1)andoutcome(Appendix B.4)cohorts. InthisexamplewewillassumetheACEin­ hibitorscohorthasID1,andtheangioedemacohorthasID2. 13.7.2 Data Extraction WefirstneedtotellRhowtoconnecttotheserver. PatientLevelPrediction usesthe DatabaseConnector package,whichprovidesafunctioncalled createConnectionDetails . Type?createConnectionDetails for the specific settings required for the various database management systems (DBMS). For example, one might connect to a Post­ greSQLdatabaseusingthiscode: library(PatientLevelPrediction) connDetails <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" )\n",
      "page text: 13.7. Implementing the Study in R 267 cdmDbSchema <- \"my_cdm_data\" cohortsDbSchema <- \"scratch\" cohortsDbTable <- \"my_cohorts\" cdmVersion <- \"5\" Thelastfourlinesdefinethe cdmDbSchema ,cohortsDbSchema ,andcohortsDbTable variables,aswellastheCDMversion. WewillusetheselatertotellRwherethedatain CDMformatlive,wherethecohortsofinteresthavebeencreated,andwhatversionCDM isused. NotethatforMicrosoftSQLServer,databaseschemasneedtospecifyboththe databaseandtheschema,soforexample cdmDbSchema <- \"my_cdm_data.dbo\" . Firstitmakessensetoverifythatthecohortcreationhassucceededbycountingthenum­ berofcohortentries: sql <-paste(\"SELECT cohort_definition_id, COUNT(*) AS count\" , \"FROM @cohortsDbSchema.cohortsDbTable\" , \"GROUP BY cohort_definition_id\" ) conn <- connect(connDetails) renderTranslateQuerySql (connection = conn, sql =sql, cohortsDbSchema = cohortsDbSchema, cohortsDbTable = cohortsDbTable) ## cohort_definition_id count ## 1 1 527616 ## 2 2 3201 Nowwecantell PatientLevelPrediction toextractallnecessarydataforouranalysis. Co­ variatesareextractedusingthe FeatureExtraction package. Formoredetailedinfor­ mation on the FeatureExtraction package see its vignettes. For our example study we decidedtousethesesettings: covariateSettings <- createCovariateSettings ( useDemographicsGender = TRUE, useDemographicsAge = TRUE, useConditionGroupEraLongTerm = TRUE, useConditionGroupEraAnyTimePrior = TRUE, useDrugGroupEraLongTerm = TRUE, useDrugGroupEraAnyTimePrior = TRUE, useVisitConceptCountLongTerm = TRUE, longTermStartDays = -365, endDays = -1) The final step for extracting the data is to run the getPlpData function and input the connectiondetails,thedatabaseschemawherethecohortsarestored,thecohortdefinition IDs for the cohort and outcome, and the washout period which is the minimum number\n",
      "page text: 268 Chapter 13. Patient­Level Prediction ofdayspriortocohortindexdatethatthepersonmusthavebeenobservedtobeincluded intothedata,andfinallyinputthepreviouslyconstructedcovariatesettings. plpData <- getPlpData (connectionDetails = connDetails, cdmDatabaseSchema = cdmDbSchema, cohortDatabaseSchema = cohortsDbSchema, cohortTable = cohortsDbSchema, cohortId = 1, covariateSettings = covariateSettings, outcomeDatabaseSchema = cohortsDbSchema, outcomeTable = cohortsDbSchema, outcomeIds = 2, sampleSize = 10000 ) There are many additional parameters for the getPlpData function which are all doc­ umented in the PatientLevelPrediction manual. The resulting plpDataobject uses the packageffto store information in a way that ensures R does not run out of memory, evenwhenthedataarelarge. Creatingthe plpDataobjectcantakeconsiderablecomputingtime,anditisprobablya good idea to save it for future sessions. Because plpDatausesff, we cannot use R’s regularsavefunction. Instead,we’llhavetousethe savePlpData function: savePlpData (plpData, \"angio_in_ace_data\" ) Wecanusethe loadPlpData() functiontoloadthedatainafuturesession. 13.7.3 Additional Inclusion Criteria Thefinalstudypopulationisobtainedbyapplyingadditionalconstraintsonthetwoearlier defined cohorts, e.g., a minimum time at risk can be enforced ( requireTimeAtRisk, minTimeAtRisk ) and we can specify if this also applies to patients with the outcome (includeAllOutcomes ). Here we also specify the start and end of the risk window relative to target cohort start. For example, if we like the risk window to start 30 days aftertheat­riskcohortstartandendayearlaterwecanset riskWindowStart = 30 and riskWindowEnd = 365 . Insomecasestheriskwindowneedstostartatthecohortend date. This can be achieved by setting addExposureToStart = TRUE which adds the cohort(exposure)timetothestartdate. Intheexamplebelowallthesettingswedefinedforourstudyareimposed: population <- createStudyPopulation (plpData = plpData, outcomeId = 2, washoutPeriod = 364, firstExposureOnly = FALSE,\n",
      "page text: 13.7. Implementing the Study in R 269 removeSubjectsWithPriorOutcome = TRUE, priorOutcomeLookback = 9999, riskWindowStart = 1, riskWindowEnd = 365, addExposureDaysToStart = FALSE, addExposureDaysToEnd = FALSE, minTimeAtRisk = 364, requireTimeAtRisk = TRUE, includeAllOutcomes = TRUE, verbosity = \"DEBUG\" ) 13.7.4 Model Development In the set function of an algorithm the user can specify a list of eligible values for each hyper­parameter. All possible combinations of the hyper­parameters are included in a so­calledgridsearchusingcross­validationonthetrainingset. Ifauserdoesnotspecify anyvaluethenthedefaultvalueisusedinstead. Forexample,ifweusethefollowingsettingsforthegradientboostingmachine: ntrees = c(100,200), maxDepth = 4 the grid search will apply the gradient boosting ma­ chine algorithm with ntrees = 100 andmaxDepth = 4 plus the default settings for otherhyper­parametersand ntrees = 200 andmaxDepth = 4 plusthedefaultsettings for other hyper­parameters. The hyper­parameters that lead to the best cross­validation performancewillthenbechosenforthefinalmodel. Forourproblemwechoosetobuild agradientboostingmachinewithseveralhyper­parametervalues: gbmModel <- setGradientBoostingMachine (ntrees = 5000, maxDepth = c(4,7,10), learnRate = c(0.001,0.01,0.1,0.9)) TherunPlPfunctionusesthepopulation, plpData,andmodelsettingstotrainandevalu­ atethemodel. Wecanusethe testSplit (person/time)and testFraction parameters tosplitthedataina75%­25%splitandrunthepatient­levelpredictionpipeline: gbmResults <- runPlp(population = population, plpData = plpData, modelSettings = gbmModel, testSplit = 'person' , testFraction = 0.25, nfold = 2, splitSeed = 1234) UnderthehoodthepackagewillnowusetheRxgboostpackagetofitaagradientboost­ ingmachinemodelusing75%ofthedataandwillevaluatethemodelontheremaining\n",
      "page text: 270 Chapter 13. Patient­Level Prediction 25%. A results data structure is returned containing information about the model, its performance,etc. IntherunPlpfunctionthereareseveralparameterstosavethe plpData,plpResults , plpPlots,evaluation ,etc. objectswhichareallsetto TRUEbydefault. Wecansavethemodelusing: savePlpModel (gbmResults $model,dirPath = \"model\") Wecanloadthemodelusing: plpModel <- loadPlpModel (\"model\") Youcanalsosavethefullresultsstructureusing: savePlpResult (gbmResults, location = \"gbmResults\" ) Toloadthefullresultsstructureuse: gbmResults <- loadPlpResult (\"gbmResults\" ) 13.7.5 Internal Validation Onceweexecutethestudy,the runPlpfunctionreturnsthetrainedmodelandtheevalu­ ationofthemodelonthetrain/testsets. Youcaninteractivelyviewtheresultsbyrunning: viewPlp(runPlp = gbmResults) . ThiswillopenaShinyAppinwhichwecanview allperformancemeasurescreatedbytheframework,includinginteractiveplots(seeFig­ ure13.16inthesectionontheShinyApplication). Togenerateandsavealltheevaluationplotstoafolderrunthefollowingcode: plotPlp(gbmResults, \"plots\") TheplotsaredescribedinmoredetailinSection 13.4.2. 13.7.6 External Validation We recommend to always perform external validation, i.e. apply the final model on as much new datasets as feasible and evaluate its performance. Here we assume the data extraction has already been performed on a second database and stored in the newData folder. Weloadthemodelwepreviouslyfittedfromthe modelfolder:\n",
      "page text: 13.7. Implementing the Study in R 271 # load the trained model plpModel <- loadPlpModel (\"model\") #load the new plpData and create the population plpData <- loadPlpData (\"newData\" ) population <- createStudyPopulation (plpData = plpData, outcomeId = 2, washoutPeriod = 364, firstExposureOnly = FALSE, removeSubjectsWithPriorOutcome = TRUE, priorOutcomeLookback = 9999, riskWindowStart = 1, riskWindowEnd = 365, addExposureDaysToStart = FALSE, addExposureDaysToEnd = FALSE, minTimeAtRisk = 364, requireTimeAtRisk = TRUE, includeAllOutcomes = TRUE ) # apply the trained model on the new data validationResults <- applyModel (population, plpData, plpModel) Tomakethingseasierwealsoprovidethe externalValidatePlp functionforperform­ ingexternalvalidationthatalsoextractstherequireddata. Assumingweran result <- runPlp(...) thenwecanextractthedatarequiredforthemodelandevaluateitonnew data. Assuming the validation cohorts are in the table mainschema.dob.cohort with IDs1and2andtheCDMdataisintheschema cdmschema.dob : valResult <- externalValidatePlp ( plpResult = result, connectionDetails = connectionDetails, validationSchemaTarget = 'mainschema.dob' , validationSchemaOutcome = 'mainschema.dob' , validationSchemaCdm = 'cdmschema.dbo' , databaseNames = 'new database' , validationTableTarget = 'cohort' , validationTableOutcome = 'cohort' , validationIdTarget = 1, validationIdOutcome = 2 ) Ifwehavemultipledatabasestovalidatethemodelonthenwecanrun:\n",
      "page text: 272 Chapter 13. Patient­Level Prediction valResults <- externalValidatePlp ( plpResult = result, connectionDetails = connectionDetails, validationSchemaTarget = list('mainschema.dob' , 'difschema.dob' , 'anotherschema.dob' ), validationSchemaOutcome = list('mainschema.dob' , 'difschema.dob' , 'anotherschema.dob' ), validationSchemaCdm = list('cdms1chema.dbo' , 'cdm2schema.dbo' , 'cdm3schema.dbo' ), databaseNames = list('new database 1' , 'new database 2' , 'new database 3' ), validationTableTarget = list('cohort1' , 'cohort2' , 'cohort3' ), validationTableOutcome = list('cohort1' , 'cohort2' , 'cohort3' ), validationIdTarget = list(1,3,5), validationIdOutcome = list(2,4,6) ) 13.8 Results Dissemination 13.8.1 Model Performance Exploring the performance of a prediction model is easiest with the viewPlpfunction. Thisrequiresaresultsobjectastheinput. IfdevelopingmodelsinRwecanusetheresult ofrunPLpas the input. If using the ATLAS­generated study package, then we need to loadoneofthemodels(inthisexamplewewillloadAnalysis_1): plpResult <- loadPlpResult (file.path (outputFolder, 'Analysis_1' , 'plpResult' )) Here“Analysis_1”correspondstotheanalysiswespecifiedearlier. WecanthenlaunchtheShinyappbyrunning: viewPlp(plpResult) The Shiny app opens with a summary of the performance metrics on the test and train sets(seeFigure 13.16). TheresultsshowthattheAUConthetrainsetwas0.78andthis\n",
      "page text: 13.8. Results Dissemination 273 droppedto0.74onthetestset. ThetestsetAUCisthemoreaccuratemeasure. Overall, themodelappearstobeabletodiscriminatethosewhowilldeveloptheoutcomeinnew usersofACEinhibitorsbutitslightlyoverfitastheperformanceonthetrainsetishigher thanthetestset. TheROCplotispresentedinFigure 13.17. Figure13.16: SummaryevaluationstatisticsintheShinyapp. The calibration plot in Figure 13.18shows that generally the observed risk matches the predictedriskasthedotsarearoundthediagonalline. Thedemographiccalibrationplotin Figure13.19howevershowsthatthemodelisnotwellcalibratedfortheyoungerpatients, astheblueline(thepredictedrisk)differsfromtheredline(theobservedrisk)forthose aged below 40. This may indicate we need to remove the under 40s from the target population(astheobservedriskfortheyoungerpatientsisnearlyzero). Finally,theattritionplotshowsthelossofpatientsfromthelabelleddatabasedoninclu­ sion/exclusioncriteria(seeFigure 13.20). Theplotshowsthatwelostalargeportionof the target population due to them not being observed for the whole time at risk (1 year followup). Interestingly,notasmanypatientswiththeoutcomelackedthecompletetime atrisk.\n",
      "page text: 274 Chapter 13. Patient­Level Prediction Figure13.17: TheROCplot. Figure13.18: Thecalibrationofthemodel\n",
      "page text: 13.8. Results Dissemination 275 Figure13.19: Thedemographiccalibrationofthemodel Figure13.20: Theattritionplotforthepredictionproblem\n",
      "page text: 276 Chapter 13. Patient­Level Prediction 13.8.2 Comparing Models The study package as generated by ATLAS allows generating and evaluating many dif­ ferent prediction models for different prediction problems. Therefore, specifically for the output generated by the study package an additional Shiny app has been developed forviewingmultiplemodels. Tostartthisapp,run viewMultiplePlp(outputFolder) whereoutputFolder is the path containing the analysis results as specified when run­ ningtheexecutecommand(andshouldforexamplecontainasub­foldernamed“Anal­ ysis_1”). Viewing the Model Summary and Settings TheinteractiveShinyappwillstartatthesummarypageasshowninFigure 13.21. Figure13.21: Theshinysummarypagecontainingkeyholdoutsetperformancemetrics foreachmodeltrained Thissummarypagetablecontains: •basicinformationaboutthemodel(e.g.,databaseinformation,classifiertype,time­ at­risksettings,targetpopulationandoutcomenames) •holdouttargetpopulationcountandincidenceofoutcome •discriminationmetrics: AUC,AUPRC Totheleftofthetableisthefilteroption,wherewecanspecifythedevelopment/validation databases to focus on, the type of model, the time at risk settings of interest and/or the cohortsofinterest. Forexample,topickthemodelscorrespondingtothetargetpopulation “NewusersofACEinhibitorsasfirstlinemono­therapyforhypertension”,selectthisin theTarget Cohort option. To explore a model click on the corresponding row, a selected row will be highlighted. With a row selected, we can now explore the model settings used when developing the modelbyclickingonthe Model Settings tab: Similarly,wecanexplorethepopulationandcovariatesettingsusedtogeneratethemodel intheothertabs.\n",
      "page text: 13.8. Results Dissemination 277 Figure13.22: Toviewthemodelsettingsusedwhendevelopingthemodel. Viewing Model Performance Onceamodelrowhasbeenselectedwecanalsoviewthemodelperformance. Clickon toopenthethresholdperformancesummaryshowninFigure 13.23. Figure13.23: Thesummaryperformancemeasuresatasetthreshold. This summary view shows the selected prediction question in the standard format, a thresholdselectorandadashboardcontainingkeythreshold­basedmetricssuchasposi­ tivepredictivevalue(PPV),negativepredictivevalue(NPV),sensitivityandspecificity (seeSection 13.4.2). InFigure 13.23weseethatatathresholdof0.00482thesensitivity is 83.4% (83.4% of patients with the outcome in the following year have a risk greater thanorequalto0.00482)andthePPVis1.2%(1.2%ofpatientswithariskgreaterthan or equal to 0.00482 have the outcome in the following year). As the incidence of the outcomewithintheyearis0.741%,identifyingpatientswithariskgreaterthanorequal\n",
      "page text: 278 Chapter 13. Patient­Level Prediction to0.00482wouldfindasubgroupofpatientsthathavenearlydoubletheriskofthepopu­ lationaveragerisk. Wecanadjustthethresholdusingtheslidertoviewtheperformance atothervalues. To look at the overall discrimination of the model click on the “Discrimination” tab to view the ROC plot, precision­recall plot, and distribution plots. The line on the plots corresponds to the selected threshold point. Figure 13.24show the ROC and precision­ recallplots. TheROCplotshowsthemodelwasabletodiscriminatebetweenthosewho willhavetheoutcomewithintheyearandthosewhowillnot. However,theperformance looks less impressive when we see the precision­recall plot, as the low incidence of the outcomemeansthereisahighfalsepositiverate. Figure13.24: TheROCandprecision­recallplotsusedtoaccesstheoveralldiscrimina­ tionabilityofthemodel. Figure13.25showsthepredictionandpreferencescoredistributions. Finally,wecanalsoinspectthecalibrationofthemodelbyclickingonthe“Calibration” tab. This displays the calibration plot and the demographic calibration shown in Figure 13.26. We see that the average predicted risk appears to match the observed fraction who ex­ perienced the outcome within a year, so the model is well calibrated. Interestingly, the demographiccalibrationshowsthattheexpectedlineishigherthantheobservedlinefor youngpatients,sowearepredictingahigherriskforyoungagegroups. Conversely,for the patients above 80 the model is predicting a lower risk than the observed risk. This maypromptustodevelopseparatemodelsfortheyoungerorolderpatients. Viewing the Model Toinspect the final model, select the option from the left hand menu. This willopenaviewcontainingplotsforeachvariableinthemodel,showninFigure 13.27,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████▏                                               | 302/464 [00:03<00:01, 97.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 13.8. Results Dissemination 279 Figure13.25: Thepredictedriskdistributionforthosewithandwithouttheoutcome. The moretheseoverlaptheworsethediscrimination Figure13.26: Theriskstratifiedcalibrationanddemographiccalibration\n",
      "page text: 280 Chapter 13. Patient­Level Prediction and a table summarizing all the candidate covariates, shown in Figure 13.28. The vari­ ableplotsareseparatedintobinaryvariablesandcontinuousvariables. Thex­axisisthe prevalence/mean in patients without the outcome and the y­axis is the prevalence/mean in patients with the outcome. Therefore, any variable’s dot falling above the diagonal is more common in patients with the outcome and any variable’s dot falling below the diagonalislesscommoninpatientswiththeoutcome. Figure13.27: Modelsummaryplots. Eachdotcorrespondstoavariableincludedinthe model. The table in Figure 13.28displays the name, value (coefficient if using a general linear model,orvariableimportanceotherwise)forallthecandidatecovariates,outcomemean (themeanvalueforthosewhohavetheoutcome)andnon­outcomemean(themeanvalue forthosewhodonothavetheoutcome). Predictivemodelsarenotcausalmodels,andpredictorsshouldnotbemistakenfor causes. ThereisnoguaranteethatmodifyinganyofthevariablesinFigure 13.28 willhaveaneffectontheriskoftheoutcome. 13.9 Additional Patient-Level Prediction Features 13.9.1 Journal Paper Generation We have added functionality to automatically generate a word document we can use as startofajournalpaper. Itcontainsmanyofthegeneratedstudydetailsandresults. Ifwe have performed external validation these results will can be added as well. Optionally, we can add a “Table 1” that contains data on many covariates for the target population. Wecancreatethedraftjournalpaperbyrunningthisfunction:\n",
      "page text: 13.9. Additional Patient­Level Prediction Features 281 Figure13.28: Modeldetailstable.\n",
      "page text: 282 Chapter 13. Patient­Level Prediction createPlpJournalDocument (plpResult = <your plp results >, plpValidation = <your validation results >, plpData = <your plp data >, targetName = \"<target population>\" , outcomeName = \"<outcome>\" , table1 = F, connectionDetails = NULL, includeTrain = FALSE, includeTest = TRUE, includePredictionPicture = TRUE, includeAttritionPlot = TRUE, outputLocation = \"<your location>\" ) Formoredetailsseethehelppageofthefunction. 13.10 Summary –Patient­level prediction aims to develop a model that predicts future events usingdatafromthepast. –The selection of the best machine algorithm for model development is an empiricalquestion,i.e.itshouldbedrivenbytheproblemanddataathand. –ThePatientLevelPredictionPackageimplementsbestpracticesforthedevel­ opmentandvalidationofpredictionmodelsusingdatastoredintheOMOP­ CDM. –Thedisseminationofthemodelanditsperformancemeasuresisimplemented throughinteractivedashboards. –OHDSI’spredictionframeworkenableslarge­scaleexternalvalidationofpre­ dictionmodelswhichisapre­requisiteforclinicaladoption. 13.11 Exercises Prerequisites For these exercises we assume R, R­Studio and Java have been installed as described in Section 8.4.5. Also required are the SqlRender,DatabaseConnector ,Eunomiaand PatientLevelPrediction packages,whichcanbeinstalledusing: install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) remotes::install_github (\"ohdsi/PatientLevelPrediction\" )\n",
      "page text: 13.11. Exercises 283 TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. Theseexercisesalsomakeuseofseveralcohorts. ThecreateCohorts functionintheEunomiapackagewillcreatetheseintheCOHORT table: Eunomia::createCohorts (connectionDetails) Problem Definition In patients that started using NSAIDs for the first time, predict who will developagastrointestinal(GI)bleedinthenextyear. TheNSAIDnew­usercohorthasCOHORT_DEFINITION_ID=4. TheGIbleedcohort hasCOHORT_DEFINITION_ID=3. Exercise 13.1. Using the PatientLevelPrediction R package, define the covariates you wanttouseforthepredictionandextractthePLPdatafromtheCDM.Createthesummary ofthePLPdata. Exercise 13.2. Revisit the design choices you have to make to define the final target population and specify these using the createStudyPopulation function. What will theeffectofyourchoicesbeonthefinalsizeofthetargetpopulation? Exercise 13.3. BuildapredictionmodelusingLASSOandevaluateitsperformanceusing theShinyapplication. Howwellisyourmodelperforming? SuggestedanswerscanbefoundinAppendix E.9.\n",
      "page text: 284 Chapter 13. Patient­Level Prediction\n",
      "page text: Part IV Evidence Quality 285\n",
      "page text: Chapter 14 Evidence Quality Chapter leads: Patrick Ryan & Jon Duke 14.1 Attributes of Reliable Evidence Beforeembarkingonanyjourney,itcanbehelpfultoenvisionwhattheidealdestination might look like. To support our journey from data to evidence, we highlight desired attributesthatcanunderliewhatmakesevidencequalityreliable. Figure14.1: Desiredattributesofreliableevidence Reliableevidenceshouldbe repeatable , meaningthatresearchersshouldexpecttopro­ duce identical results when applying the same analysis to the same data for any given question. Implicit in this minimum requirement is the notion that evidence is the result oftheexecutionofadefinedprocesswithaspecifiedinput,andshouldbefreeofmanual interventionofpost­hocdecision­makingalongtheway. Moreideally,reliableevidence should be reproducible such that a different researcher should be able to perform the same task of executing a given analysis on a given database and expect to produce an identical result as the first researcher. Reproducibility requires that the process is fully­ specified,generallyinbothhuman­readableandcomputer­executableformsuchthatno 287\n",
      "page text: 288 Chapter 14. Evidence Quality study decisions are left to the discretion of the investigator. The most efficient solution toachieverepeatabilityandreproducibilityistousestandardizedanalyticsroutinesthat have defined inputs and outputs, and apply these procedures against version­controlled databases. We are more likely to be confident that our evidence is reliable if it can be shown to be replicable,suchthatthesamequestionaddressedusingtheidenticalanalysisagainstsim­ ilardatayieldsimilarresults. Forexample,evidencegeneratedfromananalysisagainst anadministrativeclaimsdatabasefromonelargeprivateinsurermaybestrengthenedif replicated on claims data from a different insurer. In the context of population­level ef­ fectestimation,thisattributealignswellwithSirAustinBradfordHill’scausalviewpoint onconsistency,“Hasitbeenrepeatedlyobservedbydifferentpersons,indifferentplaces, circumstances and times?…whether chance is the explanation or whether a true hazard hasbeenrevealedmaysometimesbeansweredonlybyarepetitionofthecircumstances and the observations.” ( Hill,1965) In the context of patient­level prediction, replicabil­ ityhighlightsthevalueofexternalvalidationandtheabilitytoevaluateperformanceof a model that was trained on one database by observing its discriminative accuracy and calibration when applied to a different database. In circumstances where identical anal­ ysesareperformedagainstdifferentdatabasesandstillshowconsistentlysimilarresults, we have further gain confidence that our evidence is generalizable . A key value of the OHDSI research network is the diversity represented by different populations, geogra­ phies and data capture processes. Madigan et al. (2013b) showed that effect estimates canbesensitivetochoiceofdata. Recognizingthateachdatasourcecarrieswithitinher­ ent limitations and unique biases that limit our confidence in singular findings, there is tremendouspowerinobservingsimilarpatternsacrossheterogeneousdatasetsbecauseit greatlydiminishesthelikelihoodthatsource­specificbiasesalonecanexplainthefindings. Whennetworkstudiesshowconsistentpopulation­leveleffectestimatesacrossmultiple claims and EHR databases across US, Europe and Asia, they should be recognized as strongerevidenceaboutthemedicalinterventionthatcanhaveabroaderscopetoimpact medicaldecision­making. Reliableevidenceshouldbe robust,meaningthatthefindingsshouldnotbeoverlysen­ sitivetothesubjectivechoicesthatcanbemadewithinananalysis. Iftherearealterna­ tive statistical methods that can be considered potentially reasonable for a given study, thenitcanprovidereassurancetoseethatthedifferentmethodsyieldsimilarresults, or converselycangivecautionifdiscordantresultsareuncovered. ( Madiganetal. ,2013a) For population­level effect estimation, sensitivity analyses can include high­level study designchoice, suchaswhethertoapplyacomparativecohortorself­controlledcasese­ riesdesign,orcanfocusonanalyticalconsiderationsembeddedwithinadesign,suchas whethertoperformpropensityscorematching,stratificationorweightingasaconfound­ ingadjustmentstrategywithinthecomparativecohortframework. Last,butpotentiallymostimportant,evidenceshouldbe calibrated . Itisnotsufficientto have an evidence generating system that produces answers to unknown questions if the performance of that system cannot be verified. A closed system should be expected to have known operating characteristics, which should be able to measured and communi­\n",
      "page text: 14.2. Understanding Evidence Quality 289 catedascontextforinterpretinganyresultsthatthesystemproduces. Statisticalartifacts shouldbeabletobeempiricallydemonstratedtohavewell­definedproperties,suchasa 95% confidence interval having 95% coverage probability or a cohort with a predicted probabilityof10%havingaobservedproportionofeventsin10%ofthepopulation. An observationalstudyshouldalwaysbeaccompaniedbystudydiagnosticsthattestassump­ tions around the design, methods, and data. These diagnostics should be centered on evaluating the primary threats to study validity: selection bias, confounding, and mea­ surementerror. Negativecontrolshavebeenshowntobeapowerfultoolforidentifying andmitigatingsystematicerrorinobservationalstudies. ( Schuemieetal. ,2016,2018a,b) 14.2 Understanding Evidence Quality But how do we know if the results of a study are reliable enough? Can they be trusted for use in clinical settings? What about in regulatory decision­making? Can they serve asafoundationforfutureresearch? Eachtimeanewstudyispublishedordisseminated, readersmustconsiderthesequestions,regardlessofwhethertheworkwasarandomized controlledtrial,anobservationalstudy,oranothertypeofanalysis. Oneoftheconcernsthatisoftenraisedaroundobservationalstudiesandtheuseof“real worlddata”isthetopicofdataquality. ( Botsisetal. ,2010;Hershetal. ,2013;Sherman etal.,2016)Commonlynotedisthatdatausedinobservationalresearchwerenotorigi­ nallygatheredforresearchpurposesandthusmaysufferfromincompleteorinaccurate datacaptureaswellasinherentbiases. Theseconcernshavegivenrisetoagrowingbody ofresearcharoundhowtomeasure,characterize,andideallyimprovedataquality. ( Kahn et al.,2012;Liaw et al. ,2013;Weiskopf and Weng ,2013) The OHDSI community is a strong advocate of such research and community members have led and participated in manystudieslookingatdataqualityintheOMOPCDMandtheOHDSInetwork. ( Huser etal.,2016;Kahnetal. ,2015;Callahanetal. ,2017;Yoonetal. ,2016) Giventhefindingsofthepastdecadeinthisarea,ithasbecomeapparentthatdataquality isnotperfectandneverwillbe. ThisnotionisnicelyreflectedinthisquotefromDr.Clem McDonald,apioneerinthefieldofmedicalinformatics: Lossoffidelitybeginswiththemovementofdatafromthedoctor’sbrainto themedicalrecord. Thus, as a community we must ask the question – given imperfect data, how can we achieve reliable evidence? Theanswerrestsinlookingholisticallyat“evidencequality”: examiningtheentirejour­ neyfromdatatoevidence,identifyingeachofthecomponentsthatmakeuptheevidence generation process, determining how to build confidence in the quality of each compo­ nent, and transparently communicating what has been learned each step along the way. Evidencequalityconsidersnotonlythequalityofobservationaldatabutalsothevalidity ofthemethods,software,andclinicaldefinitionsusedinourobservationalanalyses. Inthefollowingchapters,wewillexplorefourcomponentsofevidencequalitylistedin\n",
      "page text: 290 Chapter 14. Evidence Quality Table14.1. Table14.1: Thefourcomponentsofevidencequality. Componentof EvidenceQuality WhatitMeasures DataQuality Arethedatacompletelycapturedwithplausiblevaluesina mannerthatisconformanttoagreed­uponstructureand conventions? ClinicalValidity Towhatextentdoestheanalysisconductedmatchtheclinical intention? SoftwareValidity Canwetrustthattheprocesstransformingandanalyzingthedata doeswhatitissupposedtodo? MethodValidity Isthemethodologyappropriateforthequestion,giventhe strengthsandweaknessesofthedata? 14.3 Communicating Evidence Quality Animportantaspectofevidencequalityistheabilitytoexpresstheuncertaintythatarises alongthejourneyfromdatatoevidence. TheoverarchinggoalofOHDSI’sworkaround evidencequalityistoproduceconfidenceinhealthcaredecision­makersthattheevidence generatedbyOHDSI–whileundoubtedlyimperfectinmanyways–hasbeenconsistently measuredforitsweaknessesand strengthsandthatthisinformation hasbeencommuni­ catedinarigorousandopenmanner. 14.4 Summary –The evidence we generate should be repeatable ,reproducible ,replicable, generalizable ,robust,and calibrated . –Evidence quality considers more than just data quality when answering whetherevidenceisreliable: *DataQuality *ClinicalValidity *SoftwareValidity *MethodValidity –When communicating evidence, we should express the uncertainty arising fromthevariouschallengestoevidencequality.\n",
      "page text: Chapter 15 Data Quality Chapter leads: Martijn Schuemie, Vojtech Huser & Clair Blacketer Mostofthedatausedforobservationalhealthcareresearchwerenotcollectedforresearch purposes. Forexample,electronichealthrecords(EHRs)aimtocapturetheinformation neededtosupportthecareofpatients,andadministrativeclaimsarecollectedtoprovide agroundsforallocatingcoststopayers. Manyhavequestionedwhetheritisappropriate to use such data for clinical research, with van der Lei (1991) even stating that “Data shall be used only for the purpose for which they were collected.” The concern is that because the data were not collected for the research that we would like to do, it is not guaranteedtohavesufficientquality. Ifthequalityofthedataispoor(garbagein),then thequalityoftheresultofresearchusingthatdatamustbepooraswell(garbageout). An importantaspectofobservationalhealthcareresearchthereforedealswithassessingdata quality,aimingtoanswerthequestion: Arethedataofsufficientqualityforourresearchpurposes? Wecandefinedataquality(DQ)as( Roebuck,2012): Thestateofcompleteness,validity,consistency,timelinessandaccuracythat makesdataappropriateforaspecificuse. Note that it is unlikely that our data are perfect, but they may be good enough for our purposes. DQcannotbeobserveddirectly,butmethodologyhasbeendevelopedtoassessit. Two typesofDQassessmentscanbedistinguished( WeiskopfandWeng ,2013): assessments to evaluate DQ in general, and assessments to evaluate DQ in the context of a specific study. In this chapter we will first review possible sources of DQ problems, after which we’ll discussthetheoryofgeneralandstudy­specificDQassessments,followedbyastep­by­ stepdescriptionofhowtheseassessmentscanbeperformedusingtheOHDSItools. 291\n",
      "page text: 292 Chapter 15. Data Quality 15.1 Sources of Data Quality Problems Therearemanythreatstothequalityofthedata,startingasnotedinChapter 14whenthe doctor records her or his thoughts. Dasu and Johnson (2003) distinguish the following stepsinthelifecycleofdata, recommendingDQbeintegratedineachstep. Theyrefer tothisastheDQcontinuum: 1.Data gathering and integration . Possible problems include fallible manual en­ try, biases (e.g. upcoding in claims), erroneous joining of tables in an EHR, and replacingmissingvalueswithdefaultones. 2.Data storage and knowledge sharing . Potentialproblemsarelackofdocumenta­ tionofthedatamodel,andlackofmeta­data. 3.Data analysis . Problemscanincludeincorrectdatatransformations,incorrectdata interpretation,anduseofinappropriatemethodology. 4.Data publishing . Whenpublishingdatafordownstreamuse. Oftenthedataweusehasalreadybeencollectedandintegrated,sothereislittlewecan dotoimprovestep1. WedohavewaystochecktheDQproducedbythisstepaswillbe discussedinsubsequentsectionsinthischapter. Similarly, we often receive the data in a specific form, so we have little influence over partofstep2. However,inOHDSIweconvertallourobservationaldatatotheCommon DataModel(CDM),andwedohaveownershipoverthisprocess. Somehaveexpressed concernsthatthisspecificstepcandegradeDQ.Butbecausewecontrolthisprocess,we canbuildstringentsafeguardstopreserveDQasdiscussedlaterinSection 15.2.2. Several investigations( Defalcoetal. ,2013;MakadiaandRyan ,2014;Matchoetal. ,2014;Voss et al.,2015a,b;Hripcsak et al. ,2018) have shown that when properly executed, little to no error is introduced when converting to the CDM. In fact, having a well­documented datamodelthatissharedbyalargecommunityfacilitatesdatastorageinanunambiguous andclearmanner. Step3(dataanalysis)alsofallsunderourcontrol. InOHDSI,wetendtonotusetheterm DQforthequalityissuesduringthisstep,butrathertheterms clinical validity ,software validityandmethod validity , which are discussed at length in Chapters 16,17, and18, respectively. 15.2 Data Quality in General Wecanaskthequestionwhetherourdataarefitforthegeneralpurposeofobservational research.Kahnetal. (2016)definesuchgenericDQasconsistingofthreecomponents: 1.Conformance : Do data values adhere to specified standards and formats? Three sub­typesareidentified: •Value: Arerecordeddataelementsinagreementwiththespecifiedformats? Forexample,areallprovidermedicalspecialtiesvalidspecialties? •Relational : Is the recorded data in agreement with specified relational con­ straints? For example, does the PROVIDER_ID in a DRUG_EXPOSURE\n",
      "page text: 15.2. Data Quality in General 293 datahaveacorrespondingrecordinthePROVIDERtable? •Computation : Docomputations onthe datayield theintended results? For example,isBMIcomputedfromheightandweightequaltotheverbatimBMI recordedinthedata? 2.Completeness : Referstowhetheraparticularvariableispresent(e.g.isweightas measuredinthedoctor’sofficerecorded?) aswellaswhethervariablescontainall recordedvalues(e.g.doallpersonshaveaknowngender?) 3.Plausibility : Aredatavaluesbelievable? Threesub­typesaredefined: •Uniqueness : For example, does each PERSON_ID occur only once in the PERSONtable? •Atemporal : Dovalues,distributions,ordensitiesagreewithexpectedvalues? Forexample,istheprevalenceofdiabetesimpliedbythedatainlinewiththe knownprevalence? •Temporal: Arechangesinvaluesinlinewithexpectations? Forexample,are immunizationsequencesinlinewithrecommendations? Eachcomponentcanbeevaluatedintwoways: •Verification focusesonmodelandmetadatadataconstraints,systemassumptions, and local knowledge. It does not rely on an external reference. The key feature withverificationistheabilitytodetermineexpectedvaluesanddistributionsusing resourceswithinthelocalenvironment. •Validation focusesonthealignmentofdatavalueswithrespecttorelevantexternal benchmarks. One possible source of an external benchmark can be to combine resultsacrossmultipledatasites. 15.2.1 Data Quality Checks Kahnintroducestheterm data quality check (sometimesreferredtoasa data quality rule ) thattestswhetherdataconformtoagivenrequirement(e.g.,flagginganimplausibleage of 141 of a patient, potentially due to incorrect birth year or missing death event). We canimplementsuchchecksinsoftwarebycreatingautomatedDQtools. Onesuchtoolis ACHILLES (AutomatedCharacterizationofHealthInformationatLarge­scaleLongitu­ dinalEvidenceSystems). ( Huseretal. ,2018)ACHILLESisasoftwaretoolthatprovides characterizationandvisualizationofadatabaseconformingtotheCDM.Assuch,itcan be used to evaluate DQ in a network of databases. ( Huser et al. ,2016) ACHILLES is availableasastand­alonetool,anditisalsointegratedintoATLASasthe“DataSources” function. ACHILLES pre­computes over 170 data characterization analyses, with each analysis havingananalysisIDandashortdescriptionoftheanalysis;twosuchexamplesare“715: Distribution of DAYS_SUPPLY by DRUG_CONCEPT_ID” and “506: Distribution of ageatdeathbygender.” Theresultsoftheseanalysesarestoredinadatabaseandcanbe accessedbyawebviewerorbyATLAS. Another tool created by the community to assess DQ is the Data Quality Dashboard (DQD). Where ACHILLES runs characterization analyses to provide an overall visual\n",
      "page text: 294 Chapter 15. Data Quality understandingofaCDMinstance,theDQDgoestablebytableandfieldbyfieldtoquan­ tifythenumberofrecordsinaCDMthatdonotconformtothegivenspecifications. In all,over1,500checksareperformed,eachoneorganizedintotheKahnframework. For eachchecktheresultiscomparedtoathresholdwherebyaFAILisconsideredtobeany percentage of violating rows falling above that value. Table 15.1shows some example checks. Table 15.1: Example data quality rules in the Data Quality Dash­ board. Fraction violated rows Checkdescription Threshold Status 0.34 Ayesornovalueindicatingiftheprovider_idin theVISIT_OCCURRENCEistheexpecteddata typebasedonthespecification.0.05 FAIL 0.99 Thenumberandpercentofdistinctsourcevalues inthemeasurement_source_valuefieldofthe MEASUREMENTtablemappedto0.0.30 FAIL 0.09 Thenumberandpercentofrecordsthathavea valueinthedrug_concept_idfieldinthe DRUG_ERAtablethatdonotconformtothe ingredientclass.0.10 PASS 0.02 Thenumberandpercentofrecordswithavalue intheverbatim_end_datefieldofthe DRUG_EXPOSUREthatoccurspriortothedate intheDRUG_EXPOSURE_START_DATEfield oftheDRUG_EXPOSUREtable.0.05 PASS 0.00 Thenumberandpercentofrecordsthathavea duplicatevalueintheprocedure_occurrence_id fieldofthePROCEDURE_OCCURRENCE.0.00 PASS Within the tool the checks are organized in multiple ways, one being into table, field, and concept level checks. Table checks are those done at a high­level within the CDM, for example determining if all required tables are present. The field level checks are carried out in such a way to evaluate every field within every table for conformance to CDMspecifications. Theseincludemakingsureallprimarykeysaretrulyuniqueandall standard concept fields contain concepts ids in the proper domain, among many others. Conceptlevelchecksgoalittledeepertoexamineindividualconceptids. Manyofthese fall into the plausibility category of the Kahn framework such as ensuring that gender­ specificconceptsarenotattributedtopersonsofincorrectgender(i.e.prostatecancerin afemalepatient).\n",
      "page text: 15.2. Data Quality in General 295 ACHILLESandDQDareexecutedagainstthedataintheCDM.DQissuesiden­ tifiedthiswaymaybeduetotheconversiontotheCDM,butmayalsoreflectDQ issuesalreadypresentinthesourcedata. Iftheconversionisatfault,itisusually withinourcontroltoremedytheproblem,butiftheunderlyingdataareatfaultthe onlycourseofactionmaybetodeletetheoffendingrecords. 15.2.2 ETL Unit T ests Inadditiontohighleveldataqualitychecks, individualleveldatachecksshouldbeper­ formed. TheETL(Extract­Transform­Load)processbywhichdataareconvertedtothe CDMisoftenquitecomplex,andwiththatcomplexitycomesthedangerofmakingmis­ takes that may go unnoticed. Moreover, as time goes by the source data model may change, or the CDM may be updated, making it necessary to modify the ETL process. Changes to a process as complicated as an ETL can have unintended consequences, re­ quiringallaspectsoftheETLtobereconsideredandreviewed. TomakesuretheETLdoeswhatitissupposedtodo,andcontinuestodoso,itishighly recommended to construct a set of unit tests. A unit test is a small piece of code that automaticallychecksasingleaspect. TheRabbit­in­a­HattooldescribedinChapter 6can createaunittestframeworkthatmakeswritingsuchunittestseasier. Thisframeworkis a collection of R functions created specifically for the source database and target CDM versionoftheETL.Someofthesefunctionsareforcreatingfakedataentriesthatadhere to the source data schema, while other functions can be used to specify expectations on thedataintheCDMformat. Hereisanexampleunittest: source(\"Framework.R\" ) declareTest (101,\"Person gender mappings\" ) add_enrollment (member_id = \"M000000102\" ,gender_of_member = \"male\") add_enrollment (member_id = \"M000000103\" ,gender_of_member = \"female\" ) expect_person (PERSON_ID = 102,GENDER_CONCEPT_ID = 8507 expect_person (PERSON_ID = 103,GENDER_CONCEPT_ID = 8532) Inthisexample,theframeworkgeneratedbyRabbit­in­a­Hatissourced,loadingthefunc­ tionsthatareusedintheremainderofthecode. Wethendeclarewewillstarttestingper­ songendermappings. ThesourceschemahasanENROLLMENTtable,andweusethe add_enrollment function created by Rabbit­in­a­Hat to create two entries with different values for the MEMBER_ID and GENDER_OF_MEMBER fields. Finally, we specify the expectation that after the ETL two entries should exist in the PERSON table with variousexpectedvalues. NotethattheENROLLMENTtablehasmanyotherfields,butwedonotcaremuchabout whatvaluestheseotherfieldshaveinthecontextofthistest. However,leavingthoseval­ ues(e.g.dateofbirth)emptymightcausetheETLtodiscardtherecordorthrowanerror. Toovercomethisproblemwhilekeepingthetestcodeeasytoread,the add_enrollment\n",
      "page text: 296 Chapter 15. Data Quality function will assign default values (the most prevalent values as observed in the White Rabbitscanreport)tofieldvaluesthatarenotexplicitlyspecifiedbytheuser. SimilarunittestscanbecreatedforallotherlogicinanETL,typicallyresultinginhun­ dredsoftests. Whenwearedonedefiningthetest,wecanusetheframeworktogenerate twosetsofSQLstatements,onetocreatethefakesourcedata,andonetocreatethetests ontheETL­eddata: insertSql <- generateInsertSql (databaseSchema = \"source_schema\" ) testSql <- generateTestSql (databaseSchema = \"cdm_test_schema\" ) TheoverallprocessisdepictedinFigure 15.1. Figure15.1: UnittestinganETL(Extract­Transform­Load)processusingtheRabbit­in­ a­Hattestingframework. The test SQL returns a table that will look like Table 15.2. In this table we see that we passedthetwotestswedefinedearlier. Table15.2: ExampleETLunittestresults. ID Description Status 101 Persongendermappings PASS 101 Persongendermappings PASS ThepoweroftheseunittestsisthatwecaneasilyrerunthemanytimetheETLprocess ischanged.\n",
      "page text: 15.3. Study­Specific Checks 297 15.3 Study-Specific Checks The chapter has so far focused on general DQ checks. Such checks should be executed priortousingthedataforresearch. Sincethesechecksaredoneregardlessoftheresearch questionswerecommendperformingstudy­specificDQassessments. SomeoftheseassessmentscantaketheformofDQrulesthatarespecificallyrelevantfor thestudy. Forexample,wemaywanttoimposearulethatatleast90%oftherecordsfor ourexposureofinterestspecifythelengthofexposure. A standard assessment is to review the concepts that are most relevant for the study in ACHILLES,forexamplethosespecifiedinthestudycohortdefinitions. Suddenchanges over time in the rate with which a code is observed may hint at DQ problems. Some exampleswillbediscussedlaterinthischapter. Another assessment is to review the prevalence and changes in prevalence over time of theresultingcohortsgeneratedusingthecohortdefinitionsdevelopedforthestudy,and see whether these agree with expectations based on external clinical knowledge. For example,exposureofanewdrugshouldbeabsentbeforeintroductiontothemarket,and will likely increase over time after introduction. Similarly, the prevalence of outcomes shouldbeinlinewithwhatisknownoftheprevalenceoftheconditioninthepopulation. If a study is executed across a network of databases, we can compare the prevalence of cohorts across databases. If a cohort is highly prevalent in one database, but is missing in another database, there might be a DQ issue. Note that such an assessment overlaps withthenotionof clinical validity ,asdiscussedinChapter 16;wemayfindunexpected prevalenceinsomedatabasesnotbecauseofDQissues,butbecauseourcohortdefinition isnottrulycapturingthehealthstatesweareinterestedin, orbecausethesehealthstate rightlyvaryoverdatabasesthatcapturedifferentpatientpopulations. 15.3.1 Checking Mappings Onepossiblesourceoferrorthatfirmlyfallsunderourcontrolisthemappingofsource codes to Standard Concepts. The mappings in the Vocabulary are meticulously crafted, anderrorsinthemappingthatarenotedbymembersofthecommunityarereportedinthe Vocabulary issue tracker1and fixed in future releases. Nevertheless, it is impossible to completelycheckallmappingsbyhand,anderrorslikelystillexist. Whenperforminga study,wethereforerecommendreviewingthemappingsforthoseconceptsmostrelevant tothestudy. Fortunately,thiscanbeachievedquiteeasilybecauseintheCDMwestore notonlytheStandardConcepts,butalsothesourcecodes. Wecanreviewboththesource codesthatmaptotheconceptsusedinthestudy,aswellasthosethatdon’t. Onewaytoreviewthesourcecodesthatmapistousethe checkCohortSourceCodes function in the MethodEvaluation R package. This function uses a cohort definition as createdbyATLASasinput,andforeachconceptsetusedinthecohortdefinitionitchecks which source codes map to the concepts in the set. It also computes the prevalence of 1https://github.com/OHDSI/Vocabulary­v5.0/issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 323/464 [00:03<00:01, 81.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 298 Chapter 15. Data Quality these codes over time to help identify temporal issues associated with specific source codes. The example output in Figure 15.2shows a (partial) breakdown of a concept set called “Depressive disorder.” The most prevalent concept in this concept set in the databaseofinterestisconcept 440383(“Depressivedisorder”). Weseethatthreesource codes in the database map to this concept: ICD­9 code 3.11, and ICD­10 codes F32.8 andF32.89. Ontheleftweseethattheconceptasawholefirstshowsagradualincrease over time, but then shows a sharp drop. If we look at the individual codes, we see that this drop can be explained by the fact that the ICD­9 code stops being used at the time of the drop. Even though this is the same time the ICD­10 codes start being used, the combined prevalence of the ICD­10 codes is much smaller than that of the ICD­9 code. ThisspecificexamplewasduetothefactthattheICD­10codeF32.9(“Majordepressive disorder, single episode, unspecified”) should have also mapped to the concept. This problemhassincebeenresolvedintheVocabulary. Figure15.2: ExampleoutputofthecheckCohortSourceCodesfunction. Even though the previous example demonstrates a chance finding of a source code that was not mapped, in general identifying missing mappings is more difficult than checking mappings that are present. It requires knowing which source codes should map but don’t. A semi­automated way to perform this assessment is to use the findOrphanSourceCodes functioninthe MethodEvaluation Rpackage. Thisfunction allows one to search the vocabulary for source codes using a simple text search, and it checkswhetherthesesourcecodesmaptoaspecificconceptortooneofthedescendants ofthatconcept. Theresultingsetofsourcecodesissubsequentlyrestrictedtoonlythose that appear in the CDM database at hand. For example, in a study the concept “Gan­ grenousdisorder”( 439928)andallofitsdescendantswasusedtofindalloccurrencesof gangrene. To evaluate whether this truly includes all source codes indicating gangrene, several terms (e.g. “gangrene”) were used to search the descriptions in the CONCEPT and SOURCE_TO_CONCEPT_MAP tables to identify source codes. An automated search is then used to evaluate whether each gangrene source code appearing in the\n",
      "page text: 15.4. ACHILLES in Practice 299 data indeed directly or indirectly (through ancestry) maps to the concept “Gangrenous disorder.” TheresultofthisevaluationisshowninFigure 15.3,revealingthattheICD­10 code J85.0 (“Gangrene and necrosis of lung”) was only mapped to concept 4324261 (“Pulmonarynecrosis”),whichisnotadescendantof“Gangrenousdisorder.” Figure15.3: Exampleorphansourcecode. 15.4 ACHILLES in Practice HerewewilldemonstratehowtorunACHILLESagainstadatabaseintheCDMformat. WefirstneedtotellRhowtoconnecttotheserver. ACHILLESusesthe DatabaseCon­ nectorpackage, which provides a function called createConnectionDetails . Type ?createConnectionDetails forthespecificsettingsrequiredforthevariousdatabase management systems (DBMS). For example, one might connect to a PostgreSQL databaseusingthiscode: library(Achilles) connDetails <- createConnectionDetails (dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) cdmDbSchema <- \"my_cdm_data\" cdmVersion <- \"5.3.0\" Thelasttwolinesdefinethe cdmDbSchema variable,aswellastheCDMversion. Wewill usetheselater totellR wherethedata inthe CDMformatlive, and whatversion CDM isused. NotethatforMicrosoftSQLServer,databaseschemasneedtospecifyboththe databaseandtheschema,soforexample cdmDbSchema <- \"my_cdm_data.dbo\" . Next,werunACHILLES: result <- achilles (connectionDetails, cdmDatabaseSchema = cdmDbSchema,\n",
      "page text: 300 Chapter 15. Data Quality resultsDatabaseSchema = cdmDbSchema, sourceName = \"My database\" , cdmVersion = cdmVersion) This function will create several tables in the resultsDatabaseSchema , which we’ve setheretothesamedatabaseschemaastheCDMdata. We can view the ACHILLES database characterization. This can be done by pointing ATLAStotheACHILLESresultsdatabases,orbyexportingtheACHILLESresultstoa setofJSONfiles: exportToJson (connectionDetails, cdmDatabaseSchema = cdmDatabaseSchema, resultsDatabaseSchema = cdmDatabaseSchema, outputPath = \"achillesOut\" ) The JSON files will be written to the achillesOut sub­folder, and can be used together with the AchillesWeb web application to explore the results. For example, Figure 15.4 showstheACHILLESdatadensityplot. Thisplotshowsthatthebulkofthedatastartsin 2005. However,therealsoappeartobeafewrecordsfromaround1961,whichislikely anerrorinthedata. Figure15.4: ThedatadensityplotintheACHILLESwebviewer. Another example is shown in Figure 15.5, revealing a sudden change in the prevalence ofadiabetesdiagnosiscode. Thischangecoincideswithchangesinthereimbursement rulesinthisspecificcountry,leadingtomorediagnosesbutprobablynotatrueincrease inprevalenceintheunderlyingpopulation.\n",
      "page text: 15.5. Data Quality Dashboard in Practice 301 Figure15.5: MonthlyrateofdiabetescodedintheACHILLESwebviewer. 15.5 Data Quality Dashboard in Practice Here we will demonstrate how to run the Data Quality Dashboard against a database in the CDM format. We do this by executing a large set of checks against the CDM connection described in Section 15.4. For now the DQD supports only CDM v5.3.1 so before connecting be sure your database is in the correct version. As with ACHILLES weneedtocreatethevariable cdmDbSchema totellRwheretolookforthedata. cdmDbSchema <- \"my_cdm_data.dbo\" Next,weruntheDashboard… DataQualityDashboard ::executeDqChecks (connectionDetails = connectionDetails, cdmDatabaseSchema = cdmDbSchema, resultsDatabaseSchema = cdmDbSchema, cdmSourceName = \"My database\" , outputFolder = \"My output\" ) Theabovefunctionwillexecuteallavailabledataqualitychecksontheschemaspecified. It will then write a table to the resultsDatabaseSchema which we have here set to the same schema as the CDM. This table will include all information about each check runincludingtheCDMtable,CDMfield,checkname,checkdescription,Kahncategory and subcategory, number of violating rows, the threshold level, and whether the check passesorfails,amongothers. InadditiontoatablethisfunctionalsowritesaJSONfile to the location specified as the outputFolder . Using this JSON file we can launch a webviewertoinspecttheresults. viewDqDashboard (jsonPath) Thevariable jsonPath shouldbethepathtotheJSONfilecontainingtheresultsofthe\n",
      "page text: 302 Chapter 15. Data Quality Dashboard,locatedinthe outputFolder specifiedwhencallingthe executeDqChecks functionabove. WhenyoufirstopentheDashboardyouwillbepresentedwiththeoverviewtable,asseen inFigure15.6. ThiswillshowyouthetotalnumberofchecksrunineachKahncategory broken out by context, the number and percent that pass in each, as well as the overall passrate. Figure15.6: OverviewofDataQualityChecksintheDataQualityDashboard. Clickingon Resultsintheleft­handmenuwilltakeyoutothedrilldownresultsforeach check that was run (Figure 15.7). In this example, the table showing a check run to determine the completeness of individual CDM tables, or, the number and percent of persons in the CDM that have at least one record in the specified table. In this case the five tables listed are all empty which the Dashboard counts as a fail. Clicking on the iconwillopenawindowthatdisplaystheexactquerythatwasrunonyourdata to produce the results listed. This allows for easy identification of the rows that were consideredfailuresbytheDashboard. 15.6 Study-Specific Checks in Practice Next,wewillexecuteseveralchecksspecificallyfortheangioedemacohortdefinitionpro­ videdinAppendix B.4. Wewillassumetheconnectiondetailshavebeensetasdescribed in Section 15.4, and that the cohort definition JSON and SQL of the cohort definition havebeensavedinthefiles“cohort.json”and“cohort.sql”,respectively. TheJSONand SQLcanbeobtainedfromtheExporttabintheATLAScohortdefinitionfunction.\n",
      "page text: 15.6. Study­Specific Checks in Practice 303 Figure15.7: DrilldownintoDataQualityChecksintheDataQualityDashboard. library(MethodEvaluation) json <- readChar (\"cohort.json\" ,file.info (\"cohort.json\" )$size) sql <-readChar (\"cohort.sql\" ,file.info (\"cohort.sql\" )$size) checkCohortSourceCodes (connectionDetails, cdmDatabaseSchema = cdmDbSchema, cohortJson = json, cohortSql = sql, outputFile = \"output.html\" ) We can open the output file in a web browser as shown in Figure 15.8. Here we see thattheangioedemacohortdefinitionhastwoconceptsets: “InpatientorERvisit”,and “Angioedema”. Inthisexampledatabasethevisitswerefoundthroughdatabase­specific sourcecodes“ER”and“IP”,thatarenotintheVocabulary,althoughtheyweremapped duringtheETLtostandardconcepts. Wealsoseethatangioedemaisfoundthroughone ICD­9and two ICD­10 codes. Weclearly see the pointin time of the cut­overbetween thetwocodingsystemswhenwelookatthespark­linesfortheindividualcodes,butfor theconceptsetasawholethereisnodiscontinuityatthattime. Next,wecansearchfororphansourcecodes,whicharesourcecodesthatdonotmapto standardconceptcodes. HerewelookfortheStandardConcept“Angioedema,”andthen welookforanycodesandconceptsthathave“Angioedema”oranyofthesynonymswe provideaspartoftheirname:\n",
      "page text: 304 Chapter 15. Data Quality Figure15.8: Sourcecodesusedintheangioedemacohortdefinition. orphans <- findOrphanSourceCodes (connectionDetails, cdmDatabaseSchema = cdmDbSchema, conceptName = \"Angioedema\" , conceptSynonyms = c(\"Angioneurotic edema\" , \"Giant hives\" , \"Giant urticaria\" , \"Periodic edema\" )) View(orphans) code description vocabularyId overallCount T78.3XXS Angioneuroticedema,sequela ICD10CM 508 10002425 Angioedemas MedDRA 0 148774 AngioneuroticEdemaofLarynx CIEL 0 402383003 Idiopathicurticariaand/orangioedema SNOMED 0 232437009 Angioneuroticedemaoflarynx SNOMED 0 10002472 Angioneuroticedema,notelsewhereclassified MedDRA 0 Theonlypotentialorphanfoundthatisactuallyusedinthedatais“Angioneuroticedema, sequela”, which should not be mapped to angioedema. This analysis therefore did not revealanymissingcodes.\n",
      "page text: 15.7. Summary 305 15.7 Summary –Mostobservationalhealthcaredatawerenotcollectedforresearch. –Data quality checks are an integral part of research. Data quality must be assessed to determine whether the data are of sufficient quality for research purposes. –Weshouldassessdataqualityforthepurposeofresearchingeneral,andcrit­ icallyinthecontextofaspecificstudy. –Someaspectsofdataqualitycanbeassessedautomaticallythroughlargesets ofpredefinedrules,forexamplethoseintheDataQualityDashboard. –Other tools exist to evaluate the mapping of codes relevant for a particular study. 15.8 Exercises Prerequisites FortheseexercisesweassumeR,R­StudioandJavahavebeeninstalledasdescribedin Section8.4.5. Also required are the SqlRender,DatabaseConnector ,ACHILLES , and Eunomiapackages,whichcanbeinstalledusing: install.packages (c(\"SqlRender\" ,\"DatabaseConnector\" ,\"remotes\" )) remotes::install_github (\"ohdsi/Achilles\" ) remotes::install_github (\"ohdsi/DataQualityDashboard\" ) remotes::install_github (\"ohdsi/Eunomia\" ,ref =\"v1.0.0\" ) TheEunomiapackageprovidesasimulateddatasetintheCDMthatwillruninsideyour localRsession. Theconnectiondetailscanbeobtainedusing: connectionDetails <- Eunomia::getEunomiaConnectionDetails () TheCDMdatabaseschemais“main”. Exercise 15.1. ExecuteACHILLESagainsttheEunomiadatabase. Exercise 15.2. ExecutetheDataQualityDashboardagainsttheEunomiadatabase. Exercise 15.3. ExtracttheDQDlistofchecks. SuggestedanswerscanbefoundinAppendix E.10.\n",
      "page text: 306 Chapter 15. Data Quality\n",
      "page text: Chapter 16 Clinical Validity Chapter leads: Joel Swerdel, Seng Chan You, Ray Chen & Patrick Ryan Thelikelihoodoftransformingmatterintoenergyissomethingakintoshoot­ ingbirdsinthedarkinacountrywherethereareonlyafewbirds. Einstein, 1935 The vision of OHDSI is “A world in which observational research produces a compre­ hensive understanding of health and disease.” Retrospective designs provide a vehicle forresearchusingexistingdatabutcanberiddledwiththreatstovariousaspectsofvalid­ ityasdiscussedinChapter 14. Itisnoteasytoisolateclinicalvalidityfromqualityofdata and statistical methodology, but here we will focus on three aspects in terms of clinical validity: Characteristicsofhealthcaredatabases,Cohortvalidation,andGeneralizability of the evidence. Let’s go back to the example of population­level estimation (Chapter 12). We tried to answer the question “Do ACE inhibitors cause angioedema compared to thiazide or thiazide­like diuretics?” In that example, we demonstrated that ACE in­ hibitorscausedmoreangioedemathanthiazideorthiazide­likediuretics. Thischapteris dedicatedtoanswerthequestion: “Towhatextentdoestheanalysisconductedmatchthe clinicalintention?” 16.1 Characteristics of Health Care Databases It is possible that what we found is the relationship between prescription of ACE in­ hibitor and angioedema rather than the relationship between useof ACE inhibitor and angioedema. We’ve already discussed data quality in the previous chapter ( 15). The quality of the converted database into the Common Data Model (CDM) cannot exceed theoriginaldatabase. Hereweareaddressingthecharacteristicsofmosthealthcareutiliza­ tiondatabases. ManydatabasesusedinOHDSIoriginatedfromadministrativeclaimsor electronichealthrecords(EHR).ClaimsandEHRhavedifferentdatacaptureprocesses, neitherofwhichhasresearchasaprimaryintention. Dataelementsfromclaimsrecords arecapturedforthepurposeofreimbursement,financialtransactionsbetweenclinicians 307\n",
      "page text: 308 Chapter 16. Clinical Validity andpayerswherebyservicesprovidedtopatientsbyprovidersaresufficientlyjustifiedto enableagreementonpaymentsbytheresponsibleparties. DataelementsinEHRrecords are captured to support clinical care and administrative operations, and they commonly onlyreflecttheinformationthatproviderswithinagivenhealthsystemfeelarenecessary todocumentthecurrentserviceandprovidenecessarycontextforanticipatedfollow­up care within their health system. They may not represent a patient’s complete medical historyandmaynotintegratedatafromacrosshealthsystems. Togeneratereliableevidencefromobservationaldata,itisusefulforaresearchertoun­ derstand the journey that the data undergoes from the moment that a patient seeks care throughthemomentthatthedatareflectingthatcareareusedinananalysis. Asanexam­ ple,“drugexposure”canbeinferredfromvarioussourcesofobservationaldata,including prescriptionswrittenbyclinicians,pharmacydispensingrecords,hospitalproceduralad­ ministrations,orpatientself­reportedmedicationhistory. Thesourceofdatacanimpact ourlevelofconfidenceintheinferencewedrawaboutwhichpatientsdidordidnotuse thedrug,aswellaswhenandforhowlong. Thedatacaptureprocesscanresultinunder­ estimationofexposure,suchasiffreesamplesorover­thecounterdrugsarenotrecorded, orover­estimationofexposure,suchasifapatientdoesn’tfilltheprescriptionwrittenor doesn’t adherently consume the prescription dispensed. Understanding the potential bi­ asesinexposureandoutcomeascertainment,andmoreideallyquantifyingandadjusting forthesemeasurementerrors,canimproveourconfidenceinthevalidityoftheevidence wedrawfromthedatawehaveavailable. 16.2 Cohort Validation Hripcsak and Albers (2017) described that “a phenotype is a specification of an observ­ able,potentiallychangingstateofanorganism,asdistinguishedfromthegenotype,which isderivedfromanorganism’sgeneticmakeup. Thetermphenotypecanbeappliedtopa­ tientcharacteristicsinferredfromelectronichealthrecord(EHR)data. Researchershave beencarryingoutEHRphenotypingsincethebeginningofinformatics,frombothstruc­ tured data and narrative data. The goal is to draw conclusions about a target concept based on raw EHR data, claims data, or other clinically relevant data. Phenotype algo­ rithms–i.e., algorithmsthatidentifyorcharacterizephenotypes–maybegeneratedby domain exerts and knowledge engineers, including recent research in knowledge engi­ neeringorthroughdiverseformsofmachinelearning…togeneratenovelrepresentations ofthedata.” Thisdescriptionhighlightsseveralattributesusefultoreinforcewhenconsideringclinical validity: 1)itmakesitclearthatwearetalkingaboutsomethingthatisobservable(and therefore possible to be captured in our observational data); 2) it includes the notion of time in the phenotype specification (since a state of a person can change); 3) it draws a distinction between the phenotype as the desired intent vs. the phenotype algorithm, whichistheimplementationofthedesiredintent. OHDSIhasadoptedtheterm“cohort”todefinethesetofpersonssatisfyingoneormore\n",
      "page text: 16.2. Cohort Validation 309 inclusioncriteriaforadurationoftime. A“cohortdefinition”representsthelogicneces­ sary to instantiate a cohort against an observational database. In this regard, the cohort definition(orphenotypealgorithm)isusedtoproduceacohort,whichisintendedtorep­ resent the phenotype, being the persons who belong to the observable clinical state of interest. Mosttypesofobservationalanalyses,includingclinicalcharacterization,population­level effect estimation, and patient­level prediction, require one or more cohorts to be estab­ lishedaspartofthestudyprocess. Toevaluatethevalidityoftheevidenceproducedby theseanalyses,onemustconsiderthisquestionforeachcohort: towhatextentdotheper­ sonsidentifiedinthecohortbasedonthecohortdefinitionandtheavailableobservational dataaccuratelyreflectthepersonswhotrulybelongtothephenotype? To return to the population­level estimation example (Chapter 12) “Do ACE inhibitors causeangioedemacomparedtothiazideorthiazide­likediuretics?”,wemustdefinethree cohorts: a target cohort of persons who are new users of ACE inhibitors, a comparator cohortofpersonswhoarenewusersofthiazidediuretics,andanoutcomecohortofper­ sons who develop angioedema. How confident are we that all use of ACE inhibitors or thiazidediureticsiscompletelycaptured,suchthat“newusers”canbeidentifiedbythe first observed exposure, without concern of prior (but unobserved) use? Can we com­ fortablyinferthatpersonswhohaveadrugexposurerecordforACEinhibitorswerein factexposedtothedrug,andthosewithoutadrugexposurewereindeedunexposed? Is thereuncertaintyindefiningthedurationoftimethatapersonisclassifiedinthestateof “ACEinhibitoruse,”eitherwheninferringcohortentryatthetimethedrugwasstartedor cohortexitwhenthedrugwasdiscontinued? Havepersonswithaconditionoccurrence record of “Angioedema” actually experienced rapid swelling beneath the skin, differen­ tiated from other types of dermatologic allergic reactions? What proportion of patients whodevelopedangioedemareceivedmedicalattentionthatwouldgiverisetotheobserva­ tionaldatausedtoidentifytheseclinicalcasesbasedonthecohortdefinition? Howwell can the angioedema events which are potentially drug­induced be disambiguated from theeventsknowntobecausedbyotheragents,suchasfoodallergyorviralinfection? Is disease onset sufficiently well captured that we have confidence in drawing a temporal association between exposure status and outcome incidence? Answering these types of questionsisattheheartofclinicalvalidity. In this chapter, we will discuss the methods for validating cohort definitions. We first describethemetricsusedtomeasurethevalidityofacohortdefinition. Next,wedescribe two methods to estimate these metrics: 1) clinical adjudication through source record verification, and 2) PheValuator, a semi­automated method using diagnostic predictive modeling. 16.2.1 Cohort Evaluation Metrics Oncethecohortdefinitionforthestudyhasbeendetermined,thevalidityofthedefinition can be evaluated. A common approach to assess validity is by comparing some or all persons in a defined cohort to a reference ‘gold standard’ and expressing the results in\n",
      "page text: 310 Chapter 16. Clinical Validity a confusion matrix, a two­by­two contingency table that stratifies persons according to their gold standard classification and qualification within the cohort definition. Figure 16.1showstheelementsoftheconfusionmatrix. Figure16.1: Confusionmatrix. Thetrueandfalseresultsfromthecohortdefinitionaredeterminedbyapplyingthedefi­ nitiontoagroupofpersons. Thoseincludedinthedefinitionareconsideredpositivefor thehealthconditionandarelabeled“True.” Thosepersonsnotincludedinthecohortdef­ initionareconsiderednegativeforthehealthconditionandarelabeled“False”. Whilethe absolutetruthofaperson’sheathstateconsideredinthecohortdefinitionisverydifficult to determine, there are multiple methods to establish a reference gold standard, two of whichwillbedescribedlaterinthechapter. Regardlessofthemethodused,thelabeling ofthesepersonsisthesameasdescribedforthecohortdefinition. Inadditiontoerrorsinthebinaryindicationofphenotypedesignation,thetimingofthe health condition may also be incorrect. For example, while the cohort definition may correctlylabelapersonasbelongingtoaphenotype,thedefinitionmayincorrectlyspecify thedateandtimewhenapersonwithouttheconditionbecameapersonwiththecondition. Thiserrorwouldaddbiastostudiesusingsurvivalanalysisresults,e.g.,hazardratios,as aneffectmeasure. The next step in the process is to assess the concordance of the gold standard with the cohort definition. Those persons that are labeled by both the gold standard method and thecohortdefinitionas“True”arecalled“TruePositives.” Thosepersonsthatarelabeled bythegoldstandardmethodas“False”andbythecohortdefinitionas“True”arecalled “FalsePositives,”i.e.,thecohortdefinitionmisclassifiedthesepersonsashavingthecon­ ditionwhentheydonot. Thosepersonsthatarelabeledbyboththegoldstandardmethod andthecohortdefinitionas“False”arecalled“TrueNegatives.” Thosepersonsthatare labeledbythegoldstandardmethodas“True”andbythecohortdefinitionas“False”are called “False Negatives,” i.e., the cohort definition incorrectly classified these persons as not having the condition, when it fact they do belong to the phenotype. Using the counts from the four cells in the confusion matrix, we can quantify the accuracy of the cohortdefinitioninclassifyingphenotypestatusinagroupofpersons. Therearestandard performancemetricsformeasuringcohortdefinitionperformance: 1.Sensitivity of the cohort definition – what proportion of the persons who truly belong to the phenotype in the population were correctly identified to have the healthoutcomebasedonthecohortdefinition? Thisisdeterminedbythefollowing formula:\n",
      "page text: 16.3. Source Record Verification 311 Sensitivity=TruePositives/(TruePositives+FalseNegatives) 2.Specificity of the cohort definition –whatproportionofthepersonswhodonot belongtothephenotypeinthepopulationwerecorrectlyidentifiedtonothavethe healthoutcomebasedonthecohortdefinition? Thisisdeterminedbythefollowing formula: Specificity=TrueNegatives/(TrueNegatives+FalsePositives) 3.Positive predictive value (PPV) of the cohort definition – what proportion of thepersonsidentifiedbythecohortdefinitiontohavethehealthconditionactually belongtothephenotype? Thisisdeterminedbythefollowingformula: PPV=TruePositives/(TruePositives+FalsePositives) 4.Negative predictive value (NPV) of the cohort definition –whatproportionofthe personsidentifiedbythecohortdefinitiontonothavethehealthconditionactually didnotbelongtothephenotype? Thisisdeterminedbythefollowingformula: NPV=TrueNegatives/(TrueNegatives+FalseNegatives) Perfect scores for these measures are 100%. Due to the nature of observational data, perfect scores are usually far from the norm. Rubbo et al. (2015) reviewed studies val­ idating cohort definitions for myocardial infarction. Of the 33 studies they examined, onlyonecohortdefinitioninonedatasetobtainedaperfectscoreforPPV.Overall,31of the 33 studies reported PPVs ≥ 70%. They also found, however, that of the 33 studies only 11 reported sensitivity and 5 reported specificity. PPV is a function of sensitivity, specificity, and prevalence. Datasets with different values for prevalence will produce differentvaluesforPPVwithsensitivityandspecificityheldconstant. Withoutsensitiv­ ityandspecificity,correctingforbiasduetoimperfectcohortdefinitionsisnotpossible. Additionally, the misclassification of the health condition may be differential, meaning thecohortdefinitionperformsdifferentlyononegroupofpersonsrelativetothecompar­ ison group, or non­differentially, when the cohort definition performs similarly on both comparisongroups. Priorcohortdefinitionvalidationstudieshavenottestedforpotential differentialmisclassification,eventhoughitcanleadtostrongbiasineffectestimates. Oncetheperformancemetricshavebeenestablishedforthecohortdefinition,thesemay be used to adjust the results for studies using these definitions. In theory, adjusting study results for these measurement error estimates has been well established. In prac­ tice,though,becauseofthedifficultyinobtainingtheperformancecharacteristics,these adjustmentsarerarelyconsidered. Themethodsusedtodeterminethegoldstandardare describedintheremainderofthissection. 16.3 Source Record Verification A common method used to validate cohort definitions has been clinical adjudication throughsourcerecordverification: athoroughexaminationofaperson’srecordsbyone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████                                       | 332/464 [00:03<00:01, 77.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 312 Chapter 16. Clinical Validity or more domain experts with sufficient knowledge to competently classify the clinical conditionorcharacteristicofinterest. Chartreviewgenerallyfollowsthefollowingsteps: 1.Obtain permission from local institutional review board (IRB) and/or persons as neededtoconductstudyincludingchartreview. 2.Generate cohort using cohort definition to be evaluated. Sample a subset of the personstomanuallyreviewifthereareinsufficientresourcestoadjudicatetheentire cohort. 3.Identify one or more persons with sufficient clinical expertise to review person records. 4.Determineguidelinesforadjudicatingwhetherapersonispositiveornegativefor thedesiredclinicalconditionorcharacteristic. 5.Clinicalexpertsreviewandadjudicateallavailabledataforthepersonswithinthe sampletoclassifyeachpersonastowhethertheybelongtothephenotypeornot. 6.Tabulatepersonsaccordingtothecohortdefinitionclassificationandclinicaladju­ dicationclassificationintoaconfusionmatrix,andcalculatetheperformancechar­ acteristicspossiblefromthedatacollected. Results from a chart review are typically limited to the evaluation of one performance characteristic, positive predictive value (PPV). This is because the cohort definition un­ der evaluation only generates persons that are believed to have the desired condition or characteristics. Therefore,eachpersoninthesampleofthecohortisclassifiedaseither a true positive or false positive based on the clinical adjudication. Without knowledge ofallpersonsinthephenotypeintheentirepopulation(includingthosenotidentifiedby thecohortdefinition),itisnotpossibletoidentifythefalsenegatives,andtherebyfillin theremainderoftheconfusionmatrixtogeneratetheremainingperformancecharacteris­ tics. Potentialmethodsofidentifyingallpersonsinthephenotypeacrossthepopulation includechartreviewoftheentiredatabase,whichisgenerallynotfeasibleunlesstheover­ allpopulationissmall,ortheutilizationofcomprehensiveclinicalregistriesinwhichall true cases have already been flagged and adjudicated, such as tumor registries (see ex­ ample below). Alternatively, one can sample persons who do not qualify for the cohort definitiontoproduceasubsetofpredictednegatives,andthenrepeatingsteps3­6ofthe chartreviewabovetocheckwhetherthesepatientsaretrulylackingtheclinicalcondition orcharacteristicofinterestcanidentifytruenegativesorfalsenegatives. Thiswouldal­ lowtheestimationofnegativepredictivevalue(NPV),andifanappropriateestimateof thephenotypeprevalenceisavailable,thensensitivityandspecificitycanbeestimated. There are a number of limitations to clinical adjudication through source record verifi­ cation. As alluded to earlier, chart review can be a very time­consuming and resource­ intensiveprocess, evenjustfortheevaluationofasinglemetricsuchasPPV.Thislimi­ tationsignificantlyimpedesthepracticalityofevaluatinganentirepopulationtofillout a complete confusion matrix. In addition, multiple steps in the above process have the potentialtobiastheresultsofthestudy. Forexample,ifrecordsarenotequallyaccessible intheEHR,ifthereisnoEHR,orifindividualpatientconsentisrequired,thenthesubset underevaluationmaynotbetrulyrandomandcouldintroducesamplingorselectionbias. In addition, manual adjudication is susceptible to human error or misclassification and\n",
      "page text: 16.3. Source Record Verification 313 therebymaynotrepresentaperfectlyaccuratemetric. Therecanoftenbedisagreement betweenclinicaladjudicatorsduetothedataintheperson’srecordbeingvague,subjec­ tive, or of low quality. In many studies, the process involves a majority­rules decision for consensus which yields a binary classification for persons that does not reflect the inter­raterdiscordance. 16.3.1 Example of Source Record Verification An example of the process to conduct a cohort definition validation using chart review is provided from a study by the Columbia University Irving Medical Center (CUIMC), whichvalidatedacohortdefinitionformultiplecancersaspartofafeasibilitystudyforthe NationalCancerInstitute(NCI).Thestepsusedtoconductthevalidationfortheexample ofoneofthesecancers—prostatecancer—areasfollows: 1.Submitted proposal and obtained IRB consent for OHDSI cancer phenotyping study. 2.Developedacohortdefinitionforprostatecancer: UsingATHENAandATLASto explore the vocabulary, we created a cohort definition to include all patients with aconditionoccurrenceforMalignantTumorofProstate(conceptID4163261),ex­ cludingSecondaryNeoplasmofProstate(conceptID4314337)orNon­Hodgkin’s LymphomaofProstate(conceptID4048666). 3.GeneratedcohortusingATLASandrandomlyselected100patientsformanualre­ view,mappingeachPERSON_IDbacktopatientMRNusingmappingtables. 100 patientswere selectedin orderto achieveour desiredlevel ofstatistical precision fortheperformancemetricofPPV. 4.ManuallyreviewedrecordsinthevariousEHRs—bothinpatientandoutpatient— inordertodeterminewhethereachpersonintherandomsubsetwasatrueorfalse positive. 5.Manual review and clinical adjudication were performed by one physician (although ideally in future more rigorous validation studies would be done by a highernumberofreviewerstoassessforconsensusandinter­raterreliability). 6.Determinationofareferencestandardwasbasedonclinicaldocumentation,pathol­ ogyreports,labs,medicationsandproceduresasdocumentedintheentiretyofthe availableelectronicpatientrecord. 7.Patients were labeled as 1) prostate cancer 2) no prostate cancer or 3) unable to determine. 8.AconservativeestimateofPPVwascalculatedusingthefollowing: prostatecan­ cer/(noprostatecancer+unabletodetermine). 9.Then,usingthetumorregistryasanadditionalgoldstandardtoidentifyareference standardacrosstheentireCUIMCpopulation,wecountedthenumberofpersonsin thetumorregistrywhichwereandwerenotaccuratelyidentifiedbythecohortdef­ inition,whichallowedustoestimatesensitivityusingthesevaluesastruepositives andfalsenegatives. 10.Using the estimated sensitivity, PPV, and prevalence, we could then estimate specificity for this cohort definition. As noted previously, this process was time­\n",
      "page text: 314 Chapter 16. Clinical Validity consuming and labor­intensive, as each cohort definition had to be individually evaluated through manual chart review as well as correlated with the CUIMC tumor registry in order to identify all performance metrics. The IRB approval process itself took weeks despite an expedited review while obtaining access to thetumorregistry,andtheprocessofmanualchartreviewitselftookafewweeks longer. Areviewofvalidationeffortsformyocardialinfarction(MI)cohortdefinitionsby Rubbo etal.(2015)foundthattherewassignificantheterogeneityinthecohortdefinitionsused in the studies as well as in the validation methods and the results reported. The authors concludedthatforacutemyocardialinfarctionthereisnogoldstandardcohortdefinition available. They noted that the process was both costly and time­consuming. Due to that limitation, most studies had small sample sizes in their validation leading to wide variations in the estimates for the performance characteristics. They also noted that in the 33 studies, while all the studies reported positive predictive value, only 11 studies reported sensitivity and only five studies reported specificity. As mentioned previously, withoutestimatesofsensitivityandspecificity,statisticalcorrectionformisclassification biascannotbeperformed. 16.4 Phe Valuator The OHDSI community has developed a different approach to constructing a gold stan­ dardbyusingdiagnosticpredictivemodels. ( Swerdeletal. ,2019)Thegeneralideaisto emulatetheascertainmentofthehealthoutcomesimilartothewayclinicianswouldina sourcerecordvalidation,butinanautomatedwaythatcanbeappliedatscale. Thetool hasbeendevelopedasanopen­sourceRpackagecalledPheValuator.1PheValuatoruses functionsfromthePatientLevelPredictionpackage. Theprocessisasfollows: 1.Createanextremelyspecific(“ xSpec”)cohort: Determineasetofpersonswitha veryhighlikelihoodofhavingtheoutcomeofinteresttobeusedasnoisypositive labelswhentrainingadiagnosticpredictivemodel. 2.Create an extremely sensitive (“ xSens”) cohort: Determine a set of persons that shouldincludeanyonewhocouldpossiblehavetheoutcome. Thiscohortwillbe used to identify its inverse: the set of people we are confident do not have the outcome,tobeusedasnoisynegativelabelswhentrainingadiagnosticpredictive model. 3.FitapredictivemodelusingthexSpecandxSenscohort: AsdescribedinChapter 13, we fit a model using a wide array of patient features as predictors, and aim to predict whether a person belongs to the xSpec cohort (those we believe have theoutcome)ortheinverseofthexSenscohort(thosewebelievedonothavethe outcome). 1https://github.com/OHDSI/PheValuator\n",
      "page text: 16.4. PheValuator 315 4.Applythefittedmodeltoestimatetheprobabilityoftheoutcomeforahold­outset ofpersonswhowillbeusedtoevaluatecohortdefinitionperformance: Thesetof predictorsfromthemodelcanbeappliedtoaperson’sdatatoestimatethepredicted probabilitythatthepersonbelongstothephenotype. Weusethesepredictionsasa probabilistic gold standard . 5.Evaluate the performance characteristics of the cohort definitions: We compare thepredictedprobabilitytothebinaryclassificationofacohortdefinition(thetest conditions for the confusion matrix). Using the test conditions and the estimates forthetrueconditions,wecanfullypopulatetheconfusionmatrixandestimatethe entiresetofperformancecharacteristics,i.e.,sensitivity,specificity,andpredictive values. Theprimarylimitationtousingthisapproachisthattheestimationoftheprobabilityof apersonhavingthehealthoutcomeislimitedbythedatainthedatabase. Dependingon thedatabase,importantinformation,suchascliniciannotes,maynotbeavailable. In diagnostic predictive modeling we create a model that discriminates between those withthediseaseandthosewithoutthedisease. AsdescribedinthePatient­LevelPredic­ tionchapter(Chapter 13),predictionmodelsaredevelopedusinga target cohort andan outcome cohort . Thetargetcohortincludespersonswithandwithoutthehealthoutcome; theoutcomecohortidentifiesthosepersonsinthetargetcohortwiththehealthoutcome. ForthePheValuatorprocess,weuseanextremelyspecificcohortdefinition,the“xSpec” cohort,todeterminetheoutcomecohortforthepredictionmodel. ThexSpeccohortuses a definition to find those with a very high probability of having the disease of interest. The xSpec cohort may be defined as those persons who have multiple condition occur­ rence records for the health outcome of interest. For example, for atrial fibrillation, we mayhavepersonswhohave10ormorerecordswiththeatrialfibrillationdiagnosiscode. ForMI,anacuteoutcome,wemayuse5occurrencesofMIandincludetherequirement ofhavingatleasttwooccurrencesfromaninpatientsetting. Thetargetcohortforthepre­ dictive model is constructed from the union of persons with a low likelihood of having thehealthoutcomeofinterestandthosepersonsinthexSpeccohort. Todeterminethose personswithalowlikelihoodofhavingthehealthoutcomeofinterest,wesamplefrom theentiredatabaseandexcludepersonswhohavesomeevidencesuggestiveofbelonging tothephenotype,typicallybyremovingpersonswithanyrecordscontainingtheconcepts usedtodefinethexSpeccohort. Therearelimitationstothismethod. Itispossiblethat thesexSpeccohortpersonsmayhavedifferentcharacteristicsthanotherswiththedisease. Itmayalsobethatthesepersonshadlongerobservationtimeafterinitialdiagnosisthan the average patient. We use LASSO logistic regression to create the prediction model used to generate the probabilistic gold standard. ( Suchard et al. ,2013) This algorithm produces a parsimonious model and typically removes many of the collinear covariates which may be present across the dataset. In the current version of the PheValuator soft­ ware,outcomestatus(yes/no)isevaluatedbasedonalldataforaperson(allobservation time),anddoesnotevaluatetheaccuracyofthecohortstartdate.\n",
      "page text: 316 Chapter 16. Clinical Validity 16.4.1 Example Validation By Phe Valuator WemayusePheValuatortoassessthecompleteperformancecharacteristicsforacohort definitiontobeusedinastudywhereitisnecessarytodeterminethosepersonswhohave hadanacutemyocardialinfarction. ThefollowingarethestepsfortestingcohortdefinitionsforMIusingPheValuator: Step 1: Define the xSpec Cohort Determine those with MI with a high probability. We required a condition occurrence record with a concept for myocardial infarction or any of its descendants, with one or moreoccurrencesofMIrecordedfromahospitalin­patientvisitwithin5days,and4or moreoccurrencesofMIinthepatientrecordwithin365days. Figure 16.2illustratesthis cohortdefinitionforMIinATLAS. Step 2: Define the xSens Cohort Wethendevelopanextremelysensitivecohort(xSens). Thiscohortmaybedefinedfor MIasthosepersonswithatleastoneconditionoccurrencerecordcontainingamyocardial infarctionconceptatanytimeintheirmedicalhistory. Figure 16.3illustratesthexSens cohortdefinitionforMIinATLAS. Step 3: Fit the Predictive Model Thefunction createPhenoModel developsthediagnosticpredictivemodelforassessing theprobabilityofhavingthehealthoutcomeofinterestintheevaluationcohort. Touse this function, we utilize the xSpec and xSens cohorts developed in Steps 1 and 2. The xSpeccohortwillbeenteredasthe xSpecCohort parameterinthefunction. ThexSens cohortwillbeenteredasthe exclCohort parameterinthefunctiontoindicatethatthose inthexSenscohortshouldbeexcludedfromthetargetcohortusedinthemodelingpro­ cess. Using this exclusion method, we can determine persons with a low likelihood of havingthehealthoutcome. Wemaythinkofthisgroupas“noisynegative”persons,i.e., a group of persons likely negative for the health outcome but allowing for a small pos­ sibilityofincludingsomepersonspositiveforthehealthoutcome. Wemayalsousethe xSenscohortasthe prevCohort parameterinthefunction. Thisparameterisusedinthe processtodetermineanapproximateprevalenceofthehealthoutcomeinthepopulation. Normally,alargerandomsampleofpersonsfromadatabaseshouldproduceapopulation ofpersonswherethepersonswiththeoutcomeofinterestareaboutinproportiontothe prevalenceoftheoutcomeinthedatabase. Usingthemethodwedescribed,wenolonger havearandomsampleofpersonsandneedtore­calibratethepredictivemodelbasedon resettingtheproportionofpersonswiththeoutcometothosewithouttheoutcome. AllconceptsusedtodefinethexSpeccohortmustbeexcludedfromthemodelingprocess. To do this we set the excludedConcepts parameter to the list of concepts used in the xSpec definition. For example, for MI we created a concept set in ATLAS using the concept for Myocardial infarction plus all its descendants. For this example, we would\n",
      "page text: 16.4. PheValuator 317 Figure16.2: Anextremelyspecificcohortdefinition(xSpec)formyocardialinfarction.\n",
      "page text: 318 Chapter 16. Clinical Validity Figure16.3: Anextremelysensitivecohortdefinition(xSens)formyocardialinfarction. settheexcludedConceptsparameterto4329847,theconceptIdforMyocardialinfarction, andwewouldalsosettheaddDescendantsToExcludeparametertoTRUE,indicatingthat anydescendantsoftheexcludedconceptsshouldalsobeexcluded. Thereareseveralparametersthatmaybeusedtospecifythecharacteristicsofthepersons included in the modeling process. We can set the ages of the persons included in the modeling process by setting the lowerAgeLimit to the lower bounds of age desired in the model and the upperAgeLimit to the upper bounds. We may wish to do this if the cohortdefinitionsforaplannedstudywillbecreatedforacertainagegroup. Forexample, ifthecohortdefinitiontobeusedinastudyisforType1diabetesmellitusinchildren,you maywanttolimittheagesusedtodevelopthediagnosticpredictivemodeltoages5to17 yearsoldforexample. Indoingso,wewillproduceamodelwithfeaturesthatarelikely more closely related to the persons selected by the cohort definitions to be tested. We canalso specifywhich sex isincluded in themodel bysetting the genderparameterto theconceptIDforeithermaleorfemale. Bydefault,theparameterissettoincludeboth males and females. This feature may be useful in sex­specific health outcomes such as prostatecancer. Wecansetthetimeframeforpersoninclusionbasedonthefirstvisitin theperson’srecordbysettingthe startDate andendDateparameterstothelowerand upper bounds of the date range, respectively. Finally, the mainPopnCohort parameter maybeusedtospecifyalargepopulationcohortfromwhichallpersonsinthetargetand outcome cohorts will be selected. In most instances this will be set to 0, indicating no limitationonselectingpersonsforthetargetandoutcomecohorts. Theremaybetimes, however, when this parameter is useful for building a better model, possibly in cases where the prevalence of the health outcome is extremely low, perhaps 0.01% or lower. Forexample:\n",
      "page text: 16.4. PheValuator 319 setwd(\"c:/temp\" ) library(PheValuator) connectionDetails <- createConnectionDetails ( dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) phenoTest <- createPhenoModel ( connectionDetails = connectionDetails, xSpecCohort = 10934, cdmDatabaseSchema = \"my_cdm_data\" , cohortDatabaseSchema = \"my_results\" , cohortDatabaseTable = \"cohort\" , outDatabaseSchema = \"scratch.dbo\" ,#should have write access trainOutFile = \"5XMI_train\" , exclCohort = 1770120, #the xSens cohort prevCohort = 1770119, #the cohort for prevalence determination modelAnalysisId = \"20181206V1\" , excludedConcepts = c(312327,314666), addDescendantsToExclude = TRUE, cdmShortName = \"myCDM\", mainPopnCohort = 0,#use the entire person population lowerAgeLimit = 18, upperAgeLimit = 90, gender = c(8507,8532), startDate = \"20100101\" , endDate = \"20171231\" ) In this example, we used the cohorts defined in the “my_results” database, specify­ ing the location of the cohort table (cohortDatabaseSchema, cohortDatabaseTable ­ “my_results.cohort”) and where the model will find the conditions, drug exposures, etc. to inform the model (cdmDatabaseSchema ­ “my_cdm_data”). The persons included in the model will be those whose first visit in the CDM is between January 1, 2010 and December 31, 2017. We are also specifically excluding the concept IDs 312327, 314666, and their descendants which were used to create the xSpec cohort. Their ages at the time of first visit will be between 18 and 90. With the parameters above, the name of the predictive model output from this step will be: “c:/temp/lr_results_5XMI_train_myCDM_ePPV0.75_20181206V1.rds” Step 4: Creating the Evaluation Cohort The function createEvalCohort uses the PatientLevelPrediction package function applyModel toproducealargecohortofpersons, eachwithapredictedprobabilityfor the health outcome of interest. The function requires specifying the xSpec cohort (by setting the xSpecCohort parameter to the xSpec cohort ID). We may also specify the characteristicsofthepersonsincludedintheevaluationcohortaswedidintheprevious\n",
      "page text: 320 Chapter 16. Clinical Validity step. Thiscouldincludespecifyingthelowerandupperageslimits(bysetting, asages, thelowerAgeLimit andupperAgeLimit arguments, respectively), the sex (by setting thegenderparameter to the concept IDs for male and/or female), the starting and endingdates(bysetting,asdates,the startDate andendDatearguments,respectively), and designating a large population from which to select the persons by setting the mainPopnCohort tothecohortIdforthepopulationtouse. Forexample: setwd(\"c:/temp\" ) connectionDetails <- createConnectionDetails ( dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) evalCohort <- createEvalCohort ( connectionDetails = connectionDetails, xSpecCohort = 10934, cdmDatabaseSchema = \"my_cdm_data\" , cohortDatabaseSchema = \"my_results\" , cohortDatabaseTable = \"cohort\" , outDatabaseSchema = \"scratch.dbo\" , testOutFile = \"5XMI_eval\" , trainOutFile = \"5XMI_train\" , modelAnalysisId = \"20181206V1\" , evalAnalysisId = \"20181206V1\" , cdmShortName = \"myCDM\", mainPopnCohort = 0, lowerAgeLimit = 18, upperAgeLimit = 90, gender = c(8507,8532), startDate = \"20100101\" , endDate = \"20171231\" ) In this example, the parameters specify that the function should use the model file: “c:/temp/lr_results_5XMI_train_myCDM_ePPV0.75_20181206V1.rds” to produce the evaluationcohortfile: “c:/temp/lr_results_5XMI_eval_myCDM_ePPV0.75_20181206V1.rds” Themodelandtheevaluationcohortfilescreatedinthisstepwillbeusedintheevaluation ofthecohortdefinitionsprovidedinthenextstep. Step 5: Creating and Testing Cohort Definitions The next step is to create and test the cohort definitions to be evaluated. The desired performancecharacteristicsmaydependontheintendeduseofthecohorttoaddressthe research question of interest. For certain questions, a very sensitive algorithm may be required;othersmayrequireamorespecificalgorithm. Theprocessfordeterminingthe performancecharacteristicsforacohortdefinitionusingPheValuatorisshowninFigure\n",
      "page text: 16.4. PheValuator 321 16.4. InpartAofFigure 16.4,weexaminedthepersonsfromthecohortdefinitiontobetested and found those persons from the evaluation cohort (created in the previous step) who wereincludedinthecohortdefinition(PersonIDs016,019,022,023,and025)andthose from the evaluation cohort who were not included (Person Ids 017, 018, 020, 021, and 024). For each of these included/excluded persons, we had previously determined the probabilityofthehealthoutcomeusingthepredictivemodel(p(O)). We estimated the values for True Positives, True Negatives, False Positives, and False Negativesasfollows(PartBofFigure 16.4): 1.If the cohort definition included a person from the evaluation cohort, i.e., the co­ hortdefinitionconsideredthepersona“positive.” Thepredictedprobabilityforthe health outcome indicated the expected value of the number of counts contributed by that person to the True Positives, and one minus the probability indicated the expectedvalueofthenumberofcountscontributedbythatpersontotheFalsePos­ itives for that person. We added all the expected values of counts across persons togetthetotalexpectedvalue. Forexample,PersonId016hadapredictedproba­ bility of 99% for the presence of the health outcome, 0.99 was added to the True Positives (expected value of counts added 0.99) and 1.00–0.99 = 0.01 was added totheFalsePositives(0.01expectedvalue). Thiswasrepeatedforallthepersons from the evaluation cohort included in the cohort definition (i.e., PersonIds 019, 022,023,and025). 2.Similarly,ifthecohortdefinitiondidnotincludeapersonfromtheevaluationco­ hort, i.e. the cohort definition considered the person a “negative,” one minus the predicted probability for the phenotype for that person was the expected value of countscontributedtoTrueNegativesandwasaddedtoit,and,inparallel,thepre­ dictedprobabilityforthephenotypewastheexpectedvalueofcountscontributed totheFalseNegativesandwasaddedtoit. Forexample, PersonId017hadapre­ dictedprobabilityof1%forthepresenceofthehealthoutcome(and, correspond­ ingly,99%fortheabsenceofthehealthoutcome)and1.00–0.01=0.99wasadded totheTrueNegativesand0.01wasaddedtotheFalseNegatives. Thiswasrepeated forallthepersonsfromtheevaluationcohortnotincludedinthecohortdefinition (i.e.,PersonIds018,020,021,and024). Afteraddingthesevaluesoverthefullsetofpersonsintheevaluationcohort,wefilledthe fourcellsoftheconfusionmatrixwiththeexpectedvaluesofcountsforeachcell,andwe wereabletocreatepointestimatesofthePAperformancecharacteristicslikesensitivity, specificity,andpositivepredictivevalue(Figure1C).Weemphasizethattheseexpected cellcountscannotbeusedtoassessthevarianceoftheestimates,onlythepointestimates. Intheexample,thesensitivity,specificity,PPV,andNPVwere0.99,0.63,0.42,and0.99, respectively. Determining the performance characteristics of the cohort definition uses the func­ tiontestPhenotype . This function uses the output from the prior two steps where\n",
      "page text: 322 Chapter 16. Clinical Validity Figure 16.4: Determining the Performance Characteristics of a cohort definition using PheValuator. p(O) = Probability of outcome; TP = True Positive; FN = False Negative; TN=TrueNegative;FP=FalsePositive.\n",
      "page text: 16.4. PheValuator 323 we created the model and evaluation cohorts. We would set the modelFileName parameter to the RDS file output from createPhenoModel function, in this example, “c:/temp/lr_results_5XMI_train_myCDM_ePPV0.75_20181206V1.rds”. We would set theresultsFileNameparametertotheRDSfileoutputfromcreateEvalCohortfunction,in this example, “c:/temp/lr_results_5XMI_eval_myCDM_ePPV0.75_20181206V1.rds”. To test the cohort definition we wish to use in our study, we set the cohortPheno to the cohort ID for that cohort definition. We can set the phenText parameter to some humanreadabledescriptionforthecohortdefinition, suchas“MIOccurrence, Hospital In­Patient Setting”. We will set the testText parameter to some human readable description for the xSpec definition, such as “5 X MI.” The output from this step is a data frame that contains the performance characteristics for the cohort definition tested. The settings for the cutPoints parameter is a list of values that will be used to develop the performance characteristics results. The performance characteristics are usually calculated using the “expected values” as described in Figure 1. To retrieve the performance characteristics based on the expected values, we include “EV” in the list forthecutPoints parameter. Wemayalsowanttoseetheperformancecharacteristics based on specific predicted probabilities, i.e., cut points. For example, if we wanted to see the performance characteristics of all those at or above a predicted probability of 0.5 were considered positive for the health outcome and all those under a predicted probability of 0.5 were considered negative, we would add “0.5” to the cutPoints parameterlist. Forexample: setwd(\"c:/temp\" ) connectionDetails <- createConnectionDetails ( dbms =\"postgresql\" , server = \"localhost/ohdsi\" , user =\"joe\", password = \"supersecret\" ) phenoResult <- testPhenotype ( connectionDetails = connectionDetails, cutPoints = c(0.1,0.2,0.3,0.4,0.5,\"EV\",0.6,0.7,0.8,0.9), resultsFileName = \"c:/temp/lr_results_5XMI_eval_myCDM_ePPV0.75_20181206V1.rds\" , modelFileName = \"c:/temp/lr_results_5XMI_train_myCDM_ePPV0.75_20181206V1.rds\" , cohortPheno = 1769702, phenText = \"All MI by Phenotype 1 X In-patient, 1st Position\" , order = 1, testText = \"MI xSpec Model - 5 X MI\" , cohortDatabaseSchema = \"my_results\" , cohortTable = \"cohort\" , cdmShortName = \"myCDM\") Inthisexample,awiderangeofpredictionthresholdsareprovided(cutPoints)including the expected value (“EV”). Given that parameter setting, the output from this step will\n",
      "page text: 324 Chapter 16. Clinical Validity provide performance characteristics (i.e, sensitivity, specificity, etc.) at each prediction thresholdaswellasthoseusingtheexpectedvaluecalculations. Theevaluationusesthe prediction information for the evaluation cohort developed in the prior step. The data framesproducedfromthisstepmaybesavedtoacsvfilefordetailedexamination. Using this process, Table 16.1displays the performance characteristics for four cohort definitionsforMIacrossfivedatasets. Foracohortdefinitionsimilartotheoneevaluated by Cutrona and colleagues, “>=1 X HOI, In­Patient”, we found a mean PPV of 67% (range: 59%­74%). Table16.1: Performancecharacteristicsoffourcohortdefinitions using diagnostic condition codes to determine myocardial infarc­ tion on multiple datasets using pheValuator. Sens – Sensitivity ; PPV–PositivePredictiveValue;Spec–Specificity;NPV–Neg­ ativePredictiveValue;DxCode–Diagnosiscodeforthecohort. PhenotypeAlgorithm Database Sens PPV Spec NPV >=1XHOI CCAE 0.761 0.598 0.997 0.999 Optum1862 0.723 0.530 0.995 0.998 OptumGE66 0.643 0.534 0.973 0.982 MDCD 0.676 0.468 0.990 0.996 MDCR 0.665 0.553 0.977 0.985 >=2XHOI CCAE 0.585 0.769 0.999 0.998 Optum1862 0.495 0.693 0.998 0.996 OptumGE66 0.382 0.644 0.990 0.971 MDCD 0.454 0.628 0.996 0.993 MDCR 0.418 0.674 0.991 0.975 >=1XHOI,In­Patient CCAE 0.674 0.737 0.999 0.998 Optum1862 0.623 0.693 0.998 0.997 OptumGE66 0.521 0.655 0.987 0.977 MDCD 0.573 0.593 0.995 0.994 MDCR 0.544 0.649 0.987 0.980 1XHOI,In­Patient,1stPosition CCAE 0.633 0.788 0.999 0.998 Optum1862 0.581 0.754 0.999 0.997 OptumGE66 0.445 0.711 0.991 0.974 MDCD 0.499 0.666 0.997 0.993 MDCR 0.445 0.711 0.991 0.974 16.5 Generalizability of the Evidence While a cohort can be well­defined and fully evaluated within the context of a given observational database, the clinical validity is limited by the extent to which the results are considered generalizable to the target population of interest. Multiple observational studies on the same topic can yield different results, which can be caused by not only\n",
      "page text: 16.6. Summary 325 by their designs and analytic methods, but also bt their choice of data source. Madigan et al.(2013b) demonstrated that choice of database affects the result of observational study. Theysystematicallyinvestigatedheterogeneityintheresultsfor53drug­outcome pairs and two study designs (cohort studies and self­controlled case series) across the 10 observational databases. Even though they held study design constant, substantial heterogeneityineffectestimateswasobserved. AcrosstheOHDSInetwork,observationaldatabasesvaryconsiderablyinthepopulations theyrepresent(e.g.pediatricvs.elderly,privately­insuredemployeesvs.publicly­insured unemployed),thecaresettingswheredataarecaptured(e.g.inpatientvs.outpatient,pri­ maryvs.secondary/specialtycare),thedatacaptureprocesses(e.g.administrativeclaims, EHRs,clinicalregistries),andthenationalandregionalhealthsystemfromwhichcareis based. Thesedifferencescanmanifestasheterogeneityobservedwhenstudyingdisease and the effects of medical interventions and can also influence the confidence we have in the quality of each data source that may contribute evidence within a network study. WhilealldatabaseswithintheOHDSInetworkarestandardizedtotheCDM,itisimpor­ tanttoreinforcethatstandardizationdoesnotreducethetrueinherentheterogeneitythat ispresentacrosspopulations,butsimplyprovidesaconsistentframeworktoinvestigate and better understand the heterogeneity across the network. The OHDSI research net­ workprovidestheenvironmenttoapplythesameanalyticprocessonvariousdatabases across the world, so that researchers can interpret results across multiple data sources while holding other methodological aspects constant. OHDSI’s collaborative approach toopenscienceinnetworkresearch,whereresearchersacrossparticipatingdatapartners worktogetheralongsidethosewithclinicaldomainknowledgeandmethodologistswith analytical expertise, is one way of reaching a collective level of understanding of the clinical validity of data across a network that should serve as a foundation for building confidenceintheevidencegeneratedusingthesedata. 16.6 Summary –Clinical validity can be established by understanding the characteristics of theunderlyingdatasource,evaluatingtheperformancecharacteristicsofthe cohortswithinananalysis, andassessingthegeneralizabilityofthestudyto thetargetpopulationofinterest. –Acohortdefinitioncanbeevaluatedontheextenttowhichpersonsidentified in the cohort based on the cohort definition and the available observational dataaccuratelyreflectthepersonswhotrulybelongtothephenotype. –Cohort definition validation requires estimating multiple performance char­ acteristics,includingsensitivity,specificity,andpositivepredictivevalue,to fullysummarizeandenableadjustmentformeasurementerror. –ClinicaladjudicationthroughsourcerecordverificationandPheValuatorrep­ resenttwoalternativeapproachestoestimatingcohortdefinitionvalidation. –OHDSInetworkstudiesprovideamechanismtoexaminedatasourcehetero­\n",
      "page text: 326 Chapter 16. Clinical Validity geneityandexpandthegeneralizabilityoffindingstoimproveclinicalvalidity ofreal­worldevidence.\n",
      "page text: Chapter 17 Software Validity Chapter lead: Martijn Schuemie Thecentralquestionofsoftwarevalidityis Doesthesoftwaredowhatitisexpectedtodo? Softwarevalidityisanessentialcomponentofevidencequality: onlyifouranalysissoft­ ware does what it is expected to do can we produce reliable evidence. As described in Section17.1.1, it is essential to view every study as a software development exercise, creatinganautomatedscriptthatexecutestheentireanalysis,fromdataintheCommon DataModel(CDM)totheresultssuchasestimates,figuresastables. Itisthisscript,and anysoftwareusedinthisscript,thatmustbevalidated. AsdescribedinSection 8.1,we canwritetheentireanalysisascustomcode,orwecanusethefunctionalityavailablein theOHDSIMethodsLibrary . TheadvantageofusingtheMethodsLibraryisthatgreat carehasalreadybeentakentoensureitsvalidity,soestablishingthevalidityoftheentire analysisbecomeslessburdensome. Inthischapterwefirstdescribebestpracticesforwritingvalidanalysiscode. Afterthis wediscusshowtheMethodslibraryisvalidatedthroughitssoftwaredevelopmentprocess andtesting. 17.1 Study Code Validity 17.1.1 Automation As a Requirement for Reproducibility Traditionally,observationalstudiesareoftenviewedasajourneyratherthanaprocess: a database expert may extract a data set from the database and hand this over to the data analyst,whomayopenitinaspreadsheeteditororotherinteractivetool,andstartworking on the analysis. In the end, a result is produced, but little is preserved of how it came about. The destination of the journey was reached, but it is not possible to retrace the exact steps taken to get there. This practice is entirely unacceptable, both because it is 327\n",
      "page text: 328 Chapter 17. Software Validity not reproducible, but also because it lacks transparency; we do not know exactly what wasdonetoproducetheresult,sowealsocannotverifythatnomistakesweremade. Everyanalysisgeneratingevidencemustthereforebefullyautomated. Byautomatedwe meantheanalysisshouldbeimplementedasasinglescript,andweshouldbeabletoredo theentireanalysisfromdatabaseinCDMformattoresults,includingtablesandfigures, withasinglecommand. Theanalysiscanbeofarbitrarycomplexity,perhapsproducing justasinglecount,orgeneratingempiricallycalibratedestimatesformillionsofresearch questions, but the same principle applies. The script can invoke other scripts, which in turncaninvokeevenlower­levelanalysisprocesses. The analysis script can be implemented in any computer language, although in OHDSI thepreferredlanguageisR.Thankstothe DatabaseConnector Rpackage,wecanconnect directly to the data in CDM format, and many advanced analytics are available through theotherRpackagesinthe OHDSIMethodsLibrary . 17.1.2 Programming Best Practices Observational analyses can become very complex, with many steps needed to produce the final results. This complexity can make it harder to maintain the analysis code and increase the likelihood of making errors, as well as making it harder to notice errors. Luckily,computerprogrammershaveovermanyyearsdevelopedbestpracticesforwrit­ ing code that can deal with complexity, which are easy to read, reuse, adapt, and verify. (Martin,2008)Afulldiscussionofthesebestpracticescouldfillmanybooks. Here,we highlightthesefourimportantprinciples: •Abstraction : Ratherthanwriteasinglelargescriptthatdoeseverything,leadingto so­called“spaghetticode”wheredependenciesbetweenlinesofcodecangofrom anywhere to anywhere (e.g. a value set on line 10 is used in line 1,000), we can organizeourcodeinunitscalled“functions.” Afunctionshouldhaveacleargoal, forexample“takerandomsample,”andoncecreatedwecanthenusethisfunction in our larger script without having to think of the minutiae of what the function does;wecanabstractthefunctiontoasimple­to­understandconcept. •Encapsulation : For abstraction to work, we should make sure that dependencies of a function are minimized and clearly defined. Our example sampling function should have a few arguments (e.g. a dataset and a sample size), and one output (e.g.thesample). Nothingelseshouldinfluencewhatthefunctiondoes. So­called “globalvariables”,variablesthataresetoutsideafunction,arenotargumentsofa function,butareneverthelessusedinthefunction,shouldbeavoided. •Clear naming : Variables and functions should have clear names, making code read almost like natural language. For example, instead of x <- spl(y, 100) , we can write code that reads sampledPatients <- takeSample(patients, sampleSize = 100) . Try to resist the urge to abbreviate. Modern languages havenolimitsonthelengthofvariableandfunctionnames. •Reuse: Oneadvantageofwritingclear,wellencapsulatedfunctionsisthattheycan oftenbereused. Thisnotonlysavestime,italsomeanstherewillbelesscode,so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 351/464 [00:03<00:01, 79.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 17.2. Methods Library Software Development Process 329 lesscomplexityandfeweropportunitiesforerrors. 17.1.3 Code Validation Several approaches exist to verify the validity of software code, but two are especially relevantforcodeimplementinganobservationalstudy: •Code review : Onepersonwritesthecode,andanotherpersonreviewsthecode. •Double coding : Two persons both independently write the analysis code, and af­ terwardstheresultsofthetwoscriptsarecompared. Codereviewhastheadvantagethatitisusuallylesswork,butthedisadvantageisthatthe reviewermightmisssomeerrors. Doublecodingontheotherhandisusuallyverylabor intensive,butitislesslikely,althoughnotimpossible,thaterrorsaremissed. Anotherdis­ advantageofdoublecodingisthattwoseparateimplementations almost always produce differentresults,duetothemanyminorarbitrarychoicesthatneedtomade(e.g.should “until exposure end” be interpreted as including the exposure end date, or not?). As a consequence,thetwosupposedlyindependentprogrammersoftenneedtoworktogether toaligntheiranalyses,thusbreakingtheirindependence. Other software validation practices such as unit testing are less relevant here because a studyistypicallyaone­timeactivitywithhighlycomplexrelationshipsbetweeninput(the data in CDM) and outputs (the study results), making these practices less usable. Note thatthesepracticesareappliedintheMethodsLibrary. 17.1.4 Using the Methods Library TheOHDSI Methods Library provides a large set of functions, allowing most observa­ tional studies to be implemented using only a few lines of code. Using the Methods Li­ brarythereforeshiftsmostoftheburdenofestablishingthevalidityofone’sstudycode to the Library. Validity of the Methods Library is ensured by its software development processandbyextensivetesting. 17.2 Methods Library Software Development Process TheOHDSIMethodsLibraryisdevelopedbytheOHDSIcommunity. Proposedchanges to the Library are discussed in two venues: The GitHub issue trackers (for example the CohortMethodissuetracker1)andtheOHDSIForums.2Bothareopentothepublic. Any member of the community can contribute software code to the Library, however, final approvalofanychangesincorporatedinthereleasedversionsofthesoftwareisperformed by the OHDSI Population­Level Estimation Workgroup leadership (Drs. Marc Suchard andMartijnSchuemie)andOHDSIPatient­LevelPredictionWorkgroupleadership(Drs. PeterRijnbeekandJennaReps)only. 1https://github.com/OHDSI/CohortMethod/issues 2http://forums.ohdsi.org/\n",
      "page text: 330 Chapter 17. Software Validity UserscaninstalltheMethodsLibraryinRdirectlyfromthemasterbranchesintheGitHub repositories,orthroughasystemknownas“drat”thatisalwaysup­to­datewiththemaster branches. AnumberoftheMethodsLibrarypackagesareavailablethroughR’sCompre­ hensiveRArchiveNetwork(CRAN),andthisnumberisexpectedtoincreaseovertime. ReasonablesoftwaredevelopmentandtestingmethodologiesareemployedbyOHDSIto maximizetheaccuracy,reliabilityandconsistencyoftheMethodsLibraryperformance. Importantly, as the Methods Library is released under the terms of the Apache License V2, all source code underlying the Methods Library, whether it be in R, C++, SQL, or JavaisavailableforpeerreviewbyallmembersoftheOHDSIcommunity,andthepublic ingeneral. Thus,allthefunctionalityembodiedwithintheMethodsLibraryissubjectto continuouscritiqueandimprovementrelativetoitsaccuracy,reliabilityandconsistency. 17.2.1 Source Code Management AlloftheMethodsLibrary’ssourcecodeismanagedinthesourcecodeversioncontrol system “git” publicly accessible via GitHub. The OHDSI Methods Library repositories are access­controlled. Anyone in the world can view the source code, and any mem­ beroftheOHDSIcommunitycansubmitchangesthroughso­calledpullrequests. Only theOHDSIPopulation­LevelEstimationWorkgroupandPatient­LevelPredictionWork­ group leadership can approve such requests, make changes to the master branches, and releasenewversions. ContinuouslogsofcodechangesaremaintainedwithintheGitHub repositoriesandreflectallaspectsofchangesincodeanddocumentation. Thesecommit logsareavailableforpublicreview. New versions are released by the OHDSI Population­Level Estimation Workgroup and Patient­LevelPredictionWorkgroupleadershipasneeded. Anewreleasestartsbypush­ ing changes to a master branch with a package version number (as defined in the DE­ SCRIPTIONfileinsidethepackage)thatisgreaterthantheversionnumberoftheprevi­ ousrelease. Thisautomaticallytriggerscheckingandtestingofthepackage. Ifalltests are passed, the new version is automatically tagged in the version control system and the package is automatically uploaded to the OHDSI drat repository. New versions are numberedusingthree­componentversionnumber: •New micro versions (e.g. from 4.3.2 to 4.3.3) indicate bug fixes only. No new functionality,andforwardandbackwardcompatibilityareguaranteed •New minor versions (e.g.from4.3.3to4.4.0)indicateaddedfunctionality. Only backwardcompatibilityisguaranteed •New major versions (e.g.from4.4.0to5.0.0)indicatemajorrevisions. Noguar­ anteesaremadeintermsofcompatibility 17.2.2 Documentation AllpackagesintheMethodsLibraryaredocumentedthroughR’sinternaldocumentation framework. Eachpackagehasapackagemanualthatdescribeseveryfunctionavailablein thepackage. Topromotealignmentbetweenthefunctiondocumentationandthefunction\n",
      "page text: 17.2. Methods Library Software Development Process 331 implementation, the roxygen2software is used to combine a function’s documentation and source code in a single file. The package manual is available on demand through R’scommandlineinterface,asaPDFinthepackagerepositories,andasawebpage. In addition,manypackagesalsohavevignettesthathighlightspecificusecasesofapackage. AlldocumentationcanbeviewedthoughtheMethodsLibrarywebsite.3 AllMethodLibrarysourcecodeisavailabletoendusers. Feedbackfromthecommunity isfacilitatedusingGitHub’sissuetrackingsystemandtheOHDSIforums. 17.2.3 Availability of Current and Historical Archive Versions Current and historical versions of the Methods Library packages are available in two locations. First,theGitHubversioncontrolsystemcontainsthefulldevelopmenthistory of each package, and the state of a package at each point in time can be reconstructed andretrieved. Mostimportantly,eachreleasedversionistaggedinGitHub. Second,the releasedRsourcepackagesarestoredintheOHDSIGitHubdratrepository. 17.2.4 Maintenance, Support and Retirement EachcurrentversionoftheMethodsLibraryisactivelysupportedbyOHDSIwithrespect tobugreporting,fixesandpatches. IssuescanbereportedthroughGitHub’sissuetrack­ ing system, and through the OHDSI forums. Each package has a package manual, and zero,oneorseveralvignettes. Onlinevideotutorialsareavailable,andin­persontutorials areprovidedfromtimetotime. 17.2.5 Qualified Personnel MembersoftheOHDSIcommunityrepresentmultiplestatisticaldisciplinesandarebased atacademic,not­for­profitandindustry­affiliatedinstitutionsonmultiplecontinents. All leaders of the OHDSI Population­Level Estimation Workgroup and OHDSI Patient­ Level Prediction Workgroup hold PhDs from accredited academic institutions and have publishedextensivelyinpeerreviewedjournals. 17.2.6 Physical and Logical Security The OHDSI Methods Library is hosted on the GitHub4system. GitHub’s security mea­ suresaredescribedat https://github.com/security . Usernamesandpasswordsarerequired byallmembersoftheOHDSIcommunitytocontributemodificationstotheMethodsLi­ brary,andonlythePopulation­LevelEstimationWorkgroupandPatient­LevelPrediction Workgroupleadershipcanmakechangestothemasterbranches. Useraccountsarelim­ itedinaccessbaseduponstandardsecuritypoliciesandfunctionalrequirements. 3https://ohdsi.github.io/MethodsLibrary/ 4https://github.com/\n",
      "page text: 332 Chapter 17. Software Validity 17.2.7 Disaster Recovery TheOHDSIMethodsLibraryishostedontheGitHubsystem. GitHub’sdisasterrecovery facilitiesaredescribedat https://github.com/security . 17.3 Methods Library T esting WedistinguishbetweentwotypesoftestsperformedontheMethodsLibrary: Testsfor individualfunctionsinthepackages(so­called“unittests”),andtestsformorecomplex functionalityusingsimulations. 17.3.1 Unit T est AlargesetofautomatedvalidationtestsismaintainedandupgradedbyOHDSItoenable thetestingofsourcecodeagainstknowndataandknownresults. Eachtestbeginswith specifyingsomesimpleinputdata,thenexecutesafunctioninoneofthepackagesonthis input, and evaluates whether the output is exactly what would be expected. For simple functions,theexpectedresultisoftenobvious(forexamplewhenperformingpropensity score matching on example data containing only a few subjects); for more complicated functions the expected result may be generated using combinations of other functions availableinR(forexample,Cyclops,ourlarge­scaleregressionengine,istestedamong othersbycomparingresultsonsimpleproblemswithotherregressionroutinesinR).We aimforthesetestsintotaltocover100%ofthelinesofexecutablesourcecode. Thesetestsareautomaticallyperformedwhenchangesaremadetoapackage(specifically, when changes are pushed to the package repository). Any errors noted during testing automatically trigger emails to the leadership of the Workgroups, and must be resolved priortoreleaseofanewversionofapackage. Thesourcecodeandexpectedresultsfor these tests are available for review and use in other applications as may be appropriate. Thesetestsarealsoavailabletoendusersand/orsystemadministratorsandcanberunas partoftheirinstallationprocesstoprovidefurtherdocumentationandobjectiveevidence astotheaccuracy,reliabilityandconsistencyoftheirinstallationoftheMethodsLibrary. 17.3.2 Simulation Formorecomplexfunctionalityitisnotalwaysobviouswhattheexpectedoutputshould begiventheinput. Inthesecasessimulationsaresometimesused,generatinginputgiven a specific statistical model, and establishing whether the functionality produces results in line with this known model. For example, in the SelfControlledCaseSeries package simulations are used to verify that the method is able to detect and appropriately model temporaltrendsinsimulateddata.\n",
      "page text: 17.4. Summary 333 17.4 Summary –An observational study should be implemented as an automated script that executes the entire analysis, from data in the CDM to the results, to ensure reproducibilityandtransparency. –Custom study code should adhere to best programming practices, including abstraction,encapsulation,clearnaming,andcodereuse. –Customstudycodecanbevalidatedusingcodereviewordoublecoding. –TheMethodsLibraryprovidesvalidatedfunctionalitythatcanbeusedinob­ servationalstudies. –The Methods Library is validated by using a software development process aimedatcreatingvalidsoftware,andbytesting.\n",
      "page text: 334 Chapter 17. Software Validity\n",
      "page text: Chapter 18 Method Validity Chapter lead: Martijn Schuemie Whenconsideringmethodvalidityweaimtoanswerthequestion Isthismethodvalidforansweringthisquestion? “Method”includesnotonlythestudydesign,butalsothedataandtheimplementationof thedesign. Methodvalidityisthereforesomewhatofacatch­all;itisoftennotpossible toobservegoodmethodvaliditywithoutgooddataquality,clinicalvalidity,andsoftware validity. Thoseaspectsofevidencequalityshouldhavealreadybeenaddressedseparately beforeweconsidermethodvalidity. The core activity when establishing method validity is evaluating whether important as­ sumptionsintheanalysishavebeenmet. Forexample,weassumethatpropensity­score matchingmakestwopopulationscomparable,butweneedtoevaluatewhetherthisisthe case. Where possible, empirical tests should be performed to verify these assumptions. We can for example generate diagnostics to show that our two populations are indeed comparableonawiderangeofcharacteristicsaftermatching. InOHDSIwehavedevel­ opedmanystandardizeddiagnosticsthatshouldbegeneratedandevaluatedwheneveran analysisisperformed. In this chapter we will focus on the validity of methods use in population­level estima­ tion. Wewillfirstbrieflyhighlightsomestudydesign­specificdiagnostics,andwillthen discussdiagnosticsthatareapplicabletomostifnotallpopulation­levelestimationstud­ ies. Followingthisisastep­by­stepdescriptionofhowtoexecutethesediagnosticsusing the OHDSI tools. We close this chapter with an advanced topic, reviewing the OHDSI MethodsBenchmarkanditsapplicationtotheOHDSIMethodsLibrary. 18.1 Design-Specific Diagnostics Foreachstudydesigntherearediagnosticsspecifictosuchadesign. Manyofthesediag­ nosticsareimplementedandreadilyavailableintheRpackagesofthe OHDSIMethods 335\n",
      "page text: 336 Chapter 18. Method Validity Library. For example, Section 12.9lists a wide range of diagnostics generated by the CohortMethod package,including: •Propensity score distribution toassesinitialcomparabilityofcohorts. •Propensity model toidentifypotentialvariablesthatshouldbeexcludedfromthe model. •Covariate balance toevaluatewhetherpropensityscoreadjustmenthasmadethe cohortscomparable(asmeasuredthroughbaselinecovariates). •Attritiontoobservehowmanysubjectswereexcludedinthevariousanalysissteps, which may inform on the generalizability of the results to the initial cohorts of interest. •Powertoassesswhetherenoughdataisavailabletoanswerthequestion. •Kaplan Meier curve toassestypicaltimetoonset,andwhethertheproportionality assumptionunderlyingCoxmodelsismet. Otherstudydesignsrequiredifferentdiagnosticstotestthedifferentassumptionsinthose designs. For example, for the self­controlled case series (SCCS) design we may check thenecessaryassumptionthattheendofobservationisindependentoftheoutcome. This assumptionisoftenviolatedinthecaseofserious,potentiallylethal,eventssuchasmy­ ocardialinfarction. Wecanevaluatewhethertheassumptionholdsbygeneratingtheplot showninFigure 18.1,whichshowshistogramsofthetimetoobservationperiodendfor those that are censored, and those that are uncensored. In our data we consider those whose observation period ends at the end date of data capture (the date when observa­ tionstoppedfortheentiredatabase,forexamplethedateofextraction,orthestudyend date)tobeuncensored, andallotherstobecensored. InFigure 18.1weseeonlyminor differencesbetweenthetwodistributions,suggestingourassumptionsholds. 18.2 Diagnostics for All Estimation Nexttothedesign­specificdiagnostics,therearealsoseveraldiagnosticsthatareapplica­ bleacrossallcausaleffectestimationmethods. Manyoftheserelyontheuseofcontrol hypotheses, research questions where the answer is already known. Using control hy­ potheseswecanthenevaluatewhetherourdesignproducesresultsinlinewiththetruth. Controlscanbedividedintonegativecontrolsandpositivecontrols. 18.2.1 Negative Controls Negative controls are exposure­outcome pairs where one believes no causal effect ex­ ists,anditincludesnegativecontrolsor“falsificationendpoints”( PrasadandJena ,2013) that have been recommended as a means to detect confounding, ( Lipsitch et al. ,2010) selection bias, and measurement error. ( Arnold et al. ,2016) For example, in one study (Zaadstraetal. ,2008)investigatingtherelationshipbetweenchildhooddiseasesandlater multiplesclerosis(MS),theauthorsincludethreenegativecontrolsthatarenotbelieved to cause MS: a broken arm, concussion, and tonsillectomy. Two of these three controls produce statistically significant associations with MS, suggesting that the study may be\n",
      "page text: 18.2. Diagnostics for All Estimation 337 Figure 18.1: Time to observation end for those that are censored, and those that are un­ censored. biased. Weshouldselectnegativecontrolsthatarecomparabletoourhypothesisofinterest,which meanswetypicallyselectexposure­outcomepairsthateitherhavethesameexposureas thehypothesisofinterest(so­called“outcomecontrols”)orthesameoutcome(“exposure controls”). Ournegativecontrolsshouldfurthermeetthesecriteria: •Theexposure should not cause theoutcome. Onewaytothinkofcausationisto thinkofthecounterfactual: couldtheoutcomebecaused(orprevented)ifapatient was not exposed, compared to if the patient had been exposed? Sometimes this is clear, for example ACEi are known to cause angioedema. Other times this is far less obvious. For example, a drug that may cause hypertension can therefore indirectlycausecardiovasculardiseasesthatareaconsequenceofthehypertension. •The exposure should also not prevent or treat the outcome. This is just another causal relationship that should be absent if we are to believe the true effect size (e.g.thehazardratio)is1. •Thenegativecontrolshould exist in the data ,ideallywithsufficientnumbers. We trytoachievethisbyprioritizingcandidatenegativecontrolsbasedonprevalence. •Negative controls should ideally be independent . For example, we should avoid havingnegativecontrolsthatareeitherancestorsofeachother(e.g.“ingrownnail” and“ingrownnailoffoot”)orsiblings(e.g.“fractureofleftfemur”and“fracture ofrightfemur”). •Negative controls should ideally have some potential for bias . For example, the lastdigitofsomeone’ssocialsecuritynumberisbasicallyarandomnumber,andis\n",
      "page text: 338 Chapter 18. Method Validity unlikelytoshowconfounding. Itshouldthereforenotbeusedasanegativecontrol. Some argue that negative controls should also have the same confounding structure as the exposure­outcome pair of interest. ( Lipsitch et al. ,2010) However, we believe this confoundingstructureisunknowable;therelationshipsbetweenvariablesfoundinreality isoftenfarmorecomplexthanpeopleimagine. Also,eveniftheconfounderstructurewas known, it is unlikely that a negative control exists having that exact same confounding structure,butlackingthedirectcausaleffect. ForthisreasoninOHDSIwerelyonalarge numberofnegativecontrols,assumingthatsuchasetrepresentsmanydifferenttypesof bias,includingtheonespresentinthehypothesisofinterest. Theabsenceofacausalrelationshipbetweenanexposureandanoutcomeisrarelydocu­ mented. Instead,weoftenmaketheassumptionthatalackofevidenceofarelationship impliesthelackofarelationship. Thisassumptionismorelikelytoholdiftheexposure and outcome have both been studied extensively, so a relationship could have been de­ tected. For example, the lack of evidence for a completely novel drug likely implies a lackofknowledge,notthelackofarelationship. Withthisprincipleinmindwehavede­ veloped a semi­automated procedure for selecting negative controls. ( Voss et al.,2016) In brief, information from literature, product labels, and spontaneous reporting is auto­ maticallyextractedandsynthesizedtoproduceacandidatelistofnegativecontrols. This list must then undergo manual review, not only to verify that the automated extraction wasaccurate,butalsotoimposeadditionalcriteriasuchasbiologicalplausibility. 18.2.2 Positive Controls To understand the behavior of a method when the true relative risk is smaller or greater than one requires the use of positive controls where the null is believed to not be true. Unfortunately,realpositivecontrolsforobservationalresearchtendtobeproblematicfor three reasons. First, in most research contexts, for example when comparing the effect oftwotreatments,thereisapaucityofpositivecontrolsrelevantforthatspecificcontext. Second,evenifpositivecontrolsareavailable,themagnitudeoftheeffectsizemaynotbe knownwithgreataccuracy,andoftendependsonthepopulationinwhichonemeasures it. Third, when treatments are widely known to cause a particular outcome, this shapes the behavior of physicians prescribing the treatment, for example by taking actions to mitigate the risk of unwanted outcomes, thereby rendering the positive controls useless asameansforevaluation. ( Norenetal. ,2014) InOHDSIwethereforeusesyntheticpositivecontrols,( Schuemieetal. ,2018a)created by modifying a negative control through injection of additional, simulated occurrences oftheoutcomeduringthetimeatriskoftheexposure. Forexample,assumethat,during exposuretoACEi,noccurrencesofournegativecontroloutcome“ingrowingnail”were observed. If we now add an additional n simulated occurrences during exposure, we havedoubledtherisk. Sincethiswasanegativecontrol,therelativeriskcomparedtothe counterfactualwasone,butafterinjection,itbecomestwo. Oneissuethatstandsimportantisthepreservationofconfounding. Thenegativecontrols mayshowstrongconfounding,butifweinjectadditionaloutcomesrandomly,thesenew\n",
      "page text: 18.2. Diagnostics for All Estimation 339 outcomeswillnotbeconfounded,andwemaythereforebeoptimisticinourevaluation ofourcapacitytodealwithconfoundingforpositivecontrols. Topreserveconfounding, wewantthenewoutcomestoshowsimilarassociationswithbaselinesubject­specificco­ variatesastheoriginaloutcomes. Toachievethis,foreachoutcomewetrainamodelto predictthesurvivalratewithrespecttotheoutcomeduringexposureusingcovariatescap­ tured prior to exposure. These covariates include demographics, as well as all recorded diagnoses, drug exposures, measurements, and medical procedures. An L1­regularized Poissonregression( Suchardetal. ,2013)using10­foldcross­validationtoselectthereg­ ularizationhyperparameterfitsthepredictionmodel. Wethenusethepredictedratesto samplesimulatedoutcomesduringexposuretoincreasethetrueeffectsizetothedesired magnitude. Theresultingpositivecontrolthuscontainsbothrealandsimulatedoutcomes. Figure18.2depictsthisprocess. Notethatalthoughthisproceduresimulatesseveralim­ portantsourcesofbias,itdoesnotcaptureall. Forexample,someeffectsofmeasurement error are not present. The synthetic positive controls imply constant positive predictive valueandsensitivity,whichmaynotbetrueinreality. Figure18.2: Synthesizingpositivecontrolsfromnegativecontrols. Althoughwerefertoasingletrue“effectsize”foreachcontrol,differentmethodsestimate different statistics of the treatment effect. For negative controls, where we believe no causaleffectexists,allsuchstatistics,includingtherelativerisk,hazardratio,oddsratio, incidencerateratio,bothconditionalandmarginal,aswellastheaveragetreatmenteffect inthetreated(ATT)andtheoverallaveragetreatmenteffect(ATE)willbeidenticalto1. Ourprocessforcreatingpositivecontrolssynthesizesoutcomeswithaconstantincidence rateratioovertimeandbetweenpatients,usingamodelconditionedonthepatientwhere thisratioisheldconstant,uptothepointwherethemarginaleffectisachieved. Thetrue effect size is thus guaranteed to hold as the marginal incidence rate ratio in the treated. Undertheassumptionthatouroutcomemodelusedduringsynthesisiscorrect,thisalso holdsfortheconditionaleffectsizeandtheATE.Sincealloutcomesarerare,oddsratios areallbutidenticaltotherelativerisk. 18.2.3 Empirical Evaluation Basedontheestimatesofaparticularmethodforthenegativeandpositivecontrols,we can then understand the operating characteristics by computing a range of metrics, for example:\n",
      "page text: 340 Chapter 18. Method Validity •Area Under the receiver operator Curve (AUC) : the ability to discriminate be­ tweenpositiveandnegativecontrols. •Coverage: howoftenthetrueeffectsizeiswithinthe95%confidenceinterval. •Mean precision : precisioniscomputedas 1/(𝑠𝑡𝑎𝑛𝑑𝑎𝑟𝑑 𝑒𝑟𝑟𝑜𝑟)2,higherprecision means narrower confidence intervals. We use the geometric mean to account for theskeweddistributionoftheprecision. •Mean squared error (MSE) :Meansquarederrorbetweenthelogoftheeffectsize point­estimateandthelogofthetrueeffectsize. •Type 1 error : Fornegativecontrols,howoftenwasthenullrejected(at 𝛼 = 0.05). Thisisequivalenttothefalsepositiverateand 1 − 𝑠𝑝𝑒𝑐𝑖𝑓 𝑖𝑐𝑖𝑡𝑦 . •Type 2 error : For positive controls, how often was the null not rejected (at 𝛼 = 0.05). Thisisequivalenttothefalsenegativerateand 1 − 𝑠𝑒𝑛𝑠𝑖𝑡𝑖𝑣𝑖𝑡𝑦 . •Non­estimable : Forhowmanyofthecontrolswasthemethodunabletoproduce an estimate? There can be various reasons why an estimate cannot be produced, forexamplebecausetherewerenosubjectsleftafterpropensityscorematching,or becausenosubjectsremainedhavingtheoutcome. Depending on our use case, we can evaluate whether these operating characteristics are suitableforourgoal. Forexample,ifwewishtoperformsignaldetection,wemaycare about type 1 and type 2 error, or if we are willing to modify our 𝛼threshold, we may inspecttheAUCinstead. 18.2.4 P-Value Calibration Often the type 1 error (at 𝛼 = 0.05 ) is larger than 5%. In other words, we are often morelikelythan5%torejectthenullhypothesiswheninfactthenullhypothesisistrue. Thereasonisthatthep­valueonlyreflectsrandomerror,theerrorduetohavingalimited samplesize. Itdoesnotreflectsystematicerror,forexampletheerrorduetoconfounding. OHDSI has developed a process for calibrating p­values to restore the type 1 error to nominal. (Schuemieetal. ,2014)Wederiveanempiricalnulldistributionfromtheactual effect estimates for the negative controls. These negative control estimates give us an indicationofwhatcanbeexpectedwhenthenullhypothesisistrue,andweusethemto estimateanempiricalnulldistribution. Formally,wefitaGaussianprobabilitydistributiontotheestimates,takingintoaccount thesamplingerrorofeachestimate. Let ̂𝜃𝑖denotetheestimatedlogeffectestimate(rel­ ativerisk,oddsorincidencerateratio)fromthe 𝑖thnegativecontroldrug–outcomepair, andlet ̂ 𝜏𝑖denotethecorrespondingestimatedstandarderror, 𝑖 = 1, … , 𝑛 . Let 𝜃𝑖denote thetruelogeffectsize(assumed0fornegativecontrols),andlet 𝛽𝑖denotethetrue(but unknown)biasassociatedwithpair 𝑖, thatis, thedifferencebetweenthelogofthetrue effect size and the log of the estimate that the study would have returned for control 𝑖 had it been infinitely large. As in the standard p­value computation, we assume that ̂𝜃𝑖 isnormallydistributedwithmean 𝜃𝑖+ 𝛽𝑖andstandarddeviation ̂ 𝜏2 𝑖. Notethatintradi­ tionalp­valuecalculation, 𝛽𝑖isalwaysassumedtobeequaltozero,butthatweassume the 𝛽𝑖’s,arisefromanormaldistributionwithmean 𝜇andvariance 𝜎2. Thisrepresents thenull(bias)distribution. Weestimate 𝜇and 𝜎2viamaximumlikelihood. Insummary,\n",
      "page text: 18.2. Diagnostics for All Estimation 341 weassumethefollowing: 𝛽𝑖∼ 𝑁 (𝜇, 𝜎2)and ̂𝜃𝑖∼ 𝑁 (𝜃𝑖+ 𝛽𝑖, 𝜏2 𝑖) where 𝑁 (𝑎, 𝑏)denotesaGaussiandistributionwithmean 𝑎andvariance 𝑏,andestimate 𝜇and 𝜎2bymaximizingthefollowinglikelihood: 𝐿(𝜇, 𝜎|𝜃, 𝜏 ) ∝𝑛 ∏ 𝑖=1∫ 𝑝( ̂𝜃𝑖|𝛽𝑖, 𝜃𝑖, ̂ 𝜏𝑖)𝑝(𝛽𝑖|𝜇, 𝜎)d𝛽𝑖 yielding maximum likelihood estimates ̂ 𝜇and ̂ 𝜎. We compute a calibrated p­value that usestheempiricalnulldistribution. Let ̂𝜃𝑛+1denotethelogoftheeffectestimatefrom a new drug–outcome pair, and let ̂ 𝜏𝑛+1denote the corresponding estimated standard er­ ror. Fromtheaforementionedassumptionsandassuming 𝛽𝑛+1arisesfromthesamenull distribution,wehavethefollowing: ̂𝜃𝑛+1 ∼ 𝑁 ( ̂ 𝜇, ̂ 𝜎 + ̂ 𝜏𝑛+1 ) When ̂𝜃𝑛+1issmallerthan ̂ 𝜇,theone­sidedcalibratedp­valueforthenewpairisthen 𝜙⎛⎜⎜ ⎝𝜃𝑛+1 − ̂ 𝜇 √ ̂ 𝜎2+ ̂ 𝜏2 𝑛+1⎞⎟⎟ ⎠ where 𝜙(⋅)denotesthecumulativedistributionfunctionofthestandardnormaldistribu­ tion. When ̂𝜃𝑛+1isbiggerthan ̂ 𝜇,theone­sidedcalibratedp­valueisthen 1 − 𝜙⎛⎜⎜ ⎝𝜃𝑛+1 − ̂ 𝜇 √ ̂ 𝜎2+ ̂ 𝜏2 𝑛+1⎞⎟⎟ ⎠ 18.2.5 Confidence Interval Calibration Similarly, we typically observe that the coverage of the 95% confidence interval is less than95%: thetrueeffectsizeisinsidethe95%confidenceintervallessthan95%ofthe time. For confidence interval calibration ( Schuemie et al. ,2018a) we extend the frame­ work for p­value calibration by also making use of our positive controls. Typically, but not necessarily, the calibrated confidence interval is wider than the nominal confidence interval, reflecting the problems unaccounted for in the standard procedure (such as un­ measured confounding, selection bias and measurement error) but accounted for in the calibration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 360/464 [00:03<00:01, 64.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 342 Chapter 18. Method Validity Formally,weassumethat 𝑏𝑒𝑡𝑎𝑖,thebiasassociatedwithpair 𝑖,againcomesfromaGaus­ siandistribution,butthistimeusingameanandstandarddeviationthatarelinearlyrelated to𝑡ℎ𝑒𝑡𝑎𝑖,thetrueeffectsize: 𝛽𝑖∼ 𝑁 (𝜇(𝜃𝑖), 𝜎2(𝜃𝑖)) where 𝜇(𝜃𝑖) = 𝑎 + 𝑏 × 𝜃𝑖and 𝜎(𝜃𝑖)2= 𝑐 + 𝑑× ∣ 𝜃𝑖∣ Weestimate 𝑎,𝑏,𝑐and 𝑑bymaximizingthemarginalizedlikelihoodinwhichweintegrate outtheunobserved 𝛽𝑖: 𝑙(𝑎, 𝑏, 𝑐, 𝑑|𝜃, ̂𝜃, ̂ 𝜏 ) ∝𝑛 ∏ 𝑖=1∫ 𝑝( ̂𝜃𝑖|𝛽𝑖, 𝜃𝑖, ̂ 𝜏𝑖)𝑝(𝛽𝑖|𝑎, 𝑏, 𝑐, 𝑑, 𝜃𝑖)d𝛽𝑖, yieldingmaximumlikelihoodestimates ( ̂ 𝑎, ̂𝑏, ̂ 𝑐, ̂𝑑). WecomputeacalibratedCIthatusesthesystematicerrormodel. Let ̂𝜃𝑛+1againdenote thelogoftheeffectestimateforanewoutcomeofinterest,andlet ̂ 𝜏𝑛+1denotethecor­ responding estimated standard error. From the assumptions above, and assuming 𝛽𝑛+1 arisesfromthesamesystematicerrormodel,wehave: ̂𝜃𝑛+1 ∼ 𝑁 (𝜃𝑛+1 + ̂ 𝑎 + ̂𝑏 × 𝜃𝑛+1 , ̂ 𝑐 + ̂𝑑× ∣ 𝜃𝑛+1 ∣ + ̂ 𝜏2 𝑛+1 ). Wefindthelowerboundofthecalibrated95%CIbysolvingthisequationfor 𝜃𝑛+1: Φ⎛⎜⎜ ⎝𝜃𝑛+1 + ̂ 𝑎 + ̂𝑏 × 𝜃𝑛+1 − ̂𝜃𝑛+1 √( ̂ 𝑐 + ̂𝑑× ∣ 𝜃𝑛+1 ∣) + ̂ 𝜏2 𝑛+1⎞⎟⎟ ⎠= 0.025, where Φ(⋅)denotesthecumulativedistributionfunctionofthestandardnormaldistribu­ tion. We find the upper bound similarly for probability 0.975. We define the calibrated pointestimatebyusingprobability0.5. Bothp­valuecalibrationandconfidenceintervalcalibrationareimplementedinthe Em­ piricalCalibration package. 18.2.6 Replication Across Sites Anotherformofmethodvalidationcomesfromexecutingthestudyacrossseveraldiffer­ ent databases that represent different populations, different health care systems, and/or differentdatacaptureprocesses. Priorresearchhasshownthatexecutingthesamestudy\n",
      "page text: 18.3. Method Validation in Practice 343 designacrossdifferentdatabasescanproducevastlydifferenteffectsizeestimates,( Madi­ ganetal.,2013b)suggestingthateithertheeffectdiffersgreatlyfordifferentpopulations, orthatthedesigndoesnotadequatelyaddressthedifferentbiasesfoundinthedifferent databases. Infact,weobservethataccountingforresidualbiasinadatabasethroughem­ piricalcalibrationofconfidenceintervalscangreatlyreducebetween­studyheterogeneity. (Schuemieetal. ,2018a) One way to express between­database heterogeneity is the 𝐼2score, describing the per­ centage of total variation across studies that is due to heterogeneity rather than chance. (Higgins et al. ,2003) A naive categorization of values for 𝐼2would not be appropriate forallcircumstances,althoughonecouldtentativelyassignadjectivesoflow,moderate, andhighto 𝐼2valuesof25%,50%,and75%. Inastudyestimatingtheeffectsformany depression treatments using a new­user cohort design with large­scale propensity score adjustment, ( Schuemie et al. ,2018b) observed only 58% of the estimates to have an 𝐼2 below25%. Afterempiricalcalibrationthisincreasedto83%. Observing between­database heterogeneity casts doubt on the validity of the esti­ mates. Unfortunately,theinverseisnottrue. Notobservingheterogeneitydoesnot guaranteeanunbiasedestimate. Itisnotunlikelythatalldatabasesshareasimilar bias,andthatallestimatesarethereforeconsistentlywrong. 18.2.7 Sensitivity Analyses When designing a study there are often design choices that are uncertain. For example, shouldpropensityscorematchingofstratificationbeused? Ifstratificationisused,how many strata? What is the appropriate time­at­risk? When faced with such uncertainty, one solution is to evaluate various options, and observe the sensitivity of the results to thedesignchoice. Iftheestimateremainsthesameundervariousoptions,wecansaythe studyisrobusttotheuncertainty. Thisdefinitionofsensitivityanalysisshouldnotbeconfusedwiththedefinitionsusedby otherssuchas, Rosenbaum (2005)whodefinessensitivityanalysisto“appraisehowthe conclusionsofastudymightbealteredbyhiddenbiasesofvariousmagnitudes.” 18.3 Method Validation in Practice Here we build on the example in Chapter 12, where we investigate the effect of ACE inhibitors(ACEi)ontheriskofangioedemaandacutemyocardialinfarction(AMI),com­ pared to thiazides and thiazide­like diuretics (THZ). In that chapter we already explore manyofthediagnosticsspecifictothedesignweused,thecohortmethod. Here,weapply additionaldiagnosticsthatcouldalsohavebeenappliedhadotherdesignsbeenused. If thestudyisimplementedusingATLASasdescribedinSection 12.7thesediagnosticsare availableintheShinyappthatisincludedinthestudyRpackagegeneratedbyATLAS.If thestudyisimplementedusingRinstead,asdescribedinSection 12.8,thenRfunctions\n",
      "page text: 344 Chapter 18. Method Validity availableinthevariouspackagesshouldbeused,asdescribedinthenextsections. 18.3.1 Selecting Negative Controls We must select negative controls, exposure­outcome pairs where no causal effect is be­ lieved to exist. For comparative effect estimation such as our example study, we select negativecontroloutcomesthatarebelievedtobeneithercausedbythetargetnorthecom­ paratorexposure. Wewantenoughnegativecontrolstomakesurewehaveadiversemix ofbiasesrepresentedinthecontrols,andalsotoallowempiricalcalibration. Asarule­of­ thumbwetypicallyaimtohave50­100suchnegativecontrols. Wecouldcomeupwith thesecontrolscompletelymanually, butfortunatelyATLASprovidesfeaturestoaidthe selectionofnegativecontrolsusingdatafromliterature,productlabels,andspontaneous reports. To generate a candidate list of negative controls, we first must create a concept set con­ taining all exposures of interest. In this case we select all ingredients in the ACEi and THZclasses,asshowninFigure 18.3. Figure 18.3: A concept set containing the concepts defining the target and comparator exposures. Next, we go to the “Explore Evidence” tab, and click on the button. Gen­ eratingtheevidenceoverviewwilltakeafewminutes,afterwhichyoucanclickonthe button. ThiswillopenthelistofoutcomesasshowninFigure 18.4. This list shows condition concepts, along with an overview of the evidence linking the conditiontoanyoftheexposureswedefined. Forexample,weseethenumberofpublica­ tionsthatlinktheexposurestotheoutcomesfoundinPubMedusingvariousstrategies,the numberofproductlabelsofourexposuresofinterestthatlisttheconditionasapossible adverseeffect,andthenumberofspontaneousreports. Bydefaultthelistissortedtoshow candidatenegativecontrolsfirst. Itisthensortedbythe“SortOrder,” whichrepresents theprevalenceoftheconditioninacollectionofobservationaldatabases. Thehigherthe\n",
      "page text: 18.3. Method Validation in Practice 345 Figure 18.4: Candidate control outcomes with an overview of the evidence found in lit­ erature,productlabels,andspontaneousreports. SortOrder,thehighertheprevalence. Althoughtheprevalenceinthesedatabasesmight notcorrespondwiththeprevalenceinthedatabasewewishtorunthestudy,itislikelya goodapproximation. Thenextstepistomanuallyreviewthecandidatelist,typicallystartingatthetop,sowith themostprevalentcondition,andworkingourwaydownuntilwearesatisfiedwehave enough. OnetypicalwaytodothisistoexportthelisttoaCSV(commaseparatedvalues) file,andhavecliniciansreviewthese,consideringthecriteriamentionedinSection 18.2.1. Forourexamplestudyweselectthe76negativecontrolslistedinAppendix C.1. 18.3.2 Including Controls Oncewehavedefinedoursetofnegativecontrolswemustincludetheminourstudy. First we must define some logic for turning our negative control condition concepts into out­ comecohorts. Section 12.7.3discusseshowATLASallowscreatingsuchcohortsbased on a few choices the user must make. Often we simply choose to create a cohort based onanyoccurrenceofanegativecontrolconceptoranyofitsdescendants. Ifthestudyis implemented in R, then SQL (Structured Query Language) can be used to construct the negativecontrolcohorts. Chapter 9describeshowcohortscanbecreatedusingSQLand R.WeleaveitasanexerciseforthereadertowritetheappropriateSQLandR. The OHDSI tools also provide functionality for automatically generating and including positive controls derived from the negative controls. This functionality can be found in the Evaluation Settings section in ATLAS described in Section 12.7.3, and it is imple­\n",
      "page text: 346 Chapter 18. Method Validity mentedinthe synthesizePositiveControls functioninthe MethodEvaluation pack­ age. Herewegeneratethreepositivecontrolsforeachnegativecontrol, withtrueeffect sizesof1.5,2,and4,usingasurvivalmodel: library(MethodEvaluation) # Create a data frame with all negative control exposure- # outcome pairs, using only the target exposure (ACEi = 1). eoPairs <- data.frame (exposureId = 1, outcomeId = ncs) pcs <-synthesizePositiveControls ( connectionDetails = connectionDetails, cdmDatabaseSchema = cdmDbSchema, exposureDatabaseSchema = cohortDbSchema, exposureTable = cohortTable, outcomeDatabaseSchema = cohortDbSchema, outcomeTable = cohortTable, outputDatabaseSchema = cohortDbSchema, outputTable = cohortTable, createOutputTable = FALSE, modelType = \"survival\" , firstExposureOnly = TRUE, firstOutcomeOnly = TRUE, removePeopleWithPriorOutcomes = TRUE, washoutPeriod = 365, riskWindowStart = 1, riskWindowEnd = 0, endAnchor = \"cohort end\" , exposureOutcomePairs = eoPairs, effectSizes = c(1.5,2,4), cdmVersion = cdmVersion, workFolder = file.path (outputFolder, \"pcSynthesis\" )) Note that we must mimic the time­at­risk settings used in our estimation study design. ThesynthesizePositiveControls functionwill extract informationabout the expo­ suresandnegativecontroloutcomes,fitoutcomemodelsperexposure­outcomepair,and synthesize outcomes. The positive control outcome cohorts will be added to the cohort table specified by cohortDbSchema andcohortTable . The resulting pcsdata frame containstheinformationonthesynthesizedpositivecontrols. Next we must execute the same study used to estimate the effect of interest to also esti­ mateeffectsforthenegativeandpositivecontrols. Settingthesetofnegativecontrolsin thecomparisonsdialog inATLASinstructsATLAStocomputeestimatesforthesecon­ trols. Similarly,specifyingthatpositivecontrolsbegeneratedintheEvaluationSettings includestheseinouranalysis. InR,thenegativeandpositivecontrolsshouldbetreated as any other outcome. All estimation packages in the OHDSI Methods Library readily allowestimationofmanyeffectsinanefficientmanner.\n",
      "page text: 18.3. Method Validation in Practice 347 18.3.3 Empirical Performance Figure18.5shows the estimated effect sizes for the negative and positive controls in­ cluded in our example study, stratified by true effect size. This plot is included in the ShinyappthatcomeswiththestudyRpackagegeneratedbyATLAS,andcanbegener­ atedusingthe plotControls functioninthe MethodEvaluation package. Notethatthe number of controls is often lower than what was defined because there was not enough datatoeitherproduceanestimateortosynthesizeapositivecontrol. Figure18.5: Estimatesforthenegative(truehazardratio=1)andpositivecontrols(true hazardratio>1). Eachdotrepresentsacontrol. Estimatesbelowthedashedlinehavea confidenceintervalthatdoesn’tincludethetrueeffectsize. Based on these estimates we can compute the metrics shown in Table 18.1using the computeMetrics functioninthe MethodEvaluation package. Table18.1: Methodperformancemetricsderivedfromthenegative andpositivecontrolestimates. Metric Value AUC 0.96 Coverage 0.97 MeanPrecision 19.33 MSE 2.08 Type1error 0.00 Type2error 0.18 Non­estimable 0.08 Weseethatcoverageandtype1errorareveryclosetotheirnominalvaluesof95%and 5%,respectively,andthattheAUCisveryhigh. Thisiscertainlynotalwaysthecase. NotethatalthoughinFigure 18.5notallconfidenceintervalsincludeonewhenthetrue hazardratioisone,thetype1errorinTable 18.1is0%. Thisisanexceptionalsituation, caused by the fact that confidence intervals in the Cyclopspackage are estimated using likelihood profiling, which is more accurate than traditional methods but can result in asymmetricconfidenceintervals. Thep­valueinsteadiscomputedassumingsymmetrical confidenceintervals,andthisiswhatwasusedtocomputethetype1error.\n",
      "page text: 348 Chapter 18. Method Validity 18.3.4 P-Value Calibration Wecanusetheestimatesforournegativecontrolstocalibrateourp­values. Thisisdone automaticallyintheShinyapp, andcanbedonemanuallyinR.Assumingwehavecre­ atedthesummaryobject summasdescribedinSection 12.8.6,wecanplottheempirical calibrationeffectplot: # Estimates for negative controls (ncs) and outcomes of interest (ois): ncEstimates <- summ[summ $outcomeId %in%ncs, ] oiEstimates <- summ[summ $outcomeId %in%ois, ] library(EmpiricalCalibration) plotCalibrationEffect (logRrNegatives = ncEstimates $logRr, seLogRrNegatives = ncEstimates $seLogRr, logRrPositives = oiEstimates $logRr, seLogRrPositives = oiEstimates $seLogRr, showCis = TRUE) Figure18.6: P­valuecalibration: estimatesbelowthedashedlinehaveaconventionalp < 0.05. Estimates in the shaded area have calibrated p < 0.05. The narrow band around the edge of the shaded area denotes the 95% credible interval. Dots indicate negative controls. Diamondsindicateoutcomesofinterest. InFigure18.6weseethattheshadedareaalmostexactlyoverlapswiththeareadenotedby thedashedlines,indicatinghardlyanybiaswasobservedforthenegativecontrols. One oftheoutcomesofinterest(AMI)isabovethedashedlineandtheshadedarea,indicating wecannotrejectthenullaccordingtoboththeuncalibratedandcalibratedp­value. The otheroutcome(angioedema)clearlystandsoutfromthenegativecontrol,andfallswell withintheareawherebothuncalibratedandcalibratedp­valuesaresmallerthan0.05.\n",
      "page text: 18.3. Method Validation in Practice 349 Wecancomputethecalibratedp­values: null <- fitNull(logRr = ncEstimates $logRr, seLogRr = ncEstimates $seLogRr) calibrateP (null, logRr=oiEstimates $logRr, seLogRr = oiEstimates $seLogRr) ## [1] 1.604351e-06 7.159506e-01 Andcontrastthesewiththeuncalibratedp­values: oiEstimates $p ## [1] [1] 1.483652e-06 7.052822e-01 As expected, because little to no bias was observed, the uncalibrated and calibrated p­ valuesareverysimilar. 18.3.5 Confidence Interval Calibration Similarly, we can use the estimates for our negative and positive controls to calibrate the confidence intervals. The Shiny app automatically reports the calibrate confidence intervals. In R we can calibrate intervals using the fitSystematicErrorModel and calibrateConfidenceInterval functionsinthe EmpiricalCalibration package,asde­ scribedindetailinthe “Empiricalcalibrationofconfidenceintervals”vignette . Beforecalibration,theestimatedhazardratios(95%confidenceinterval)are4.32(2.45­ 8.08)and1.13(0.59­2.18),forangioedemaandAMIrespectively. Thecalibratedhazard ratiosare4.75(2.52­9.04)and1.15(0.58­2.30). 18.3.6 Between-Database Heterogeneity Justasweexecutedouranalysisononedatabase,inthiscasetheIBMMarketScanMed­ icaid(MDCD)database,wecanalsorunthesameanalysiscodeonotherdatabasesthat adheretotheCommonDataModel(CDM).Figure 18.7showstheforestplotandmeta­ analytic estimates (assuming random effects) ( DerSimonian and Laird ,1986) across a totaloffivedatabasesfortheoutcomeofangioedema. Thisfigurewasgeneratedusing theplotMetaAnalysisForest functioninthe EvidenceSynthesis package. Although all confidence intervals are above one, suggesting agreement on the fact that thereisaneffect,the 𝐼2suggestsbetween­databaseheterogeneity. However,ifwecom­ putethe 𝐼2usingthecalibratedconfidenceintervalsasshowninFigure 18.8,weseethat this heterogeneity can be explained by the bias measured in each database through the negative and positive controls. The empirical calibration appears to properly take this biasintoaccount.\n",
      "page text: 350 Chapter 18. Method Validity Figure18.7: Effectsizeestimatesand95%confidenceintervals(CI)fromfivedifferent databasesandameta­analyticestimatewhencomparingACEinhibitorstothiazidesand thiazide­likediureticsfortheriskofangioedema. Figure18.8: CalibratedEffectsizeestimatesand95%confidenceintervals(CI)fromfive differentdatabasesandameta­analyticestimateforthehazardratioofangioedemawhen comparingACEinhibitorstothiazidesandthiazide­likediuretics.\n",
      "page text: 18.4. OHDSI Methods Benchmark 351 18.3.7 Sensitivity Analyses Oneofthedesignchoicesinouranalysiswastousevariable­ratiomatchingonthepropen­ sityscore. However,wecouldhavealsousedstratificationonthepropensityscore. Be­ causeweareuncertainaboutthischoice, wemaydecidetouseboth. Table 18.2shows theeffectsizeestimatesforAMIandangioedema,bothcalibratedanduncalibrated,when usingvariable­ratiomatchingandstratification(with10equally­sizedstrata). Table18.2: Uncalibrated and calibrated hazard ratios (95% confi­ denceinterval)forthetwoanalysisvariants. Outcome Adjustment Uncalibrated Calibrated Angioedema Matching 4.32(2.45­8.08) 4.75(2.52­9.04) Angioedema Stratification 4.57(3.00­7.19) 4.52(2.85­7.19) Acutemyocardialinfarction Matching 1.13(0.59­2.18) 1.15(0.58­2.30) Acutemyocardialinfarction Stratification 1.43(1.02­2.06) 1.45(1.03­2.06) Weseethattheestimatesfromthematchedandstratifiedanalysisareinstrongagreement, withtheconfidenceintervalsforstratificationfallingcompletelyinsideoftheconfidence intervalsformatching. Thissuggeststhatouruncertaintyaroundthisdesignchoicedoes notimpactthevalidityofourestimates. Stratificationdoesappeartogiveusmorepower (narrower confidence intervals), which is not surprising since matching results in loss of data, whereas stratification does not. The price for this could be an increase in bias, duetowithin­strataresidualconfounding,althoughweseenoevidenceofincreasedbias reflectedinthecalibratedconfidenceintervals. Studydiagnosticsallowustoevaluatedesignchoicesevenbeforefullyexecuting a study. It is recommended not to finalize the protocol before generating and re­ viewingallstudydiagnostics. Toavoidp­hacking(adjustingthedesigntoachieve a desired result), this should be done while blinded to the effect size estimate of interest. 18.4 OHDSI Methods Benchmark Although the recommended practice is to empirically evaluate a method’s performance withinthecontextthatitisapplied,usingnegativeandpositivecontrolsthatareinways similartotheexposures­outcomespairsofinterest(forexampleusingthesameexposure or the same outcome) and on the database used in the study, there is also value in eval­ uatingamethod’sperformanceingeneral. ThisiswhytheOHDSIMethodsEvaluation Benchmark was developed. The benchmark evaluates performance using a wide range of control questions, including those with chronic or acute outcomes, and long­term or short­term exposures. The results on this benchmark can help demonstrate the overall usefulnessofamethod,andcanbeusedtoformapriorbeliefabouttheperformanceof\n",
      "page text: 352 Chapter 18. Method Validity amethodwhenacontext­specificempiricalevaluationisnot(yet)available. Thebench­ markconsistsof200carefullyselectednegativecontrolsthatcanbestratifiedintoeight categories,withthecontrolsineachcategoryeithersharingthesameexposureorthesame outcome. From these 200 negative controls, 600 synthetic positive controls are derived as described in Section 18.2.2. To evaluate a method, it must be used to produce effect sizeestimatesforallcontrols,afterwhichthemetricsdescribedinSection 18.2.3canbe computed. Thebenchmarkispubliclyavailable,andcanbedeployedasdescribedinthe RunningtheOHDSIMethodsBenchmarkvignette intheMethodEvaluation package. WehaverunallthemethodsintheOHDSIMethodsLibrarythroughthisbenchmark,with variousanalysischoicespermethod. Forexample,thecohortmethodwasevaluatedusing propensityscorematching, stratification, andweighting. Thisexperimentwasexecuted onfourlargeobservationalhealthcaredatabases. Theresults,viewableinanonlineShiny app1,showthatalthoughseveralmethodsshowhighAUC(theabilitytodistinguishpos­ itive controls from negative controls), most methods in most settings demonstrate high type1errorandlowcoverageofthe95%confidenceinterval,asshowninFigure 18.9. Thisemphasizestheneedforempiricalevaluationandcalibration: ifnoempiricalevalu­ ationisperformed,whichistrueforalmostallpublishedobservationalstudies,wemust assume a prior informed by the results in Figure 18.9, and conclude that it is likely that thetrueeffectsizeisnotcontainedinthe95%confidenceinterval! OurevaluationofthedesignsintheMethodsLibraryalsoshowsthatempiricalcalibration restores type 1 error and coverage to their nominal values, although often at the cost of increasingtype2erroranddecreasingprecision. 18.5 Summary –A method’s validity depends on whether the assumptions underlying the methodaremet. –Where possible, these assumptions should be empirically tested using study diagnostics. –Controlhypotheses,questionswheretheanswerisknown,shouldbeusedto evaluate whether a specific study design produces answers in line with the truth. –Often,p­valuesandconfidenceintervalsdonotdemonstratenominalcharac­ teristicsasmeasuredusingcontrolhypotheses. –Thesecharacteristicscanoftenberestoredtonominalusingempiricalcalibra­ tion. 1http://data.ohdsi.org/MethodEvalViewer/\n",
      "page text: 18.5. Summary 353 Figure 18.9: Coverage of the 95% confidence interval for the methods in the Methods Library. Each dot represents the performance of a specific set of analysis choices. The dashed line indicates nominal performance (95% coverage). SCCS = Self­Controlled CaseSeries,GI=Gastrointestinal,IBD=inflammatoryboweldisease. –Studydiagnosticscanbeusedtoguideanalyticdesignchoicesandadaptthe protocol,aslongastheresearcherremainsblindedtotheeffectofinterestto avoidp­hacking.\n",
      "page text: 354 Chapter 18. Method Validity\n",
      "page text: Part V OHDSI Studies 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 378/464 [00:04<00:01, 62.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: Chapter 19 Study steps Chapter leads: Sara Dempster & Martijn Schuemie Hereweaimtoprovideageneralstep­by­stepguidetothedesignandimplementationof anobservationalstudywiththeOHDSItools. Wewillbreakouteachstageofthestudy process and then describe steps generically and in some cases discuss specific aspects of the main study types (1) characterization, (2) population level estimation (PLE), and (3) patient level prediction (PLP) described in earlier chapters of the Book of OHDSI. Todoso,wewillsynthesizemanyelementsdiscussedinthepreviouschaptersinaway that is accessible for the beginner. At the same time, this chapter can stand alone for a readerwhowantspracticalhigh­levelexplanationswithoptionstopursuemorein­depth materials in other chapters as needed. Finally, we will illustrate throughout with a few keyexamples. In addition, we will summarize guidelines and best practices for observational studies as recommended by the OHDSI community. Some principles that we will discuss are generic and shared with best practice recommendations found in many other guidelines for observational research while other recommended processes are more specific to the OHDSI framework. We will therefore highlight where OHDSI­specific approaches are enabledbytheOHDSItoolstack. Throughout the chapter, we assume that an infrastructure of OHDSI tools, R and SQL areavailabletothereaderandthereforewedonotdiscussanyaspectsofsettingupthis infrastructure in this chapter (see Chapters 8and9for guidance). We also assume our readerisinterestedinrunningastudyprimarilyondataattheirownsiteusingadatabase in OMOP CDM (for OMOP ETL, see Chapter 6). However, we emphasize that once a study package is prepared as discussed below, it can in principle be distributed and executed at other sites. Additional considerations specific to running OHDSI network studies,includingorganizationalandtechnicaldetails,arediscussedindetailinChapter 20. 357\n",
      "page text: 358 Chapter 19. Study steps 19.1 General Best Practice Guidelines 19.1.1 Observational Study Definition Anobservationalstudyisastudywhere,bydefinition,patientsaresimplyobservedand no attempt is made to intervene in the treatment of specific patients. Sometimes, obser­ vationaldataarecollectedforaspecificpurposeasinaregistrystudy,butinmanycases, thesedataarecollectedforsomepurposeotherthanthespecificstudyquestionathand. Common examples of the latter type of data are Electronic Health Records (EHRs) or administrativeclaimsdata. Observationalstudies areoftenreferredto assecondaryuse of data. A fundamental guiding principle for performing any observational study is to explicitlydescribe one’sresearch questionand fullyspecify the approachin advanceof executing a study. In this regard, an observational study should be no different than a clinicaltrial,exceptthatinaclinicaltrial,patientsarerecruitedandfollowedintimefor the primary purpose of answering a specific question, usually about the efficacy and/or safetyofatherapeuticintervention. Therearemanywaysinwhichtheanalysismethods employed in observational studies are different than those used in clinical trials. Most notably, the lack of randomization in PLE observational studies requires approaches to control confounding if the goal is to draw causal inferences (see Chapters 12and18 fordetaileddiscussionofOHDSI­supportedstudydesignsandmethodsforPLEsuchas methodstoremoveobservedconfoundingbybalancingpopulationsacrossmanycharac­ teristics). 19.1.2 Pre-Specification of Study Design Pre­specificationofanobservationalstudydesignandparametersiscriticaltoavoidintro­ ducingfurtherbiasbysubconsciouslyorconsciouslyevolvingone’sapproachtoachieve a desired result, sometimes referred to as p­hacking. The temptation not to fully spec­ ify the study details in advance is greater with secondary use of data than primary use because these data, such as EHR and claims, sometimes give the researcher a sense of infinitepossibilities,leadingtoameanderinglineofinquiry. Thekeythenistostillim­ pose the rigorous structure of scientific inquiry despite the apparent easy availability of pre­existing data. The principle of pre­specification is especially important in PLE or PLP to ensure rigorous or reproducible results as these findings may ultimately inform clinicalpracticeorregulatorydecisions. Eveninthecaseofacharacterizationstudybe­ ingconductedpurelyforexploratoryreasons,itisstillpreferabletohaveawell­specified plan. Otherwiseanevolvingstudydesignandanalysisprocesswillbecomeunwieldyto document,explainandreproduce. 19.1.3 Protocol Anobservationalstudyplanshouldbedocumentedintheformofaprotocolcreatedprior to executing a study. At a minimum, a protocol describes the primary study question, the approach, and metrics that will be used to answer the question. The study popula­ tion should be described to a level of detail such that the study population may be fully\n",
      "page text: 19.1. General Best Practice Guidelines 359 reproduced by others. In addition, all methods or statistical procedures and the form of expected study results such as metrics, tables and graphs should be described. Often, a protocolwillalsodescribeasetofpre­analysesdesignedtoassessthefeasibilityorstatis­ tical power of the study. Furthermore, protocols may contain descriptions of variations ontheprimarystudyquestionreferredtoassensitivityanalyses. Sensitivityanalysesare designedtoevaluatethepotentialimpactofstudydesignchoicesontheoverallstudyfind­ ingsandshouldbedescribedinadvancewheneverpossible. Sometimesunanticipatedis­ suesarisethatmaynecessitateaprotocolamendmentafteraprotocoliscompleted. Ifthis becomes necessary, it is critical to document the change and the reasons for the change intheprotocolitself. ParticularlyinthecaseofPLEorPLP,acompletedstudyprotocol willideallyberecordedinanindependentplatform(suchasclinicaltrials.govorOHDSI’s studyProtocolssandbox)whereitsversionsandanyamendmentscanbetrackedindepen­ dentlywithtimestamps. Itisalsooftenthecasethatyourinstitutionortheownerofthe datasourcewillrequiretheopportunitytoreviewandapproveyourprotocolpriortostudy execution. 19.1.4 Standardized Analyses AuniqueadvantageofOHDSIisthewaysinwhichthetoolssupportplanning,documen­ tationandreportingbyrecognizingthattherearereallyafewmainclassesofquestions that are asked repeatedly in observational studies (Chapters 2,7,11,12,13), thereby streamlining the protocol development and study implementation process through au­ tomation of aspects that are repeated. Many of the tools are designed to parameterize a fewstudydesignsormetricsthataddressamajorityofusecasesthatwillbeencountered. For example, the researchers specify their study populations and a few additional pa­ rametersandperformnumerouscomparativestudiesiteratingoverdifferentdrugsand/or outcomes. Ifaresearcher’squestionsfitintothegeneraltemplate, therearewaystoau­ tomate the generation of many of the basic descriptions of study populations and other parametersrequiredfortheprotocol. Historically, theseapproachesweremotivatedout oftheOMOPexperimentswhichsoughttoevaluatehowwellobservationalstudydesigns wereabletoreproduceknowncausallinksbetweendrugsandadverseeventsbyiterating overmanydifferentstudydesignsandparameters. The OHDSI approach supports the inclusion of feasibility and study diagnostics within the protocol by again enabling these steps to be performed relatively simply within a commonframeworkandtools(seesection 19.2.4below). 19.1.5 Study Packages Anothermotivationforstandardizedtemplatesanddesignsisthatevenwhenaresearcher thinksastudyisdescribedincompletedetailintheformofaprotocol, theremaybeel­ ements that are not actually sufficiently specified to generate the full computer code to executethestudy. ArelatedfundamentalprinciplewhichisenabledbytheOHDSIframe­ work is to generate a completely traceable and reproducible process documented in the form of computer code, often referred to as a “study package.” OHDSI best practice is\n",
      "page text: 360 Chapter 19. Study steps to record such a study package in the git environment. This study package contains all parametersandversioningstampsforthecodebase. Asmentionedpreviously,observa­ tionalstudiesareoftenaskingquestionswithpotentialtoimpactpublichealthdecisions and policy. Therefore, before acting on any findings, they should ideally be replicated inmultiplesettingsbydifferentresearchers. Theonlywaytoachievesuchagoalisfor every detail required to fully reproduce a study to be mapped out explicitly and not left to guesswork or misinterpretation. To support this best practice, the OHDSI tools are designedtoaidinthetranslationfromaprotocolintheformofawrittendocumentintoa computerormachine­readablestudypackage. Onetradeoffofthisframeworkisthatnot everyusecaseorcustomizedanalysiscaneasilybeaddressedwiththeexistingOHDSI tools. As the community grows and evolves, however, more functionality to address a larger array of use cases is being added. Anyone involved in the community may raise suggestionsfornewfunctionalitydrivenbyanovelusecase. 19.1.6 The Data Underlying the CDM OHDSIstudiesarepremisedonobservationaldatabasesbeingtranslatedintotheOMOP commondatamodel(CDM).AllOHDSItoolsanddownstreamanalyticsstepsmakean assumption that the data representation conforms to the specifications of the CDM (see Chapter4). ItisthereforealsocriticalthattheETLprocess(seeChapter 6)fordoingso iswell­documentedforyourspecificdatasourcesasthisprocessmayintroduceartifacts ordifferencesbetweendatabasesatdifferentsites. ThepurposeoftheOMOPCDMisto movein the direction of reducing site specific data representation, but this is far from a perfectprocessandstillremainsachallengingareathatthecommunityseekstoimprove. Itthereforeremainscriticalwhenexecutingstudiestocollaboratewithindividualsatyour site,oratexternalsiteswhenexecutingnetworkstudies,whoareintimatelyfamiliarwith anysourcedatathathasbeentransformedintotheOMOPCDM. In addition to the CDM, the OMOP standardized vocabulary system (Chapter 5) is also a critical component of working with the OHDSI framework to obtain interoperability acrossdiversedatasources. Thestandardizedvocabularyseekstodefineasetofstandard concepts within each vocabulary domain to which all other source vocabulary systems aremapped. Inthisway,twodifferentdatabaseswhichuseadifferentsourcevocabulary systemfordrugs,diagnosesorprocedureswillbecomparablewhentransformedintothe CDM.TheOMOPvocabulariesalsocontainhierarchieswhichareusefulinidentifying the appropriate codes for a particular cohort definition. Again, it is recommended best practicetoimplementthevocabularymappingsandusethecodesofOMOPstandardized vocabularies in downstream queries in order to gain the full benefits of ETLing your databaseintotheOMOPCDMandusingtheOMOPvocabulary.\n",
      "page text: 19.2. Study Steps in Detail 361 19.2 Study Steps in Detail 19.2.1 Define Question Thefirststepistotranslateyourresearchinterestintoaprecisequestionthatcanbead­ dressedwithanobservationalstudy. Let’ssaythatyouareaclinicaldiabetesresearcher and you want to investigate the quality of care being delivered to patients with type 2 diabetesmellitus(T2DM).Youcanbreakthisbiggerobjectivedownintomuchmorespe­ cificquestionsthatfallintooneofthethreetypesofquestionsfirstdescribedinChapter 7. In a characterization study, one could ask, “do prescribing practices conform to what is currently recommended for those with mild T2DM versus those with severe T2DM in a given healthcare environment?” This question does not ask a causal question about the effectiveness of any given treatment relative to another; it is simply characterizing prescribingpracticesinyourdatabaserelativetoasetofexistingclinicalguidelines. Maybeyouarealsoskepticalwhetheror nottheprescribingguidelinesforT2DMtreat­ ment are best for a particular subset of patients such as those with both a diagnosis of T2DMandheartdisease. ThislineofinquirycanbetranslatedintoaPLEstudy. Specif­ ically, you can ask a question about the comparative effectiveness of 2 different T2DM drugclassesinpreventingcardiovascularevents,suchasheartfailure. Youmightdesign a study to examine the relative risks of hospitalization for heart failure in two separate cohortsofpatientstakingthedifferentdrugs,butwherebothcohortshaveadiagnosisof T2DMandheartdisease. Alternatively, you may want to develop a model to predict which patients will progress frommildT2DMtosevereT2DM.ThiscanbeframedasaPLPquestionandcouldserve toflagpatientsatgreaterriskoftransitioningtosevereT2DMformorevigilantcare. Fromapurelypragmaticpointofview,definingastudyquestionalsorequiresassessing whethertheapproachesrequiredtoansweraquestionconformstoavailablefunctionality withintheOHDSItoolset(seeChapter 7foradetaileddiscussionofquestiontypesthat can addressed with current tool). Of course it is always possible to design your own analytictoolsormodifythosecurrentlyavailabletoanswerotherquestions. 19.2.2 Review Data Availability and Quality Beforecommittingtoaparticularstudyquestion,itisrecommendedtoreviewthequality ofthedata(seeChapter 15)andreallyunderstandthenatureofyourparticularobserva­ tional healthcare database in terms of which fields are populated and what care settings thedatacovers. Thiscanhelptoquicklyidentifyissuesthatmaymakeastudyquestion infeasible in a particular database. Below, we point out some common issues that may arise. Let’sreturntotheexampleaboveofdevelopingapredictivemodelforprogressionfrom mildT2DMtosevereT2DM.IdeallyseverityofT2DMmightbeassessedbyexamining\n",
      "page text: 362 Chapter 19. Study steps glycosylated hemoglobin (HbA1c) levels which is a lab measurement that reflects a pa­ tient’sbloodsugarlevelsaveragedovertheprior3months. Thesevaluesmayormaynot beavailableforallpatients. Ifunavailableforallorevenaportionofpatients,youwill have to consider whether other clinical criteria for severity of T2DM can be identified and used instead. Alternatively, if the HbA1c values are available for only a subset of patients, you will also need to evaluate whether focusing on this subset of patients only wouldleadtounwantedbiasinthestudy. SeeChapter 7foradditionaldiscussionofthe issueofmissingdata. Another common issue is the lack of information about a particular care setting. In the PLEexampledescribedabove,thesuggestedoutcomewashospitalizationforheartfail­ ure. If a given database does not have any inpatient information, one may need to con­ sider a different outcome to evaluate the comparative effectiveness of different T2DM treatmentapproaches. Inotherdatabases,outpatientdiagnosisdatamaynotbeavailable andthereforeonewouldneedtoconsiderthedesignofthecohort. 19.2.3 Study Populations Definingastudypopulationorpopulationsisafundamentalstepofanystudy. Inobser­ vationalresearch,agroupofindividualsthatisrepresentativeofthestudypopulationof interestisoftenreferredtoasacohort. Therequiredpatientcharacteristicsforselection into a cohort will be determined by the study population that is relevant for the clinical question at hand. An example of a simple cohort would be patients older than 18 years of age AND with a diagnosis code for T2DM in their medical record. This cohort defi­ nition has two criteria connected by AND logic. Often cohort definitions contain many morecriteriawhichareconnectedbymorecomplex,nestedbooleanlogicandadditional temporalcriteriasuchasspecificstudyperiodsorrequiredlengthsoftimeforapatient’s baselineperiod. Arefinedsetofcohortdefinitionsrequiresthereviewofappropriatescientificliterature andadvicefromclinicalandtechnicalexpertswhounderstandsomeofthechallengesin interpretingyourspecificdatabasetoidentifyappropriategroupsofpatients. It’simpor­ tanttokeepinmindwhenworkingwithobservationaldatathatthesedatadonotprovide acompletepictureofapatient’smedicalhistory, butratherasnapshotintimewhosefi­ delityissubjecttobothhumanerrorandbiasthatmayhavebeenintroducedinrecording oftheinformation. Agivenpatientmayonlybefollowedforafinitetimereferredtoas their observation period. For a given database or care setting and disease or treatment under study, a clinical researcher may be able to make suggestions to avoid the most commonsourcesoferror. Togiveastraightforwardexample,acommonissueinidenti­ fying patients with T2DM is that T1DM patients are sometimes mistakenly coded with adiagnosisofT2DM.BecausepatientswithT1DMarefundamentallyadifferentgroup, theunintentionalinclusionofagroupofT1DMpatientsinastudyintendedtoexamine T2DM patients could skew the results. In order to have a robust definition of a T2DM cohort,onemaywanttoeliminatepatientswhohaveonlyeverbeenprescribedinsulinas adiabetestreatmenttoavoidhavingpatientswithT1DMerroneouslyrepresented. Atthe same time, however, there may also be situations where one is simply interested in the\n",
      "page text: 19.2. Study Steps in Detail 363 characteristics of all patients who have a T2DM diagnosis code in their medical record. In this case, it may not be appropriate to apply further qualifying criteria to attempt to removeerroneouslycodedT1DMpatients. Once the definition of a study population or populations is described, the OHDSI tool ATLAS is a good starting point to create the relevant cohorts. ATLAS and the cohort generationprocessaredescribedindetailinChapters 8and10. Briefly,ATLASprovides auserinterface(UI)todefineandgeneratecohortswithdetailedinclusioncriteria. Once cohorts are defined in ATLAS, a user can directly export their detailed definitions in a human­readable format for incorporation in a protocol. If for some reason an ATLAS instanceisnotconnectedtoanobservationalhealthdatabase,ATLAScanstillbeusedto createacohortdefinitionanddirectlyexporttheunderlyingSQLcodeforincorporation intoastudypackagetoberunseparatelyonaSQLdatabaseserver. DirectlyusingATLAS is recommended when possible because ATLAS provides some advantages above and beyondthecreationofSQLcodeforthecohortdefinition(seebelow). Finally,theremay besomeraresituationswhereacohortdefinitioncannotbeimplementedwiththeATLAS UIandrequiresmanualcustomSQLcode. The ATLAS UI enables defining cohorts based on numerous selection criteria. Criteria for cohort entry and exit as well as baseline criteria can be defined on the basis of any domainsoftheOMOPCDMsuchasconditions,drugs,procedures,etc. wherestandard codesmustbespecifiedforeachdomain. Inaddition,logicalfiltersonthebasisofthese domains, as well as time­based filters to define study periods, and baseline timeframes canbedefinedwithinATLAS.ATLAScanbeparticularlyhelpfulwhenselectingcodes foreachcriteria. ATLASincorporatesavocabulary­browsingfeaturewhichcanbeused tobuildsetsofcodesrequiredforyourcohortdefinitions. Thisfeaturereliessolelyonthe OMOPstandardvocabulariesandhasoptionstoincludealldescendantsinthevocabulary hierarchy(seeChapter 5). Notethereforethatthisfeaturerequiresthatallcodeshavebeen appropriately mapped to standard codes during the ETL process (see Chapter 6). If the bestcodesetstouseinyourinclusioncriteriaarenotclear,thismaybeaplacewheresome exploratoryanalysismaybewarrantedincohortdefinitions. Alternativelyamoreformal sensitivityanalysiscouldbeconsideredtoaccountfordifferentpossibledefinitionsofa cohortusingdifferentcodesets. AssumingthatATLASisconfiguredappropriatelytoconnecttoadatabase,SQLqueries togeneratethedefinedcohortscanberundirectlywithinATLAS.ATLASwillautomati­ callyassigneachcohortauniqueidwhichcanalsobeusedtodirectlyreferencethecohort inthebackenddatabaseforfutureuse. ThecohortmaybedirectlyusedwithinATLAS torunanincidenceratestudyoritmaybepointedtodirectlyinthebackenddatabaseby codeinaPLEorPLPstudypackage. Foragivencohort,ATLASsavesonlythepatient ids,indexdatesandcohortexitdatesoftheindividualsinthecohorts. Thisinformationis sufficienttoderivealltheotherattributesorcovariatesthatmaybeneededforthepatients suchaspatient’sbaselinecovariatesforacharacterization,PLEorPLPstudy. When a cohort is created, summary characteristics of the patient demographics and fre­ quenciesofthemostfrequentdrugsandconditionsobservedcanbecreatedandviewed\n",
      "page text: 364 Chapter 19. Study steps bydefaultdirectlywithinATLAS. In reality, most studies require specifying multiple cohorts or multiple sets of cohorts which are then compared in various ways to gain new clinical insights. For PLE and PLP, the OHDSI tools provide a structured framework to define these multiple cohorts. Forexample,inaPLEcomparativeeffectivenessstudy,youwilltypicallydefineatleast 3 cohorts, a target cohort, a comparator and an outcome cohort (see Chapter 12). In addition,torunafullPLEcomparativeeffectivenessstudy,youwillalsoneedanumber of cohorts with negative control outcomes and positive control outcomes. The OHDSI toolsetprovideswaystohelpspeedandinsomecasesautomatethegenerationofthese negativeandpositivecontrolcohortsasdiscussedindetailinChapter 18. Asafinalnote,definingcohortsforastudymaybenefitfromongoingworkintheOHDSI communityto definealibraryofrobustandvalidatedphenotypeswhereaphenotypeis essentiallyanexportablecohortdefinition. Ifanyoftheseexistingcohortdefinitionsare appropriateforyourstudy,theexactdefinitionscanbeobtainedbyimportofajsonfile intoyourATLASinstance. 19.2.4 Feasibility and Diagnostics Oncecohortsaredefinedandgenerated,amoreformalprocesstoexaminestudyfeasibil­ ityinavailabledatasourcescanbeundertakenandthefindingssummarizedinthefinal­ izedprotocol. Anevaluationofstudyfeasibilitycanencompassanumberofexploratory andsometimesiterativeactivities. Wedescribeafewcommonaspectshere. A primary activity at this stage will be to thoroughly review the distributions of charac­ teristics within your cohorts to ensure that the cohort you generated is consistent with thedesiredclinicalcharacteristicsandflaganyunexpectedcharacteristics. Returningto ourT2DMexampleabove,bycharacterizingthissimpleT2DMcohortbyreviewingthe frequenciesofallotherdiagnosesreceived,onemaybeabletoflagtheissueofalsocap­ turingpatientswithT1DMorotherunanticipatedissues. Itisgoodpracticetobuildsuch astepofinitiallycharacterizinganynewcohortintothestudyprotocolasaqualitycheck ofclinicalvalidityofthecohortdefinition. Intermsofimplementation, theeasiestway toperformafirstpassatthiswillbetoexaminethecohortdemographicsandtopdrugs and conditions that can be generated by default when a cohort is created in ATLAS. If the option to create the cohorts directly within ATLAS is not available, manual SQL or useoftheRfeatureextractionpackagecanbeusedtocharacterizeacohort. Inpractice, inalargerPLEstudyorPLPstudy, thesestepscanbebuiltintothestudypackagewith featureextractionsteps. Another common and important step to assess feasibility for a PLE or PLP is an assess­ mentofcohortsizesandthecountsofoutcomesinthetargetandcomparatorcohorts. The incidence rate feature of ATLAS can be used to find these counts which can be used to performpowercalculationsasdescribedelsewhere. AnotheroptionwhichishighlyrecommendedforaPLEstudyistocompletethepropen­ sity score (PS) matching steps and relevant diagnostics to ensure that there is sufficient\n",
      "page text: 19.2. Study Steps in Detail 365 overlap between the populations in the target and comparator groups. These steps are described in detail in Chapter 12. In addition, using these final matched cohorts, the statisticalpowercanthenbecalculated. Insomecases,workintheOHDSIcommunityexaminesthestatisticalpoweronlyafter a study is run by reporting a minimal detectable relative risk (MDRR) given the avail­ able sample sizes. This approach may be more useful when running high throughput, automatedstudiesacrossalotofdatabasesandsites. Inthisscenario,astudy’spowerin anygivendatabaseisperhapsbetterexploredaftertheallanalyseshavebeenperformed ratherthanpre­filtering. 19.2.5 Finalize Protocol and Study Package Oncethelegworkforallthepreviousstepshasbeencompleted,afinalprotocolshouldbe assembledthatincludesdetailedcohortdefinitionsandstudydesigninformationideally exportedfromATLAS.InAppendix D,weprovideasampletableofcontentsforafull protocolforaPLEstudy. ThiscanalsobefoundontheOHDSIgithub. Weprovidethis sampleasacomprehensiveguideandchecklist,butnotesomesectionsmayormaynot berelevantforyourstudy. As shown in Figure 19.1, assembling the final study protocol in human­readable form shouldbeperformedinparallelwithpreparingallthemachine­readablestudycodethat is incorporated into the final study package. These latter steps are referred to as study implementation in the diagram below. This will include export of the finalized study packagefromATLASand/ordevelopmentofanycustomcodethatmayberequired. Thecompletedstudypackagecanthenbeusedtoexecuteonlythepreliminarydiagnos­ tics steps which in turn can be described in the protocol. For example, in the case of a newusercohortPLEstudytoexaminecomparativeeffectivenessoftwotreatments,the preliminaryexecutionofstudydiagnosticsstepswillrequirecohortcreation,propensity scorecreation,andmatchingtoconfirmthatthetargetandcomparatorpopulationshave sufficient overlap for the study to be feasible. Once this is determined, power calcula­ tionscanbeperformedwiththematchedtargetandcomparatorcohortsintersectedwith theoutcomecohorttoobtainoutcomecountsandtheresultsofthesecalculationscanbe described in the protocol. On the basis of these diagnostics results, a decision can then bemadewhetherornottomoveforwardwithexecutingthefinaloutcomemodel. Inthe context of a characterization or a PLP study, there may be similar steps that need to be completedatthisstage,althoughwedon’tattempttooutlineallscenarioshere. Importantly, we recommend at this stage to have your finalized protocol reviewed by clinicalcollaboratorsandstakeholders. 19.2.6 Execute Study Onceallpriorstepshavebeencompleted, studyexecutionshouldideallybestraightfor­ ward. Ofcourse,thecodeorprocessshouldbereviewedforfidelitytothemethodsand\n",
      "page text: 366 Chapter 19. Study steps Figure19.1: Diagramofthestudyprocess. parameters outlined in the protocol. It may also be necessary to test and debug a study packagetoensureitrunsappropriatelyinyourenvironment. 19.2.7 Interpretation and Write-Up Ina well­definedstudy wheresample sizes aresufficientanddata quality isreasonable, theinterpretationofresultswilloftenbestraightforward. Similarly,becausemostofthe workofcreatingafinalreportotherthanwritingupthefinalresultsisdoneintheplanning and creation of the protocol, the final write­up of a report or manuscript for publication willoftenbestraightforwardaswell. There are, however, some common situations where interpretation becomes more chal­ lengingandshouldbeapproachedwithcaution. 1.Samplesizesareborderlineforsignificanceandconfidenceintervalsbecomelarge 2.SpecificforPLE:p­valuecalibrationwithnegativecontrolsmayrevealsubstantial bias 3.Unanticipated data quality issues come to light during the process of running the study For any given study, it will be up to the discretion of the study authors to report on any concernsaboveandtempertheirinterpretationofstudyresultsaccordingly. Aswiththe protocoldevelopmentprocess,wealsorecommendthatthestudyfindingsandinterpreta­ tionsbereviewedbyclinicalexpertsandstakeholderspriortoreleasingafinalreportor submittingamanuscriptforpublication.\n",
      "page text: 19.3. Summary 367 19.3 Summary –Studyshouldexamineawell­definedquestion. –Perform appropriate checks of data quality, completeness and relevance in advance. –Recommendtoincludesourcedatabaseexpertinprotocoldevelopmentpro­ cessifpossible. –Documentproposedstudyinaprotocolaheadoftime. –Generate study package code in parallel with written protocol and perform anddescribeanyfeasibilityanddiagnosticspriortoexecutingthefinalstudy. –Study should be registered and approved (if required) ahead of study execu­ tion. –Finalized report or manuscript should be reviewed by clinical experts and otherstakeholders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 395/464 [00:04<00:00, 70.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 368 Chapter 19. Study steps\n",
      "page text: Chapter 20 OHDSI Network Research Chapter leads: Kristin Kostka, Greg Klebanov & Sara Dempster The mission of OHDSI is to generate high­quality evidence through observational re­ search. Aprimarywaythisisaccomplishedisthroughcollaborativeresearchstudies. In priorchapterswediscussedhowtheOHDSIcommunityhasauthoredstandardsandtools to facilitate high­quality, reproducible research, including OMOP Standardized Vocabu­ laries, the Common Data Model (CDM), analytical methods packages, ATLAS and the study steps (Chapter 19) to run a retrospective database study. OHDSI network studies represent the culmination of a transparent, consistent and reproducible way to conduct researchacrossalargenumberofgeographicallydisperseddata. Inthischapterwewill discusswhatconstitutesanOHDSInetworkstudy,howtorunanetworkstudyanddiscuss enablingtechnologiessuchastheARACHNEResearchNetwork. 20.1 OHDSI as a Research Network TheOHDSIresearchnetworkisaninternationalcollaborationofresearchersseekingto advance observational data research in healthcare. Today, the network consists of over 100databasesstandardizedtotheOMOPcommondatamodel,collectivelyrepresenting over1billionpatientrecords. OHDSIisanopennetwork,invitinghealthcareinstitutions across the globe with patient­level data to join the network by converting data to the OMOP CDM and participating in network research studies. As data conversions are complete,collaboratorsareinvitedtoreportsiteinformationintheDataNetworkcensus maintained by the OHDSI Program Manager . Each OHDSI network site participates voluntarily. Therearenohardobligations. Eachsiteopts­intoeachrespectivenetwork study. In each study, data remains at the site behind a firewall. No patient­level data poolingoccursacrossnetworksites. Only aggregate results are shared. Benefits of a Data Owner Joining the OHDSI Network 369\n",
      "page text: 370 Chapter 20. OHDSI Network Research –Access to free tools: OHDSIpublishesfree,opensourcetoolsfordatachar­ acterization and standardized analytics (e.g. browsing the clinical concepts, defining and characterizing cohorts, running Population­Level Estimation andPatient­LevelPredictionstudies). –Participate in a premier research community: Authorandpublishnetwork research, collaboratewithleadersacrossvariousdisciplinesandstakeholder groups. –Opportunity to benchmark care: Networkstudiescanenableclinicalchar­ acterizationandqualityimprovementbenchmarksacrossdatapartners. 20.2 OHDSI Network Studies Inthepriorchapter(Chapter 19),wediscussedgeneraldesignconsiderationsforrunning a study using the CDM. In general, a study may be conducted on a single CDM or on multiple CDMs. It can be run within a single institution’s CDM data or across many institutions. In this section we will discuss why you may want to expand your analyses acrossmultipleinstitutionsintoanetworkstudy. 20.2.1 Motivations for Conducting an OHDSI Network Study Atypicalusecaseforobservationalstudiesistoexaminethecomparativeeffectiveness or safety of a treatment in a “real world” setting. More specifically, you may aim to replicateaclinicaltrialinapost­marketsettingtoaddressconcernsaboutgeneralizability offindingsfromaclinicaltrial. Inotherscenarios,youmaywanttorunastudycomparing twotreatmentsthathaveneverbeencomparedinaclinicaltrialbecauseonetreatmentis beingusedoff­label. Oryoumayneedtostudyararepost­marketsafetyoutcomethata clinical trial was underpowered to observe. To address these research questions, it may notbesufficienttorunasingleobservationalstudyinoneoreventwodatabasesatyour site because you are getting an answer that is meaningful in the context of a particular groupofpatientsonly. Theresultsofanobservationalstudycanbeinfluencedbymanyfactorsthatvarybythe locationofthedatasourcesuchasadherence,geneticdiversity,orenvironmentalfactors, overallhealthstatus: factorsthatmaynothavebeenpossibletovaryinthecontextofa clinicaltrialevenifoneexistsforyoursamestudyquestion. Atypicalmotivationtorun anobservationalstudyinanetworkisthereforetoincreasethediversityofdatasources andpotentiallystudypopulationstounderstandhowwelltheresultsgeneralize. Inother words, can the study findings be replicated across multiple sites or do they differ and if theydiffer,cananyinsightsbegleanedastowhy? Networkstudies,therefore,offertheopportunitytoinvestigatetheeffectsof“realworld” factorsonobservationalstudies’findingsbyexaminingabroadarrayofsettingsanddata sources.\n",
      "page text: 20.2. OHDSI Network Studies 371 20.2.2 Definition of an OHDSI Network Study When is a study considered a network study?An OHDSI study becomes an OHDSI network study when it is run across multiple CDMs at different institu­ tions. TheOHDSIapproachtonetworkresearchusestheOMOPCDMandstandardizedtools andstudypackageswhichfullyspecifyallparametersforrunningastudy. OHDSIstan­ dardizedanalyticsaredesignedspecificallytoreduceartifactsandimprovetheefficiency andscalabilityofnetworkstudies. NetworkstudiesareanimportantpartoftheOHDSIresearchcommunity. However,there is no mandate that an OHDSI study be packaged and shared across the entire OHDSI network. You may still conduct research using the OMOP CDM and OHDSI methods librarywithinasingleinstitutionorlimitaresearchstudytoonlyselectinstitutions. These research contributions are equally important to the community. It is at the discretion of each investigator whether a study is designed to run on a single database, conduct a study across a limited set of partners or open the study to full participation the OHDSI network. Thischapterintendstospeaktotheopen­to­allnetworkstudiesthattheOHDSI communityconducts. Elements of an Open OHDSI Network Study: WhenconductinganopenOHDSInet­ workstudy,youarecommittingtofullytransparentresearch. Thereareafewcomponents thatmakeOHDSIresearchunique. Thisincludes: •Alldocumentation,studycodeandsubsequentresultsaremadepubliclyavailable ontheOHDSIGitHub. •Investigators must create and publish a public study protocol detailing the scope andintentoftheanalysistobeperformed. •Investigatorsmustcreateastudypackage(typicallywithRorSQL)withcodethat isCDMcompliant. •Investigators are encouraged to attend OHDSI Community Calls to promote and recruitcollaboratorsfortheirOHDSInetworkstudy. •Attheendoftheanalysis,aggregatestudyresultsaremadeavailableintheOHDSI GitHub. •Where possible, investigators are encouraged to publish study R Shiny Applica­ tionstodata.ohdsi.org . In the next section we will talk about how to create your own network study as well as theuniquedesignandlogisticalconsiderationsforimplementinganetworkstudy. 20.2.3 Design Considerations for an OHDSI Network Study Designing a study to run across the OHDSI network requires a paradigm shift in how you design and assemble your study code. Ordinarily, you may design a study with a targetdatasetinmind. Indoingso,youmaywritecoderelativetowhatyouknowtobe\n",
      "page text: 372 Chapter 20. OHDSI Network Research trueinthedatayouareutilizingforyouranalysis. Forexample,ifyouwereassembling an angioedema cohort you may opt to pick only concept codes for angioedema that are represented in your CDM. This may be problematic if your data are in a specific care setting (e.g. primary care, ambulatory settings) or specific to a region (e.g. US­centric). Yourcodeselectionsmightbebiasingyourcohortdefinition. In an OHDSI network study, you are no longer designing and building a study package justforyourdata. Youarebuildingastudypackagetoberunacrossmultiplesitesacross the globe. You will never see the underlying data for participating sites outside of your own institution. OHDSI network studies only share results files. Your study package can only collect what data that is available in the domains of the CDM. You will need anexhaustiveapproachtoconceptsetcreationtorepresentthediversityofcaresettings that observational health data are captured. OHDSI study packages often use the same cohort definition across all sites. This means that you must think holistically to avoid biasingacohortdefinitiontoonlyrepresentasubsetofeligibledata(e.g.claims­centric data or EHR­specific data) in the network. You are encouraged to write an exhaustive cohortdefinitionthatcanbeportedacrossmultipleCDMs. OHDSIstudypackagesuse thesamesetofparameterizedcodeacrossallsites–withonlyminorcustomizationsfor connectingintothedatabaselayerandstoringlocalresults. Lateron,wewilldiscussthe implicationsforinterpretingclinicalfindingsfromdiversedatasets. In addition to clinical coding variation, you will need to design anticipating variations in the local technical infrastructure. Your study code will no longer be running in a sin­ gletechnicalenvironment. EachOHDSInetworksitemakesitsownindependentchoice of database layer. This means that you cannot hard­code a study package to a specific databasedialect. ThestudycodeneedstobeparameterizedtoatypeofSQLthatcanbe easilymodifiedtotheoperatorsinthatdialect. Fortunately,theOHDSICommunityhas solutionssuchasATLAS, DatabaseConnector ,andSqlRender tohelpyougeneralizeyour studypackageforCDMcomplianceacrossdifferentdatabasedialects. OHDSIinvestiga­ torsareencouragedtosolicithelpfromothernetworkstudysitestotestandvalidatethe studypackagecanbeexecutedindifferentenvironments. Whencodingerrorscomeup, OHDSIResearcherscanutilizethe OHDSIForums todiscussanddebugpackages. 20.2.4 Logistical Considerations for an OHDSI Network Study OHDSI is an open science community, and the OHDSI central coordinating center pro­ videsacommunityinfrastructuretoallowitscollaboratorstoleadandparticipateincom­ munityresearch. EveryOHDSInetworkstudyrequiresaleadinvestigator,andthatcanbe anycollaboratoracrosstheOHDSIcommunity. OHDSInetworkstudiesrequirecoordi­ nationbetweentheleadinvestigator,collaboratingresearchers,andparticipatingnetwork datapartners. Eachsitemustperformitsownduediligencetoensurethestudyprotocol is approved and authorized to be executed on the local CDM, if requred. Data analysts mayneedtoenlistassistancefromthelocalITteamtoenableappropriatepermissionsto runthestudy. Thesizeandscopeofthestudyteamateachsitewillbeafunctionofthe size and complexity of the proposed network study as well as the maturity of the site’s adoptionoftheOMOPCDMandOHDSItoolstack. Thelevelofexperiencethatasite\n",
      "page text: 20.2. OHDSI Network Studies 373 haswithrunninganOHDSInetworkstudywillalsoimpactthepersonnelrequired. Foreachstudy,sitestart­upactivitiesmayinclude: •Registering the study with the Institutional Review Board (or equivalent), if re­ quired •ReceivingInstitutionalReviewBoardapprovaltoexecutethestudy,ifrequired •Receivingdatabaselevelpermissionstoread/writeaschematotheapprovedCDM •Ensuring configuration of a functional RStudio environment to execute the study package •Reviewingthestudycodeforanytechnicalanomalies •Working with a local IT team to permit and install any dependent R packages neededtoexecutethepackagewithintechnicalconstraints Data Quality and Network Studies: AsdiscussedinChapter 6,qualitycontrolis afundamentalanditerativepieceoftheETLprocess. Thisshouldbedoneregularly outside of the network study process. For a network study, a study lead may ask toreviewparticipatingsite’sdataqualityreportsordesigncustomSQLqueriesto understandpotentialvariationincontributingdatasources. Formoredetailonthe dataqualityeffortsgoingonwithinOHDSI,pleaseseeChapter 15. Eachsitewillhavealocaldataanalystwhoexecutesthestudypackage. Thisindividual must review the output of the study package to ensure no sensitive information is trans­ mitted,althoughallthedatainCDMhadbeenalreadyde­identified. Whenyouareusing pre­builtOHDSImethodssuchasPopulation­LevelEffectEstimation(PLE)andPatient Level Prediction (PLP), there are configurable settings for the minimum cell count for a given analysis. The data analyst is required to review these thresholds and ensure it followslocalgovernancepolicies. Whensharingstudyresults,thedataanalystmustcomplywithalllocalgovernancepoli­ cies, inclusiveofmethodofresultstransmissionandadheringtoapprovalprocessesfor externalpublicationofresults. OHDSI network studies do not share patient­level data. Inotherwords,patientleveldatafromdifferentsitesisneverpooledinacentralenviron­ ment. Studypackagescreateresultsfilesdesignedtobeaggregateresults(e.g.summary statistics, point­estimates, diagnostic plots, etc.) and do not share patient­level informa­ tion. Many organizations do not require data sharing agreements be executed between theparticipatingstudyteammembers. However,dependingontheinstitutionsinvolved and the data sources, it may be necessary to have more formal data sharing agreements inplaceandsignedbyspecificstudyteammembers. Ifyouareadataownerinterested inparticipatinginnetworkstudies,youareencouragedtoconsultyourlocalgovernance teamtounderstandwhatpoliciesareinplaceandmustbefulfilledtojoinOHDSIcom­ munitystudies.\n",
      "page text: 374 Chapter 20. OHDSI Network Research 20.3 Running an OHDSI Network Study RunninganOHDSINetworkStudyhasthreegeneraldistinctstages: •Studydesignandfeasibility •Studyexecution •Resultsdisseminationandpublication 20.3.1 Study Design and Feasibility Thestudyfeasibilitystage (or the pre­study stage) definesastudyquestionanddescribes theprocesstoanswerthisquestionviathestudyprotocol. Thisstagefocusesonassessing thefeasibilityofexecutingthestudyprotocolacrossparticipatingsites. The outcome of the feasibility stage is the generation of a finalized protocol and study package that is published ready for network execution. The formal protocol will detail the study team, including the designated study lead (often the corresponding author for publication purposes), and information on the timeline for the study. The protocol is a critical component for additional network sites to review, approve and execute the full studypackageontheirCDMdata. Aprotocolmustincludeinformationonstudypopula­ tion,themethodsbeingused,howtheresultswillbestoredandanalyzedaswellashow thestudyresultswillbedisseminatedaftercompletion(e.g.apublication,presentationat scientificconference,etc.). The feasibility stage is not a well­defined process. It is a series of activities that are highlydependentonthetypeofstudyproposed. Ataminimum,thestudyleadwillspend timeidentifyingrelevantnetworksitesthatcontainthetargetedpatientpopulation(s)with required drug exposure, procedure information, condition or demographics information. Where possible, the study lead should provisionally use their own CDM to design the target cohorts. However, there is no requirement that a study lead have access to a live OMOP CDM with real patient data to run a network study. The study lead may design their target cohort definition using synthetic data (e.g. CMS Synthetic Public Use Files, SyntheticMassfromMitreorSynthea)andaskcollaboratorsatOHDSInetworksitesto helpwithvalidatingthefeasibilityofthiscohort. Feasibilityactivitiesmayincludeasking collaborators to create and characterize cohorts using JSON files of cohort definitions from ATLAS or testing study R packages and running initial diagnostics as discussed in Chapter 19. At the same time, the study lead may need to initiate any organization­ specific processes to approve an OHDSI study at the organizing institution, if required –suchinternalInstitutional ReviewBoardapproval. Itis theresponsibilityof thestudy leadtocompletetheseorganization­specificactivitiesduringthefeasibilityphase. 20.3.2 Study Execution After completing feasibility exercises, the study advances to the execution phase. This period represents when OHDSI network sites can opt­in to participate in the analysis. This phase is when the design and logistical considerations we discussed become most important.\n",
      "page text: 20.3. Running an OHDSI Network Study 375 AstudywillmovetoexecutionwhenthestudyleadreachesouttotheOHDSIcommunity toformallyannounceanewOHDSInetworkstudyandformallybeginsrecruitingpartic­ ipatingsites. ThestudyleadwillpublishthestudyprotocoltotheOHDSIGitHub. The studyleadwillannouncethestudyontheweeklyOHDSICommunityCalland OHDSI Forum, inviting participating centers and collaborators. As sites opt­in to participate, a study lead will communicate directly with each site and provide information on the GitHub repository where the study protocol and code are published as well as instruc­ tions on how to execute the study package. Ideally, a network study will be performed inparallelbyallsites,sothefinalresultsaresharedconcurrentlyensuringthatnosite’s teammembersarebiasedbyknowledgeofanotherteam’sfindings. At each site, the study team will ensure the study follows institutional procedures for receiving approval to participate in the study, execute the package and share results ex­ ternally. ThiswilllikelyincludereceivingInstitutionalReviewBoard(IRB)exemption orapprovalorequivalentforthespecifiedprotocol. Whenthestudyisapprovedtorun, thesitedatascientists/statisticianswillfollowthestudylead’sinstructionstoaccessthe OHDSIstudypackageandgenerateresultsinthestandardizedformatfollowingOHDSI guidelines. Each participating site will follow internal institutional processes regarding datasharingrules. Sitesshouldnotshareresultsunlessapprovalorexemptionisobtained fromIRBorotherinstitutionalapprovalprocesses. The study lead will be responsible for communicating how they want to receive results (e.g. via SFTP or a secure Amazon S3 bucket) and the time­frame for turning around results. Sitesmayspecifyifthemethodoftransmissionisoutofcompliancewithinternal protocolandaworkaroundmaybedevelopedaccordingly. During the execution phase, the collective study team (inclusive of the study lead and participatingsiteteams)mayiterateonresults,ifreasonableadjustmentsarerequired. If thescopeandextentoftheprotocolevolvebeyondwhatisapproved,itistheresponsibil­ ityoftheparticipatingsitetocommunicatethistotheirorganizationbyworkingwiththe study lead to update the protocol then resubmit the protocol for review and re­approval bythelocalIRB. It is ultimately the responsibility of the study lead and any supporting data scien­ tist/statistician to perform the aggregation of results across centers and perform meta­analysis, as appropriate. The OHDSI community has validated methodologies to aggregate results files shared from multiple network sites into a single answer. The EvidenceSynthesis package is a freely available R package containing routines for combiningevidenceanddiagnosticsacrossmultiplesources,suchasmultipledatasites in a distributed study. This includes functions for performing meta­analysis and forest plots. Thestudyleadwillneedtomonitorsiteparticipationandhelpeliminatebarriersinexe­ cuting the package by regularly checking in with participating sites. Study execution is not one­size­fits­all at each site. There may be challenges related to the database layer (e.g.accessrights/schemapermissions)oranalyticstoolintheirenvironment(e.g.unable toinstallrequiredpackages,unabletoaccessdatabasesthroughR,etc.). Theparticipating\n",
      "page text: 376 Chapter 20. OHDSI Network Research sitewillbeinthedriver’sseatandwillcommunicatewhatbarriersexisttoexecutingthe study. Itisultimatelythediscretionoftheparticipatingsitetoenlistappropriateresources tohelpresolveissuesencounteredintheirlocalCDM. While OHDSI studies can be executed rapidly, it is advised to allow for a reasonable amountoftimeforallparticipatingsitestoexecutethestudyandreceiveappropriateap­ provalstopublishresults. NewerOHDSInetworksitesmayfindthefirstnetworkstudy theyparticipateintobelongerthannormalastheyworkthroughissueswithenvironment configurationsuchasdatabasepermissionsoranalyticslibraryupdates. Supportisavail­ ablefromtheOHDSICommunity. Issuescanbepostedtothe OHDSIForum astheyare encountered. A study lead should set study milestones in the protocol and communicate anticipated closuredateinadvancetoassistwithmanagingtheoverallstudytimeline. Ifthetimeline isnotadheredto,itistheresponsibilityofthestudyleadtoinformparticipatingsitesof updatestothestudyscheduleandmanagetheoverallprogressofstudyexecution. 20.3.3 Results Dissemination and Publication During the results dissemination and publication phase, the study lead will collaborate withotherparticipantsonvariousadministrativetasks,suchasmanuscriptdevelopment andoptimizingdatavisualizations. Oncethestudyisexecutedandresultsarestoredcen­ trallyforthestudyleadtofurtheranalyze. Thestudyleadisresponsibleforthecreation and dissemination of full study results (e.g. a Shiny Application) for review by partici­ pating centers. If the study lead is using an OHDSI study skeleton, either generated by AtlasormanuallymodifiedfromtheGitHubcode,theShinyApplicationwillbeautomat­ icallycreated. Intheeventastudyleadiscreatingcustomcode,thestudyleadmayuse the OHDSI Forum to ask for help to create their own Shiny Application for their study package. Not sure where to publish your OHDSI network study? Consult JANE (Jour­ nal/Author Name Estimator), a tool which takes your abstract and scans publicationsforrelevanceandfit.1 As manuscripts are written, each participating collaborator is encouraged to review and ensure the output follows external publication processes. At a minimum, the participat­ ingsiteshoulddesignateapublicationlead–thisindividualwillensurethatinternalpro­ cesses are adhered to during the manuscript preparation and submission. The choice of whichjournaltosubmitastudytoisatthediscretionofthestudylead,thoughshouldbe theresultsofcollaborativediscussionattheonsetofastudy. Allco­authorsonOHDSI studiesareexpectedtosatisfyICMJEauthorshipguidelines.2Thepresentationofresults mayoccurinanyforumoftheirchoosing(e.g.anOHDSISymposium,anotheracademic proceeding or in a journal publication). Researchers are also invited to present OHDSI 2http://www.icmje.org/recommendations/browse/roles­and­responsibilities/defining­the­role­of­ authors­and­contributors.html\n",
      "page text: 20.4. Forward Looking: Using Network Study Automation 377 NetworkStudiesonweeklyOHDSIcommunitycallsandatOHDSISymposiaacrossthe globe. 20.4 Forward Looking: Using Network Study Automation The current network study process is manual – with study team members using various mechanisms(includingWiki,GitHubandemail)tocollaborateonstudydesign,sharing code and results. This process is not consistent and scalable and to solve that issue, the OHDSIcommunityisactivelyworkingtosystemizestudyprocesses. Figure20.1: TheARACHNENetworkStudyProcess. ARACHNEisaplatformthatisdesignedtostreamlineandautomatetheprocessofcon­ ductingnetworkstudies. ARACHNEusesOHDSIstandardsandestablishesaconsistent, transparent, secure and compliant observational research process across multiple orga­ nizations. ARACHNE standardizes the communication protocol to access the data and exchangeanalysisresults, whileenablingauthenticationandauthorizationforrestricted content. Itbringsparticipatingorganizations­dataproviders,investigators,sponsorsand datascientists­intoasinglecollaborativestudyteamandfacilitatesanend­to­endobser­ vationalstudycoordination. Thetoolenablesthecreationofacomplete,standards­based R,PythonandSQLexecutionenvironmentincludingapprovalworkflowscontrolledby thedatacustodian. ARACHNEisbuilttoprovideaseamlessintegrationwithotherOHDSItools,including ACHILLESreportsandanabilitytoimportATLASdesignartifacts,createself­contained packages and automatically execute those across multiple sites. The future vision is to eventuallyenablemultiplenetworkstobelinkedtogetherforthepurposeofconducting researchnotonlybetweenorganizationswithinasinglenetwork,butalsobetweenorga­\n",
      "page text: 378 Chapter 20. OHDSI Network Research nizationsacrossmultiplenetworks. Figure20.2: TheARACHNENetworkofNetworks. 20.5 Best Practice for OHDSI Network Studies Asyouareconductinganetworkstudy,theOHDSIcommunityisavailabletoassistyou inensuringyouadheretobestpracticeforOHDSINetworkstudies. Study Design and Feasibility: When running a network study, make sure that you are notbiasingyourstudydesigntoasingletypeofdata. Thetaskofharmonizingthecohort definitions to represent consistent populations across all the sites may be more or less involved depending on the how heterogeneous the data types are and how carefully the studysitefollowedallstandardizedconventionsforconvertingdatatotheOMOPCDM. Thereasonthatthisissocriticalistheneedtocontroldifferencesindatacapture,represen­ tationandtransformationacrossnetworksitesversusthosethatareclinicallymeaningful. Inparticular,forcomparativeeffectivenessstudies,challengescanariseinensuringcon­ cordant exposure cohorts and outcome cohort definitions across the sites. For example, drugexposureinformationcancomefromvariousdatasourceswhichmayvaryintheir potentialformisclassification. Apharmacydispensingclaimfromahealthinsuranceplan maybeadjudicatedmeaningthatwhenthereisaclaimforamedication, thereisavery good chance that the person filled the prescription order. However, a prescription order entered into an EHR may be all that is available, without linkage to other data to deter­ minewhethertheorderwasdispensedorconsumed. Theremaybeatimegapbetweenthe recordofaphysicianwritingaprescriptionorder,thetimewhenthepharmacistdispensed the prescription, the time when the patient picked up their medication at the pharmacy, andthetimewhenthepatientactuallyconsumedherfirstpill. Thismeasurementerrorcan potentiallybiasresultsacrossanyanalyticusecase. Thus,itisimportanttoperformstudy feasibilitytoevaluatetheappropriatenessofdatabaseparticipationwhendevelopingthe studyprotocol.\n",
      "page text: 20.5. Best Practice for OHDSI Network Studies 379 Study Execution: Where possible, study leads are encouraged to utilize ATLAS, the OHDSI Methods Library and OHDSI Study Skeletons to create study code that used standardizedanalyticspackagesasmuchaspossible. Studycodeshouldalwaysbeina CDMcompliant,databaselayeragnosticwayusingOHDSIpackages. Besuretoparam­ eterizeallfunctionsandvariables(e.g.donotharddatabaseconnection,localharddrive path, assume a certain operating system). When recruiting participating sites, a study lead should ensure that each network site is CDM compliant and regularly updates the OMOPstandardizedvocabularies. Astudyleadshouldperformduediligencetoensure witheachnetworksitehasperformedanddocumenteddataqualitychecksontheirCDM (e.g. ensuring ETL has followed THEMIS business rules and conventions, correct data was placed into correct CDM tables and fields). Each data analyst is advised to update theirlocalRpackagestothelatestOHDSIpackageversionsbeforeexecutingthestudy package. Results and dissemination: A study lead should ensure each site follows local gover­ nancerulesbeforeresultsareshared. Open,reproduciblesciencemeansthateverything thatisdesignedandexecutedbecomesavailable. OHDSINetworkstudiesarefullytrans­ parent with all documentation and subsequent results published to the OHDSI GitHub repository or the data.ohdsi.org R Shiny server. As you prepare your manuscript, the studyleadshouldreviewtheprinciplesoftheOMOPCDMandStandardizedVocabular­ iestoensurethejournalunderstandshowdatacanvaryacrossOHDSInetworksites. For example,ifyouareperforminganetworkstudythatusesclaimsdatabasesandEHRs,you may be asked by journal reviewers to explain how the integrity of the cohort definition wasmaintainedacrossmultipledatatypes. Areviewermaywanttounderstandhowthe OMOP observation period (as discussed in Chapter 4compares to an eligibility file – a filethatexistsinclaimsdatabasestoattributewhenapersonisandisnotcoveredbyan insurance provider. This is inherently asking to focus on an artifactual element of the databases themselves and focuses on the ETL of how the CDM transforms the records intoobservations. Inthiscase,thenetworkstudyleadmayfindithelpfultoreferencehow theOMOPCDMOBSERVATIONPERIODiscreatedanddescribehowobservationsare createdusingtheencountersinthesourcesystem. Themanuscriptdiscussionmayneed to acknowledge the limitations of how EHR data, unlike claims data which reflects all paid encounters for that period of time they are covered, it does not record when a per­ son sees a provider who uses a different EHR of record and thus, breaks in observation periodsmayoccurbecauseofthepersonseekscarefromanout­of­EHRprovider. This isanartifactofhowdataexistsinthesystemitiscapturedin. Itisnotaclinicallymean­ ingfuldifferencebutmayconfusethosewhoareunfamiliarwithhowOMOPderivesthe observation period table. It is worth explaining in the discussion section to clarify this unfamiliarconvention. Similarly,astudyleadmayfinditusefultodescribetheterminol­ ogy service provided by the OMOP standard vocabularies enables a clinical concept to bethesameacrosswhereveritiscaptured. Therearealwaysdecisionsmadeinmapping of source codes to standard concepts however THEMIS conventions and CDM quality checks can help provide information on where information should go and how well a databaseadheredtothatprinciple.\n",
      "page text: 380 Chapter 20. OHDSI Network Research 20.6 Summary –An OHDSI study becomes an OHDSI Network study when it is run across multipleCDMsatdifferentinstitutions. –OHDSI network studies are open to all. Anyone can lead a network study. Anyone with an OMOP compliant database may opt to participate and con­ tributeresults. –Needhelprunninganetworkstudy? ConsultwiththeOHDSIStudyNurture Committeetohelpdesignandexecuteyourstudy. –Sharing is caring. Allstudydocumentation,codeandresultsarepublished ontheOHDSIGitHuborinanRShinyapplication. Studyleadsareinvited topresenttheirresearchatOHDSIevents.\n",
      "page text: Chapter A Glossary ACHILLES Adatabase­levelcharacterizationreport. ARACHNE TheOHDSIplatformthatisbeingdevelopedtoallowtheorchestrationand executionoffederatednetworkstudies. ATLASA web­based application that is installed on participating sites to support the design and execution of observational analyses to generate real world evidence frompatientlevelclinicaldata. BiasTheexpectedvalueoftheerror(thedifferencebetweenthetruevalueandtheesti­ matedvalue). BooleanVariablethathasonlytwovalues(trueorfalse). Care site A uniquely identified institutional (physical or organizational) unit where healthcaredeliveryispracticed(office,ward,hospital,clinic,etc.). Case control Atypeofretrospectivestudydesignforpopulation­leveleffectestimation. Case­control studies match “cases” with the target outcome to “controls” without thetargetoutcome. Thentheylookbackintimeandcomparetheoddsofexposure inthecasesandthecontrols. Causal effect What population­level estimation concerns itself with. One definition equatesa“causaleffect”astheaverageofthe“unit­levelcausaleffects”inatarget population. The unit­level causal effect is the contrast between the outcome had anindividualbeenexposedandtheoutcomehadthatindividualnotbeenexposed (orbeenexposedtoAasagainstB). Characterization Descriptivestudyofacohortorentiredatabase. SeeChapter 11. Claims data Datageneratedforthepurposeofbillingahealthinsurancecompany. Clinical trial Interventionalclinicalstudy. CohortAsetofpersonswhosatisfyoneormoreinclusioncriteriaforadurationoftime. SeeChapter 10. ConceptA term (with a code) defined in a medical terminology (e.g., SNOMED CT). SeeChapter 5. Concept set A concept set is an expression representing a list of concepts that can be usedasareusablecomponentinvariousanalyses. SeeChapter 10. 381\n",
      "page text: 382 Appendix A. Glossary Common Data Model (CDM) A convention for representing healthcare data that al­ lowsportabilityofanalysis(thesameanalysisunmodifiedcanbeexecutedonmul­ tipledatasets). SeeChapter 4. Comparative Effectiveness A comparison of the effects of two different exposures on anoutcomeofinterest. SeeChapter 12. Condition Adiagnosis,asign,orasymptom,whichiseitherobservedbyaprovideror reportedbythepatient. Confounding Confounding is a distortion (inaccuracy) in the estimated measure of as­ sociationthatoccurswhentheprimaryexposureofinterestismixedupwithsome otherfactorthatisassociatedwiththeoutcome. Covariate Dataelement(e.g.,weight)thatisusedinastatisticalmodelasindependent variable. Data quality The state of completeness, validity, consistency, timeliness and accuracy thatmakesdataappropriateforaspecificuse. DeviceA foreign physical object or instrument which is used for diagnostic or thera­ peutic purposes through a mechanism beyond chemical action. Devices include implantable objects (e.g. pacemakers, stents, artificial joints), medical equipment andsupplies(e.g.bandages,crutches,syringes),otherinstrumentsusedinmedical procedures (e.g. sutures, defibrillators) and material used in clinical care (e.g. ad­ hesives,bodymaterial,dentalmaterial,surgicalmaterial). DrugA Drug is a biochemical substance formulated in such a way that when admin­ istered to a Person it will exert a certain physiological effect. Drugs include pre­ scription and over­the­counter medicines, vaccines, and large­molecule biologic therapies. RadiologicaldevicesingestedorappliedlocallydonotcountasDrugs. DomainA Domain defines the set of allowable Concepts for the standardized fields in the CDM tables. For example, the “Condition” Domain contains Concepts that describe a condition of a patient, and these Concepts can only be stored in the condition_concept_id field of the CONDITION_OCCURRENCE and CONDITION_ERAtables. Electronic Health Record (EHR) Datageneratedduringcourseofcareandrecordedin anelectronicsystem. Epidemiology Thestudyofthedistribution,patternsanddeterminantsofhealthanddis­ easeconditionsindefinedpopulations. Evidence­based medicine Theuseofempiricalandscientificevidenceinmakingdeci­ sionsaboutthecareofindividualpatients. ETL (Extract­Transform­Load) Theprocessofconvertingdatafromoneformattoan­ other,forexamplefromasourceformattotheCDM.SeeChapter 6. Matching Many population­level effect estimation approaches attempt to identify the causal effects of exposures by comparing outcomes in exposed patients to those sameoutcomesinunexposedpatients(orexposedtoAversusB).Sincethesetwo patient groups might differ in ways other than exposure, “matching” attempts to createexposedandunexposedpatientgroupsthatareassimilaraspossibleatleast withrespecttomeasuredpatientcharacteristics. Measurement Astructuredvalue(numericalorcategorical)obtainedthroughsystematic\n",
      "page text: 383 andstandardizedexaminationortestingofapersonorperson’ssample. Measurement error Occurswhenarecordedmeasurement(e.g.,bloodpressure,patient age,durationoftreatment)differsfromthecorrespondingtruemeasurement. Metadata A set of data that describes and gives information about other data and in­ cludes descriptive metadata, structural metadata, administrative metadata, refer­ encemetadataandstatisticalmetadata. Methods Library A set of R packages developed by the OHDSI community for per­ formingobservationalstudies. Model misspecification Many OHDSI methods employ statistical models such as pro­ portionalhazardsregressionorrandomforests. Insofarasthemechanismthatgen­ eratedthedatadeviatefromtheassumedmodel,themodelis“misspecified.” Negative control Anexposure­outcomepairwheretheexposureisbelievedtonotcause orpreventtheoutcome. Canbeusedtoassesswhethereffectestimationmethods produceresultsinlinewiththetruth. SeeChapter 18. Observation AclinicalfactaboutaPersonobtainedinthecontextofexamination,ques­ tioningoraprocedure. Observation period Thespanoftimeforwhichapersonisat­risktohaveclinicalevents recordedwithinthesourcesystems,evenifnoeventsinfactarerecorded(healthy patientwithnohealthcareinteractions). Observational study Astudywheretheresearcherhasnocontrolovertheintervention. OHDSI SQL A SQL dialect that can be automatically translated to various other SQL dialects using the SqlRender R package. OHDSI SQL is mostly a subset of SQL ServerSQL,butallowsforadditionalparameterization. SeeChapter 9. Open science The movement to make scientific research (including publications, data, physicalsamples,andsoftware)anditsdisseminationaccessibletoalllevelsofan inquiringsociety,amateurorprofessional. SeeChapter 3. Outcome An observation that provides a focal point for an analysis. For example, a patient­level predictive model might predict the outcome “stroke.” Or a population­level estimation might estimate the causal effect of a drug on the outcome“headache.” Patient­level prediction Developmentandapplicationofpredictivemodelstoproduce patient­specificprobabilitiesforexperiencingsomefutureoutcomebasedonbase­ linecharacteristics. Phenotype Adescriptionofphysicalcharacteristics. Thisincludesvisiblecharacteristics like your weight and hair color, but also your overall health, your disease history, andyourbehavior. Population­level estimation A study into causal effects. Estimates an average (population­level)effectsize. Positive control An exposure­outcome pair where the exposure is believed to cause or prevent the outcome. Can be used to assess whether effect estimation methods produceresultsinlinewiththetruth. SeeChapter 18. Procedure Activityorprocessorderedby,orcarriedoutby,ahealthcareprovideronthe patienttohaveadiagnosticortherapeuticpurpose. Propensity score (PS) a single metric used in population­level estimation to balance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 426/464 [00:04<00:00, 108.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: 384 Appendix A. Glossary populationsinorder tomimic randomizationbetween twotreatmentgroups inan observationalstudy. ThePSrepresentstheprobabilityofapatientreceivingatreat­ ment of interest as a function of a set of observed baseline covariates. It is most oftencalculatedusingalogisticregressionmodelwherethebinaryoutcomeisset to one for the group receiving the target treatment of interest and to zero for the comparatortreatment. SeeChapter 12. ProtocolAhumanreadabledocumentthatfullyspecifiesthedesignofastudy. Rabbit­in­a­Hat AninteractivesoftwaretooltohelpdefinetheETLfromsourceformat toCDM.UsesthedatabaseprofilegeneratedbyWhiteRabbitasinput. SeeChapter 7. Selection bias Abiasthatoccurswhenthesetofpatientsinyourdatadeviatesfromthe patientsinthepopulationinwaysthatdistortstatisticalanalyses. Self­controlled designs Study designs that compare outcomes during different expo­ sureswithinthesamepatient. Sensitivity analysis Avariantofthemainanalysisusedinastudytoassestheimpactof ananalysischoiceoverwhichuncertaintyexists. SNOMED Asystematicallyorganizedcomputerprocessablecollectionofmedicalterms providing codes, terms, synonyms and definitions used in clinical documentation andreporting. Study diagnostics Setofanalyticalstepswherethegoalistodeterminewhetheragiven analyticalapproachcanbeused(isvalid)foransweringagivenresearchquestion. SeeChapter 18. Study package Acomputer­executableprogramthatfullyexecutesthestudy. SeeChap­ ter17. Source code Acodeusedinasourcedatabase. ForexampleanICD­10code. Standard Concept Aconceptthatisdesignatedasvalidconceptandallowedtoappear intheCDM. THEMIS OHDSIworkgroupthataddressestargetdataformatthatisofhighergranular­ ityanddetailwithrespecttoCDMmodelspecifications. VisitThespanoftimeapersoncontinuouslyreceivesmedicalservicesfromoneormore providersatacaresiteinagivensettingwithinthehealthcaresystem. Vocabulary A list of words and often phrases, usually arranged alphabetically and de­ finedortranslated. SeeChapter 5. White Rabbit A software tool for profiling a database before defining the ETL to the CDM.SeeChapter 6.\n",
      "page text: Chapter B Cohort definitions ThisAppendixcontainscohortdefinitionsusedthroughoutthebook. B.1 ACE Inhibitors Initial Event Cohort Peoplehavinganyofthefollowing: •a drug exposure of ACE inhibitors (TableB.1) for the first time in the person’s history withcontinuousobservationofatleast365dayspriorand0daysaftereventindexdate, andlimitinitialeventsto: alleventsperperson. Limitqualifyingcohortto: alleventsperperson. End Date Strategy Custom Drug Era Exit Criteria This strategy creates a drug era from the codes found in the specified concept set. If the index event is found within an era, the cohort end date will use the era’s end date. Otherwise, it will use the observation period end date that containstheindexevent. Usetheeraenddateof ACE inhibitors (TableB.1) •allowing30daysbetweenexposures •adding0daysafterexposureend Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof30days. 385\n",
      "page text: 386 Appendix B. Cohort definitions Concept Set Definitions TableB.1: ACEinhibitors ConceptId ConceptName Excluded Descendants Mapped 1308216 Lisinopril NO YES NO 1310756 moexipril NO YES NO 1331235 quinapril NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1340128 Captopril NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1363749 Fosinopril NO YES NO 1373225 Perindopril NO YES NO B.2 New Users of ACE Inhibitors Monotherapy Initial Event Cohort Peoplehavinganyofthefollowing: •a drug exposure of ACE inhibitors (TableB.2) for the first time in the person’s history withcontinuousobservationofatleast365dayspriorand0daysaftereventindexdate, andlimitinitialeventsto: earliesteventperperson. Inclusion Rules InclusionCriteria#1: hashypertensiondiagnosisin1yrpriortotreatment Havingallofthefollowingcriteria: •at least 1 occurrences of a condition occurrence of Hypertensive disorder (Table B.3)whereeventstartsbetween365daysBeforeand0daysAfterindexstartdate InclusionCriteria#2: Hasnopriorantihypertensivedrugexposuresinmedicalhistory Havingallofthefollowingcriteria: •exactly0occurrencesofadrugexposureof Hypertension drugs (TableB.4)where eventstartsbetweenalldaysBeforeand1daysBeforeindexstartdate Inclusion Criteria #3: Is only taking ACE as monotherapy, with no concomitant combi­ nationtreatments Havingallofthefollowingcriteria:\n",
      "page text: B.2. New Users of ACE Inhibitors Monotherapy 387 •exactly 1 distinct occurrences of a drug era of Hypertension drugs (TableB.4) whereeventstartsbetween0daysBeforeand7daysAfterindexstartdate Limitqualifyingcohortto: earliesteventperperson. End Date Strategy CustomDrugEraExitCriteria. Thisstrategycreatesadrugerafromthecodesfoundin the specified concept set. If the index event is found within an era, the cohort end date will use the era’s end date. Otherwise, it will use the observation period end date that containstheindexevent. Usetheeraenddateof ACE inhibitors (TableB.2) •allowing30daysbetweenexposures •adding0daysafterexposureend Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof0days. Concept Set Definitions TableB.2: ACEinhibitors ConceptId ConceptName Excluded Descendants Mapped 1308216 Lisinopril NO YES NO 1310756 moexipril NO YES NO 1331235 quinapril NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1340128 Captopril NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1363749 Fosinopril NO YES NO 1373225 Perindopril NO YES NO TableB.3: Hypertensivedisorder ConceptId ConceptName Excluded Descendants Mapped 316866 Hypertensivedisorder NO YES NO\n",
      "page text: 388 Appendix B. Cohort definitions TableB.4: Hypertensiondrugs ConceptId ConceptName Excluded Descendants Mapped 904542 Triamterene NO YES NO 907013 Metolazone NO YES NO 932745 Bumetanide NO YES NO 942350 torsemide NO YES NO 956874 Furosemide NO YES NO 970250 Spironolactone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 991382 Amiloride NO YES NO 1305447 Methyldopa NO YES NO 1307046 Metoprolol NO YES NO 1307863 Verapamil NO YES NO 1308216 Lisinopril NO YES NO 1308842 valsartan NO YES NO 1309068 Minoxidil NO YES NO 1309799 eplerenone NO YES NO 1310756 moexipril NO YES NO 1313200 Nadolol NO YES NO 1314002 Atenolol NO YES NO 1314577 nebivolol NO YES NO 1317640 telmisartan NO YES NO 1317967 aliskiren NO YES NO 1318137 Nicardipine NO YES NO 1318853 Nifedipine NO YES NO 1319880 Nisoldipine NO YES NO 1319998 Acebutolol NO YES NO 1322081 Betaxolol NO YES NO 1326012 Isradipine NO YES NO 1327978 Penbutolol NO YES NO 1328165 Diltiazem NO YES NO 1331235 quinapril NO YES NO 1332418 Amlodipine NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1338005 Bisoprolol NO YES NO 1340128 Captopril NO YES NO 1341238 Terazosin NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1344965 Guanfacine NO YES NO 1345858 Pindolol NO YES NO\n",
      "page text: B.3. Acute Myocardial Infarction (AMI) 389 ConceptId ConceptName Excluded Descendants Mapped 1346686 eprosartan NO YES NO 1346823 carvedilol NO YES NO 1347384 irbesartan NO YES NO 1350489 Prazosin NO YES NO 1351557 candesartan NO YES NO 1353766 Propranolol NO YES NO 1353776 Felodipine NO YES NO 1363053 Doxazosin NO YES NO 1363749 Fosinopril NO YES NO 1367500 Losartan NO YES NO 1373225 Perindopril NO YES NO 1373928 Hydralazine NO YES NO 1386957 Labetalol NO YES NO 1395058 Chlorthalidone NO YES NO 1398937 Clonidine NO YES NO 40226742 olmesartan NO YES NO 40235485 azilsartan NO YES NO B.3 Acute Myocardial Infarction (AMI) Initial Event Cohort Peoplehavinganyofthefollowing: •aconditionoccurrenceof Acute myocardial Infarction (TableB.5) withcontinuousobservationofatleast0dayspriorand0daysaftereventindexdate,and limitinitialeventsto: alleventsperperson. ForpeoplematchingthePrimaryEvents,include: Havinganyofthefollowingcriteria: •at least 1 occurrences of a visit occurrence of Inpatient or ER visit (TableB.6) where event starts between all days Before and 0 days After index start date and eventendsbetween0daysBeforeandalldaysAfterindexstartdate Limitcohortofinitialeventsto: alleventsperperson. Limitqualifyingcohortto: alleventsperperson. End Date Strategy Date Offset Exit Criteria. This cohort definition end date will be the index event’s start dateplus7days\n",
      "page text: 390 Appendix B. Cohort definitions Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof180days. Concept Set Definitions TableB.5: InpatientorERvisit ConceptId ConceptName Excluded Descendants Mapped 314666 Oldmyocardialinfarction YES YES NO 4329847 Myocardialinfarction NO YES NO TableB.6: InpatientorERvisit ConceptId ConceptName Excluded Descendants Mapped 262 EmergencyRoomandInpatientVisit NO YES NO 9201 InpatientVisit NO YES NO 9203 EmergencyRoomVisit NO YES NO B.4 Angioedema Initial Event Cohort Peoplehavinganyofthefollowing: •aconditionoccurrenceof Angioedema (TableB.7) withcontinuousobservationofatleast0dayspriorand0daysaftereventindexdate,and limitinitialeventsto: alleventsperperson. ForpeoplematchingthePrimaryEvents,include: Havinganyofthefollowingcriteria: •at least 1 occurrences of a visit occurrence of Inpatient or ER visit (TableB.8) where event starts between all days Before and 0 days After index start date and eventendsbetween0daysBeforeandalldaysAfterindexstartdate Limitcohortofinitialeventsto: alleventsperperson. Limitqualifyingcohortto: alleventsperperson. End Date Strategy Thiscohortdefinitionenddatewillbetheindexevent’sstartdateplus7days Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof30days.\n",
      "page text: B.5. New Users of Thiazide­Like Diuretics Monotherapy 391 Concept Set Definitions TableB.7: Angioedema ConceptId ConceptName Excluded Descendants Mapped 432791 Angioedema NO YES NO TableB.8: InpatientorERvisit ConceptId ConceptName Excluded Descendants Mapped 262 EmergencyRoomandInpatientVisit NO YES NO 9201 InpatientVisit NO YES NO 9203 EmergencyRoomVisit NO YES NO B.5 New Users of Thiazide-Like Diuretics Monotherapy Initial Event Cohort Peoplehavinganyofthefollowing: •a drug exposure of Thiazide or thiazide­like diuretic (TableB.9) for the first time intheperson’shistory withcontinuousobservationofatleast365dayspriorand0daysaftereventindexdate, andlimitinitialeventsto: earliesteventperperson. Inclusion Rules InclusionCriteria#1: hashypertensiondiagnosisin1yrpriortotreatment Havingallofthefollowingcriteria: •at least 1 occurrences of a condition occurrence of Hypertensive disorder (Table B.10)whereeventstartsbetween365daysBeforeand0daysAfterindexstartdate InclusionCriteria#2: Hasnopriorantihypertensivedrugexposuresinmedicalhistory Havingallofthefollowingcriteria: •exactly0occurrencesofadrugexposureof Hypertension drugs (TableB.11)where eventstartsbetweenalldaysBeforeand1daysBeforeindexstartdate Inclusion Criteria #3: Is only taking ACE as monotherapy, with no concomitant combi­ nationtreatments Havingallofthefollowingcriteria:\n",
      "page text: 392 Appendix B. Cohort definitions •exactly 1 distinct occurrences of a drug era of Hypertension drugs (TableB.11) whereeventstartsbetween0daysBeforeand7daysAfterindexstartdate Limitqualifyingcohortto: earliesteventperperson. End Date Strategy CustomDrugEraExitCriteria. Thisstrategycreatesadrugerafromthecodesfoundin the specified concept set. If the index event is found within an era, the cohort end date will use the era’s end date. Otherwise, it will use the observation period end date that containstheindexevent. Usetheeraenddateof Thiazide or thiazide­like diuretic (TableB.9) •allowing30daysbetweenexposures •adding0daysafterexposureend Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof0days. Concept Set Definitions TableB.9: Thiazideorthiazide­likediuretic ConceptId ConceptName Excluded Descendants Mapped 907013 Metolazone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 1395058 Chlorthalidone NO YES NO TableB.10: Hypertensivedisorder ConceptId ConceptName Excluded Descendants Mapped 316866 Hypertensivedisorder NO YES NO TableB.11: Hypertensiondrugs ConceptId ConceptName Excluded Descendants Mapped 904542 Triamterene NO YES NO 907013 Metolazone NO YES NO 932745 Bumetanide NO YES NO 942350 torsemide NO YES NO\n",
      "page text: B.5. New Users of Thiazide­Like Diuretics Monotherapy 393 ConceptId ConceptName Excluded Descendants Mapped 956874 Furosemide NO YES NO 970250 Spironolactone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 991382 Amiloride NO YES NO 1305447 Methyldopa NO YES NO 1307046 Metoprolol NO YES NO 1307863 Verapamil NO YES NO 1308216 Lisinopril NO YES NO 1308842 valsartan NO YES NO 1309068 Minoxidil NO YES NO 1309799 eplerenone NO YES NO 1310756 moexipril NO YES NO 1313200 Nadolol NO YES NO 1314002 Atenolol NO YES NO 1314577 nebivolol NO YES NO 1317640 telmisartan NO YES NO 1317967 aliskiren NO YES NO 1318137 Nicardipine NO YES NO 1318853 Nifedipine NO YES NO 1319880 Nisoldipine NO YES NO 1319998 Acebutolol NO YES NO 1322081 Betaxolol NO YES NO 1326012 Isradipine NO YES NO 1327978 Penbutolol NO YES NO 1328165 Diltiazem NO YES NO 1331235 quinapril NO YES NO 1332418 Amlodipine NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1338005 Bisoprolol NO YES NO 1340128 Captopril NO YES NO 1341238 Terazosin NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1344965 Guanfacine NO YES NO 1345858 Pindolol NO YES NO 1346686 eprosartan NO YES NO 1346823 carvedilol NO YES NO 1347384 irbesartan NO YES NO 1350489 Prazosin NO YES NO 1351557 candesartan NO YES NO 1353766 Propranolol NO YES NO\n",
      "page text: 394 Appendix B. Cohort definitions ConceptId ConceptName Excluded Descendants Mapped 1353776 Felodipine NO YES NO 1363053 Doxazosin NO YES NO 1363749 Fosinopril NO YES NO 1367500 Losartan NO YES NO 1373225 Perindopril NO YES NO 1373928 Hydralazine NO YES NO 1386957 Labetalol NO YES NO 1395058 Chlorthalidone NO YES NO 1398937 Clonidine NO YES NO 40226742 olmesartan NO YES NO 40235485 azilsartan NO YES NO B.6 Patients Initiating First-Line Therapy for Hyperten- sion Initial Event Cohort Peoplehavinganyofthefollowing: •adrugexposureof First­line hypertension drugs (TableB.12)forthefirsttimein theperson’shistory withcontinuousobservationofatleast365dayspriorand365daysaftereventindexdate, andlimitinitialeventsto: earliesteventperperson. Inclusion Rules Havingallofthefollowingcriteria: •exactly0occurrencesofadrugexposureof Hypertension drugs (TableB.13)where eventstartsbetweenalldaysBeforeand1daysBeforeindexstartdate •andatleast1occurrencesofaconditionoccurrenceof Hypertensive disorder (Table B.14)whereeventstartsbetween365daysBeforeand0daysAfterindexstartdate Limit cohort of initial events to: earliest event per person. Limit qualifying cohort to: earliesteventperperson. End Date Strategy No end date strategy selected. By default, the cohort end date will be the end of the observationperiodthatcontainstheindexevent. Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof0days.\n",
      "page text: B.6. Patients Initiating First­Line Therapy for Hypertension 395 Concept Set Definitions TableB.12: First­linehypertensiondrugs ConceptId ConceptName Excluded Descendants Mapped 907013 Metolazone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 1307863 Verapamil NO YES NO 1308216 Lisinopril NO YES NO 1308842 valsartan NO YES NO 1310756 moexipril NO YES NO 1317640 telmisartan NO YES NO 1318137 Nicardipine NO YES NO 1318853 Nifedipine NO YES NO 1319880 Nisoldipine NO YES NO 1326012 Isradipine NO YES NO 1328165 Diltiazem NO YES NO 1331235 quinapril NO YES NO 1332418 Amlodipine NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1340128 Captopril NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1346686 eprosartan NO YES NO 1347384 irbesartan NO YES NO 1351557 candesartan NO YES NO 1353776 Felodipine NO YES NO 1363749 Fosinopril NO YES NO 1367500 Losartan NO YES NO 1373225 Perindopril NO YES NO 1395058 Chlorthalidone NO YES NO 40226742 olmesartan NO YES NO 40235485 azilsartan NO YES NO TableB.13: Hypertensiondrugs ConceptId ConceptName Excluded Descendants Mapped 904542 Triamterene NO YES NO 907013 Metolazone NO YES NO 932745 Bumetanide NO YES NO 942350 torsemide NO YES NO\n",
      "page text: 396 Appendix B. Cohort definitions ConceptId ConceptName Excluded Descendants Mapped 956874 Furosemide NO YES NO 970250 Spironolactone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 991382 Amiloride NO YES NO 1305447 Methyldopa NO YES NO 1307046 Metoprolol NO YES NO 1307863 Verapamil NO YES NO 1308216 Lisinopril NO YES NO 1308842 valsartan NO YES NO 1309068 Minoxidil NO YES NO 1309799 eplerenone NO YES NO 1310756 moexipril NO YES NO 1313200 Nadolol NO YES NO 1314002 Atenolol NO YES NO 1314577 nebivolol NO YES NO 1317640 telmisartan NO YES NO 1317967 aliskiren NO YES NO 1318137 Nicardipine NO YES NO 1318853 Nifedipine NO YES NO 1319880 Nisoldipine NO YES NO 1319998 Acebutolol NO YES NO 1322081 Betaxolol NO YES NO 1326012 Isradipine NO YES NO 1327978 Penbutolol NO YES NO 1328165 Diltiazem NO YES NO 1331235 quinapril NO YES NO 1332418 Amlodipine NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1338005 Bisoprolol NO YES NO 1340128 Captopril NO YES NO 1341238 Terazosin NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1344965 Guanfacine NO YES NO 1345858 Pindolol NO YES NO 1346686 eprosartan NO YES NO 1346823 carvedilol NO YES NO 1347384 irbesartan NO YES NO 1350489 Prazosin NO YES NO 1351557 candesartan NO YES NO 1353766 Propranolol NO YES NO\n",
      "page text: B.7. Patients Initiating First­Line Therapy for Hypertension With >3 Yr Follow­Up 397 ConceptId ConceptName Excluded Descendants Mapped 1353776 Felodipine NO YES NO 1363053 Doxazosin NO YES NO 1363749 Fosinopril NO YES NO 1367500 Losartan NO YES NO 1373225 Perindopril NO YES NO 1373928 Hydralazine NO YES NO 1386957 Labetalol NO YES NO 1395058 Chlorthalidone NO YES NO 1398937 Clonidine NO YES NO 40226742 olmesartan NO YES NO 40235485 azilsartan NO YES NO TableB.14: Hypertensivedisorder ConceptId ConceptName Excluded Descendants Mapped 316866 Hypertensivedisorder NO YES NO B.7 Patients Initiating First-Line Therapy for Hyperten- sion With >3 Y r Follow-Up Sameas cohort definition B.6butwithcontinuousobservationofatleast365daysprior and1095 days aftereventindexdate B.8 ACE Inhibitor Use Initial Event Cohort Peoplehavinganyofthefollowing: •adrugexposureof ACE inhibitors (TableB.15) withcontinuousobservationofatleast0dayspriorand0daysaftereventindexdate,and limitinitialeventsto: alleventsperperson. Limitqualifyingcohortto: alleventsperperson. End Date Strategy This strategy creates a drug era from the codes found in the specified concept set. If the index event is found within an era, the cohort end date will use the era’s end date. Otherwise,itwillusetheobservationperiodenddatethatcontainstheindexevent. Usetheeraenddateof ACE inhibitors (TableB.15)\n",
      "page text: 398 Appendix B. Cohort definitions •allowing30daysbetweenexposures •adding0daysafterexposureend Cohort Collapse Strategy Collapsecohortbyerawithagapsizeof30days. Concept Set Definitions TableB.15: ACEinhibitors ConceptId ConceptName Excluded Descendants Mapped 1308216 Lisinopril NO YES NO 1310756 moexipril NO YES NO 1331235 quinapril NO YES NO 1334456 Ramipril NO YES NO 1335471 benazepril NO YES NO 1340128 Captopril NO YES NO 1341927 Enalapril NO YES NO 1342439 trandolapril NO YES NO 1363749 Fosinopril NO YES NO 1373225 Perindopril NO YES NO B.9 Angiotensin Receptor Blocker (ARB) Use Same as cohort definition B.8with Angiotensin Receptor Blockers (ARBs) (TableB.16) inplaceof ACE inhibitors (TableB.15). Concept Set Definitions TableB.16: AngiotensinReceptorBlockers(ARBs) ConceptId ConceptName Excluded Descendants Mapped 1308842 valsartan NO YES NO 1317640 telmisartan NO YES NO 1346686 eprosartan NO YES NO 1347384 irbesartan NO YES NO 1351557 candesartan NO YES NO 1367500 Losartan NO YES NO 40226742 olmesartan NO YES NO 40235485 azilsartan NO YES NO\n",
      "page text: B.10. Thiazide Or Thiazide­Like Diuretic Use 399 B.10 Thiazide Or Thiazide-Like Diuretic Use Sameas cohort definition B.8with Thiazide or thiazide­like diuretic (TableB.17)inplace ofACE inhibitors (TableB.15). Concept Set Definitions TableB.17: Thiazideorthiazide­likediuretic ConceptId ConceptName Excluded Descendants Mapped 907013 Metolazone NO YES NO 974166 Hydrochlorothiazide NO YES NO 978555 Indapamide NO YES NO 1395058 Chlorthalidone NO YES NO B.11 Dihydropyridine Calcium Channel Blocker (dCCB) Use Same as cohort definition B.8with dihydropyridine Calcium Channel Blocker (dCCB) (TableB.18)inplaceof ACE inhibitors (TableB.15). Concept Set Definitions TableB.18: DihydropyridineCalciumchannelblockers(dCCB) ConceptId ConceptName Excluded Descendants Mapped 1318137 Nicardipine NO YES NO 1318853 Nifedipine NO YES NO 1319880 Nisoldipine NO YES NO 1326012 Isradipine NO YES NO 1332418 Amlodipine NO YES NO 1353776 Felodipine NO YES NO B.12 Non-Dihydropyridine Calcium Channel Blocker (nd- CCB) Use Same as cohort definition B.8with non­dihydropyridine Calcium channel blockers (nd­ CCB)(TableB.19)inplaceof ACE inhibitors (TableB.15). Concept Set Definitions\n",
      "page text: 400 Appendix B. Cohort definitions Table B.19: non­dihydropyridine Calcium channel blockers (nd­ CCB) ConceptId ConceptName Excluded Descendants Mapped 1307863 Verapamil NO YES NO 1328165 Diltiazem NO YES NO B.13 Beta-Blocker Use Sameas cohort definition B.8with Beta blockers (TableB.20)inplaceof ACE inhibitors (TableB.15). Concept Set Definitions TableB.20: Betablockers ConceptId ConceptName Excluded Descendants Mapped 1307046 Metoprolol NO YES NO 1313200 Nadolol NO YES NO 1314002 Atenolol NO YES NO 1314577 nebivolol NO YES NO 1319998 Acebutolol NO YES NO 1322081 Betaxolol NO YES NO 1327978 Penbutolol NO YES NO 1338005 Bisoprolol NO YES NO 1345858 Pindolol NO YES NO 1346823 carvedilol NO YES NO 1353766 Propranolol NO YES NO 1386957 Labetalol NO YES NO B.14 Diuretic-Loop Use Same as cohort definition B.8with Diuretics ­ Loop (TableB.21) in place of ACE in­ hibitors(TableB.15). Concept Set Definitions TableB.21: Diuretics­Loop ConceptId ConceptName Excluded Descendants Mapped 932745 Bumetanide NO YES NO\n",
      "page text: B.15. Diuretic­Potassium Sparing Use 401 ConceptId ConceptName Excluded Descendants Mapped 942350 torsemide NO YES NO 956874 Furosemide NO YES NO B.15 Diuretic-Potassium Sparing Use Same as cohort definition B.8with Diuretics ­ potassium sparing (TableB.22) in place ofACE inhibitors (TableB.15). Concept Set Definitions TableB.22: Diuretics­potassiumsparing ConceptId ConceptName Excluded Descendants Mapped 904542 Triamterene NO YES NO 991382 Amiloride NO YES NO B.16 Alpha-1 Blocker Use Same as cohort definition B.8with Alpha­1 blocker (TableB.23) in place of ACE in­ hibitors(TableB.15). Concept Set Definitions TableB.23: Alpha­1blocker ConceptId ConceptName Excluded Descendants Mapped 1341238 Terazosin NO YES NO 1350489 Prazosin NO YES NO 1363053 Doxazosin NO YES NO\n",
      "page text: 402 Appendix B. Cohort definitions\n",
      "page text: Chapter C Negative controls ThisAppendixcontainsnegativecontrolsusedinvariouschaptersofthebook. C.1 ACEi and THZ Table C.1: Negative control outcomes when comparing ACE in­ hibitors(ACEi)tothiazidesandthiazide­likediuretics(THZ). ConceptID ConceptName 434165 Abnormalcervicalsmear 436409 Abnormalpupil 199192 Abrasionand/orfrictionburnoftrunkwithoutinfection 4088290 Absenceofbreast 4092879 Absentkidney 44783954 Acidreflux 75911 Acquiredhalluxvalgus 137951 Acquiredkeratoderma 77965 Acquiredtriggerfinger 376707 Acuteconjunctivitis 4103640 Amputatedfoot 73241 Analandrectalpolyp 133655 Burnofforearm 73560 Calcanealspur 434327 Cannabisabuse 4213540 Cervicalsomaticdysfunction 140842 Changesinskintexture 81378 Chondromalaciaofpatella 432303 Cocaineabuse 4201390 Colostomypresent 403\n",
      "page text: 404 Appendix C. Negative controls ConceptID ConceptName 46269889 ComplicationduetoCrohn’sdisease 134438 Contactdermatitis 78619 Contusionofknee 201606 Crohn’sdisease 76786 Derangementofknee 4115402 Difficultysleeping 45757370 Disproportionofreconstructedbreast 433111 Effectsofhunger 433527 Endometriosis 4170770 Epidermoidcyst 4092896 Fecescontentsabnormal 259995 Foreignbodyinorifice 40481632 Ganglioncyst 4166231 Geneticpredisposition 433577 Hammertoe 4231770 Hereditarythrombophilia 440329 Herpeszosterwithoutcomplication 4012570 Highrisksexualbehavior 4012934 Homocystinuria 441788 Humanpapillomavirusinfection 4201717 Ileostomypresent 374375 Impactedcerumen 4344500 Impingementsyndromeofshoulderregion 139099 Ingrowingnail 444132 Injuryofknee 196168 Irregularperiods 432593 Kwashiorkor 434203 Lateeffectofcontusion 438329 Lateeffectofmotorvehicleaccident 195873 Leukorrhea 4083487 Maculardrusen 4103703 Melena 4209423 Nicotinedependence 377572 Noiseeffectsoninnerear 40480893 Nonspecifictuberculintestreaction 136368 Non­toxicmultinodulargoiter 140648 Onychomycosisduetodermatophyte 438130 Opioidabuse 4091513 Passingflatus 4202045 Postviralfatiguesyndrome 373478 Presbyopia 46286594 Problemrelatedtolifestyle 439790 Psychalgia\n",
      "page text: C.1. ACEi and THZ 405 ConceptID ConceptName 81634 Ptoticbreast 380706 Regularastigmatism 141932 Senilehyperkeratosis 36713918 Somaticdysfunctionoflumbarregion 443172 Splinterofface,withoutmajoropenwound 81151 Sprainofankle 72748 Strainofrotatorcuffcapsule 378427 Tearfilminsufficiency 437264 Tobaccodependencesyndrome 194083 Vaginitisandvulvovaginitis 140641 Verrucavulgaris 440193 Wristdrop 4115367 Wristjointpain\n",
      "page text: 406 Appendix C. Negative controls\n",
      "page text: Chapter D Protocol template 1.Tableofcontents 2.Listofabbreviations 3.Abstract 4.AmendmentsandUpdates 5.Milestones 6.RationaleandBackground 7.StudyObjectives •PrimaryHypotheses •SecondaryHypotheses •PrimaryObjectives •SecondaryObjectives 8.Researchmethods •StudyDesign •DataSource(s) •Studypopulation •Exposures •Outcomes •Covariates 9.DataAnalysisPlan •Calculationoftime­atrisk •ModelSpecification •Poolingeffectestimatesacrossdatabases •Analysestoperform •Output •EvidenceEvaluation 10.StudyDiagnostics •SampleSizeandStudyPower •CohortComparability •SystematicErrorAssessment 407\n",
      "page text: 408 Appendix D. Protocol template 11.StrengthsandLimitationsoftheResearchMethods 12.ProtectionofHumanSubjects 13.ManagementandReportingofAdverseEventsandAdverseReactions 14.PlansforDisseminatingandCommunicatingStudyResults 15.Appendix: Negativecontrols 16.References\n",
      "page text: Chapter E Suggested Answers ThisAppendixcontainssuggestedanswersfortheexercisesinthebook. E.1 The Common Data Model Exercise 4.1 Basedonthedescriptionintheexercise,John’srecordshouldlooklikeTable E.1. TableE.1: ThePERSONtable. Columnname Value Explanation PERSON_ID 2 Auniqueinteger. GENDER_CONCEPT_ID 8507 TheconceptIDformalegenderis 8507. YEAR_OF_BIRTH 1974 MONTH_OF_BIRTH 8 DAY_OF_BIRTH 4 BIRTH_DATETIME 1974­08­04 00:00:00Whenthetimeisnotknownmidnightis used. DEATH_DATETIME NULL RACE_CONCEPT_ID 8516 TheconceptIDforblackorAfrican Americanis 8516. ETHNICITY_ CONCEPT_ID38003564 38003564 refersto“Nothispanic”. LOCATION_ID Hisaddressisnotknown. PROVIDER_ID HisprimarycareProviderisnotknown. CARE_SITE HisprimaryCareSiteisnotknown. PERSON_SOURCE_ VALUENULL Notprovided. GENDER_SOURCE_ VALUEMan Thetextusedinthedescription. 409\n",
      "page text: 410 Appendix E. Suggested Answers Columnname Value Explanation GENDER_SOURCE_ CONCEPT_ID0 RACE_SOURCE_ VALUEAfrican AmericanThetextusedinthedescription. RACE_SOURCE_ CONCEPT_ID0 ETHNICITY_SOURCE_ VALUENULL ETHNICITY_SOURCE_ CONCEPT_ID0 Exercise 4.2 Basedonthedescriptionintheexercise,John’srecordshouldlooklikeTable E.2. TableE.2: TheOBSERVATION_PERIODtable. Columnname Value Explanation OBSERVATION_ PERIOD_ID2 Auniqueinteger. PERSON_ID 2 ThisisaforeignkeytoJohn’srecordinthe PERSONtable. OBSERVATION_PERIOD_ START_DATE2015­01­01 Thedateofenrollment. OBSERVATION_PERIOD_ END_DATE2019­07­01 Nodatacanbeexpectedafterthedata extractiondate. PERIOD_TYPE_ CONCEPT_ID44814722 44814724 refersto“Periodwhileenrolled ininsurance”. Exercise 4.3 Basedonthedescriptionintheexercise,John’srecordshouldlooklikeTable E.3. TableE.3: TheDRUG_EXPOSUREtable. Columnname Value Explanation DRUG_EXPOSURE_ID 1001 Someuniqueinteger PERSON_ID 2 ThisisaforeignkeytoJohn’srecordinthe PERSONtable. DRUG_CONCEPT_ID 19078461 TheprovidedNDCcodemapstoStandard Concept19078461.\n",
      "page text: E.1. The Common Data Model 411 Columnname Value Explanation DRUG_EXPOSURE_ START_DATE2019­05­01 Thestartdateoftheexposuretothedrug. DRUG_EXPOSURE_ START_DATETIME2019­05­01 00:00:00Midnightisusedasthetimeisnotknown. DRUG_EXPOSURE_ END_DATE2019­05­31 Basedonstartdate+dayssupply. DRUG_EXPOSURE_ END_DATETIME2019­05­31 00:00:00Midnightisusedastimeisunknown. VERBATIM_END_DATE NULL Notprovided. DRUG_TYPE_ CONCEPT_ID38000177 38000177 indicates“Prescriptionwritten”. STOP_REASON NULL REFILLS NULL QUANTITY NULL Notprovided. DAYS_SUPPLY 30 Asdescribedintheexercise. SIG NULL Notprovided. ROUTE_CONCEPT_ID 4132161 4132161indicates“Oral”. LOT_NUMBER NULL Notprovided. PROVIDER_ID NULL Notprovided. VISIT_OCCURRENCE_ IDNULL Noinformationonthevisitwasprovided.. VISIT_DETAIL_ID NULL DRUG_SOURCE_ VALUE76168009520 ThisisprovidedNDCcode. DRUG_SOURCE_ CONCEPT_ID583945 583945representsthedrugsourcevalue (NDCcode“76168009520”). ROUTE_SOURCE_ VALUENULL Exercise 4.4 Tofindthesetofrecords,wecanquerytheCONDITION_OCCURRENCEtable: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT * FROM @cdm.condition_occurrence WHERE condition_concept_id = 192671;\" result <- renderTranslateQuerySql (connection, sql, cdm =\"main\") head(result) ## CONDITION_OCCURRENCE_ID PERSON_ID CONDITION_CONCEPT_ID ...\n",
      "page text: 412 Appendix E. Suggested Answers ## 1 4657 273 192671 ... ## 2 1021 61 192671 ... ## 3 5978 351 192671 ... ## 4 9798 579 192671 ... ## 5 9301 549 192671 ... ## 6 1997 116 192671 ... Exercise 4.5 Tofindthe set of records, we can query theCONDITION_OCCURRENCE table using theCONDITION_SOURCE_VALUEfield: sql <-\"SELECT * FROM @cdm.condition_occurrence WHERE condition_source_value = 'K92.2';\" result <- renderTranslateQuerySql (connection, sql, cdm =\"main\") head(result) ## CONDITION_OCCURRENCE_ID PERSON_ID CONDITION_CONCEPT_ID ... ## 1 4657 273 192671 ... ## 2 1021 61 192671 ... ## 3 5978 351 192671 ... ## 4 9798 579 192671 ... ## 5 9301 549 192671 ... ## 6 1997 116 192671 ... Exercise 4.6 ThisinformationisstoredintheOBSERVATION_PERIODtable: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT * FROM @cdm.observation_period WHERE person_id = 61;\" renderTranslateQuerySql (connection, sql, cdm =\"main\") ## OBSERVATION_PERIOD_ID PERSON_ID OBSERVATION_PERIOD_START_DATE ... ## 1 61 61 1968-01-21 ...\n",
      "page text: E.2. Standardized Vocabularies 413 E.2 Standardized Vocabularies Exercise 5.1 ConceptID192671(“Gastrointestinalhemorrhage”) Exercise 5.2 ICD­10CMcodes: •K29.91“Gastroduodenitis,unspecified,withbleeding” •K92.2“Gastrointestinalhemorrhage,unspecified” ICD­9CMcodes: •578“Gastrointestinalhemorrhage” •578.9“Hemorrhageofgastrointestinaltract,unspecified” Exercise 5.3 MedDRApreferredterms: •“Gastrointestinalhaemorrhage”(ConceptID35707864) •“Intestinalhaemorrhage”(ConceptID35707858) E.3 Extract T ransform Load Exercise 6.1 A)DataexpertsandCDMexpertstogetherdesigntheETL B)Peoplewithmedicalknowledgecreatethecodemappings C)AtechnicalpersonimplementstheETL D)Allareinvolvedinqualitycontrol Exercise 6.2 Column Value Answer PERSON_ID A123B456 Thiscolumnhasadatatypeof integersothesourcerecordvalue needstobetranslatedtoanumeric value. GENDER_CONCEPT_ID 8532\n",
      "page text: 414 Appendix E. Suggested Answers Column Value Answer YEAR_OF_BIRTH NULL Ifwedonotknowthemonthorday ofbirth,wedonotguess. Aperson canexistwithoutamonthordayof birth. Ifapersonlacksabirthyear thatpersonshouldbedropped. This personwouldhavetobedropped duetonowyearofbirth. MONTH_OF_BIRTH NULL DAY_OF_BIRTH NULL RACE_CONCEPT_ID 0 TheraceisWHITEwhichshould bemappedto8527. ETHNICITY_CONCEPT_ ID8527 Noethnicitywasprovided,this shouldbemappedto0. PERSON_SOURCE_ VALUEA123B456 GENDER_SOURCE_ VALUEF RACE_SOURCE_VALUE WHITE ETHNICITY_SOURCE_ VALUENONE PROVIDED Exercise 6.3 Column Value VISIT_OCCURRENCE_ID 1 PERSON_ID 11 VISIT_START_DATE 2004­09­26 VISIT_END_DATE 2004­09­30 VISIT_CONCEPT_ID 9201 VISIT_SOURCE_VALUE inpatient E.4 Data Analytics Use Cases Exercise 7.1 1.Characterization 2.Patient­levelprediction 3.Population­levelestimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 443/464 [00:04<00:00, 124.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: E.5. SQL and R 415 Exercise 7.2 Probablynot. Defininganon­exposurecohortthatiscomparabletoyourdiclofenacexpo­ surecohortisoftenimpossible,sincepeopletakediclofenacforareason. Thisprecludesa between­personcomparison. Itmightpossibletoawithin­personcomparison,soforeach patientinthediclofenaccohortidentifyingtimewhentheyarenotexposed,butasimilar problemoccurshere: thesetimesarelikelyincomparable,becausetherearereasonswhen atonetimesomeoneisexposedandatothertimesnot. E.5 SQL and R Exercise 9.1 TocomputethenumberofpeoplewecansimplyquerythePERSONtable: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT COUNT(*) AS person_count FROM @cdm.person;\" renderTranslateQuerySql (connection, sql, cdm =\"main\") ## PERSON_COUNT ## 1 2694 Exercise 9.2 Tocomputethenumberofpeoplewithatleastoneprescriptionofcelecoxib,wecanquery theDRUG_EXPOSUREtable. Tofindalldrugscontainingtheingredientcelecoxib,we jointotheCONCEPT_ANCESTORandCONCEPTtables: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT COUNT(DISTINCT(person_id)) AS person_count FROM @cdm.drug_exposure INNER JOIN @cdm.concept_ancestor ON drug_concept_id = descendant_concept_id INNER JOIN @cdm.concept ingredient ON ancestor_concept_id = ingredient.concept_id WHERE LOWER(ingredient.concept_name) = 'celecoxib' AND ingredient.concept_class_id = 'Ingredient' AND ingredient.standard_concept = 'S';\" renderTranslateQuerySql (connection, sql, cdm =\"main\") ## PERSON_COUNT\n",
      "page text: 416 Appendix E. Suggested Answers ## 1 1844 Notethatweuse COUNT(DISTINCT(person_id)) tofindthenumberofdistinctpersons, consideringthatapersonmighthavemorethanoneprescription. Alsonotethatweuse theLOWERfunctiontomakeoursearchfor“celecoxib”case­insensitive. Alternatively,wecanusetheDRUG_ERAtable,whichisalreadyrolleduptotheingre­ dientlevel: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT COUNT(DISTINCT(person_id)) AS person_count FROM @cdm.drug_era INNER JOIN @cdm.concept ingredient ON drug_concept_id = ingredient.concept_id WHERE LOWER(ingredient.concept_name) = 'celecoxib' AND ingredient.concept_class_id = 'Ingredient' AND ingredient.standard_concept = 'S';\" renderTranslateQuerySql (connection, sql, cdm =\"main\") ## PERSON_COUNT ## 1 1844 Exercise 9.3 To compute the number of diagnoses during exposure we extend our previous query by joining to the CONDITION_OCCURRENCE table. We join to the CON­ CEPT_ANCESTOR table to find all condition concepts that imply a gastrointestinal haemorrhage: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT COUNT(*) AS diagnose_count FROM @cdm.drug_era INNER JOIN @cdm.concept ingredient ON drug_concept_id = ingredient.concept_id INNER JOIN @cdm.condition_occurrence ON condition_start_date >= drug_era_start_date AND condition_start_date <= drug_era_end_date INNER JOIN @cdm.concept_ancestor ON condition_concept_id =descendant_concept_id WHERE LOWER(ingredient.concept_name) = 'celecoxib' AND ingredient.concept_class_id = 'Ingredient' AND ingredient.standard_concept = 'S' AND ancestor_concept_id = 192671;\"\n",
      "page text: E.6. Defining Cohorts 417 renderTranslateQuerySql (connection, sql, cdm =\"main\") ## DIAGNOSE_COUNT ## 1 41 Note that in this case it is essential to use the DRUG_ERA table instead of the DRUG_EXPOSURE table, because drug exposures with the same ingredient can overlap,butdrugerascannot. Thiscouldleadtodoublecounting. Forexample,imagine apersonreceivedtwodrugdrugscontainingcelecoxibatthesametime. Thiswouldbe recordedastwodrugexposures, soanydiagnosesoccurringduringtheexposurewould becountedtwice. Thetwoexposureswillbemergedintoasinglenon­overlappingdrug era. E.6 Defining Cohorts Exercise 10.1 Wecreateinitialeventcriteriaencodingtheserequirements: •Newusersofdiclofenac •Ages16orolder •Withatleast365daysofcontinuousobservationpriortoexposure Whendone,thecohortentryeventsectionshouldlooklikeFigure E.1. FigureE.1: Cohortentryeventsettingsfornewusersofdiclofenac The concept set expression for diclofenac should look like Figure E.2, including the in­ gredient ‘Diclofenac’ and all of its descendant, thus including all drugs containing the ingredientdiclofenac. Next,werequirenopriorexposuretoanyNSAID,asshowninFigure E.3. The concept set expression for NSAIDs should look like Figure E.4, including the NSAIDsclassandallofitsdescendant,thusincludingalldrugscontaininganyNSAID.\n",
      "page text: 418 Appendix E. Suggested Answers FigureE.2: Conceptsetexpressionfordiclofenac. FigureE.3: RequiringnopriorexposuretoanyNSAID. FigureE.4: ConceptsetexpressionforNSAIDs\n",
      "page text: E.6. Defining Cohorts 419 Additionally,werequirenopriordiagnosisofcancer,asshowninFigure E.5. FigureE.5: Requiringnopriorcancerdiagnosis. Theconceptsetexpressionfor“Broadmalignancies”shouldlooklikeFigure E.6,includ­ ingthehighlevelconcept“Malignantneoplasticdisease”andallofitsdescendant. FigureE.6: Conceptsetexpressionforbroadmalignancies Finally, wedefinethecohortexitcriteriaasdiscontinuationofexposure(allowingfora 30­daygap),asshowninFigure E.7. Exercise 10.2 For readability we here split the SQL into two steps. We first find all condition occur­ rencesofmyocardialinfarction,andstoretheseinatemptablecalled“#diagnoses”: library(DatabaseConnector) connection <- connect(connectionDetails) sql <-\"SELECT person_id AS subject_id, condition_start_date AS cohort_start_date INTO #diagnoses\n",
      "page text: 420 Appendix E. Suggested Answers FigureE.7: Settingthecohortexitdate. FROM @cdm.condition_occurrence WHERE condition_concept_id IN ( SELECT descendant_concept_id FROM @cdm.concept_ancestor WHERE ancestor_concept_id = 4329847 -- Myocardial infarction ) AND condition_concept_id NOT IN ( SELECT descendant_concept_id FROM @cdm.concept_ancestor WHERE ancestor_concept_id = 314666 -- Old myocardial infarction );\" renderTranslateExecuteSql (connection, sql, cdm =\"main\") We then select only those that occur during an inpatient or ER visit, using some unique COHORT_DEFINITION_ID(weselected‘1’): sql <-\"INSERT INTO @cdm.cohort ( subject_id, cohort_start_date, cohort_definition_id ) SELECT subject_id, cohort_start_date, CAST (1 AS INT) AS cohort_definition_id FROM #diagnoses INNER JOIN @cdm.visit_occurrence ON subject_id = person_id\n",
      "page text: E.7. Characterization 421 AND cohort_start_date >= visit_start_date AND cohort_start_date <= visit_end_date WHERE visit_concept_id IN (9201, 9203, 262); -- Inpatient or ER;\" renderTranslateExecuteSql (connection, sql, cdm =\"main\") Note that an alternative approach would have been to join the conditions to the visits based on the VISIT_OCCURRENCE_ID, instead of requiring the condition date to fall withinthevisitstartandenddate. Thiswouldlikelybemoreaccurate,asitwouldguar­ antee that the condition was recorded in relation to the inpatient or ER visit. However, manyobservationaldatabasesdonotrecordthelinkbetweenvisitanddiagnose,andwe thereforechosetousethedatesinstead,likelygivingusahighersensitivitybutperhaps lowerspecificity. Notealsothatweignoredthecohortenddate. Often,whenacohortisusedtodefinean outcomeweareonlyinterestedinthecohortstartdate, andthereisnopointincreating an(ill­defined)cohortenddate. Itisrecommendedtocleanupanytemptableswhennolongerneeded: sql <-\"TRUNCATE TABLE #diagnoses; DROP TABLE #diagnoses;\" renderTranslateExecuteSql (connection, sql) E.7 Characterization Exercise 11.1 In ATLAS we click on and select the data source we’re interested in. We could select the Drug Exposure report, select the “Table” tab, and search for “cele­ coxib” as shown in Figure E.8. Here we see that this particular database has exposures tovariousformulationsofcelecoxib. Wecouldclickonanyofthesedrugstogetamore detailedview,forexampleshowingageandgenderdistributionsforthesedrugs. Exercise 11.2 Clickon andthen “New cohort” to createa new cohort. Give the cohortameaningfulname(e.g.“Celecoxibnewusers”)andgotothe“ConceptSets”tab. Clickon“NewConceptSet”,andgiveyourconceptsetameaningfulnames(e.g.“Cele­ coxib”). Openthe module,searchfor“celecoxib”,restricttheClassto“Ingre­ dient”andStandardConceptto“Standard”,andclickthe toaddtheconcepttoyour conceptsetasshowinFigure E.9.\n",
      "page text: 422 Appendix E. Suggested Answers FigureE.8: Datasourcecharacterization.\n",
      "page text: E.7. Characterization 423 FigureE.9: Selectingthestandardconceptfortheingredient”celecoxib”.\n",
      "page text: 424 Appendix E. Suggested Answers Click on the left arrow shown at the top left of Figure E.9to return to your cohort defi­ nition. Clickon“+AddInitialEvent”andthen“AddDrugEra”. Selectyourpreviously createdconceptsetforthedrugeracriterion. Clickon“Addattribute…”andselect“Add FirstExposureCriteria.” Settherequiredcontinuousobservationtoatleast365daysbe­ foretheindexdate. TheresultshouldlooklikeFigure E.10. LeavetheInclusionCriteria, CohortExit,andCohortErassectionastheyare. Makesuretosavethecohortdefinition byclicking ,andcloseitbyclicking . FigureE.10: Asimplecelecoxibnewusercohortdefinition. Nowthatwehaveourcohortdefined,wecancharacterizeit. Clickon and then “New Characterization”. Give you characterization a meaningful name (e.g. “Celecoxib new users characterization”). Under Cohort Definitions, click on “Import” and select your recently created cohort definition. Under “Feature Analyses”, click on “Import” and select at least one condition analysis and one drug analysis, for example“DrugGroupEraAnyTimePrior”and“ConditionGroupEraAnyTimePrior”. YourcharacterizationdefinitionshouldnowlooklikeFigure E.11. Makesuretosavethe characterizationsettingsbyclicking . Click on the “Executions” tab, and click on “Generate” for one of the data sources. It may take a while for the generation to complete. When done, we can click on “View latest results”. The resulting screen will look something like Figure E.12, showing for example that pain and arthropathy are commonly observed, which should not surprise use as these are indications for celecoxib. Lower on the list we may see conditions we werenotexpecting.\n",
      "page text: E.7. Characterization 425 FigureE.11: Characterizationsettings.\n",
      "page text: 426 Appendix E. Suggested Answers FigureE.12: Characterizationsettings.\n",
      "page text: E.7. Characterization 427 Exercise 11.3 Clickon andthen “New cohort” to createa new cohort. Give the cohort a meaningful name (e.g. “GI bleed”) and go to the “Concept Sets” tab. Click on “New Concept Set”, and give your concept set a meaningful names (e.g. “GI bleed”). Openthe module,searchfor“Gastrointestinalhemorrhage”,andclickthe nexttothetopconcepttoaddtheconcepttoyourconceptsetasshowinFigure E.13. FigureE.13: Selectingthestandardconceptfor”Gastrointestinalhemorrhage”. ClickontheleftarrowshownatthetopleftofFigure E.13toreturntoyourcohortdef­ inition. Open the “Concept Sets” tab again, and check “Descendants” next to the GI hemorrhageconcept,asshowninFigure E.14. FigureE.14: Addingalldescendantsto”Gastrointestinalhemorrhage”. Return to the “Definition” tab, click on “+Add Initial Event” and then “Add Condition Occurrence”. Select your previously created concept set for the condition occurrence criterion. The result should look like Figure E.15. Leave the Inclusion Criteria, Cohort Exit, and Cohort Eras section as they are. Make sure to save the cohort definition by clicking ,andcloseitbyclicking .\n",
      "page text: 428 Appendix E. Suggested Answers FigureE.15: Asimplegastrointestinalbleedcohortdefinition. Now that we have our cohort defined, we can compute the incidence rate. Click on and then “New Analysis”. Give your analysis a meaningful name (e.g.“IncidenceofGIbleedaftercelecoxibinitiation”). Click“AddTargetCohort”and selectourcelecoxibnewusercohort. Clickon“AddOutcomeCohort”andaddournew GIbleedcohort. SettheTimeAtRisktoend1095daysafterthestartdate. Theanalysis shouldnowlooklikeFigure E.16. Makesuretosavetheanalysissettingsbyclicking . FigureE.16: Aincidencerateanalysis. Clickonthe“Generation”tab,andclickon“Generate”. Selectoneofthedatasourcesand click“Generate”. Whendone,wecanseethecomputedincidencerateandproportion,as showninFigure E.17.\n",
      "page text: E.8. Population­Level Estimation 429 FigureE.17: Incidenceresults. E.8 Population-Level Estimation Exercise 12.1 We specify the default set of covariates, but we must exclude the two drugs we’re com­ paring, including all their descendants, because else our propensity model will become perfectlypredictive: library(CohortMethod) nsaids <- c(1118084,1124300) # celecoxib, diclofenac covSettings <- createDefaultCovariateSettings ( excludedCovariateConceptIds = nsaids, addDescendantsToExclude = TRUE) # Load data: cmData <- getDbCohortMethodData ( connectionDetails = connectionDetails, cdmDatabaseSchema = \"main\", targetId = 1, comparatorId = 2, outcomeIds = 3, exposureDatabaseSchema = \"main\", exposureTable = \"cohort\" , outcomeDatabaseSchema = \"main\", outcomeTable = \"cohort\" , covariateSettings = covSettings) summary(cmData) ## CohortMethodData object summary ## ## Treatment concept ID: 1 ## Comparator concept ID: 2 ## Outcome concept ID(s): 3 ## ## Treated persons: 1800 ## Comparator persons: 830 ## ## Outcome counts: ## Event count Person count\n",
      "page text: 430 Appendix E. Suggested Answers ## 3 479 479 ## ## Covariates: ## Number of covariates: 389 ## Number of non-zero covariate values: 26923 Exercise 12.2 Wecreatethestudypopulationfollowingthespecifications, andoutputtheattritiondia­ gram: studyPop <- createStudyPopulation ( cohortMethodData = cmData, outcomeId = 3, washoutPeriod = 180, removeDuplicateSubjects = \"remove all\" , removeSubjectsWithPriorOutcome = TRUE, riskWindowStart = 0, startAnchor = \"cohort start\" , riskWindowEnd = 99999) drawAttritionDiagram (studyPop)\n",
      "page text: E.8. Population­Level Estimation 431 We see that we did not lose any subjects compared to the original cohorts, probably be­ causetherestrictionsusedherewerealreadyappliedinthecohortdefinitions. Exercise 12.3 WefitasimpleoutcomemodelusingaCoxregression: model <- fitOutcomeModel (population = studyPop, modelType = \"cox\") model ## Model type: cox ## Stratified: FALSE ## Use covariates: FALSE ## Use inverse probability of treatment weighting: FALSE ## Status: OK ## ## Estimate lower .95 upper .95 logRr seLogRr\n",
      "page text: 432 Appendix E. Suggested Answers ## treatment 1.34612 1.10065 1.65741 0.29723 0.1044 Itislikelythatcelecoxibusersarenotexchangeablewithdiclofenacusers,andthatthese baselinedifferencesalreadyleadtodifferentrisksoftheoutcome. Ifwedonotadjustfor thesedifference,likeinthisanalysis,wearelikelyproducingbiasedestimates. Exercise 12.4 Wefitapropensitymodelonourstudypopulation,usingallcovariatesweextracted. We thenshowthepreferencescoredistribution: ps <-createPs (cohortMethodData = cmData, population = studyPop) plotPs(ps,showCountsLabel = TRUE,showAucLabel = TRUE) Note that this distribution looks a bit odd, with several spikes. This is because we are usingaverysmallsimulateddataset. Realpreferencescoredistributionstendtobemuch smoother. ThepropensitymodelachievesanAUCof0.63,suggestedtherearedifferencesbetween targetandcomparatorcohort. Weseequitealotoverlapbetweenthetwogroupssuggest­ ingPSadjustmentcanmakethemmorecomparable. Exercise 12.5 We stratify the population based on the propensity scores, and compute the covariate balancebeforeandafterstratification:\n",
      "page text: E.8. Population­Level Estimation 433 strataPop <- stratifyByPs (ps,numberOfStrata = 5) bal <-computeCovariateBalance (strataPop, cmData) plotCovariateBalanceScatterPlot (bal, showCovariateCountLabel = TRUE, showMaxLabel = TRUE, beforeLabel = \"Before stratification\" , afterLabel = \"After stratification\" ) Weseethatvariousbaselinecovariatesshowedalarge(>0.3)standardizeddifferenceof means before stratification (x­axis). After stratification, balance is increased, with the maximumstandardizeddifference<=0.1. Exercise 12.6 WefitaoutcomemodelusingaCoxregression,butstratifyitbythePSstrata: adjModel <- fitOutcomeModel (population = strataPop, modelType = \"cox\", stratified = TRUE) adjModel ## Model type: cox ## Stratified: TRUE ## Use covariates: FALSE\n",
      "page text: 434 Appendix E. Suggested Answers ## Use inverse probability of treatment weighting: FALSE ## Status: OK ## ## Estimate lower .95 upper .95 logRr seLogRr ## treatment 1.13211 0.92132 1.40008 0.12409 0.1068 We see the adjusted estimate is lower than the unadjusted estimate, and that the 95% confidence interval now includes 1. This is because we are now adjusting for baseline differencesbetweenthetwoexposuregroups,thusreducingbias. E.9 Patient-Level Prediction Exercise 13.1 We specify a set of covariate settings, and use the getPlpData function to extract the datafromthedatabase: library(PatientLevelPrediction) covSettings <- createCovariateSettings ( useDemographicsGender = TRUE, useDemographicsAge = TRUE, useConditionGroupEraLongTerm = TRUE, useConditionGroupEraAnyTimePrior = TRUE, useDrugGroupEraLongTerm = TRUE, useDrugGroupEraAnyTimePrior = TRUE, useVisitConceptCountLongTerm = TRUE, longTermStartDays = -365, endDays = -1) plpData <- getPlpData (connectionDetails = connectionDetails, cdmDatabaseSchema = \"main\", cohortDatabaseSchema = \"main\", cohortTable = \"cohort\" , cohortId = 4, covariateSettings = covSettings, outcomeDatabaseSchema = \"main\", outcomeTable = \"cohort\" , outcomeIds = 3) summary(plpData) ## plpData object summary ## ## At risk cohort concept ID: -1 ## Outcome concept ID(s): 3 ## ## People: 2630\n",
      "page text: E.9. Patient­Level Prediction 435 ## ## Outcome counts: ## Event count Person count ## 3 479 479 ## ## Covariates: ## Number of covariates: 245 ## Number of non-zero covariate values: 54079 Exercise 13.2 Wecreateastudypopulationfortheoutcomeofinterest(inthiscasetheonlyoutcomefor which we extracted data), removing subjects who experienced the outcome before they startedtheNSAID,andrequiring364daysoftime­at­risk: population <- createStudyPopulation (plpData = plpData, outcomeId = 3, washoutPeriod = 364, firstExposureOnly = FALSE, removeSubjectsWithPriorOutcome = TRUE, priorOutcomeLookback = 9999, riskWindowStart = 1, riskWindowEnd = 365, addExposureDaysToStart = FALSE, addExposureDaysToEnd = FALSE, minTimeAtRisk = 364, requireTimeAtRisk = TRUE, includeAllOutcomes = TRUE) nrow(population) ## [1] 2578 Inthiscasewehavelostafewpeoplebyremovingthosethathadtheoutcomeprior,and byrequiringatime­at­riskofatleast364days. Exercise 13.3 We run a LASSO model by first creating a model settings object, and then calling the runPlpfunction. Inthiscasewedoapersonsplit,trainingthemodelon75%ofthedata andevaluatingon25%ofthedata: lassoModel <- setLassoLogisticRegression (seed =0) lassoResults <- runPlp(population = population, plpData = plpData, modelSettings = lassoModel,\n",
      "page text: 436 Appendix E. Suggested Answers testSplit = 'person' , testFraction = 0.25, nfold = 2, splitSeed = 0) NotethatforthisexamplesettherandomseedsbothfortheLASSOcross­validationand forthetrain­testsplittomakesuretheresultswillbethesameonmultipleruns. WecannowviewtheresultsusingtheShinyapp: viewPlp(lassoResults) This will launch the app as shown in Figure E.18. Here we see an AUC on the test set of0.645,whichisbetterthanrandomguessing,butmaybenotgoodenoughforclinical practice. FigureE.18: Patient­levelpredictionShinyapp. E.10 Data Quality Exercise 15.1 TorunACHILLES: library(ACHILLES) result <- achilles (connectionDetails, cdmDatabaseSchema = \"main\", resultsDatabaseSchema = \"main\",\n",
      "page text: E.10. Data Quality 437 sourceName = \"Eunomia\" , cdmVersion = \"5.3.0\") Exercise 15.2 ToruntheDataQualityDashboard: DataQualityDashboard ::executeDqChecks ( connectionDetails, cdmDatabaseSchema = \"main\", resultsDatabaseSchema = \"main\", cdmSourceName = \"Eunomia\" , outputFolder = \"C:/dataQualityExample\" ) Exercise 15.3 Toviewthelistofdataqualitychecks: DataQualityDashboard ::viewDqDashboard ( \"C:/dataQualityExample/Eunomia/results_Eunomia.json\" )\n",
      "page text: 438 Appendix E. Suggested Answers\n",
      "page text: Bibliography Allison, D.B., Brown, A.W., George, B.J., andKaiser, K.A.(2016). Reproducibility: Atragedyoferrors. Nature,530(7588):27–29. Arnold,B.F.,Ercumen,A.,Benjamin­Chung,J.,andColford,J.M.(2016).BriefReport: Negative Controls to Detect Selection Bias and Measurement Bias in Epidemiologic Studies. Epidemiology ,27(5):637–641. Austin, P. C. (2011). Optimal caliper widths for propensity­score matching when esti­ mating differences in means and differences in proportions in observational studies. Pharmaceutical statistics ,10(2):150–161. Banda, J. M., Halpern, Y., Sontag, D., and Shah, N. H. (2017). Electronic phenotyping with APHRODITE and the Observational Health Sciences and Informatics (OHDSI) datanetwork. AMIA Jt Summits Transl Sci Proc ,2017:48–57. Boland,M.R.,Parhi,P.,Li,L.,Miotto,R.,Carroll,R.,Iqbal,U.,Nguyen,P.A.,Schuemie, M.,You,S.C.,Smith,D.,Mooney,S.,Ryan,P.,Li,Y.J.,Park,R.W.,Denny,J.,Dudley, J. T., Hripcsak, G., Gentine, P., and Tatonetti, N. P. (2017). Uncovering exposures responsibleforbirthseason­diseaseeffects: aglobalstudy. J Am Med Inform Assoc . Botsis, T., Hartvigsen, G., Chen, F., and Weng, C. (2010). Secondary use of ehr: data qualityissuesandinformaticsopportunities. Summit on Translational Bioinformatics , 2010:1. Byrd,J.B.,Adam,A.,andBrown,N.J.(2006).Angiotensin­convertingenzymeinhibitor­ associatedangioedema. Immunol Allergy Clin North Am ,26(4):725–737. Callahan, T. J., Bauck, A. E., Bertoch, D., Brown, J., Khare, R., Ryan, P. B., Staab, J., Zozus,M.N.,andKahn,M.G.(2017).Acomparisonofdataqualityassessmentchecks insixdatasharingnetworks. eGEMs,5(1). Cepeda, M.S., Reps, J., Fife, D., Blacketer, C., Stang, P., andRyan, P.(2018). Finding treatment­resistant depression in real­world data: How a data­driven approach com­ pareswithexpert­basedheuristics. Depress Anxiety ,35(3):220–228. Chen,X.,Dallmeier­Tiessen,S.,Dasler,R.,Feger,S.,Fokianos,P.,Gonzalez,J.B.,Hir­ vonsalo,H.,Kousidis,D.,Lavasa,A.,Mele,S.,Rodriguez,D.R.,Šimko,T.,Smith,T., Trisovic,A.,Trzcinska,A.,Tsanaktsidis,I.,Zimmermann,M.,Cranmer,K.,Heinrich, 439\n",
      "page text: 440 Bibliography L., Watts, G., Hildreth, M., Iglesias, L.L., Lassila­Perini, K., and Neubert, S. (2018). Openisnotenough. Nature Physics ,15(2):113–119. Cicardi, M., Zingale, L. C., Bergamaschini, L., and Agostoni, A. (2004). Angioedema associatedwithangiotensin­convertingenzymeinhibitoruse: outcomeafterswitching toadifferenttreatment. Arch. Intern. Med. ,164(8):910–913. Dasu, T. and Johnson, T. (2003). Exploratory data mining and data cleaning , volume 479. JohnWiley&Sons. Defalco,F.J.,Ryan,P.B.,andSoledadCepeda,M.(2013). Applyingstandardizeddrug terminologiestoobservationalhealthcaredatabases: acasestudyonopioidexposure. Health Serv Outcomes Res Methodol ,13(1):58–67. DerSimonian, R. and Laird, N. (1986). Meta­analysis in clinical trials. Control Clin Trials,7(3):177–188. Duke,J.D.,Ryan,P.B.,Suchard,M.A.,Hripcsak,G.,Jin,P.,Reich,C.,Schwalm,M.S., Khoma, Y., Wu, Y., Xu, H., Shah, N. H., Banda, J. M., and Schuemie, M. J. (2017). Riskofangioedemaassociatedwithlevetiracetamcomparedwithphenytoin: Findings oftheobservationalhealthdatasciencesandinformaticsresearchnetwork. Epilepsia, 58(8):e101–e106. Farrington,C.P.(1995).Relativeincidenceestimationfromcaseseriesforvaccinesafety evaluation. Biometrics ,51(1):228–235. Farrington,C.P.,Anaya­Izquierdo,K.,Whitaker,H.J.,Hocine,M.N.,Douglas,I.,and Smeeth,L.(2011). Self­controlledcaseseriesanalysiswithevent­dependentobserva­ tionperiods. Journal of the American Statistical Association ,106(494):417–426. Fuller,W.A.(2009). Measurement error models ,volume305. JohnWiley&Sons. Garza,M.,DelFiol,G.,Tenenbaum,J.,Walden,A.,andZozus,M.N.(2016).Evaluating commondatamodelsforusewithalongitudinalcommunityregistry. J Biomed Inform , 64:333–341. Hernan,M.A., Hernandez­Diaz, S., Werler,M.M., andMitchell,A.A.(2002). Causal knowledgeasaprerequisiteforconfoundingevaluation: anapplicationtobirthdefects epidemiology. Am. J. Epidemiol. ,155(2):176–184. Hernan,M.A.andRobins,J.M.(2016). UsingBigDatatoEmulateaTargetTrialWhen aRandomizedTrialIsNotAvailable. Am. J. Epidemiol. ,183(8):758–764. Hersh, W. R., Weiner, M. G., Embi, P. J., Logan, J. R., Payne, P. R., Bernstam, E. V., Lehmann, H. P., Hripcsak, G., Hartzog, T. H., Cimino, J. J., et al. (2013). Caveats for the use of operational electronic health record data in comparative effectiveness research. Medical care ,51(803):S30. Higgins, J. P., Thompson, S. G., Deeks, J. J., and Altman, D. G. (2003). Measuring inconsistencyinmeta­analyses. BMJ,327(7414):557–560.\n",
      "page text: Bibliography 441 Hill,A.B.(1965). THEENVIRONMENTANDDISEASE:ASSOCIATIONORCAU­ SATION? Proc. R. Soc. Med. ,58:295–300. Hripcsak,G.andAlbers,D.J.(2017). High­fidelityphenotyping: richnessandfreedom frombias. J Am Med Inform Assoc . Hripcsak,G.,Duke,J.D.,Shah,N.H.,Reich,C.G.,Huser,V.,Schuemie,M.J.,Suchard, M. A., Park, R. W., Wong, I. C. K., Rijnbeek, P. R., van der Lei, J., Pratt, N., Norén, G.N.,Li,Y.­C.,Stang,P.E.,Madigan,D.,andRyan,P.B.(2015).ObservationalHealth DataSciencesandInformatics(OHDSI):OpportunitiesforObservationalResearchers. Studies in health technology and informatics ,216:574–578. Hripcsak, G., Levine, M. E., Shang, N., and Ryan, P. B. (2018). Effect of vocabulary mappingforconditionsonphenotypecohorts. J Am Med Inform Assoc ,25(12):1618– 1625. Hripcsak,G.,Ryan,P.B.,Duke,J.D.,Shah,N.H.,Park,R.W.,Huser,V.,Suchard,M.A., Schuemie, M. J., DeFalco, F. J., Perotte, A., Banda, J. M., Reich, C. G., Schilling, L.M.,Matheny,M.E.,Meeker,D.,Pratt,N.,andMadigan,D.(2016). Characterizing treatment pathways at scale using the OHDSI network. Proceedings of the National Academy of Sciences ,113(27):7329–7336. Hripcsak, G., Shang, N., Peissig, P. L., Rasmussen, L. V., Liu, C., Benoit, B., Carroll, R.J.,Carrell,D.S.,Denny,J.C.,Dikilitas,O.,Gainer,V.S.,MarieHowell,K.,Klann, J. G., Kullo, I. J., Lingren, T., Mentch, F. D., Murphy, S. N., Natarajan, K., Pacheco, J. A., Wei, W. Q., Wiley, K., and Weng, C. (2019). Facilitating phenotype transfer usingacommondatamodel. J Biomed Inform ,page103253. Huser, V., DeFalco, F.J., Schuemie, M., Ryan, P.B., Shang, N., Velez, M., Park, R.W., Boyce,R.D.,Duke,J.,Khare,R.,Utidjian,L.,andBailey,C.(2016). MultisiteEvalu­ ationofaDataQualityToolforPatient­LevelClinicalDataSets. EGEMS (Washington, DC),4(1):1239. Huser,V.,Kahn,M.G.,Brown,J.S.,andGouripeddi,R.(2018). Methodsforexamining dataqualityinhealthcareintegrateddatarepositories. Pacific Symposium on Biocom­ puting. Pacific Symposium on Biocomputing ,23:628–633. Johnston, S.S., Morton, J.M., Kalsekar, I., Ammann, E.M., Hsiao, C.W., andReps, J. (2019).UsingMachineLearningAppliedtoReal­WorldHealthcareDataforPredictive Analytics: AnAppliedExampleinBariatricSurgery. Value Health ,22(5):580–586. Kahn, M. G., Brown, J. S., Chun, A. T., Davidson, B. N., Meeker, D., Ryan, P. B., Schilling,L.M.,Weiskopf,N.G.,Williams,A.E.,andZozus,M.N.(2015). Transpar­ entreportingofdataqualityindistributeddatanetworks. EGEMS (Washington, DC) , 3(1):1052. Kahn,M.G.,Callahan,T.J.,Barnard,J.,Bauck,A.E.,Brown,J.,Davidson,B.N.,Estiri, H., Goerg, C., Holve, E., Johnson, S. G., Liaw, S.­T., Hamilton­Lopez, M., Meeker, D.,Ong,T.C.,Ryan,P.B.,Shang,N.,Weiskopf,N.G.,Weng,C.,Zozus,M.N.,and\n",
      "page text: 442 Bibliography Schilling,L.(2016).AHarmonizedDataQualityAssessmentTerminologyandFrame­ workfortheSecondaryUseofElectronicHealthRecordData. EGEMS (Washington, DC),4(1):1244. Kahn, M. G., Raebel, M. A., Glanz, J. M., Riedlinger, K., and Steiner, J. F. (2012). A pragmaticframeworkforsingle­siteandmultisitedataqualityassessmentinelectronic healthrecord­basedclinicalresearch. Medical care ,50. Liaw, S.­T., Rahimi, A., Ray, P., Taggart, J., Dennis, S., de Lusignan, S., Jalaludin, B., Yeo, A., and Talaei­Khoei, A. (2013). Towards an ontology for data quality in inte­ grated chronic disease management: a realist review of the literature. International journal of medical informatics ,82(1):10–24. Lipsitch, M., Tchetgen Tchetgen, E., and Cohen, T. (2010). Negative controls: a tool fordetectingconfoundingandbiasinobservationalstudies. Epidemiology ,21(3):383– 388. Maclure,M.(1991). Thecase­crossoverdesign: amethodforstudyingtransienteffects ontheriskofacuteevents. Am. J. Epidemiol. ,133(2):144–153. Madigan, D., Ryan, P. B., and Schuemie, M. (2013a). Does design matter? System­ aticevaluationoftheimpactofanalyticalchoicesoneffectestimatesinobservational studies. Ther Adv Drug Saf ,4(2):53–62. Madigan,D.,Ryan,P.B.,Schuemie,M.,Stang,P.E.,Overhage,J.M.,Hartzema,A.G., Suchard,M.A.,DuMouchel,W.,andBerlin,J.A.(2013b). Evaluatingtheimpactof databaseheterogeneityonobservationalstudyresults. Am. J. Epidemiol. ,178(4):645– 651. Magid,D.J.,Shetterly,S.M.,Margolis,K.L.,Tavel,H.M.,O’Connor,P.J.,Selby,J.V., andHo,P.M.(2010). Comparativeeffectivenessofangiotensin­convertingenzymein­ hibitorsversusbeta­blockersassecond­linetherapyforhypertension. Circ Cardiovasc Qual Outcomes ,3(5):453–458. Makadia, R. and Ryan, P. B. (2014). Transforming the Premier Perspective Hospital Database into the Observational Medical Outcomes Partnership (OMOP) Common DataModel. EGEMS (Wash DC) ,2(1):1110. Martin,R.C.(2008). Clean Code: A Handbook of Agile Software Craftsmanship . Pren­ ticeHallPTR,UpperSaddleRiver,NJ,USA,1edition. Matcho, A., Ryan, P., Fife, D., and Reich, C. (2014). Fidelity assessment of a clinical practice research datalink conversion to the OMOP common data model. Drug Saf, 37(11):945–959. Noren,G.N.,Caster,O.,Juhlin,K.,andLindquist,M.(2014). Zooorsavannah? Choice oftraininggroundforevidence­basedpharmacovigilance. Drug Saf,37(9):655–659. Norman, J. L., Holmes, W. L., Bell, W. A., and Finks, S. W. (2013). Life­threatening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 464/464 [00:05<00:00, 92.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page text: Bibliography 443 ACE inhibitor­induced angioedema after eleven years on lisinopril. J Pharm Pract , 26(4):382–388. Oliveira, J.L., Trifan, A., andSilva, L.A.B.(2019). EMIFcatalogue: Acollaborative platform for sharing and reusing biomedical data. International Journal of Medical Informatics ,126:35–45. Olsen, L., Aisner, D., McGinnis, J. M., et al. (2007). The learning healthcare system: workshop summary . NatlAcademyPr. O’Mara,N.B.andO’Mara,E.M.(1996).Delayedonsetofangioedemawithangiotensin­ convertingenzymeinhibitors: casereportandreviewoftheliterature. Pharmacother­ apy,16(4):675–679. Overhage, J. M., Ryan, P. B., Reich, C. G., Hartzema, A. G., and Stang, P. E. (2012). Validationofacommondatamodelforactivesafetysurveillanceresearch. J Am Med Inform Assoc ,19(1):54–60. Perkins,N.J.,Cole,S.R.,Harel,O.,TchetgenTchetgen,E.J.,Sun,B.,Mitchell,E.M., andSchisterman,E.F.(2017). Principledapproachestomissingdatainepidemiologic studies. American journal of epidemiology ,187(3):568–575. Powers, B. J., Coeytaux, R. R., Dolor, R. J., Hasselblad, V., Patel, U. D., Yancy, W. S., Gray,R.N.,Irvine,R.J.,Kendrick,A.S.,andSanders,G.D.(2012). Updatedreport oncomparativeeffectivenessofACEinhibitors,ARBs,anddirectrenininhibitorsfor patients with essential hypertension: much more data, little new information. J Gen Intern Med ,27(6):716–729. Prasad,V.andJena,A.B.(2013). Prespecifiedfalsificationendpoints: cantheyvalidate trueobservationalassociations? JAMA,309(3):241–242. Ramcharran, D., Qiu, H., Schuemie, M. J., and Ryan, P. B. (2017). Atypical Antipsy­ choticsandtheRiskofFallsandFracturesAmongOlderAdults: AnEmulationAnal­ ysis and an Evaluation of Additional Confounding Control Strategies. J Clin Psy­ chopharmacol ,37(2):162–168. Rassen,J.A.,Shelat,A.A.,Myers,J.,Glynn,R.J.,Rothman,K.J.,andSchneeweiss,S. (2012).One­to­manypropensityscorematchingincohortstudies. Pharmacoepidemiol Drug Saf,21Suppl2:69–80. Reps,J.M.,Rijnbeek,P.R.,andRyan,P.B.(2019).IdentifyingtheDEAD:Development and Validation of a Patient­Level Model to Predict Death Status in Population­Level ClaimsData. Drug Saf. Reps,J.M.,Schuemie,M.J.,Suchard,M.A.,Ryan,P.B.,andRijnbeek,P.R.(2018).De­ signandimplementationofastandardizedframeworktogenerateandevaluatepatient­ levelpredictionmodelsusingobservationalhealthcaredata. Journal of the American Medical Informatics Association ,25(8):969–975.\n",
      "page text: 444 Bibliography Roebuck,K.(2012). Data quality: high­impact strategies­what you need to know: defi­ nitions, adoptions, impact, benefits, maturity, vendors . EmereoPublishing. Rosenbaum,P.(2005). Sensitivity Analysis in Observational Studies . AmericanCancer Society. Rosenbaum, P. and Rubin, D. (1983). The central role of the propensity score in obser­ vationalstudiesforcausaleffects. Biometrika ,70:41–55. Rubbo,B.,Fitzpatrick,N.K.,Denaxas,S.,Daskalopoulou,M.,Yu,N.,Patel,R.S.,Hem­ ingway,H.,Danesh,J.,Allen,N.,Atkinson,M.,Blaveri,E.,Brannan,R.,Brayne,C., Brophy, S., Chaturvedi, N., Collins, R., deLusignan, S., Denaxas, S., Desai, P., East­ wood, S., Gallacher, J., Hemingway, H., Hotopf, M., Landray, M., Lyons, R., O’Neil, T., Pringle, M., Sprosen, T., Strachan, D., Sudlow, C., Sullivan, F., Zhang, Q., and Flaig, R. (2015). Use of electronic health records to ascertain, validate and pheno­ type acute myocardial infarction: A systematic review and recommendations. Int. J. Cardiol.,187:705–711. Rubin,D.B.(2001). Usingpropensityscorestohelpdesignobservationalstudies: appli­ cationtothetobaccolitigation. Health Services and Outcomes Research Methodology , 2(3­4):169–188. Ryan, P. B., Buse, J. B., Schuemie, M. J., DeFalco, F., Yuan, Z., Stang, P. E., Berlin, J. A., and Rosenthal, N. (2018). Comparative effectiveness of canagliflozin, SGLT2 inhibitorsandnon­SGLT2inhibitorsontheriskofhospitalizationforheartfailureand amputationinpatientswithtype2diabetesmellitus: Areal­worldmeta­analysisof4 observationaldatabases(OBSERVE­4D). Diabetes Obes Metab ,20(11):2585–2597. Ryan, P.B., Madigan, D., Stang, P.E., Overhage, J. M., Racoosin, J. A., and Hartzema, A.G.(2012).Empiricalassessmentofmethodsforriskidentificationinhealthcaredata: resultsfromtheexperimentsoftheObservationalMedicalOutcomesPartnership. Stat Med,31(30):4401–4415. Ryan, P. B., Schuemie, M. J., and Madigan, D. (2013a). Empirical performance of a self­controlledcohortmethod: lessonsfordevelopingariskidentificationandanalysis system. Drug Saf,36Suppl1:95–106. Ryan,P.B.,Schuemie,M.J.,Ramcharran,D.,andStang,P.E.(2017). AtypicalAntipsy­ chotics and the Risks of Acute Kidney Injury and Related Outcomes Among Older Adults: A Replication Analysis and an Evaluation of Adapted Confounding Control Strategies. Drugs Aging ,34(3):211–219. Ryan,P.B.,Stang,P.E.,Overhage,J.M.,Suchard,M.A.,Hartzema,A.G.,DuMouchel, W., Reich, C. G., Schuemie, M. J., and Madigan, D. (2013b). A comparison of the empiricalperformanceofmethodsforariskidentificationsystem. Drug Saf,36Suppl 1:S143–158. Sabroe,R.A.andBlack,A.K.(1997). Angiotensin­convertingenzyme(ACE)inhibitors andangio­oedema. Br. J. Dermatol. ,136(2):153–158.\n",
      "page text: Bibliography 445 Schneeweiss,S.(2018). Automateddata­adaptiveanalyticsforelectronichealthcaredata tostudycausaltreatmenteffects. Clin Epidemiol ,10:771–788. Schuemie,M.J.,Hripcsak,G.,Ryan,P.B.,Madigan,D.,andSuchard,M.A.(2016). Ro­ bustempiricalcalibrationofp­valuesusingobservationaldata. Stat Med,35(22):3883– 3888. Schuemie, M. J., Hripcsak, G., Ryan, P. B., Madigan, D., and Suchard, M. A. (2018a). Empiricalconfidenceintervalcalibrationforpopulation­leveleffectestimationstudies inobservationalhealthcaredata. Proc. Natl. Acad. Sci. U.S.A. ,115(11):2571–2577. Schuemie,M.J.,Ryan,P.B.,DuMouchel,W.,Suchard,M.A.,andMadigan,D.(2014). Interpreting observational studies: why empirical calibration is needed to correct p­ values. Stat Med,33(2):209–218. Schuemie,M.J.,Ryan,P.B.,Hripcsak,G.,Madigan,D.,andSuchard,M.A.(2018b).Im­ provingreproducibilitybyusinghigh­throughputobservationalstudieswithempirical calibration. Philos Trans A Math Phys Eng Sci ,376(2128). Sherman, R. E., Anderson, S. A., Dal Pan, G. J., Gray, G. W., Gross, T., Hunter, N. L., LaVange,L.,Marinac­Dabic,D.,Marks,P.W.,Robb,M.A.,etal.(2016). Real­world evidence—whatisitandwhatcanittellus. N Engl J Med ,375(23):2293–2297. Simpson,S.E.,Madigan,D.,Zorych,I.,Schuemie,M.J.,Ryan,P.B.,andSuchard,M.A. (2013). Multiple self­controlled case series for large­scale longitudinal observational databases. Biometrics ,69(4):893–902. Slater,E.E.,Merrill,D.D.,Guess,H.A.,Roylance,P.J.,Cooper,W.D.,Inman,W.H.W., andEwan,P.W.(1988). ClinicalProfileofAngioedemaAssociatedWithAngiotensin Converting­EnzymeInhibition. JAMA,260(7):967–970. Stang, P. E., Ryan, P. B., Racoosin, J. A., Overhage, J. M., Hartzema, A. G., Reich, C., Welebob, E., Scarnecchia, T., and Woodcock, J. (2010). Advancing the science foractivesurveillance: rationaleanddesignfortheObservationalMedicalOutcomes Partnership. Ann. Intern. Med. ,153(9):600–606. Suchard,M.A.,Simpson,S.E.,Zorych,I.,Ryan,P.B.,andMadigan,D.(2013).Massive parallelization of serial inference algorithms for a complex generalized linear model. ACM Trans. Model. Comput. Simul. ,23(1):10:1–10:17. Suissa,S.(1995). Thecase­time­controldesign. Epidemiology ,6(3):248–253. Swerdel, J. N., Hripcsak, G., and Ryan, P. B. (2019). PheValuator: Development and EvaluationofaPhenotypeAlgorithmEvaluator. J Biomed Inform ,page103258. Thompson, T.andFrable, M.A.(1993). Drug­induced, life­threateningangioedemare­ visited. Laryngoscope ,103(1Pt1):10–12. Tian,Y.,Schuemie,M.J.,andSuchard,M.A.(2018). Evaluatinglarge­scalepropensity scoreperformancethroughreal­worldandsyntheticdataexperiments. Int J Epidemiol , 47(6):2005–2014.\n",
      "page text: 446 Bibliography Toh, S., Reichman, M. E., Houstoun, M., Ross Southworth, M., Ding, X., Hernandez, A. F., Levenson, M., Li, L., McCloskey, C., Shoaibi, A., Wu, E., Zornberg, G., and Hennessy,S.(2012).Comparativeriskforangioedemaassociatedwiththeuseofdrugs thattargettherenin­angiotensin­aldosteronesystem. Arch. Intern. Med. ,172(20):1582– 1589. van der Lei, J. (1991). Use and abuse of computer­stored medical records. Methods of information in medicine ,30(02):79–80. Vandenbroucke,J.P.andPearce,N.(2012). Case­controlstudies: basicconcepts. Int J Epidemiol,41(5):1480–1489. Vashisht,R.,Jung,K.,Schuler,A.,Banda,J.M.,Park,R.W.,Jin,S.,Li,L.,Dudley,J.T., Johnson, K. W., Shervey, M. M., Xu, H., Wu, Y., Natrajan, K., Hripcsak, G., Jin, P., Van Zandt, M., Reckard, A., Reich, C. G., Weaver, J., Schuemie, M. J., Ryan, P. B., Callahan, A., and Shah, N. H. (2018). Association of Hemoglobin A1c Levels With UseofSulfonylureas,DipeptidylPeptidase4Inhibitors,andThiazolidinedionesinPa­ tientsWithType2DiabetesTreatedWithMetformin: AnalysisFromtheObservational HealthDataSciencesandInformaticsInitiative. JAMA Netw Open ,1(4):e181755. vonElm,E.,Altman,D.G.,Egger,M.,Pocock,S.J.,Gøtzsche,P.C.,andVandenbroucke, J.P.(2008). Thestrengtheningthereportingofobservationalstudiesinepidemiology (strobe)statement: guidelinesforreportingobservationalstudies. Journal of Clinical Epidemiology ,61(4):344–349. Voss,E.A.,Boyce,R.D.,Ryan,P.B.,vanderLei,J.,Rijnbeek,P.R.,andSchuemie,M.J. (2016). Accuracy of an Automated Knowledge Base for Identifying Drug Adverse Reactions. J Biomed Inform . Voss,E.A.,Ma,Q.,andRyan,P.B.(2015a). Theimpactofstandardizingthedefinition ofvisitsontheconsistencyofmulti­databaseobservationalhealthresearch. BMC Med Res Methodol ,15:13. Voss, E. A., Makadia, R., Matcho, A., Ma, Q., Knoll, C., Schuemie, M., DeFalco, F. J., Londhe, A., Zhu, V., and Ryan, P. B. (2015b). Feasibility and utility of applications ofthecommondatamodeltomultiple,disparateobservationalhealthdatabases. J Am Med Inform Assoc ,22(3):553–564. Walker, A. M., Patrick, A. R., Lauer, M. S., Hornbrook, M. C., Marin, M. G., Platt, R., Roger,V.L.,Stang,P.,andSchneeweiss,S.(2013). Atoolforassessingthefeasibility ofcomparativeeffectivenessresearch. Comp Eff Res ,3:11–20. Wang, Y., Desai, M., Ryan, P. B., DeFalco, F. J., Schuemie, M. J., Stang, P. E., Berlin, J.A.,andYuan,Z.(2017).Incidenceofdiabeticketoacidosisamongpatientswithtype 2diabetesmellitustreatedwithSGLT2inhibitorsandotherantihyperglycemicagents. Diabetes Res. Clin. Pract. ,128:83–90. Weinstein,R.B.,Ryan,P.,Berlin,J.A.,Matcho,A.,Schuemie,M.,Swerdel,J.,Patel,K., andFife,D.(2017).ChannelingintheUseofNonprescriptionParacetamolandIbupro­\n",
      "page text: Bibliography 447 feninanElectronicMedicalRecordsDatabase: EvidenceandImplications. Drug Saf, 40(12):1279–1292. Weiskopf, N. G. and Weng, C. (2013). Methods and dimensions of electronic health record data quality assessment: enabling reuse for clinical research. Journal of the American Medical Informatics Association: JAMIA ,20(1):144–151. Whelton, P. K., Carey, R. M., Aronow, W. S., Casey, D. E., Collins, K. J., Denni­ son Himmelfarb, C., DePalma, S. M., Gidding, S., Jamerson, K. A., Jones, D. W., MacLaughlin,E.J.,Muntner,P.,Ovbiagele,B.,Smith,S.C.,Spencer,C.C.,Stafford, R.S.,Taler,S.J.,Thomas,R.J.,Williams,K.A.,Williamson,J.D.,andWright,J.T. (2018). 2017 ACC/AHA/AAPA/ABC/ACPM/AGS/APhA/ASH/ASPC/NMA/PCNA GuidelineforthePrevention,Detection,Evaluation,andManagementofHighBlood PressureinAdults: ExecutiveSummary: AReportoftheAmericanCollegeofCardi­ ology/AmericanHeartAssociationTaskForceonClinicalPracticeGuidelines. Circu­ lation,138(17):e426–e483. Whitaker, H. J., Farrington, C. P., Spiessens, B., and Musonda, P. (2006). Tutorial in biostatistics: theself­controlledcaseseriesmethod. Stat Med,25(10):1768–1797. Who,A.(2013). Globalbriefonhypertension. World Health Organization . Wickham,H.(2015). R Packages . O’ReillyMedia,Inc.,1stedition. Wikipedia (2019a). Open science — Wikipedia, the free encyclopedia. http://en. wikipedia.org/w/index.php?title=Open%20science&oldid=900178688 . [Online; ac­ cessed24­June­2019]. Wikipedia(2019b). Science2.0—Wikipedia,thefreeencyclopedia. http://en.wikipedia. org/w/index.php?title=Science%202.0&oldid=887565958 . [Online;accessed09­July­ 2019]. Wikiquote(2019). Ronaldfisher—wikiquote,. [Online;accessed2­August­2019]. Wilkinson, M. D., Dumontier, M., Aalbersberg, I. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J. W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., Gonzalez­Beltran, A., Gray, A. J., Groth, P., Goble, C., Grethe, J. S., Heringa, J., ’t Hoen, P. A., Hooft, R., Kuhn, T., Kok, R., Kok, J., Lusher, S. J., Martone,M.E.,Mons,A.,Packer,A.L.,Persson,B.,Rocca­Serra,P.,Roos,M.,van Schaik, R., Sansone, S. A., Schultes, E., Sengstag, T., Slater, T., Strawn, G., Swertz, M.A.,Thompson,M.,vanderLei,J.,vanMulligen,E.,Velterop,J.,Waagmeester,A., Wittenburg, P., Wolstencroft, K., Zhao, J., and Mons, B. (2016). The FAIR Guiding Principlesforscientificdatamanagementandstewardship. Sci Data,3:160018. Yoon,D.,Ahn,E.K.,Park,M.Y.,Cho,S.Y.,Ryan,P.,Schuemie,M.J.,Shin,D.,Park, H., and Park, R. W. (2016). Conversion and Data Quality Assessment of Electronic HealthRecordDataataKoreanTertiaryTeachingHospitaltoaCommonDataModel forDistributedNetworkResearch. Healthc Inform Res ,22(1):54–58.\n",
      "page text: 448 Bibliography Yuan, Z., DeFalco, F.J., Ryan, P.B., Schuemie, M.J., Stang, P.E., Berlin, J. A., Desai, M.,andRosenthal,N.(2018).Riskoflowerextremityamputationsinpeoplewithtype 2diabetesmellitustreatedwithsodium­glucoseco­transporter­2inhibitorsintheUSA: Aretrospectivecohortstudy. Diabetes Obes Metab ,20(3):582–589. Zaadstra,B.M.,Chorus,A.M.,vanBuuren,S.,Kalsbeek,H.,andvanNoort,J.M.(2008). Selectiveassociationofmultiplesclerosiswithinfectiousmononucleosis. Mult. Scler. , 14(3):307–313. Zaman, M. A., Oparil, S., and Calhoun, D. A. (2002). Drugs targeting the renin­ angiotensin­aldosteronesystem. Nat Rev Drug Discov ,1(8):621–636.\n",
      "page text: Index accuracy,249 ACEinhibitors, 252 ACHILLES, 293 adaboost,246 agnosticSQL, seeSqlRender analysisimplementation, 107 angioedema, 252 APHRODITE, 152 arachne,377 areaundertheprecision­recallcurve, 251 ATHENA, 57 ATLAS,110,255 characterizationfeatures, 186 cohortcharacterization, 111 cohortdefinitions, 111 cohortpathways, 111 conceptsets, 110 configuration, 111 DataSources, 110 documentation, 112 feedback,111 incidencerates, 111 installation, 112 jobs,111 patientlevelprediction, 111 populationlevelestimation, 111 profiles,111 security,112 vocabularysearch, 110 attritiondiagram, 235 AUC,250 back­propagation, 247 balance, seecovariatebalancebaselinetime, 173 bestpracticefornetworkresearch, 378 between­databaseheterogeneity, 342 bigknn,246 BillofMortality, 55 calibration, 252 caliper,205 scale,218 case­controldesign, 206 case­crossoverdesign, 207 case­time­controldesign, 208 CDM, seeCommonDataModel chapters,11,18 characterization, 101,173 cohort,174 databaselevel, 174 treatmentpathways, 174 classes,242 classificationconcept, 62 ClemMcDonald, 289 clinicaldecisionmaking, 239 clinicalequipoise, 205 clinicalvalidity, 307 codeset,148 cohort,148 entryevent, 150 exitcriteria, 150 inclusioncriteria, 150 probabilisticdesign, 152 rule­baseddesign, 149 cohortdefinition, 148 cohortmethod, 202 colliders,205 449\n",
      "page text: 450 Index CommonDataModel, 31 backwardscompatibility, 34 conventions, 34 datalossprevention, 33 datamodeldiagram, 31 dataprotection, 33 designprinciples, 33 domains,33 scalability, 34 SourceCodes, 33 standardizedtables, 39 suitabilityforpurpose, 33 technologyneutrality, 33 commondatamodel, 327 community, 7,11,289 communitycalls, 15 comparativeeffectestimation, 201 comparativeeffectiveness, seecomparative effectestimation comparatorcohort, 202 concept,58 ancestor,69 class,61 code,63 hierarchy,67 identifier,58 mapping,65 relationship, 65 conceptset, 151 conditionedmodel, 219 confidenceintervalcalibration, 341 confounder, 203 controlhypotheses, 114 convolutionalneuralnetwork, 248 counterfactual, 201 covariatebalance, 206 example,234 covariates, 242 Cox proportional hazards model, seeCox regression Coxregression, 203 cross­validation, 245,249 Cyclops,244 dataprofiling, seeWhiteRabbitdataquality, 289,291 checks,293 completeness, 293 conformance, 293 dataqualitycheck, 293 plausibility, 293 study­specificchecks, 296 validation, 293 verification, 293 DataQualityDashboard, 293 DatabaseConnector, 122 creatingaconnection, 131 querying,132 decisionboundary, 243 decisiontree, 247 deeplearning, 248 descriptivestatistics, seecharacterization designconsiderationsfornetworkresearch, 371 diagnosticoutcome, 239 directeffectestimation, 201 discrimination, 250 diseasenaturalhistory, seecharacterization domain concept,59 drugutilization, 174 empiricalcalibration, 340 empiricalevaluation, 339 ETL, seeextract,transformandload(ETL) implementations, 92 qualitycontrol, 93 unittests,295 ETLdesign, seeRabbit­In­A­Hat evaluatingpredictionmodels, 248 evidencequality, 287,289 FAIR,25 falsenegative, 250 falsepositive, 250 featureanalyses, 181 FeatureExtraction, 187 forum,13 gradientboosting, 245\n",
      "page text: Index 451 highcorrelation, 224 hyper­parameter, 245 incidence, 175 proportion, 176 rate,176 indexdate, 173,242,252 instrumentalvariables, 205 jointhejourney, 11 k­nearestneighbors, 246 Kaplan­Meierplot, 236 labels,242 LASSO,244 limitationsofobservationalresearch, 105 logisticregression, 203,244 logisticsofnetworkresearch, 372 machinelearning, 240 methodvalidity, 335 methodslibrary, 112 minimumdetectablerelativerisk(MDRR), 235 missingdata, 106,243 mission,6 modelviewerapp, 272 naivebayes, 246 nativedata, seerawdata negativecontrols, 336 nestingcohort case­controldesign, 207 networkstudy, 370 neuralnetwork, 247 nofreelunch, 244 objectives, 7 OHDSIMethodsBenchmark, 351 OHDSISQL, seeSqlRender openscience, 21 opendata, 24 opendiscourse, 24 opensource, 24 openstandards, 23 orphancodes, 298outcomecohort, 241 case­controldesign, 207 case­crossoverdesign, 207 cohortmethod, 202 SCCSdesign, 208 self­controlledcohortdesign, 206 outcomestatus, 242 p­valuecalibration, 340 Pallassystem, 57 patient­levelprediction, 103,239 perceptron, 247 performancemetrics, 249 person­time, 176 phenotype, 148 phenotypelibrary, 153 PheValuator, 314 Poissonregression, 203 population­levelestimation, 102,201 positivecontrols, 338 synthesis,338 positivepredictivevalue, 249 post­indextime, 173 power,235 predictionmodel, 239 preferencescore, 205 example,232 prognosticoutcome, 239 programmingbestpractices, 328 propensitymodel, 204 example,233 propensityscore, 203 matching,204 stratification, 204 trimming,218 weighting, 204 protocol,358 python,245–247 qualityimprovement, seecharacterization QueryLibrary, 122 QueryLibrary, 137 R,122 installation, 115\n",
      "page text: 452 Index Rabbit­In­A­Hat, 80 randomforest, 245 randomizedtrial, 203 rawdata,75 recurrentneuralnetworks, 248 regularization, 244 regulatorydecision­making, 289 relational data model, seeCommon Data Model reliableevidence, 289 researchnetwork, 369 ROC,250 runningnetworkresearch, 374 safetysurveillance, 201 self­controlled case series (SCCS) design, 208 self­controlledcohortdesign, 206 sensitivity, 249 sensitivityanalysis, 343 sklearn,245 softwaredevelopmentprocess, 327 softwarevalidity, 327 sourcecodemapping, seeUsagi sourcedata, seerawdata sourcerecordverification, 311 specificity, 249 SQL,121 SQLQueryLibrary, seeQueryLibrary SqlRender, 122 debugging, 129 parameterization, 122 supportedfunctions, 124 translation, 124 standardconcept, 61 StandardSQLDialect, seeSqlRender standardizedvocabularies, 55 download, 57 search,57 stratifiedmodel, seeconditionedmodel stronglyignorable, 204 structuredquerylanguage, seeSQL studycodevalidity, 328 studydiagnostics, 335,364 studyfeasibilitysinglestudy, 364 studypackage, 359 study­a­thon, 22 supervisedlearning, 242 survivalplot, seeKaplan­Meierplot systemrequirements, 115 targetcohort, 241 case­controldesign, 207 case­crossoverdesign, 207 cohortmethod, 202 SCCSdesign, 208 self­controlledcohortdesign, 206 time­at­risk, 241 toolsdeployment, 118 AmazonAWS, 119 Broadsea,119 treatmentutilization, seecharacterization TRIPOD,240 truenegative, 250 truepositive, 250 Usagi,85 validation externalvalidation, 248 internalvalidation, 248 spatialvalidation, 249 temporalvalidation, 249 variableratiomatching, 204 variance,245 vignette,114 vision,7 vocabulary, 61 WhiteRabbit, 76 workgroups, 11,15 xgboost,245 xSenscohort, 317 xSpeccohort, 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "i = 1\n",
    "for page in tqdm(reader.pages):\n",
    "    res += extract_pages(page.extract_text(), i)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e27b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Page 1</td>\n",
       "      <td>The Book of OHDSI ObservationalHealthDataScien...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Page 2</td>\n",
       "      <td>ii</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Page 3</td>\n",
       "      <td>Contents Preface ix GoalsofthisBook . . . . . ...</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Page 4</td>\n",
       "      <td>iv Contents II Uniform Data Representation 29 ...</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Page 5</td>\n",
       "      <td>Contents v 8.1 AnalysisImplementation . . . . ...</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                            content  tokens\n",
       "0  Page 1  The Book of OHDSI ObservationalHealthDataScien...      26\n",
       "1  Page 2                                                 ii       5\n",
       "2  Page 3  Contents Preface ix GoalsofthisBook . . . . . ...     807\n",
       "3  Page 4  iv Contents II Uniform Data Representation 29 ...    1136\n",
       "4  Page 5  Contents v 8.1 AnalysisImplementation . . . . ...    1307"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res, columns=[\"title\", \"content\", \"tokens\"])\n",
    "df = df[df.tokens<2046]\n",
    "df = df.reset_index().drop('index',axis=1) # reset index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a717a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c74177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bytes__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__fspath__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '_accessor',\n",
       " '_cached_cparts',\n",
       " '_cparts',\n",
       " '_drv',\n",
       " '_flavour',\n",
       " '_format_parsed_parts',\n",
       " '_from_parsed_parts',\n",
       " '_from_parts',\n",
       " '_hash',\n",
       " '_make_child',\n",
       " '_make_child_relpath',\n",
       " '_parse_args',\n",
       " '_parts',\n",
       " '_pparts',\n",
       " '_root',\n",
       " '_str',\n",
       " 'absolute',\n",
       " 'anchor',\n",
       " 'as_posix',\n",
       " 'as_uri',\n",
       " 'chmod',\n",
       " 'cwd',\n",
       " 'drive',\n",
       " 'exists',\n",
       " 'expanduser',\n",
       " 'glob',\n",
       " 'group',\n",
       " 'hardlink_to',\n",
       " 'home',\n",
       " 'is_absolute',\n",
       " 'is_block_device',\n",
       " 'is_char_device',\n",
       " 'is_dir',\n",
       " 'is_fifo',\n",
       " 'is_file',\n",
       " 'is_mount',\n",
       " 'is_relative_to',\n",
       " 'is_reserved',\n",
       " 'is_socket',\n",
       " 'is_symlink',\n",
       " 'iterdir',\n",
       " 'joinpath',\n",
       " 'lchmod',\n",
       " 'link_to',\n",
       " 'lstat',\n",
       " 'match',\n",
       " 'mkdir',\n",
       " 'name',\n",
       " 'open',\n",
       " 'owner',\n",
       " 'parent',\n",
       " 'parents',\n",
       " 'parts',\n",
       " 'read_bytes',\n",
       " 'read_text',\n",
       " 'readlink',\n",
       " 'relative_to',\n",
       " 'rename',\n",
       " 'replace',\n",
       " 'resolve',\n",
       " 'rglob',\n",
       " 'rmdir',\n",
       " 'root',\n",
       " 'samefile',\n",
       " 'stat',\n",
       " 'stem',\n",
       " 'suffix',\n",
       " 'suffixes',\n",
       " 'symlink_to',\n",
       " 'touch',\n",
       " 'unlink',\n",
       " 'with_name',\n",
       " 'with_stem',\n",
       " 'with_suffix',\n",
       " 'write_bytes',\n",
       " 'write_text']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Path(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5554ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rename in module pathlib:\n",
      "\n",
      "rename(target) method of pathlib.PosixPath instance\n",
      "    Rename this path to the target path.\n",
      "    \n",
      "    The target path may be absolute or relative. Relative paths are\n",
      "    interpreted relative to the current working directory, *not* the\n",
      "    directory of the Path object.\n",
      "    \n",
      "    Returns the new Path instance pointing to the target path.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Path(filename).rename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87e793fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_file = Path(filename).with_suffix('.pages.csv')\n",
    "embeddings_file = Path(filename).with_suffix('.embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfc10b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(pages_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "365ffda2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CSV with exactly these named columns:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# \"title\", \"0\", \"1\", ... up to the length of the embedding vectors.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m doc_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_doc_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mcompute_doc_embeddings\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_doc_embeddings\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     18\u001b[0m         idx: get_doc_embedding(r\u001b[38;5;241m.\u001b[39mcontent) \u001b[38;5;28;01mfor\u001b[39;00m idx, r \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[1;32m     19\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_doc_embeddings\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 18\u001b[0m         idx: \u001b[43mget_doc_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx, r \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[1;32m     19\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m, in \u001b[0;36mget_doc_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_doc_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDOC_EMBEDDINGS_MODEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/BSC/code/environments/nlp/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/BSC/code/environments/nlp/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/BSC/code/environments/nlp/lib/python3.10/site-packages/openai/api_requestor.py:227\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    208\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    217\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    218\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    219\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/BSC/code/environments/nlp/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/BSC/code/environments/nlp/lib/python3.10/site-packages/openai/api_requestor.py:680\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    678\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    681\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "# CSV with exactly these named columns:\n",
    "# \"title\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "\n",
    "doc_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with embeddings_file.open('w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\"] + list(range(4096)))\n",
    "    for i, embedding in list(doc_embeddings.items()):\n",
    "        writer.writerow([\"Page \" + str(i + 1)] + embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
